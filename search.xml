<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>详解python django面向关系数据库的ORM对象映射系统（1）</title>
    <url>/2017/12/23/419/</url>
    <content><![CDATA[<p>django是一套开发成本低、迭代周期快的python web框架，而如mysql等关系数据库则是网站的必备组件，django通过设计一套python对象与数据库表的映射系统ORM，使得开发者不用写一行SQL语句就能实现极其复杂的关系数据库操作，特别是关联多张表的SQL操作。这让开发者的精力可以放在业务的迭代实现中，忽略SQL细节，同时提供了还不错的SQL语句性能。本文主要分析该ORM系统的实现原理及其设计思路，顺带描述python<strong>元类</strong>这个“黑魔法”。接下来，我们首先描述django model的一般用法，再说明ORM系统的结构，以及为何如此设计。 </p>
<span id="more"></span>

<p>关系数据库相对于hbase等面向海量数据的列式存储数据库而言，大多为<strong>行式存储</strong>数据库。所以这里我们主要关注表、行，django的ORM系统中，允许让应用开发者定义一个继承django.db.models.Model（事实上是django.db.models.base.Model）的类对应着表，而该类的实例对应着行的方式操作关系数据库。其中，<strong>类中的静态成员对应着列名称，而实例中的同名成员则对应着一行数据中的列</strong>。例如： class Article(models.Model): title = models.CharField(verbose_name=’标题’, max_length=255) content = HTMLField(verbose_name=’内容’) 这里的Article代表着表，Article.title是列名。若有实例article = Article()，此时article.title则表示一行中的title列的数据。所以，类和实例都会有同名的静态与对象成员title哦。 </p>
<p>ORM框架为每个表对应的类都生成了objects对象（如果你没有显式指定表的Manager的话），而这个objects对象拥有操作表的所有方法，诸如批量查询filter、单次查询get、更新update等。所以当我们执行SQL操作时，比如查询整表，可以如下： articles = Article.objects.all() 当我们查询时，大多会查询到多行数据，比如上面的all方法返回的是整张表的全部行。所以我们需要一个容器，保存着SQL操作返回的全部Article实例，它就是models.QuerySet。QuerySet是一个很强大的类，它与objects对象共用操作表的方法，这些方法支持非常复杂的参数，不只有==、&gt;、&lt;、in、like等操作，还支持含有外键等方式的多表关联查询，这些下一篇文章再细说。 </p>
<p>为了方便快速开发复杂的SQL操作，QuerySet的SQL操作方法返回的还是QuerySet对象，这样就可以<strong>嵌套叠加</strong>着、由多个QuerySet方法组合完成一个SQL操作。例如： Article.objects.filter(title=’xxx’).filter(type=1).distinct() 同时，QuerySet对象还具有“<strong>懒执行</strong>”的效果，只要没有真的使用查询出的行中数据时，查询就不会被django执行。这意味着我们尽可以写下大量的QuerySet方法，其返回的对象可以被多个条件分支反复使用。关于这一部分的实现也将在下一篇说明。 </p>
<p>本文主要讲述ORM的总体框架，以下开始说明其实现方法。 </p>
<p>当我们想通过类、对象这套OO系统映射关系数据库时，用类映射表、类成员映射列、实例映射行、实例成员映射行中的列，这是很自然的做法。作为中间件的实现者，最自然的基于OO的想法是实现一个强大的Model基类，其含有操作表的所有方法，由应用开发者继承基类后，自己定义列以及行中的列变量。然而这却是行不通的，因为： </p>
<ol>
<li>空表没有一行数据，此时Model类没有实例，但却要有表结构，所以用户不能自己定义self下的行中的列成员； </li>
<li>Model类实例只表示一行，而“一行”是没有办法包含所有SQL操作的； </li>
<li>Model类只能表示“表”这个结构，同样没有办法包含所有SQL操作； </li>
<li>只有“多行”这个概念可以适配表中的任意数据，也就是QuerySet容器，所以，由Model基类提供所有表操作方法是行不通的。 </li>
</ol>
<p>因此，由QuerySet实现几乎所有SQL操作方法是可行的，且由于QuerySet对象表示的若干行数据，SQL方法就可以被用户轻易的理解为操作这些行数据，也容易实现，而Django也确实是这么干的。那么，当未执行过查询时，QuerySet对象还不存在，这些表方法如何提供给用户呢？通常，我们可以在Model基类中提供一个方法或者成员，返回一个包含QuerySet中方法的对象（QuerySet表示若干行，所以此时不能直接返回QuerySet），而django选择提供一个成员叫objects，它是models.Manage类的实例，而这个Manager类虽然其定义中没有SQL操作方法，但被Django框架悄悄的通过“元类”的方式，将QuerySet中的所有方法都注入到Manager类中了。以上所述的内容如下图所示： <img src="/2017/12/django-ORM%E7%B1%BB%E5%9B%BE-1.jpg"> </p>
<p>如果查看django源代码会发现上图中的红色类BaseManagerFromQuerySet并不存在，它是由type元类生成的，也就是由它将QuerySet类里的方法注入到Manager类中的，从而让objects对象拥有了操作表的方法。这套系统依赖于python元类才能实现，那么，什么是元类呢？ </p>
<p>类是用于生成对象的，大部分编程语言都需要提前把类定义好才能编写基于“类”生成对象的代码。然而，python是个例外：一切皆对象，包括类也是对象，那么生成“类”这个对象的“类”称呼什么呢？元类！python允许开发者使用元类在运行时更改生成“类”的方式。 </p>
<p>就像object是所有类的基类，而type是所有元类的基类。任何类都是由type生成的，哪怕我们显式定义的类也会由type默认的生成。所以，我们自然也可以由type隐式得生成类，type生成类的方式如下： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cls = <span class="built_in">type</span>(name, base, attrs) </span><br></pre></td></tr></table></figure>
<p>name也就是类名，base是基类，而attrs就是属性，所有的成员和方法都在其中。type返回的则是类。而上图中的BaseManagerFromQuerySet类就是这么生成的，如下所示： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from</span>\<span class="title">_queryset</span>(<span class="params">cls, queryset\_class, <span class="keyword">class</span>\_name=<span class="literal">None</span></span>):</span> </span><br><span class="line"><span class="keyword">if</span> <span class="class"><span class="keyword">class</span>\<span class="title">_name</span> <span class="title">is</span> <span class="title">None</span>:</span> </span><br><span class="line">class\_name = &#x27;%sFrom%s&#x27; % (cls.\_\_name\_\_, queryset\_class.\_\_name\_\_) </span><br><span class="line">class\_dict = &#123; &#x27;\_queryset\_class&#x27;: queryset\_class, &#125; </span><br><span class="line"><span class="class"><span class="keyword">class</span>\<span class="title">_dict</span>.<span class="title">update</span>(<span class="params">cls.\_get\_queryset\_methods(<span class="params">queryset\_class</span>)</span>) </span></span><br><span class="line"><span class="class"><span class="title">return</span> <span class="title">type</span>(<span class="params"><span class="keyword">class</span>\_name, (<span class="params">cls,</span>), <span class="keyword">class</span>\_dict</span>) </span></span><br></pre></td></tr></table></figure>
<p>所以，这里通常queryset_class就是QuerySet类，而cls就是BaseManager类。BaseManager的_get_queryset_methods方法负责把QuerySet中的方法注入到class_dict属性中，进而让BaseManagerFromQuerySet类具备了SQL操作方法。而Manager类就是继承上面构造出的类，如下所示： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Manager</span>(<span class="params">BaseManager.<span class="keyword">from</span>\_queryset(<span class="params">QuerySet</span>)</span>):</span> <span class="keyword">pass</span> </span><br></pre></td></tr></table></figure>
<p>python中的类生成对象时，都是先由__new__方法生成对象，再通过__init__方法初始化对象。由于python并不需要用户管理内存，所以我们定义类时往往只重载__init__方法。元类生成类时也一样，只不过类不需要__init__方法初始化，所以我们通常定义元类时需要重载__new__方法。 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelBase</span>(<span class="params"><span class="built_in">type</span></span>):</span> <span class="string">&quot;&quot;&quot; Metaclass for all models. &quot;&quot;&quot;</span> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> \<span class="title">_</span>\<span class="title">_new</span>\<span class="title">_</span>\<span class="title">_</span>(<span class="params">cls, name, bases, attrs</span>):</span> </span><br><span class="line">    <span class="built_in">super</span>\_new = <span class="built_in">super</span>(ModelBase, cls).\_\_new\_\_ new\_attrs = &#123;...&#125; new\_class = <span class="built_in">super</span>\_new(cls, name, bases, new\_attrs)   ...   manager = Manager() manager.auto\_created = <span class="literal">True</span> cls.add\_to\_class(<span class="string">&#x27;objects&#x27;</span>, manager)   <span class="keyword">return</span> new\_class </span><br></pre></td></tr></table></figure>
<p>上面的ModelBase方法就是生成所有Model类的方法。同时，objects也是在生成类的时候就自动插入的。这里要插一句：python使用meta元类的规则是首先在当前类中查找是否使用元类，如果没有，再依次去父类中查看是否使用元类，若查找到显式指定的元类，则直接使用该元类创建类，若未找到，则使用默认的type元类生成类。所以，虽然用户描述表的Model类并没有使用元类，但仍然隐式得通过基类django.db.models.base.Model类使用了上面的ModelBase元类。而Model使用元类的方法也不太一样： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">six.<span class="keyword">with</span>\_metaclass(<span class="params">ModelBase</span>)</span>):</span> </span><br></pre></td></tr></table></figure>
<p>而通常我们可能是这么使用的： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params"><span class="built_in">object</span>, metaclass=ModelBase</span>):</span> </span><br></pre></td></tr></table></figure>
<p>这是因为，six这个库又基于上面的<strong>查找元类也会从父类找一遍</strong>规则套了一层： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">with</span>\<span class="title">_metaclass</span>(<span class="params">meta, \*bases</span>):</span> <span class="class"><span class="keyword">class</span> <span class="title">metaclass</span>(<span class="params">meta</span>):</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> \<span class="title">_</span>\<span class="title">_new</span>\<span class="title">_</span>\<span class="title">_</span>(<span class="params">cls, name, this\_bases, d</span>):</span> <span class="keyword">return</span> meta(name, bases, d) </span><br><span class="line"><span class="keyword">return</span> <span class="built_in">type</span>.\_\_new\_\_(metaclass, <span class="string">&#x27;temporary\_class&#x27;</span>, (), &#123;&#125;) </span><br></pre></td></tr></table></figure>
<p>Model是继承自动生成的父类temporary_class，而temporary_class，则使用了元类ModelBase生成。而上文的add_to_class实际调用了setattr方法，它可以向一个python object添加一个属性或者方法，如下 ： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setattr</span>(<span class="params">p\_object, name, value</span>) </span></span><br></pre></td></tr></table></figure>
<p>这里name就是目标属性的变量名，value是其值。实际上，类成员中代表的是列，而代表行的Model实例是在Model父类的__init__方法中设置的，如下： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fields\_iter = <span class="built_in">iter</span>(opts.fields) <span class="keyword">for</span> val, field <span class="keyword">in</span> <span class="built_in">zip</span>(args, fields\_iter): <span class="keyword">if</span> val <span class="keyword">is</span> \_DEFERRED: <span class="keyword">continue</span> <span class="built_in">setattr</span>(self, field.attname, val) kwargs.pop(field.name, <span class="literal">None</span>)   </span><br></pre></td></tr></table></figure>
<p>还需要注意的是objects其实是由ManagerDescripter作为descripter包装了Manager对象，如下所示： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ManagerDescriptor</span>(<span class="params"><span class="built_in">object</span></span>):</span> </span><br><span class="line">  <span class="function"><span class="keyword">def</span> \<span class="title">_</span>\<span class="title">_init</span>\<span class="title">_</span>\<span class="title">_</span>(<span class="params">self, manager</span>):</span> </span><br><span class="line">    self.manager = manager   </span><br><span class="line">  <span class="function"><span class="keyword">def</span> \<span class="title">_</span>\<span class="title">_get</span>\<span class="title">_</span>\<span class="title">_</span>(<span class="params">self, instance, cls=<span class="literal">None</span></span>):</span> </span><br><span class="line">    <span class="keyword">if</span> instance <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: </span><br><span class="line">      <span class="keyword">raise</span> AttributeError(<span class="string">&quot;Manager isn&#x27;t accessible via %s instances&quot;</span> % cls.\_\_name\_\_)   </span><br><span class="line">    <span class="keyword">if</span> cls.\_meta.abstract: </span><br><span class="line">      <span class="keyword">raise</span> AttributeError(<span class="string">&quot;Manager isn&#x27;t available; %s is abstract&quot;</span> % ( cls.\_meta.<span class="built_in">object</span>\_name, ))   </span><br><span class="line">    <span class="keyword">return</span> cls.\_meta.managers\_map\[self.manager.name\] </span><br></pre></td></tr></table></figure>
<p>因为__get__方法的instance其实是调用objects的对象，如果通过类调用，例如Article.objects时，则instance参数为None。所以，这个descripter就是起到只允许非abstract类调用的目的。 以上就是ORM整体架构，下一篇我们再详述QuerySet是如何支持复杂查询的。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>model</tag>
        <tag>ORM</tag>
        <tag>元类</tag>
      </tags>
  </entry>
  <entry>
    <title>API的接口变迁</title>
    <url>/2017/05/29/api%E7%9A%84%E6%8E%A5%E5%8F%A3%E5%8F%98%E8%BF%81/</url>
    <content><![CDATA[<p>最近前端团队越发觉得目前API接口有些不好用，所以我也借此重新理一下我们的API接口。</p>
<p>API没有什么完美的设计理念和原则，只有最适合当下的设计。这个最适合包括：当前使用的技术架构、团队规模、团队成员技术特点、开发时间、人力成本、未来业务与技术的预期等。我先来回顾下我们产品的API变迁过程。</p>
<span id="more"></span>
<p>作为从0到1的创业公司，客户、CEO提出的需求是全新没有产品先例可以参考的，故首先要验证产品原型，而最初只有我一个技术人员，因此开发效率是关键。此时，使用后端模板弱化API是速度最快的，讨论出一个页面往往一天就可以把前后端全部开发完成。特别使用django这种既把ORM做得灵活又好用，又把后端模板与表单、ORM的结合做到极致的全能型WEB框架后，一个人就可以维护上百个WEB页面和数据库表。</p>
<p>而接下来，业务驱动要求不光有浏览器还得有微信服务号、微信小程序、iOS和android的APP，这样之前的后端模板方式就有大问题了，往往每种前端都需要独立的后端模板，大量的重复代码将会产生，这对长期维护的产品是不可接受的。而团队成员也在扩张中，前后端人员招聘到位后，专业的前端人员比我这种后端出身的所谓“全栈”开发速度快很多。此时，我们第一位前端阿正建议使用前后端分离技术，用大前端框架与后端解耦合，开发频繁交互体验更好的单页式应用。而在我看来，这样也可以更好的满足多种前端并存时的产品，尤其是APP的开发上，我认定我们的APP不需要原生APP那么复杂的功能，而基于小团队定位、快速迭代开发这个原则，webapp成为我的第一选择，这与大前端是一致的。于是，我决定尝试前后端分离，而API也从此正式登场。</p>
<p>最初的产品交互原型改动频繁，而且团队的后端磊哥先于前端入职一个多月，所以，哪些数据应该划分到一个API呢？因为不能依据还没确定下来的产品原型图，于是很自然的，就以数据这个维度圈定API粒度了。通常是，一张mysql表就是一组API，包括增删改查。这么做的好处很明显，数据库是经过逻辑抽象的，改动数据库的频率要远远小于前端页面，以及API的请求参数和返回参数。而API是最怕重构式修改的，依据数据库的表设计，最初近百个API很快设计实现出来了，也确实可以支撑前端的开发。然而，问题也很明显，高度抽象的ORM使得关系数据库是完全范式设计的，所以DB表特别多！而前端最初不是一个几十人的团队，而是只有一个人！随便一个页面要拉好几个接口，这样就完全无法接受了，产品的开发速度大受影响。</p>
<p>如何解决呢？</p>
<ul>
<li>方法一：前端多拉几次接口，同时把API调用框架做得再强大些；</li>
<li>方法二：后端按照前端的要求，增加API的返回值，通常，这是由页面显示的值驱动后端在一个接口中返回多张表的数据，而后端强大的ORM模型可以轻松办到。<br>然而，由于有两套玩法，就会造成不统一，不同的场景不同的前端开发人员选用不同的方式。最重要的是对API权限的考虑不到位。这为当前的困境埋下了隐患。</li>
</ul>
<p>产品开发的差不多了，姗姗来迟的测试登场，于是权限问题冒出来了。之前，后端系统梳理过API权限的设计。由于我们的系统是平台，对接的是企业以及并不隶属于企业的工人，角色较多，且多企业实际上在协同服务于一个工程，最复杂的是角色间的关系是由实时变动的合同决定。所以API的权限会很复杂，例如：某请求可以被甲企业中的A角色调用，但不能被甲企业中的B角色调用，还不能被协同合作的乙企业中的A角色调用，但可以被乙企业中的C角色调用，且A角色中有M、N两个人，其调用完全相同参数的请求返回内容并不相同。这个现象的产生，是因为我们有多种合同，至少三种合同共同作用于一个工程时，就会产生多种角色下不同用户的权限变化多端。后端用了一种很巧妙的方式，把这种复杂以可读性还不错的配置文件实现，于是，测试提出的权限问题后端可以分分钟实现，但前端就苦逼了！就像上文我说的，有些页面前端发现需要调很多接口时，会要求后端增加返回字段；有些页面则调用了很多接口。而现在，原本体验很好的页面，因为后端在API上增加了权限限制，就会出现有些角色、用户在该页面上，部分接口调用开始权限不足，页面因为接口错误而出现各种问题！且随着测试的深入，权限控制越来越细，于是系统体验进一步变差，测试开始提更多的BUG砸向开发，前端越发对API不满。。。</p>
<p>那么，清楚了整个流程后，我们才可以梳理出脉络。之前留了些什么坑呢？有几个与实时合同关联密切的DB表，这几张表引出的相应API存在考虑产品设计不够的问题。即，不同的角色，会有场景要求对同一张表里的不同列有查询需求，而之前的API因为与DB表一一对应（抽象表时不考虑角色权限问题，因此忽略了列），且就像前文中所说API在增加字段时完全由前端人员驱动而整体考虑不足。所以，系统解决方案应为，对当前的这几个存在问题的API按照角色权限的调用，进一步归类，归类后按照类别增加关联DB表中某些列字段的返回。这个方案的修改成本最小，且DB表的抽象本来也隐含有一些权限控制，只是相对产品交互就要差一些，所以仍然可以保持API在未来不会有大的变迁。</p>
<p>再回过头来看看API的变迁，其实把一个产品从小开始往大了养，每个阶段的侧重点都应该是完全不同的。创业团队一定要勇于试错，在试错中磨合，提升团队和个人的战斗力。就像人月神话中所说，大公司的人海战术是无法跨跃试错阶段的，这也是创业公司的机会所在。而且，技术是服务于业务的，技术人员从这个角度出发，去看待项目管理，去看待产品发展，个人会有非常大的成长。所以从招聘角度，大公司从一开始就伴随公司成长的那批人，才是创业公司最需要的，他们清楚不同阶段应该采用什么策略。反之平台光环下后期加入的未经历过初始阶段的人才，一旦失去了大平台就容易无所适从，因为大平台的玩法只适合大平台，这限制了个人的成长。</p>
<p>我们公司是一家致力于改变中国建筑业的互联网公司，正在快速发展中，因为后发优势使用了诸多成熟的新技术，如docker微服务、大前端、h5 webapp、websocket协议、持续集成、一键部署、基于python的快速开发后台、人脸识别、室内外LBS服务、自动化测试、NOSQL分布式数据库、即将开展的数据挖掘，欢迎有志于创业的技术人加入我们！联系邮箱：<a href="mailto:&#x68;&#114;&#x40;&#x7a;&#x6c;&#100;&#100;&#x61;&#x74;&#x61;&#46;&#x63;&#x6e;">&#x68;&#114;&#x40;&#x7a;&#x6c;&#100;&#100;&#x61;&#x74;&#x61;&#46;&#x63;&#x6e;</a>。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>api</tag>
        <tag>webapp</tag>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title>django中ModelForm多表单组合的解决方案</title>
    <url>/2017/01/25/django%E4%B8%ADmodelform%E5%A4%9A%E8%A1%A8%E5%8D%95%E7%BB%84%E5%90%88%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>django是<a href="http://lib.csdn.net/base/python" title="Python知识库">Python</a>语言快速实现web服务的大杀器，其开发效率可以非常的高！但因为秉承了语言的灵活性，django框架又太灵活，以至于想实现任何功能都有种“条条大路通罗马”的感觉。这么多种选择放在一起，如何分出高下？我想此时的场景下就两个标准： 1、相同的功能用最少的代码实现（代码少BUG也会少）； 2、相对最易于理解，从而易于维护和扩展。 </p>
<span id="more"></span>
<p>书归正传，web服务允许用户输入，基本上要靠表单。而django对表单的支持力度非常大，我们用不着在浏览器端的html文件里写大量<form>代码，再到web端去匹配form里的id/name/value、验证规则，再与持久层<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">数据库</a>比较并做操作。我们需要完成的工作非常少，可以没有相似的重复代码。有些复杂的场景，会要求一个表单的内容存放到多张表里，本文将通过4个部分，阐述它的实现方法。 1、django基础表单的功能 定义一个表单非常简单，继承类django.forms.Form即可，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ProjectForm(forms.Form):  </span><br><span class="line">    name &#x3D; forms.CharField(label&#x3D;&#39;项目名称&#39;, max_length&#x3D;20)  </span><br></pre></td></tr></table></figure>

<p>这个表单类可以生成HTML形式的form，可以从request.POST中解析form到ProjectForm类实例。怎么做到的呢？ 看下django.forms.Form定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Form(six.with_metaclass(DeclarativeFieldsMetaclass, BaseForm)):  </span><br><span class="line">    &quot;A collection of Fields, plus their associated data.&quot;  </span><br><span class="line">    # This is a separate class from BaseForm in order to abstract the way  </span><br><span class="line">    # self.fields is specified. This class (Form) is the one that does the  </span><br><span class="line">    # fancy metaclass stuff purely for the semantic sugar -- it allows one  </span><br><span class="line">    # to define a form using declarative syntax.  </span><br><span class="line">    # BaseForm itself has no way of designating self.fields.  </span><br></pre></td></tr></table></figure>

<p>注释说得很清楚，Form这个类就是为了实现declarative syntax的，也就是说，继承了Form后，我们直观的表达ProjectForm里要有一个Field名叫name，不关心其语法实现，而通过Form多继承中的DeclarativeFieldsMetaclass语法糖，将会把name弄到类实例的self.fields里。</p>
<p>我们重点关注表单的BaseForm类，它实现了基本的逻辑。截选了一小段对接下来的陈述有意义的代码，做一个简单的注释。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class BaseForm(object):  </span><br><span class="line">    def __init__(self, data&#x3D;None, files&#x3D;None, auto_id&#x3D;&#39;id_%s&#39;, prefix&#x3D;None,  </span><br><span class="line">                 initial&#x3D;None, error_class&#x3D;ErrorList, label_suffix&#x3D;None,  </span><br><span class="line">                 empty_permitted&#x3D;False, field_order&#x3D;None, use_required_attribute&#x3D;None):  </span><br><span class="line">        #data参数用于接收request.POST字典，如果是GET方法就不传  </span><br><span class="line">    self.data &#x3D; data or &#123;&#125;  </span><br><span class="line">    #files用于接收request.FILES，也就是处理上传文件  </span><br><span class="line">    self.files &#x3D; files or &#123;&#125;  </span><br><span class="line">    #本篇文章的重点在于多个表单集成到一个form中，此时为防止有同名的field，需要加prefix前缀  </span><br><span class="line">        if prefix is not None:  </span><br><span class="line">            self.prefix &#x3D; prefix  </span><br><span class="line">    #GET显示表单时，如果要显示初始值，请用initial参数  </span><br><span class="line">        self.initial &#x3D; initial or &#123;&#125;  </span><br><span class="line">  </span><br><span class="line">    #模板中显示&#123;&#123;form&#125;&#125;时，默认是以&lt;table&gt;&lt;&#x2F;table&gt;显示的  </span><br><span class="line">    def __str__(self):  </span><br><span class="line">        return self.as_table()  </span><br><span class="line">  </span><br><span class="line">    #如果模板中不想写重复代码，只以固定的格式来显示每一个field，那么就用&#123;% for field, val in form %&#125;来遍历处理吧  </span><br><span class="line">    def __iter__(self):  </span><br><span class="line">        for name in self.fields:  </span><br><span class="line">            yield self[name]  </span><br><span class="line">  </span><br><span class="line">    #如果传入了prefix参数，html中每个field的name和id里都会加上prefix前缀  </span><br><span class="line">    def add_prefix(self, field_name):  </span><br><span class="line">        return &#39;%s-%s&#39; % (self.prefix, field_name) if self.prefix else field_name  </span><br><span class="line">  </span><br><span class="line">    #模板中以html格式显示form就靠这个方法  </span><br><span class="line">    def _html_output(self, normal_row, error_row, row_ender, help_text_html, errors_on_separate_row):  </span><br><span class="line">        &quot;Helper function for outputting HTML. Used by as_table(), as_ul(), as_p().&quot;  </span><br><span class="line">        top_errors &#x3D; self.non_field_errors()  # Errors that should be displayed above all fields.  </span><br><span class="line">        output, hidden_fields &#x3D; [], []  </span><br><span class="line">  </span><br><span class="line">    #除了默认的table方式显示外，还可以&lt;ul&gt;&lt;li&gt;或者&lt;p&gt;方式显示  </span><br><span class="line">    def as_table(self):  </span><br><span class="line">        &quot;Returns this form rendered as HTML &lt;tr&gt;s -- excluding the &lt;table&gt;&lt;&#x2F;table&gt;.&quot;  </span><br><span class="line">    def as_ul(self):  </span><br><span class="line">        &quot;Returns this form rendered as HTML &lt;li&gt;s -- excluding the &lt;ul&gt;&lt;&#x2F;ul&gt;.&quot;  </span><br><span class="line">    def as_p(self):  </span><br><span class="line">        &quot;Returns this form rendered as HTML &lt;p&gt;s.&quot;  </span><br></pre></td></tr></table></figure>

<p>所以，基本表单的功能看BaseForm已经足够了。</p>
<p>2、从模型创建表单 django对于MVC中的C与M间的映射是非常体贴的，集中体现中Model模型中（比如模型的权限与用户认证）。那么，一个模型代表着RDS中的一张表，模型的实例代表着关系数据库中的一行，而form如何与一行相对应呢？ 定义一个模型引申出的表单非常简单，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ProjectForm(ModelForm):  </span><br><span class="line">    class Meta:  </span><br><span class="line">        model &#x3D; Project  </span><br><span class="line">        fields &#x3D; [&#39;approvals&#39;,&#39;manager&#39;,&#39;name&#39;,&#39;fund_rource&#39;,&#39;content&#39;,&#39;range&#39;,]  </span><br></pre></td></tr></table></figure>

<p>在model中告诉django模型是谁，在fields中告诉django需要在表单中创建哪些字段。django会有一个django.db.models.Field到django.forms.Field的转换规则，此时会生成Form。我们看看ModelForm是什么样的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class ModelForm(six.with_metaclass(ModelFormMetaclass, BaseModelForm)):  </span><br><span class="line">    pass  </span><br></pre></td></tr></table></figure>

<p>类似Form类，ModelFormMetaclass就是语法糖，我们重点看BaseModelForm类：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class BaseModelForm(BaseForm):  </span><br><span class="line">    def __init__(self, data&#x3D;None, files&#x3D;None, auto_id&#x3D;&#39;id_%s&#39;, prefix&#x3D;None,  </span><br><span class="line">                 initial&#x3D;None, error_class&#x3D;ErrorList, label_suffix&#x3D;None,  </span><br><span class="line">                 empty_permitted&#x3D;False, instance&#x3D;None, use_required_attribute&#x3D;None):  </span><br><span class="line">        opts &#x3D; self._meta  </span><br><span class="line">    #相比较BaseForm，多了instance参数，它等价于Model模型的一个实例  </span><br><span class="line">        if instance is None:  </span><br><span class="line">            #不传instance参数，则会新构造model对象  </span><br><span class="line">            self.instance &#x3D; opts.model()  </span><br><span class="line">            object_data &#x3D; &#123;&#125;  </span><br><span class="line">        else:  </span><br><span class="line">            self.instance &#x3D; instance  </span><br><span class="line">            object_data &#x3D; model_to_dict(instance, opts.fields, opts.exclude)  </span><br><span class="line">    #此时传递了initial也一样可以生效，同时还会设置到Model中  </span><br><span class="line">        if initial is not None:  </span><br><span class="line">            object_data.update(initial)  </span><br><span class="line">  </span><br><span class="line">    def save(self, commit&#x3D;True):  </span><br><span class="line">    #默认commit是True，此时就会保存Model实例到数据库  </span><br><span class="line">        if commit:  </span><br><span class="line">            self.instance.save()  </span><br><span class="line">    #同时保存many-to-many字段对应的关系表  </span><br><span class="line">            self._save_m2m()  </span><br><span class="line">        else:  </span><br><span class="line">    #注意，本篇文章主要用到commit&#x3D;False这个参数，它会返回Model实例，允许我们在修改instance后，在instance上再调用save方法  </span><br><span class="line">            self.save_m2m &#x3D; self._save_m2m  </span><br><span class="line">        return self.instance  </span><br></pre></td></tr></table></figure>

<p>所以，对于ModelForm我们可以传入instance参数初始化表单，可以调用save()方法直接将从html里得到的表单数据持久化到数据库中。而我们只需要几十行代码就可以完成这么多工作。 3、通用视图 django.views.generic.ListView和django.views.generic.edit下的CreateView, UpdateView, DeleteView都是通用视图。即，我们又可以通过它们，把很多重复的工作交给django完成，又可以少写很多代码完成同样的功能了。这里仅以CreateView为例说明，因为它相对最复杂，接下来的多ModelForm的提交也是在CreateView上进行的。 </p>
<p>通用视图使用时，只需要承继后，再设置model或者form_class即可。比如CreateView就会由django自动的把页面上POST出的form数据解析到model生成的表单（或者form_calss指定的ModelForm类型表单），同时调用表单的save方法将数据添加到模型对应的数据库表中。当然GET请求时会生成空form到页面上。可以看到，除去定义model或者form类外，几行代码就可以搞定这么多事。我们看看CreateView的继承关系:  简单介绍下CreateView通用视图中每个父类的作用。</p>
<ol>
<li> View是所有视图类的父类，根据方法名分发请求到具体的get或者post等方法，提供as_view方法。</li>
<li> TemplateResponseMixin提供render_to_response方法将响应通过context上下文在模板上渲染。</li>
<li> ContextMixin在context上下文中加入’view’元素，值为self实例。</li>
<li> ProcessFormView在GET请求上渲染表单，在POST请求上解析form到表单实例。注意，它会在post请求中判断表单是否可用，is_valid为真时，会调用form_valid方法，因此，重写form_valid方法是第4部分处理多model到一个form的关键。</li>
<li> FormMixin允许处理表单，可指定form_class为某个表单。</li>
<li> SingleObjectMixin生成context上下文，同时根据model模型名称生成object并添加到上下文中的’object’元素。</li>
<li> ModelFormMixin提供在请求中处理modelform的方式。</li>
<li> SingleObjectTemplateResponseMixin帮助TemplateResponseMixin提供模板。</li>
</ol>
<p>所以，在用CreateView、一个模型、一个模板实现添加一行记录的功能时是多么简单，因为这些父类会自动生成object，渲染到模板，解析form表单，save到数据库中。所以，从模型创建出的表单ModelForm，配合上通用视图后，威力巨大！！ 4、多个ModelForm在一个form里提交 终于可以回到本文的主题了。CreateView默认是处理一个Model模型、一个ModelForm表单的，然而，很多时候为了解耦，会把一张表拆成多张表，通过id关联在一起。在django的模型中就体现为ForeignKey、ManyToManyField或者OneToOneField。而在业务逻辑上，需要体现为一张表单，对应着数据库里的多张表。 </p>
<p>例如，我们希望录入合同，其中合同Model中还有地址Model和项目Model，而项目Model中又有地址Model，等等。 当然，我们有很多种实现的方案，但是，前面三部分说了那么多，不是浪费口水的。我们已经有了通用视图+ModelForm这样的利器，难道还需要手动去写Form表单？我们已经习惯了在Model里定义好类型和有点注释作用还能当label的verbose_name，还需要在forms.Form里再来一遍？还需要在视图中写这么通用的逻辑代码吗？当然不用。 inlineformset_factory是一种方案，但它限制太多，而且有些晦涩，我个人感觉是不太好用的。 那么，从第1部分我介绍的Form里的prefix，以及第3部分里类图中的ProcessFormView允许重定义form_valid，以及第2部分中ModelForm的save方法的行为控制，解决方案已经一目了然了。 </p>
<p>拿上面提到的例子来说，我们创建合同时，指明了项目，包括项目地址和合同签订地址，这涉及到三张表和四条记录（地址表有两条）。 我们三张表的模型如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class PrimeContract(models.Model):  </span><br><span class="line">    address &#x3D; models.ForeignKey(Address, related_name&#x3D;&quot;prime_contract_address&quot;, verbose_name&#x3D;&quot;address&quot;)  </span><br><span class="line">    project &#x3D; models.ForeignKey(Project, related_name&#x3D;&quot;prime_contract&quot;, verbose_name&#x3D;&quot;project&quot;)  </span><br><span class="line">class Project(models.Model):  </span><br><span class="line">    address &#x3D; models.ForeignKey(Address, related_name&#x3D;&quot;project_address&quot;, verbose_name&#x3D;&quot;project address&quot;)  </span><br><span class="line">class Address(models.Model):  </span><br><span class="line">    pass  </span><br></pre></td></tr></table></figure>

<p>接着，定义ModelForm表单，这非常简单：</p>
<p> </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class AddressForm(ModelForm):  </span><br><span class="line">    class Meta:  </span><br><span class="line">        model &#x3D; Address  </span><br><span class="line">        fields &#x3D; ...  </span><br><span class="line">class ProjectForm(ModelForm):  </span><br><span class="line">    class Meta:  </span><br><span class="line">        model &#x3D; Project  </span><br><span class="line">        fields &#x3D; ...  </span><br><span class="line">class PrimeContractForm(ModelForm):  </span><br><span class="line">    class Meta:  </span><br><span class="line">        model &#x3D; PrimeContract  </span><br><span class="line">        fields &#x3D; ...  </span><br></pre></td></tr></table></figure>

<p>再写视图，这里要重写2个方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class PrimeContractAdd(CreateView):  </span><br><span class="line">    success_url &#x3D; ...  </span><br><span class="line">    template_name &#x3D; ...  </span><br><span class="line">    form_class &#x3D; PrimeContractForm  </span><br><span class="line">    def get_context_data(self, **kwargs):  </span><br><span class="line">        context &#x3D; super(PrimeContractAdd, self).get_context_data(**kwargs)  </span><br><span class="line">        #SingleObjectMixin父类只会处理PrimeContractForm表单，另外三条数据库记录对应的表单我们要自己处理了，此时prefix派上用场了，因为Field重名是百分百的事  </span><br><span class="line">        if self.request.method &#x3D;&#x3D; &#39;POST&#39;:  </span><br><span class="line">            contractAddressForm &#x3D; AddressForm(self.request.POST, prefix&#x3D;&#39;contractAddressForm&#39;)  </span><br><span class="line">            projectAddressForm &#x3D; AddressForm(self.request.POST, prefix&#x3D;&#39;projectAddressForm&#39;)  </span><br><span class="line">            projectForm &#x3D; ProjectForm(self.request.POST, prefix&#x3D;&#39;projectForm&#39;)  </span><br><span class="line">        else:  </span><br><span class="line">            contractAddressForm &#x3D; AddressForm(prefix&#x3D;&#39;contractAddressForm&#39;)  </span><br><span class="line">            projectAddressForm &#x3D; AddressForm(prefix&#x3D;&#39;projectAddressForm&#39;)  </span><br><span class="line">            projectForm &#x3D; ProjectForm(prefix&#x3D;&#39;projectForm&#39;)  </span><br><span class="line">        #注意要把自己处理的表单放到context上下文中，供模板文件使用  </span><br><span class="line">        context[&#39;contractAddressForm&#39;] &#x3D; contractAddressForm  </span><br><span class="line">        context[&#39;projectAddressForm&#39;] &#x3D; projectAddressForm  </span><br><span class="line">        context[&#39;projectForm&#39;] &#x3D; projectForm  </span><br><span class="line">        return context  </span><br><span class="line">      </span><br><span class="line">    #重写form_valid，父类ProcessFormView会在PrimeContractForm表单is_valid方法返回True时调用该方法  </span><br><span class="line">    def form_valid(self, form):  </span><br><span class="line">        #首先我们要获取到PrimeContractForm表单对应的模型，此时是不能save的，因为外键project和address对应的数据库记录还没有创建，所以commit传为False  </span><br><span class="line">        contract &#x3D; form.save(commit&#x3D;False)  </span><br><span class="line">        #获取上面get_context_data方法中在POST里得到的表单  </span><br><span class="line">        context &#x3D; self.get_context_data()  </span><br><span class="line">        #按照四条数据库记录的顺序依次的创建（调用save方法）、主键赋到下一条记录的外键中、下一次记录创建（save）  </span><br><span class="line">        projectAddress &#x3D; context[&#39;projectAddressForm&#39;].save()  </span><br><span class="line">        #从项目表单中获取到模型，先把地址的id赋到外键上再保存  </span><br><span class="line">        project &#x3D; context[&#39;projectForm&#39;].save(commit&#x3D;False)  </span><br><span class="line">        project.address &#x3D; projectAddress  </span><br><span class="line">        project.save()  </span><br><span class="line">        contractAddress &#x3D; context[&#39;contractAddressForm&#39;].save()  </span><br><span class="line">        #将合同模型中的address和project都设置好后再保存  </span><br><span class="line">        contract.address &#x3D; contractAddress  </span><br><span class="line">        contract.project &#x3D; project  </span><br><span class="line">        contract.save()  </span><br><span class="line">          </span><br><span class="line">        return super(PrimeContractAdd, self).form_valid(form)  </span><br></pre></td></tr></table></figure>

<p>最后写模板：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#这三个表单我们手动处理过的  </span><br><span class="line">&#123;&#123; contractAddressForm &#125;&#125;  </span><br><span class="line">&#123;&#123; projectAddressForm &#125;&#125;  </span><br><span class="line">&#123;&#123; projectForm &#125;&#125;  </span><br><span class="line">#这是FormMixin父类帮我们生成的  </span><br><span class="line">&#123;&#123; form &#125;&#125;  </span><br></pre></td></tr></table></figure>

<p>至此，我们可以只用几十行代码就完成复杂的功能，代码逻辑也清晰可控。</p>
<p>从这篇文章里也可以看得出，django实在是快速开发网站的必备神器！当然，快速不代表不能够支撑大并发的应用，instagram这个很火的服务就是用django写的。由于python和django过于灵活，都将要求django的开发者们唯有更资深才能写出生产环境下的服务。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>form</tag>
      </tags>
  </entry>
  <entry>
    <title>git仓库代码统计</title>
    <url>/2018/04/17/git%E4%BB%93%E5%BA%93%E4%BB%A3%E7%A0%81%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[<p>虽然以代码行数来衡量项目或者程序员并不是一件靠谱的事，但是从统计角度看趋势对于技术管理人员还是很有帮助的！推荐一个比较好用的git仓库代码统计工具：git_stats，它用于按git提交人、提交次数、修改文件数、代码行数、注释量在时间维度上进行统计，亦可按各文件类型进行简单的统计，非常方便。实际上，这么多功能通常都是用WEB在多个页面上显示的，git_stats也是如此，它需要你先安装好ruby以生成基础的页面，再用gem安装好git_stats，最后用git_stats一条语句即可生成展示页面。这些静态页面如需共享，那么搭个nginx显示静态页面即可。</p>
<span id="more"></span>
<p>废话不多说，演示下步骤： 1、首先到ruby官网（<a href="http://www.ruby-lang.org/en/downloads/">http://www.ruby-lang.org/en/downloads/</a>）上下载最新源码包，例如2.5.1版本，解决后，执行linux下以源码安装习惯用的三招：configure/make/make install。 2、接下来使用gem安装git_stats命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gem install git_stats</span><br></pre></td></tr></table></figure>

<p>3、最后进入你要统计的git代码仓库根目录下，执行命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git_stats generate -o stats --language zh_tw</span><br></pre></td></tr></table></figure>

<p>这里，-o是指定了html页面的输出目录，而输出目录里共包含了以下页面：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">├── activity</span><br><span class="line">│   ├── by_date.html  #按日期统计活跃度</span><br><span class="line">│   ├── day_of_week.html</span><br><span class="line">│   ├── hour_of_day.html</span><br><span class="line">│   ├── hour_of_week.html</span><br><span class="line">│   ├── month_of_year.html</span><br><span class="line">│   ├── year.html</span><br><span class="line">│   └── year_month.html</span><br><span class="line">├── assets  #库文件</span><br><span class="line">├── authors  #作者数量，并可按作者进行活跃度统计</span><br><span class="line">│   ├── administrator   #每一个作者一个目录</span><br><span class="line">│   │   ├── activity</span><br><span class="line">│   │   │   ├── by_date.html</span><br><span class="line">│   │   │   ├── day_of_week.html</span><br><span class="line">│   │   │   ├── hour_of_day.html</span><br><span class="line">│   │   │   ├── hour_of_week.html</span><br><span class="line">│   │   │   ├── month_of_year.html</span><br><span class="line">│   │   │   ├── year.html</span><br><span class="line">│   │   │   └── year_month.html</span><br><span class="line">│   │   └── author_details</span><br><span class="line">│   │       ├── changed_lines_by_date.html</span><br><span class="line">│   │       ├── commits_by_date.html  </span><br><span class="line">│   │       ├── deletions_by_date.html</span><br><span class="line">│   │       └── insertions_by_date.html</span><br><span class="line">│   ├── best_authors.html</span><br><span class="line">│   ├── changed_lines_by_author_by_date.html</span><br><span class="line">│   ├── commits_sum_by_author_by_date.html</span><br><span class="line">│   ├── deletions_by_author_by_date.html</span><br><span class="line">│   └── insertions_by_author_by_date.html</span><br><span class="line">├── comments  #注释统计</span><br><span class="line">│   └── by_date.html</span><br><span class="line">├── files    #文件统计</span><br><span class="line">│   ├── by_date.html</span><br><span class="line">│   └── by_extension.html</span><br><span class="line">├── general.html</span><br><span class="line">├── index.html</span><br><span class="line">└── lines   #代码行统计</span><br><span class="line">    ├── by_date.html</span><br><span class="line">    └── by_extension.html</span><br></pre></td></tr></table></figure>

<p>4、搭建nginx用以展示页面。实际上仅需要在配置好的location内加个alias指向上一步中-o选项生成的目录即可。 可见，该工具生成的页面有助于我们统计代码库中总体的代码提交趋势，以及每个coder的代码提交趋势，对于技术管理是有意义的。以下是我截取的最好用的两个页面，首先是按日期统计活跃度： <img src="/2018/04/gitstats%E6%8C%89%E6%97%A5%E6%9C%9F%E6%B4%BB%E8%B7%83%E5%BA%A6%E7%BB%9F%E8%AE%A1-2.jpg"><br>按日期统计代码行数也很好用，虽然代码行数并不能反映出个人的贡献量，但是一些明显不靠谱的事还是能够从这里发现的。 <img src="/2018/04/gitstats%E6%8C%89%E6%97%A5%E6%9C%9F%E7%BB%9F%E8%AE%A1%E4%BB%A3%E7%A0%81%E8%A1%8C%E6%95%B0-2.jpg"></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>git_stats</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title>BDTC2017北京大数据技术大会参会心得</title>
    <url>/2017/12/13/bdtc2017%E5%8C%97%E4%BA%AC%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%A4%A7%E4%BC%9A%E5%8F%82%E4%BC%9A%E5%BF%83%E5%BE%97/</url>
    <content><![CDATA[<p>12月7、8、9号三天在北京参加了BDTC大会，主题是人工智能与大数据，除了第一天的全员大会外，我参加了第二天上午的大数据云服务、下午的知识图谱、第三天的机器学习论坛。在此做一个回顾，也希望能为未参加大会的朋友们分享从我个人角度思考的心得。 禇晓文教授的《基于GPU的性能建模与分布式深度学习框架评价》是在GPU训练性能上讨论了benchmark分析方法。从CPU到GPU后，训练时间降低了一些，但能降得更多些吗？换成多块GPU显卡，可以再下降吗？应当采购什么样的显卡，性价比最好？这场分享回答了以上问题。</p>
<span id="more"></span>
<p>先来看一张图： <img src="/2017/12/gpu%E5%86%85%E5%AD%98%E5%B8%A6%E5%AE%BD%E6%98%AF%E7%93%B6%E9%A2%88-1.jpg"> 可见，显卡的计算单元ALU速度很快，从518到了15000 GFLOPS，翻了快30倍，然而显存带宽只翻了15倍，所以，显存带宽开始制约我们的训练效率。而且，一次矩阵计算至少需要两次读和一次写，对显存的操作本就更多。拿常用的gtx1080显卡来说，8.8TFLOPS和320GB/s的带宽吞吐能力，可见它们差不多有20多倍的速度差距。 所以我们通常采用多线程并行、编程控制共享显存、使用更快的显存等方法读写数据来减少速度差的影响，以使得GPU计算能力满载。 </p>
<p>我们如何设计网络模型，以使得GPU可以满载呢？这里要引入一个指标OI（operational insensity），它表示计算量除以带宽FLOPS/BYTES。例如： 求两个向量的点积，每个向量含n个float变量，那么计算量是2n，读写字节数是2*n*4，故OI是1/4。 求矩阵与向量相乘，那么计算量是2n*n，字节数是(n*n+2*n)*4，故OI是1/2。 求两个n*n矩阵相乘，那么计算量是2*n*n*n，而字节数是(n*n*3)*4，故OI可能达到n/6。 </p>
<p>而拿上面的GTX1080显卡举例，其OI达到8TFLOPS/320GB/s约等于28，所以至少需要OI达到28的运算才能把GPU跑满。 例如拿intel的E5345 cpu举例，其浮点运算能力是75GFLOPS，而内存带宽是10GB/s，那么其OI大概在7.5可以把CPU跑满，只有模型的OI超过7.5时，计算能力才会成为瓶颈，如下图所示： <img src="/2017/12/intel5345%E7%9A%84OI%E6%98%AF7.5-1.jpg"> </p>
<p>具体的模型不像上面提到的矩阵乘法那么简单，特别是现代网络的深度是很大的，下图是常见经典网络各层的计算消耗比例： <img src="/2017/12/unnamed-file-2.jpg"> 可见，卷积层是计算量最大的。而影响计算量的主要因素是卷积kernel size，所以一般kernel size都在3、5等较小的数字（都是奇数）。 </p>
<p>舒继教授的《<strong>大数据时代存储系统若干变化的思考</strong>》是一场关于深度学习训练过程的优化方法分享，关注点在前沿的工程领域，非常的酣畅淋漓！AI和大数据使得传统计算机课程都不再适用，我们心中的操作系统是这样的：CPU计算最快，它的寄存器是存储介质里在速度上最快的，其次是L1、L2等缓存，再次是内存，以上都是易丢失的存储介质，而能够落地的磁盘系统最慢（主要是机械硬盘）。所以操作系统、编译器做了大量优化，例如做IO处理时操作系统会有电梯优化算法，以加长一些IO的时延为代价，汇聚更多的IO批量读写以提高吞吐量。而现今来看，机械硬盘虽然单元存储价格最低，但<strong>时延高、吞吐量小、能耗高、可靠性低、随机读写性能差、发热量大</strong>，这必将被flash存储介质替换，如下图所示： <img src="/2017/12/unnamed-file-1-1.jpg"> </p>
<p>所以flash磁盘的大规模使用将对整个操作系统架构产生影响，例如原先的文件系统常假设外存为机械硬盘，所以有逻辑与物理地址映射管理、各种磁盘驱动程序、SATA接口等等。且各种非易失性内存技术的指标逐渐接近现在使用的DRAM内存，这会完全改变现有的系统架构。而从计算上讲，GPU由于专注于数值运算，其并行计算能力很高，从而大量的计算任务就跳过了CPU缓存、CPU寄存器，直接从GPU共享内存、缓存进入GPU计算单元中。因而，硬件的变化领先于低层软件系统，这意味着今后的底层系统会有较大的改变。 </p>
<p>徐宗本院士的《<strong>模型驱动的深度学习</strong>》让我心有戚戚：学术界工作者和小公司的从业者们如何<strong>破除深度学习必然需要大数据作为训练基础</strong>的魔咒呢？大数据只有大公司才有，如此一来，最有活力的创业公司岂不是不要再玩什么深度学习、AI之类的东东了？破局点有两个：</p>
<ul>
<li>第一，如果生产环境上并没有足够多的数据，除了下载些国外的开源标注数据外（国内标注数据真的很少），就像Alpha GO zero一样，没有大数据时大可以依据规则生成大数据，用生成的非真实大数据来训练模型，以解决冷启动时没有大数据的困境；</li>
<li>第二，如果把整个网络当成黑盒，每 一层都不知道其意义所在，那么自然只能靠堆砌大量的数据来拟合泛化。例如激活函数常见的relu等他们的表达能力都很差（为了减少计算量），所以需要大量的训练数据有效拟合，如果在优化网络时提高激活函数的表达能力，有目的的更换激活函数，则网络就有可能把规模降下来，从而不需要那么大量的训练样本。</li>
</ul>
<p>当然，百度也给了一个方案，就是百度数据众包平台（百度两场分享都在介绍这个平台）。目前的深度学习基本都是监督学习，而监督学习需要的数据都是标注数据。百度有很强的整理清洗数据的基因，例如百度百科，基于人力进行数据标注。如此一来，百度就可以通过标注图片、语音、行业数据等来提供训练样本，提供了AI中的基础训练数据。可以感觉得到，百度相比其他巨头对AI行业布局的决心，可见“All in AI“不是说说而已！   </p>
<p>长沙超算中心的彭绍亮带来的医疗AI实践的分享给我耳目一新的感觉。一直以来，我以为医疗AI只有IBM的watson，而国内只是还在信息化而已，还在采集脉搏血压心跳数据、连接患者、药厂、医生之中，如果算法能够开处方看病进入一线医疗，好像还非常遥远。而这场分享中，彭为我们描述了目前的实践已经到了可以开处方的地步，虽然只是辅助。而且由于国内信息保护很差，人口基数又大，因此中国比美国在医疗、人脸识别上有先天优势。所以，目前AI最热的三个领域有智能医疗就不足为奇了。 </p>
<p>赛迪对《人工智能产业趋势和投融资分析》的分享帮助我们看到，现在北京还是AI投资最热的第一梯队，其领先于第二梯队上海、深圳、杭州之合。同时，中美的差距一如既往，但由于对信息隐私保护上中国还很差，以及中国巨大的网民基数，使得在红绿灯、人脸识别领域已经领先于美国了。非常看好中国AI产业的发展。 </p>
<p>最后一定要吐槽，中国的大会一如既往的具有一个非常讨厌的特点：只要某一场演讲嘉宾是代表大企业的分享，那么几乎就变成广告宣讲会了，特别是产品总监或者非一线研发经理演讲时更是如此，全场都是在分享他们的产品特点。如果恰好你正在用这个产品时还稍好些（这概率真的极小），否则很浪费时间。仅有少数一线程序员会详细的说明如何实现、有哪些难点，遇到这种分享真是听众们的幸运了。当然，如果是学术界的讲师，那绝对都是业界良心，真的在分享知识和思路，可以开拓我们的视野，真心希望以后的大会组织者们注意下宣讲嘉宾的主题，不<strong>要把纯粹卖自家产品、夸自家企业的嘉宾放到这种技术大会的某场专题演讲中</strong>，哪怕提高些票价。</p>
]]></content>
      <categories>
        <category>人工智能</category>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>专访阿里陶辉：大规模分布式系统、高性能服务器设计经验分享</title>
    <url>/2017/01/25/%E4%B8%93%E8%AE%BF%E9%98%BF%E9%87%8C%E9%99%B6%E8%BE%89%EF%BC%9A%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E3%80%81%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<p><a href="http://www.csdn.net/article/2014-06-27/2820432">http://www.csdn.net/article/2014-06-27/2820432</a></p>
<p><strong>摘要：</strong>先后就职于在国内知名的互联网公司，目前在阿里云弹性计算部门做架构设计与核心模块代码的编写，主要负责云服务器管理系统和存储系统的优化。陶辉就大规模分布式系统、高性能服务器设计分享了自己的看法。</p>
<span id="more"></span>

<p>关注陶辉很长时间，初次对陶辉的了解还是在我们CSDN的博客上，从2007年开始写博客，一直到现在，如果不是对技术的追求和热爱，以及热爱分享的精神，我想不是很多人能坚持下来，拥有多年大型互联网公司的从业经验，对<a href="http://lib.csdn.net/base/linux" title="Linux知识库">Linux</a>下的高性能服务器开发、大规模分布式系统的设计有着丰富经验，对企业的Nginx\开发Nginx模块也有着独到的理解。 Nginx是一个高性能的 HTTP 和反向代理服务器， Nginx 是由俄罗斯人 Igor Sysoev 为 Rambler.ru 开发的，其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。在谈到Nginx未来会取代Apache时，陶辉表示云与端的时代，端越来越多，云的性能就会越来越重要，服务器资源的效率在企业成本上将占据越发重要的地位，从这个角度来说，Apache的市场份额被Nginx取代的趋势是不会变的。这次，笔者有幸联系到陶辉，他就大型软件的开发，云计算等分享了自己的经验心得。<br><strong><a href="http://cms.csdnimg.cn/article/201406/30/53b0ba8207723.jpg"></a>陶辉</strong><br><strong>毕业于西安交通大学计算机科学与技术专业，先后工作于华为、腾讯、思科、阿里巴巴等公司。</strong><br><strong>对linux下的高性能服务器开发、大规模分布式系统的设计有着丰富经验。著有《深入理解Nginx：模块开发与<a href="http://lib.csdn.net/base/architecture" title="大型网站架构知识库">架构</a>解析》一书。</strong> </p>
<h1 id="目前从事的工作"><a href="#目前从事的工作" class="headerlink" title="目前从事的工作"></a>目前从事的工作</h1><p><strong>CSDN：给大家介绍一下您及目前从事的工作？</strong><br><strong>陶辉：</strong>我目前在阿里云 弹性计算部门做架构设计与核心模块代码的编写，主要负责云服务器管理系统和存储系统的优化。大家在阿里云上购买的ECS服务器就是弹性计算部门的产品。 </p>
<h1 id="写Nginx书籍的缘由"><a href="#写Nginx书籍的缘由" class="headerlink" title="写Nginx书籍的缘由"></a>写Nginx书籍的缘由</h1><p><strong>CSDN：是什么缘由促使您写了一本关于Nginx的书籍？</strong><br><strong>陶辉：</strong>大约2010年在思科工作时需要开发一个云文档系统，当时选用了Nginx作为web容器开发一个有较高性能诉求的文件上传下载服务。 </p>
<p>可是发现很难从网上找到系统的资料可以指导Nginx模块的开发，对于Nginx的设计思路也是一头雾水，只好看它的源代码来倒推作者的初衷与模块设计思路。那个过程对于已有多年服务器开发经验的我来说也是痛苦的，于是就开始陆续写了一些Nginx模块开发的文章分享到CSDN上，希望能够帮助其他开发者快速解决问题。这时机械工业出版社的编辑lisa看到这些文章找到了我，希望我能写一本系统的、从开发者角度介绍Nginx的书。这本书诞生的缘由就在这里。 </p>
<h1 id="开发Nginx模块的注意事项"><a href="#开发Nginx模块的注意事项" class="headerlink" title="开发Nginx模块的注意事项"></a>开发Nginx模块的注意事项</h1><p><strong>CSDN：目前国内知名的互联网公司很多都在使用Nginx，您觉得企业在使用Nginx\开发Nginx模块的过程中需要注意什么？</strong><br><strong>陶辉：</strong>仅当需要并发处理万级别或以上的TCP连接时，才应当考虑Nginx。<br>当官方Nginx无法满足项目需求，在开发你的个性化模块之前，先看一看大量的Nginx第三方模块里，有没有能够解决问题的Nginx模块，不要重复开发轮子，尤其Nginx轮子的开发难度还不低。Nginx.conf里可以玩的花样很多（这由每一个Nginx模块决定，如ngx_lua这样的模块还可以在里面插入lua语法），或许一段几十行的配置就能完成复杂的功能。 </p>
<p>如果确实没有满足需求的模块，那么，再看看能不能通过类似subrequest这样的机制将问题分解为多个子问题，其中多数子问题可以由现成的模块完成，或者通过proxy机制来与其他现成的组件通过tcp协议交互完成。组合这些子问题来构成解是个好习惯。 </p>
<p>若真有必要编写Nginx模块，先要确保它只是解决一个非常纯粹、简单的子问题，不要耦合太多的需求。Nginx进程里是拒绝任何阻塞操作的，这是因为模块都运行在IO核心处理线程中的。任何一个边缘化的模块都可能因为自己小小的阻塞调用毁掉Nginx的高性能。所以，慎重的考虑模块中的每一个调用，确认它们不会导致进程进入sleep状态，确认它们不会在那里空转占用系统资源。好好使用Nginx定时器事件、共享内存，往往能解掉上述问题。 </p>
<p>写模块时，使用好Nginx的变量机制，让自己的模块插上http框架的翅膀，根据框架解析出的变量来做灵活的处理。甚至，提供一些新的变量作为底层模块而给上层模块使用。<br>使用好nginx.conf，通过灵活的配置来提供丰富的功能。 </p>
<p>debug级别的error.log日志非常详尽，仅有它就可以定位出很多你的模块bug，别忘了使用它必须在编译时加入–with-debug。<br>最后，如果模块可能对其他人有帮助，那么，分享它吧。 </p>
<h1 id="对正在学习Nginx同学的建议"><a href="#对正在学习Nginx同学的建议" class="headerlink" title="对正在学习Nginx同学的建议"></a>对正在学习Nginx同学的建议</h1><p><strong>CSDN：对于正在学习Nginx的同学有什么建议？对开源软件的学习有没有什么分享的？</strong><br><strong>陶辉：</strong>其实《深入理解Nginx》这本书的目录，就是我推荐的学习路径。 </p>
<p>首先，从最外面看Nginx是什么样的，了解进程模型、配置文件语法、基本功能等。 其次，从尝试编写最简单的http模块入手，渐渐地使用到Nginx Http框架的一些高级特性，了解Nginx的内存池、各<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">数据结构</a>的用法等； 再次，系统的了解Nginx框架，包括它如何启动、如何停止、如何升级、如何重载配置，多进程间如何负载均衡，http连接的建立、URL与包头的收取、解析、选用哪些http模块处理请求、如何向客户端回响应等。 </p>
<p>这样学习Nginx，大家就可以清晰得了解异步事件框架，理解松耦合设计与web请求的处理方式。 学习其他开源软件也可以仿照这一过程。 </p>
<h1 id="分布式系统设计建议"><a href="#分布式系统设计建议" class="headerlink" title="分布式系统设计建议"></a>分布式系统设计建议</h1><p><strong>CSDN：我知道你在思科、腾讯等企业工作过，关于大规模分布式系统、高性能服务器设计上有没有什么经验、心得和大家分享一下？</strong><br><strong>陶辉：</strong>使用高级语言、中间件来开发较大型软件时，一定先有一个评估标准：这样玩性能不是问题。这里的潜台词是把性能当做了基础货币。例如，使用<a href="http://lib.csdn.net/base/python" title="Python知识库">Python</a>代替C进行程序开发所牺牲的性能C1，与其带来的其他好处C2相比，必须C1&lt;C2。所以，性能其实是一个永恒的话题。下面零散的谈谈我对性能的理解。 </p>
<p>单组件的性能提升上，算法最重要。特别是越前沿的技术、场景，通用算法的功效距离期望值就越远，开发者这时要能够正确的分析不同的算法在各种情况下的运行时间，基于你的数据特性设计个性化的算法以提升性能，PS，这里终于可以用到大学里学过的如概念论这样的数学技巧了。同时，细致的梳理业务，能够并行处理的绝对不要串行化，谨慎加锁，提高吞吐量。 </p>
<p>对于组件依赖的其他系统，也需要深刻理解如何使用它，才能最大化硬件效率。例如<a href="http://lib.csdn.net/base/operatingsystem" title="操作系统知识库">操作系统</a>，如果组件使用多线程去抢占有限的CPU资源，就必须评估进程间切换的代价，这往往是性能大杀器；了解不同的设备间的访问速度（如SSD硬盘、内存等），将快速设备放在慢速设备前作为缓存；使用TCP作为通讯协议时，既要了解理论也要了解实现，包括演变过程，在实践中才能高效的使用、改进它；减少内存等资源的频繁使用，考虑内存池及如何避免大块内存拷贝；提高缓存的命中率，如coding时应当考虑变量是否经常落到CPU CACHE中，及代码分支预测的命中率等等。 </p>
<p>其实性能“高”也是相对的，需要从开发效率和运行效率上权衡。协程是一个很好的方向，通过创建协程栈来伪造线程开发环境提升开发效率，通过改变底层阻塞API的实现来提升吞吐量、运行效率。例如linux上的ucontext、nginx的lua模块，这里最大的问题还是阻塞API的协程化改造。 </p>
<p>团队的技术积累、业务特点都对开发效率有不同的要求，架构上的scalability也是重要约束，能够通过水平扩展线性地提升性能时，就可以通过牺牲单组件性能来提升开发效率了。 </p>
<p>分布式系统的ACP是一个权衡问题，适当的牺牲一致性是常见解决方案。scalability是一个重要属性，而这个属性会带来请求串行化的场景，常用zookeeper这类系统来提供可靠的锁服务。有了scalability常会导致系统引入缓存服务：组件的主存不可缓存了。缓存也有很多种成熟的解决方案，如memcached、<a href="http://lib.csdn.net/base/redis" title="Redis知识库">Redis</a>等。 </p>
<p>开发大型系统时组件间的高内聚松耦合很重要，否则代码很快就难以维护，有一种解耦方式比较受青睐：使用如rabbitmq等服务来提供异步消息订阅通知机制。 多个会落地的数据服务可能会引入“事务”，而分布式事务解决起来是比较头疼的，paxos两段式提交常常是首选，事务的回滚、清理、残留未完成事务的回滚等都是需要考虑的事项，可以借鉴关系<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">数据库</a>的undo、redo等事务解决方式。 </p>
<h1 id="Nginx的不足"><a href="#Nginx的不足" class="headerlink" title="Nginx的不足"></a>Nginx的不足</h1><p><strong>CSDN：能否谈谈Nginx目前还有哪些不足？还有哪些地方有待完善？</strong><br><strong>陶辉：</strong>我们对Nginx的期望一直在提高：早期只把它用做静态web与反向代理，渐渐地希望它能够处理动态请求。这样，在Nginx进程内部增加功能就越来越重要。 </p>
<p>怎样增加动态请求的处理呢？最方便的是使用一些抽象了常用动态功能的模块，这些模块以nginx.conf中的配置来定义web请求的动态处理流程。然而，很多时候这些模块模块只能处理大众化的需求，这样程序员们只好挽起袖子直接编写C代码了。 但是，nginx模块的开发门槛还挺高，需要开发者对于服务器的非阻塞调用、事件模型有较深的理解，而如果请求处理时需要有全局化视角时，麻烦的多进程通信又来了，开发者不能使用简单的堆分配对象，而要使用nginx_slab管理内存。 </p>
<p>因此，除了期待更多的开发者贡献出多样的抽象模块，目前nginx最应该完善的应当是二次开发的易用性–能够更方便、快速的开发出高性能的nginx模块。例如，nginx的框架可以考虑支持多线程模型，可以考虑支持ucontext协程方式，使开发时不用考虑API的异步回调，不用考虑锁的满足条件。 </p>
<h1 id="Nginx与Apache的市场份额"><a href="#Nginx与Apache的市场份额" class="headerlink" title="Nginx与Apache的市场份额"></a>Nginx与Apache的市场份额</h1><p><strong>CSDN：Nginx市场份额一直稳步提升，您觉得Nginx未来会取代Apache吗？</strong><br><strong>陶辉：</strong>在云与端的时代，端越来越多，云的性能就会越来越重要；而互联网思维本就不高富帅，同时会服务所有草根用户，而用户体验也需要提升，所以，服务器资源的效率在企业成本上将占据越发重要的地位。从这个角度来说，Apache的市场份额被Nginx取代的趋势是不会变的。 </p>
<h1 id="云计算发展"><a href="#云计算发展" class="headerlink" title="云计算发展"></a>云计算发展</h1><p><strong>CSDN：能否谈谈对目前国内云计算市场有什么看法？有哪些趋势值得去关注？</strong><br><strong>陶辉：</strong>云市场发展开始加速，云服务提供商将开始在国计民生中扮演愈发重要的角色，社会基础服务将会进入公有云中，从而对云服务的可靠性安全性有了非常高的要求。比如，早期公有云一个技术人员眼中的小bug，这时就很可能会对社会生活造成严重影响。如阿里云这样的主流公有云服务提供商必须承担起社会使命，犹如水、电、空气一样不能中断、不能出错地提供服务。服务质量越来越重要。 </p>
<p>另一方面，由于云服务提供商通过规模效应可以提供更廉价的服务，所以企业、个人都在将自己的服务上云，这又在推动着主流云商必须思考如何以更低的成本提供服务。所以，云商必须深入到基础设施中，把原先的通用性设备改造成适合云的专有设备，以此提高效率；必须提升原先不适合为云服务的管理系统，以满足不间断服务的要求。例如，云商将需要自己运维网络，需要与硬件厂商合作，设计适合特定场景的网卡、CPU、内存等，软硬结合着在底层增加效率，降低企业成本。</p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title>从wordpress迁移到hexo静态站点</title>
    <url>/2021/02/15/%E4%BB%8Ewordpress%E8%BF%81%E7%A7%BB%E5%88%B0hexo%E9%9D%99%E6%80%81%E7%AB%99%E7%82%B9/</url>
    <content><![CDATA[<blockquote>
<p>接管局通知，个人站点不得有评论功能，原先wordpress+mysql的博客站点（搭建方式见<a href="">这里</a>）需要重构。干脆基于hexo搭建了静态站点，原先的文章已经迁移了过来，大家的评论只能放弃了。本文介绍hexo静态站点的搭建方法。</p>
</blockquote>
<h1 id="wordpress与hexo静态站点的优劣比较"><a href="#wordpress与hexo静态站点的优劣比较" class="headerlink" title="wordpress与hexo静态站点的优劣比较"></a>wordpress与hexo静态站点的优劣比较</h1><p>静态站点的优点在于部署简单、性能优异，比如你可以将其部署在免费的github page上，甚至无须购买域名即可对外提供服务（你可以点击<a href="https://russelltao.github.io/">russelltao.github.io</a>查看我的github页面）。再比如，公有云提供的静态站点服务，可以将其自动部署到CDN站点上（腾讯云的Hexo部署插件见<a href="https://cloud.tencent.com/document/product/1210/43365">这里</a>），用户体验非常好。文章、图片等资源的备份也很简单，可以直接连同代码一起存放在git仓库中。</p>
<span id="more"></span>
<p>当然，静态站点的缺点也很明显，它自身无法处理用户输入的数据，比如文章的评论、阅读量等，需要借助第三方API服务才能实现。虽然类似的服务很多，但今年国家监管得很严，个人站点一旦发现评论就可能会被关站，因此，个人博客改用静态站点其实挺合适的。</p>
<p>静态站点通常以markdown格式写作，将.md文件渲染为.html文件，再发布到支持Http协议的Web服务器上，比如Apache、NodeJS或者Nginx。GoLang、Python等语言都有成熟的静态站点软件框架，而Javascript语言擅长前端UI界面的渲染，因此基于JS的Hexo框架渲染.md模板效果不错，尤其Hexo的中文文档相对较多，对国内用户更友好。Hexo有一个Next Theme主题非常好用，集成了很多常用插件。因此，我选择Hexo+Next搭建新的静态站点，并将原先的wordpress博客迁移过来，下面记录了相关步骤，供参考。</p>
<h1 id="搭建hexo-Next主题站点"><a href="#搭建hexo-Next主题站点" class="headerlink" title="搭建hexo Next主题站点"></a>搭建hexo Next主题站点</h1><p>你可以在自己熟悉的操作系统上进行内容创作，再将它发布到Linux服务器上。先来看如何构建静态站点的源码环境。</p>
<h2 id="在windows上安装生成站点环境"><a href="#在windows上安装生成站点环境" class="headerlink" title="在windows上安装生成站点环境"></a>在windows上安装生成站点环境</h2><p>安装NodeJS及hexo生成器，包括以下3步：</p>
<ol>
<li>进入<a href="https://nodejs.org/en/">NodeJS官网</a>下载安装包。</li>
<li>更换淘宝源，这样下载软件会快一些。<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry http://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></li>
<li>安装hexo：<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="建立博客站点"><a href="#建立博客站点" class="headerlink" title="建立博客站点"></a>建立博客站点</h2><p>想好用于存放站点文件的目录名，例如blog，执行：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo init blog</span><br></pre></td></tr></table></figure>
<p>进入hexo创建的blog目录中，再执行：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<p>完成后，这个站点的目录如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── <span class="built_in">source</span></span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure>
<h3 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h3><ul>
<li>source：所有博客文章（比如.md格式）、图片、视频等内容都在这里，目录层级不限。删除文章时，只要将.md及其引用资源（比如图片）删除即可。<ul>
<li>_drafts：草稿放在该目录下，这些.md文章默认不会渲染到用于部署的public目录。</li>
<li>_posts：文章放在此目录下。如果你的文章很多，<strong>为了维护方便，你可以在此目录下继续构建多级子目录放置文章</strong>。</li>
</ul>
</li>
<li>themes：主题样式目录放在此处，比如接下来将要介绍的Next主题。</li>
<li>scaffolds：新建文章时，会基于该目录下的3个模板文件，构造文章、草稿和页面。</li>
<li>package.json：依赖软件包信息。</li>
<li>_config.yml：站点级的配置文件，比如：<ul>
<li>站点名称可以通过修改title和subtitle完成。</li>
</ul>
</li>
</ul>
<h2 id="设置Next主题"><a href="#设置Next主题" class="headerlink" title="设置Next主题"></a>设置Next主题</h2><p>默认的主题太难看，而hexo中最流行的Next主题功能非常强大，简单易用，适合新手入门。<br>安装主题很简单，首先将github上的Next主题放到themes目录：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>接着，将站点配置文件_config.yml文件中theme项修改：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">next</span></span><br></pre></td></tr></table></figure>
<p>Next主题已经生效。</p>
<h3 id="设置主题风格"><a href="#设置主题风格" class="headerlink" title="设置主题风格"></a>设置主题风格</h3><p>目前Next有4种风格，可以通过修改next/_config.yml主题配置文件实现，例如修改为pisces风格：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Schemes</span></span><br><span class="line"><span class="comment">#scheme: Muse</span></span><br><span class="line"><span class="comment">#scheme: Mist</span></span><br><span class="line"><span class="attr">scheme:</span> <span class="string">Pisces</span></span><br><span class="line"><span class="comment">#scheme: Gemini</span></span><br></pre></td></tr></table></figure>
<h3 id="去除底部LOGO"><a href="#去除底部LOGO" class="headerlink" title="去除底部LOGO"></a>去除底部LOGO</h3><p>如果想将站点底部的Hexo、Next字样消除，可以将footer中的powered置为false：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="attr">powered:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>如果显示站点创建时间，则可以更改since选项：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="attr">since:</span> <span class="number">2021</span></span><br></pre></td></tr></table></figure>
<h3 id="设置站点语言"><a href="#设置站点语言" class="headerlink" title="设置站点语言"></a>设置站点语言</h3><p>将网站语言修改为中文，可以通过修改站点_config.yml文件完成，目前Next主题支持的语言如下表所示：</p>
<table>
<thead>
<tr>
<th>语言</th>
<th>代码</th>
<th>设定示例</th>
</tr>
</thead>
<tbody><tr>
<td>English</td>
<td>en</td>
<td>language: en</td>
</tr>
<tr>
<td>简体中文</td>
<td>zh-Hans</td>
<td>language: zh-Hans</td>
</tr>
<tr>
<td>Français</td>
<td>fr-FR</td>
<td>language: fr-FR</td>
</tr>
<tr>
<td>Português</td>
<td>pt</td>
<td>language: pt or language: pt-BR</td>
</tr>
<tr>
<td>繁體中文</td>
<td>zh-hk 或者 zh-tw</td>
<td>language: zh-hk</td>
</tr>
<tr>
<td>Русский язык</td>
<td>ru</td>
<td>language: ru</td>
</tr>
<tr>
<td>Deutsch</td>
<td>de</td>
<td>language: de</td>
</tr>
<tr>
<td>日本語</td>
<td>ja</td>
<td>language: ja</td>
</tr>
<tr>
<td>Indonesian</td>
<td>id</td>
<td>language: id</td>
</tr>
<tr>
<td>Korean</td>
<td>ko</td>
<td>language: ko</td>
</tr>
</tbody></table>
<p>故修改为language: zh-CN即可。</p>
<h1 id="迁移wordpress博客内容"><a href="#迁移wordpress博客内容" class="headerlink" title="迁移wordpress博客内容"></a>迁移wordpress博客内容</h1><h2 id="迁移数据"><a href="#迁移数据" class="headerlink" title="迁移数据"></a>迁移数据</h2><p>首先，安装 hexo-migrator-wordpress 插件。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-migrator-wordpress --save</span><br></pre></td></tr></table></figure>
<p>在 WordPress 仪表盘中导出数据(“Tools” → “Export” → “WordPress”)。注意，<strong>草稿里的文章建议删除后再导出，否则发布日期可能会导致插件异常</strong>。<br>接着，将导出的xxx.xml文件导入hexo站点：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo migrate wordpress xxx.xml</span><br></pre></td></tr></table></figure>
<p>这个插件问题很多，有些wordpress文章很可能导致migrate过程异常终止。出现这种问题时，我建议你先找到导致migrate抛异常的文章，做相关处理后再重新导出、migrate。</p>
<p>另外，即使migrate成功后，还需要大量的工作修复数据格式，包括更改代码、表格及段落格式等，如下文所描述的那样。</p>
<h2 id="更改代码块格式"><a href="#更改代码块格式" class="headerlink" title="更改代码块格式"></a>更改代码块格式</h2><p>wordpress导出的代码段，仅用```来分隔，不会标注代码语言，这就无法使用语法高亮显示功能了。我们需要在``` 之后添加编程语言。比如，Nginx配置文件可以这么写：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">``` nginx</span><br><span class="line"><span class="attribute">location</span> /a &#123;</span><br><span class="line">  <span class="attribute">alias</span> /d;</span><br><span class="line">&#125;   ```</span><br></pre></td></tr></table></figure>

<p>点击<a href="https://github.com/highlightjs/highlight.js/blob/master/SUPPORTED_LANGUAGES.md">代码块支持语言</a>查看所有支持的语言。</p>
<h2 id="更改表格格式"><a href="#更改表格格式" class="headerlink" title="更改表格格式"></a>更改表格格式</h2><p>默认表格迁移到markdown格式，每个行、列交汇处的数值是单行放置的！手动更改为markdown格式表格是极其痛苦的！ 如果你在用VsCode编辑器，可以安装个插件Markdown Shortcut，它可以将导入的数据简单的转换为表格。</p>
<h2 id="增加分类、标签页"><a href="#增加分类、标签页" class="headerlink" title="增加分类、标签页"></a>增加分类、标签页</h2><p>分类页可以将所有文章的Category分类聚合成为独立的页面，供用户点击选择。同样，标签页可以将所有文章的Tag标签聚合为独立的页面，并通过字体大小、粗体等方式表达标签的引用次数，如下图所示：<br><img src="/images/%E5%BB%BA%E7%AB%99/hexo%E6%A0%87%E7%AD%BE%E9%A1%B5.JPG"></p>
<p>生成这2个页面的步骤很简单，包括：</p>
<ol>
<li><p>首先生成分类页和标签页：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure></li>
<li><p>修改2个页面的type值<br>在新生成的source/categories/index.md文件中，添加type项：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2021-01-29 10:17:39</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">&quot;categories&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
<p>在新生成的source/tags/index.md文件中，同样添加type项：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">tags</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2021-01-29 10:17:44</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">&#x27;tags&#x27;</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将2个页面添加到网站首页<br>修改next/_config.yml文件，加入tags和categories页：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">home:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="attr">categories:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-th</span></span><br></pre></td></tr></table></figure>
<p>其中，fa-tags等是图标样式，你可以在<a href="https://fontawesome.com/v4.7.0/icons/">这里</a>找到所有可用的图标。</p>
<h2 id="分隔文章摘要"><a href="#分隔文章摘要" class="headerlink" title="分隔文章摘要"></a>分隔文章摘要</h2></li>
</ol>
<p>Next主题有3种提取文章摘要在首页显示的方法，包括：</p>
<ol>
<li>最好用（也是官方推荐的）的，是在文章中用<code>&lt;!-- more --&gt;</code>分隔内容。虽然这样最灵活，但很难保证首页有限摘要中含有图片。</li>
<li>在文章最前面的front-matter部分中添加description标签，标签中的内容会放在首页中以摘要方式显示。注意，这里添加图片时，不能使用markdown格式，而必须用&lt;img src=&quot;…&quot;/&gt;这种方式！</li>
<li>由Next主题按照字符数自动形成摘要，比如：<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">auto_excerpt:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">length:</span> <span class="number">150</span></span><br></pre></td></tr></table></figure>
这种配置会自动截断前150个字符，形成首页摘要。这个方法效果最差。</li>
</ol>
<p>另外，我们通常会希望将图片显示在首页，让用户更直观的看到文章内容。而more截断、description这两种方式都有些问题。此时，可以使用photos标签实现这一功能，比如：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">photos:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/2014/10/07/front-matter-photos/1000.png</span></span><br></pre></td></tr></table></figure>

<h2 id="SEO优化"><a href="#SEO优化" class="headerlink" title="SEO优化"></a>SEO优化</h2><p>为了提高站点的访问率，Next主题也已经帮我们做了很多工作。</p>
<h3 id="增加百度统计"><a href="#增加百度统计" class="headerlink" title="增加百度统计"></a>增加百度统计</h3><p>可以借助百度或者谷歌的统计功能查看站点的访问情况（JS会将用户的访问数据传到谷歌、百度后台），<strong>比如了解下，我们的用户主要靠哪些关键词才搜索到站点</strong>。用法很简单，对于<a href="https://tongji.baidu.com/">百度统计</a>，在注册好帐户后，可以从下图中获取脚本ID：<br><img src="/images/%E5%BB%BA%E7%AB%99/analytics-baidu-id.png"></p>
<p>再修改next/_config.yml文件：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">baidu_analytics:</span> <span class="string">xxxxx</span></span><br></pre></td></tr></table></figure>
<p>设置好脚本ID即可。</p>
<h3 id="设置keywords关键字"><a href="#设置keywords关键字" class="headerlink" title="设置keywords关键字"></a>设置keywords关键字</h3><p>关键字对搜索引擎更友好，方便建立倒排索引时设置词汇权重。关键字分为站点与文章2类，设置方法如下：</p>
<ol>
<li>站点级关键字<br>站点配置文件_config.yml中可以设置keywords，多个关键字之间用英文逗号分隔。</li>
<li>文章关键字<br>在文章最前方的front-matter中添加keywords项，其中填写关键字。</li>
</ol>
<h3 id="生成sitemap站点地图"><a href="#生成sitemap站点地图" class="headerlink" title="生成sitemap站点地图"></a>生成sitemap站点地图</h3><p>为了方便搜索引擎收录站点的所有文章，你可以通过以下2步提升收录速度：</p>
<ol>
<li>安装站点地图插件(详细用法见<a href="https://github.com/hexojs/hexo-generator-sitemap">这里</a>)：<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure></li>
<li>将站点地图链接加入首页<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">sitemap:</span> <span class="string">/sitemap.xml</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-sitemap</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>这样，搜索引擎一经发现/sitemap.xml页面，就会迅速找到所有文章。</p>
<h1 id="优化Next主题"><a href="#优化Next主题" class="headerlink" title="优化Next主题"></a>优化Next主题</h1><p>Next主题本身很美观也很强大，但如果想定制个性化的页面，还需要修改CSS样式。同时，Next集成了很多第三方平台的功能，这需要协同注册第三方平台才能达到效果。下面总结下常用的主题优化设置。</p>
<h2 id="分享到微信、微博等平台"><a href="#分享到微信、微博等平台" class="headerlink" title="分享到微信、微博等平台"></a>分享到微信、微博等平台</h2><p>使用Next主题默认的<a href="https://www.addthis.com/">AddThis</a>插件，注册帐号并排列分享顺序（比如默认Facebook、Twitter在最上方，国内用户可以将微博、微信优先级提前）。</p>
<p>最后在Next主题的_config.yml文件中，将AddThis中的pubid填入AddThis中：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">add_this_id:</span> <span class="string">ra-xxxxxxxxxxxxxxxxx</span></span><br></pre></td></tr></table></figure>

<h2 id="添加侧边栏头像"><a href="#添加侧边栏头像" class="headerlink" title="添加侧边栏头像"></a>添加侧边栏头像</h2><p>修改/themes/next/layout/_partials/sidebar/site-overview.swig文件：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;site-author motion-element&quot; itemprop=&quot;author&quot; itemscope itemtype=&quot;http://schema.org/Person&quot;&gt;</span><br><span class="line">  &#123;%- if theme.avatar.url %&#125;</span><br><span class="line">    &lt;a href=&quot;/关于陶辉/index.html&quot;&gt;&lt;img class=&quot;site-author-image&quot; itemprop=&quot;image&quot; alt=&quot;&#123;&#123; author &#125;&#125;&quot;</span><br><span class="line">      src=&quot;&#123;&#123; url_for(theme.avatar.url) &#125;&#125;&quot;&gt;&lt;/a&gt;</span><br><span class="line">  &#123;%- endif %&#125;</span><br><span class="line">  &lt;p class=&quot;site-author-name&quot; itemprop=&quot;name&quot;&gt;&#123;&#123; author &#125;&#125;&lt;/p&gt;</span><br><span class="line">  &lt;div class=&quot;site-description&quot; itemprop=&quot;description&quot;&gt;&#123;&#123; description &#125;&#125;&lt;/div&gt;</span><br><span class="line">&lt;/<span class="selector-tag">div</span>&gt;</span><br></pre></td></tr></table></figure>
<h2 id="显示页面的浏览进度"><a href="#显示页面的浏览进度" class="headerlink" title="显示页面的浏览进度"></a>显示页面的浏览进度</h2><p>修改主题_config.yaml文件，可以让右下角多出1个回到页头的图标，并且显示文章浏览进度：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">back2top:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Back to top in sidebar.</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Scroll percent label in b2t button.</span></span><br><span class="line">  <span class="attr">scrollpercent:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h2 id="开启文章底部的相关文章推荐"><a href="#开启文章底部的相关文章推荐" class="headerlink" title="开启文章底部的相关文章推荐"></a>开启文章底部的相关文章推荐</h2><p>将related_posts下的enable置为true即可：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">related_posts:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">params:</span></span><br><span class="line">    <span class="attr">maxCount:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>maxCount可以设置最多推荐的文章数</p>
<h2 id="开启文章版权声明"><a href="#开启文章版权声明" class="headerlink" title="开启文章版权声明"></a>开启文章版权声明</h2><p>编辑主题_config.yml配置文件，在footer中找到creative_commons，这里可以设置知识共享许可协议。creative_commons中含有以下版权许可声明：<br><img src="/images/%E5%BB%BA%E7%AB%99/%E7%9F%A5%E8%AF%86%E5%85%B1%E4%BA%AB%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.JPG"></p>
<p>如果你选择使用by-nc-sa，可以如下设置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">creative_commons:</span></span><br><span class="line">  <span class="attr">license:</span> <span class="string">by-nc-sa</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">post:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">language:</span> <span class="string">zh-CN</span></span><br></pre></td></tr></table></figure>

<h2 id="首页加入圆角矩形分隔"><a href="#首页加入圆角矩形分隔" class="headerlink" title="首页加入圆角矩形分隔"></a>首页加入圆角矩形分隔</h2><p>首页多篇文章之间的分隔并不明显，我习惯将每篇文章以矩形框显示。此时，可以修改Next主题中的next/source/css/_common/components/post/post.styl文件，找到use-motion中修改post_block的CSS代码：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.use-motion</span> &#123;</span><br><span class="line">  if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class="line">    <span class="selector-class">.post-block</span>, <span class="selector-class">.pagination</span>, <span class="selector-class">.comments</span> &#123;</span><br><span class="line">      <span class="attribute">opacity</span>: <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在post_block中加入矩形框，其中-webkit-box-shadow可以设置阴影的颜色和宽度，比如：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.use-motion</span> &#123;</span><br><span class="line">  if (hexo-config(&#x27;motion.transition.post_block&#x27;)) &#123;</span><br><span class="line">    <span class="selector-class">.post-block</span>&#123;</span><br><span class="line">      <span class="attribute">opacity</span>: <span class="number">1</span>;</span><br><span class="line">      <span class="attribute">border-radius</span>: <span class="number">20px</span>;</span><br><span class="line">      <span class="attribute">margin-top</span>: <span class="number">40px</span>;</span><br><span class="line">      <span class="attribute">margin-bottom</span>: <span class="number">20px</span>;</span><br><span class="line">      <span class="attribute">padding</span>: <span class="number">15px</span>;</span><br><span class="line">      <span class="attribute">-webkit-box-shadow</span>: <span class="number">0</span> <span class="number">0</span> <span class="number">5px</span> <span class="built_in">rgba</span>(<span class="number">51</span>, <span class="number">170</span>, <span class="number">51</span>, .<span class="number">5</span>);</span><br><span class="line">      <span class="attribute">-moz-box-shadow</span>: <span class="number">0</span> <span class="number">0</span> <span class="number">15px</span> <span class="built_in">rgba</span>(<span class="number">202</span>, <span class="number">203</span>, <span class="number">204</span>, .<span class="number">5</span>);</span><br><span class="line">    &#125;<span class="selector-class">.pagination</span>, <span class="selector-class">.comments</span> &#123;</span><br><span class="line">    <span class="attribute">opacity</span>: <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="开启文章字数统计及预估阅读时长"><a href="#开启文章字数统计及预估阅读时长" class="headerlink" title="开启文章字数统计及预估阅读时长"></a>开启文章字数统计及预估阅读时长</h2><p><a href="https://github.com/theme-next/hexo-symbols-count-time">hexo-symbols-count-time插件</a>提供了这一功能，使用它首先要安装插件：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-symbols-count-time</span><br></pre></td></tr></table></figure>
<p>接着，在主题的_config.yml中开启它：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_post:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h2 id="添加本地搜索功能"><a href="#添加本地搜索功能" class="headerlink" title="添加本地搜索功能"></a>添加本地搜索功能</h2><p><a href="https://github.com/theme-next/hexo-generator-searchdb">hexo-generator-searchdb插件</a>提供了基于JS在本地内容中搜索的能力，使用时首先要安装插件：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb</span><br></pre></td></tr></table></figure>
<p>接着修改Next主题的_config.yml配置文件，打开本地搜索功能：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h2 id="修改备案ICP号"><a href="#修改备案ICP号" class="headerlink" title="修改备案ICP号"></a>修改备案ICP号</h2><p>国内的站点都需要备案号，并将公安备案号及图标放在网站的最底部。Next主题已经将这一功能内置，你可以在主题配置文件footer中的beian中，填入备案号和图标，比如：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="attr">beian:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">icp:</span> <span class="string">&lt;a</span> <span class="string">href=&quot;https://beian.miit.gov.cn&quot;&gt;浙ICP备xxxxxx号&lt;/a&gt;</span></span><br><span class="line">    <span class="attr">gongan_id:</span> <span class="string">3xxxxxxxxxx</span></span><br><span class="line">    <span class="attr">gongan_num:</span> <span class="string">浙公网安备</span> <span class="string">3xxxxxxxxx号</span></span><br><span class="line">    <span class="attr">gongan_icon_url:</span> <span class="string">/images/备案图标.png</span></span><br></pre></td></tr></table></figure>

<h1 id="部署静态站点"><a href="#部署静态站点" class="headerlink" title="部署静态站点"></a>部署静态站点</h1><p>接下来介绍静态站点的3种部署方式。</p>
<h2 id="本地测试静态站点"><a href="#本地测试静态站点" class="headerlink" title="本地测试静态站点"></a>本地测试静态站点</h2><p>在部署到生产环境前，首先要在本机开发环境中验证页面功能。以下3项最为常用：</p>
<ol>
<li><p>生成静态站点文件<br>将.md文章在public文件夹下生成HTML站点，可以使用如下命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure>
<p>需要注意，有时public下会有上一次生成的残留文件，可以用clean命令清理：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure>
</li>
<li><p>部署本机测试环境</p>
</li>
</ol>
<p>接着，就可以s命令在本机启动NodeJS服务，通过默认的4000端口测试内容了，比如<a href="http://localhost:4000，这样，在本机的浏览器访问即可调试，非常方便。当然，你可以通过-p选项修改监听端口，还可以通过--draft选项测试草稿箱中的文章：">http://localhost:4000，这样，在本机的浏览器访问即可调试，非常方便。当然，你可以通过-p选项修改监听端口，还可以通过--draft选项测试草稿箱中的文章：</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo s --draft -p 8080</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>发布到生产环境<br>测试通过后，就可以通过d命令部署站点了：<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>究竟将public文件夹部署到哪里，下面一一来看。</p>
<h2 id="部署到免费的github-page上"><a href="#部署到免费的github-page上" class="headerlink" title="部署到免费的github page上"></a>部署到免费的github page上</h2><p>我们通常会将源代码部署到github上，但github还提供了一种功能，可以将静态页面部署在其上。当你用自己的github帐户名建立page仓库后，就可以通过hexo d命令一键部署站点了，非常方便。</p>
<p>当然，部署前先要安装插件：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<p>接着，修改站点（不是Next主题）的_config.yml文件，填入仓库地址：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:yourgithubname/yourgithubname.github.io</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>
<p>** 注意：git不能是https协议，否则需要输入用户名、密码！**</p>
<h2 id="部署到云服务器通过Nginx提供服务"><a href="#部署到云服务器通过Nginx提供服务" class="headerlink" title="部署到云服务器通过Nginx提供服务"></a>部署到云服务器通过Nginx提供服务</h2><p>如果你有Linux云服务器，可以用Nginx等Web服务器提供静态文件服务（通过root指令，具体的配置方式参见<a href="/2020/12/23/nginx/%E4%BB%8E%E9%80%9A%E7%94%A8%E8%A7%84%E5%88%99%E4%B8%AD%E5%AD%A6%E4%B9%A0nginx%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9A%E5%88%B6%E6%8C%87%E4%BB%A4/">这里</a>）。此时部署方式可以通过Linux服务器默认就提供的sftp协议上传到服务器中。</p>
<p>还是先安装插件：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-sftp --save</span><br></pre></td></tr></table></figure>

<p>接着修改站点配置文件。注意，如果你想将静态站点一键部署到多个服务器上也是可以的，比如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">sftp</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">pass:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">remotePath:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">22</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:yourgithubname/yourgithubname.github.io</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>
<p>至此，每当你修改完文章，就可以通过hexo d完成站点部署，非常方便。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>静态站点不需要数据库，也不需要php、java等编程语言基于模板生成动态页面，所以其安全性非常高，部署时只需要将public文件夹拷贝到目标服务器即可。</p>
<p>Hexo是基于Javscript+Nodejs软件生成静态站点的，它可以将Markdown等格式的文章渲染为HTML文件，还支持第三方插件，可以一键部署到远程服务器。</p>
<p>Next主题是Hexo上的首选主题，集成了许多插件，将备案号、本地搜索、搜索引擎统计、站点地图、文章推荐、版权声明、浏览进度、文章字数统计等功能都集成了进去。而且，我们可以很方便地修改主题样式。如果你的站点没有动态内容，或者通过第三方插件可以完成相应功能，那么Hexo+Next是个很好的解决方案！</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>wordpress</tag>
        <tag>nodejs</tag>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>github</tag>
        <tag>免费托管</tag>
        <tag>备案</tag>
        <tag>管局</tag>
        <tag>sftp</tag>
        <tag>评论</tag>
      </tags>
  </entry>
  <entry>
    <title>创造 ：未来商业就是智能商业 （6月底CSDI大会预告）</title>
    <url>/2018/04/15/%E5%88%9B%E9%80%A0-%EF%BC%9A%E6%9C%AA%E6%9D%A5%E5%95%86%E4%B8%9A%E5%B0%B1%E6%98%AF%E6%99%BA%E8%83%BD%E5%95%86%E4%B8%9A-%EF%BC%886%E6%9C%88%E5%BA%95csdi%E5%A4%A7%E4%BC%9A%E9%A2%84%E5%91%8A%EF%BC%8C/</url>
    <content><![CDATA[<p><strong>引言</strong>：一个好的行业，只要开放行业就好，少搞顶层设计，根据业务决定做什么，故为“因之”。硅谷成功的秘诀之一是：政府没有能力管，只把商业发生的事情交给商业本身。</p>
<span id="more"></span>
<p> <img src="http://www.taohui.pub/wp-content/uploads/2018/04/30bdaf51f202f3e390ab773fc17bed52-1.jpg">  燃えてヒーロー 沖田浩之 - 僕らのアニメ・ヒッツ <img src="/2018/04/a82ec86de382c688d0d34590f7ddbe38-1.png"> </p>
<p><strong>作者▕  董笑含</strong> <strong>编辑▕  七七</strong> <img src="http://www.taohui.pub/wp-content/uploads/2018/04/640-1.jpg"> 人们在满足衣食住行基本需求后，多少会追求享受和娱乐，随着经济在人民生活水平中的提高，消费升级带来更多商机。科技的发展让我们足不出户的购物、交友、轻娱乐、游戏等，甚至移动互联网在前几年兴起之时，社交功能无不充斥在每个应用中。如今衍生的摄影、交易、机器人、直播技术、无人驾驶、语音识别、图像识别等，而“易经”告诉我们，人类需要社交，但却不是全部在线上的交互，缺乏机制的交互是人类的退步。<strong>请让我们从虚拟世界回到现实世界。</strong> 新技术产品通常来说，需要经历三代投放普及，才能获得市场认可。 <img src="http://www.taohui.pub/wp-content/uploads/2018/04/unnamed-file-3.jpg"> ➤ 比如一代计算机图形视窗的操作系统是技术先锋施乐公司帕克研究中心，并非苹果公司；二代是苹果麦金托什电脑的视窗图形操作系统（MAC）且兼容性低、价格高，习惯其使用方式的人会一直偏爱它。三代是实用、价格适中、兼容性好的微软操作系统。 ➤ 比如一代智能手机最早的是微软、黑莓、诺基亚，那个时候还是少数人使用，多数人观摩，远远追不上智能一词；二代是苹果iphone,简约和亮眼的创新设计，吸引了国内外的眼光，却具备潜在的可升级系数，纵向一体化和“刀片+刀架”模式；三代是谷歌的安卓，兼容性高、性价比高，普及性强。 ➤ 比如一代96年-99年通用汽车公司生产的电动汽车，因为是全新的概念，性能不够好、充电时长也无法用技术直接解决，导致追捧者寥寥无几；二代是特斯拉的电动汽车，性能不错、充电时长得到解决，却价格昂贵，导致产量很低，被誉为电动汽车中的奢侈品，因为可以赶上一部中档保时捷（50万-105万）；三代是特斯拉推出的三系电动汽车，由于价格与宝马三系市场相似，性价比为它的销量带来一周20多万的成绩。 <img src="http://www.taohui.pub/wp-content/uploads/2018/04/iphone%E7%9A%84%E5%95%86%E4%B8%9A%E5%88%9B%E6%96%B0%E6%A8%A1%E5%BC%8F-1.jpg"> <strong>实践**</strong>是先行人，**<strong>理论**</strong>是追随者。** <img src="/2018/04/paypal%E4%B8%AD%E9%97%B4%E6%94%AF%E4%BB%98-1.jpg"></p>
<p><strong>VISA</strong></p>
<p>二战以后，国内曾掀起过一阵消费热潮，涌现大量的赊销公司，允许消费者月结，最终以每月的大量账单不被接纳；1950年大来卡创办，十家银行推出信用卡，但都未成规模，直到美国银行（BankAmericard）VISA信用卡提升到一个新高度。</p>
<p><strong>安全密钥</strong></p>
<p>网络的使用成本因密码安全性提升，94年网景通信公司推行了高安全性TSL协议，随着通信安全性的不断提高，在线店铺有一半以上的网络交易是有信用卡结算的，99年PayPal出现公开键密码赋予网络的新安全。</p>
<p><strong>梅西百货</strong></p>
<p>大型连锁店的兴起到一站式购物的价值，早期从现金交易、自买自提、店铺标准化、雇佣小时工、城市化覆盖等塑造原型，中期新型经济店中，从自选店降低运营成本、精简商品、提升采购能力，成功的用5年店铺数7350家升为15671家；晚期定位精准用户、谢绝划价、退换货服务、促销策略、广告投放等，成为覆盖全美的零售连锁百货。 <strong>IT新产品大部分是由不同的企业引领的，就像一个王朝的建立，迭代打磨，兴衰交替，沉淀技术经验，打破壁垒，成就新产品。</strong> <img src="/2018/04/unnamed-file-1-1.jpg"> <strong>商业模式是**</strong>革新的载体**<strong>。</strong>智能化的今天，商业的本质上千年不曾变化，企业未来所提供的是服务，不单纯是产品。 2018年广州6月29-7月1日CSDI将用<strong>数据智能、数字化转型、数据驱动、智能社交、智能服务、智能融合、AI生态、全球化创新、智慧城市、量子计算等</strong>多角度，从互联网到全行业大放异彩的为技术人呈现一场AI时代下的盛宴，携手国内外一线技术专家，为用户提供一个业务与技术支撑的实践落地内容。</p>
<p><img src="/2018/04/csdi-2018-1.jpg"></p>
<p><img src="/2018/04/csdi-2018%E5%98%89%E5%AE%BE-1.jpg"></p>
<p><strong>结束语</strong></p>
<p>智慧城市：智能洗衣机、电视、性能卓越的电脑、（VR）无人机、无人驾驶汽车将华丽丽的像一个个牙牙学语的小孩儿，用语言、图像交互的方式进入我们生活的每个角落；思想与语言的谁在前谁在后，人类一直没有探求出，或许量子计算可以模拟出人类的次级大脑； 大数据的能力遍及整个行业，我们未来或许身份证无需携带便可以走遍天下。 <strong>科技的路上，竞争对手也许是我们最温暖的陪伴者，**</strong>商业模式革新的真正目的不是竞争而是**<strong>创造**</strong>，催生更多优秀的产品和技术，生生不息。** <strong>✦✦</strong> <strong>往届回顾</strong> <strong>往期报名企业</strong>：微软、小米、阿里巴巴、百度、饿了么、华为、京东云、腾讯、亚马逊、新浪、才云、达观、google、PingCap、滴滴、花虾金融、今日头条、华泰证券、蚂蚁金服、美丽联合集团、摩拜单车、平安、普元、facebook、kyligence、前端圈、AdMaster、postverta、同程旅游、hasadate、物灵科技、微办公、顺丰、携程、Netflix、趣店、优维科技、驭势科技、易观、数人云、日志易等。 <img src="/2018/04/unnamed-file-2-1.jpg"></p>
<p><strong>座位抢购中，点击阅读原文，了解大会更多精彩内容，不容错过！</strong></p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>CSDI</tag>
      </tags>
  </entry>
  <entry>
    <title>利用cpu缓存实现高性能程序</title>
    <url>/2018/09/05/%E5%88%A9%E7%94%A8cpu%E7%BC%93%E5%AD%98%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<p>我们选购电脑时，CPU处理器的配置会有缓存大小，它是CPU性能的重要指标。 <img src="/2018/08/intel%E5%AE%98%E7%BD%91cpu%E5%88%97%E8%A1%A8%E4%B8%AD%E7%9A%84%E7%BC%93%E5%AD%98-1-3.jpg"> </p>
<p>为什么呢？因为CPU计算速度与访问主存速度非常不匹配！ </p>
<span id="more"></span>
<p>先来看计算速度。单颗CPU计算速度目前在2GHz-4GHz之间，以2.5GHz计即每秒钟计算25亿次，每个时钟周期耗时1/2.5GHz==0.4纳秒。当前所有的计算机都遵循冯诺依曼结构，所以执行任何指令（例如加法操作）的流程必然遵循下图： <img src="/2018/08/cpu%E6%8C%87%E4%BB%A4%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B-1.jpg"> </p>
<p>所以，做一次加法的指令是由多个时钟周期组成的（如取指令和数字、放入寄存器、执行ALU、将结果写回主存），做ALU执行指令仅需要1个时钟周期，而取指令或者取数据、回写结果数据就需要与主存打交道了。CPU访问内存（主存）的速度非常慢，访问一次常常需要上百纳秒以上，这与计算指令有千倍的差距！怎样解决访问主存慢导致的<strong>CPU计算能力的浪费</strong>呢？加入CPU缓存！ </p>
<p>CPU上增加缓存后，由于CPU缓存离CPU核心更近，所以访问速度比主存快得多！如果我们访问内存时，先把数据读取到CPU缓存再计算，而下次读取到该数据时直接使用缓存（若未被淘汰掉），这在时间和空间上都会降低CPU计算能力的浪费！在时间上，有些数据访问频率高（热点），多次访问之间都未被淘汰出缓存；在空间上，缓存可以同时加载相邻的数据、代码，这样函数、循环的执行都在使用缓存中的数据。 </p>
<p>CPU缓存是分为多级的，原因是热点数据太大了！最快的缓存一定离CPU核心最近，因为体积小所以容量也最小，不能满足以MB计算的热点数据。最终发展出了三级缓存，分别称为L1、L2、L3级缓存。这三级缓存的访问速度各不相同，但都远大于访问主存的速度（访问时间更小），如下图所示： <img src="/2018/08/cpu%E5%90%84%E7%BA%A7%E7%BC%93%E5%AD%98%E7%9A%84%E8%AE%BF%E9%97%AE%E9%80%9F%E5%BA%A6-2.png"> 可见，L1和L2的缓存访问速度非常快，只有不到3ns，L3稍慢一些，但都远小于访问主存的速度。当然，CPU缓存的大小也远小于主存的大小，如本文最开始的那张图，现在的CPU缓存往往只有几十MB。如果大家点击具体的CPU细看缓存，可以看到intel只标明了smart cache，如下图所示（intel e5-2620 v4）： <img src="/2018/08/intel-smart-cache-e5-2620v4-3.png"> 这个smart cache其实就是L3缓存，现在的CPU都是多核心的，而smart cache就是智能的被多CPU核心共用的意思。那么L1、L2缓存大小为什么不标出来呢？其实没有必要，因为通常L1就是32KB，而L2是256KB，在linux上我们可以直接看到：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">model name: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu1/cache/index0/size </span></span><br><span class="line">32K</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu1/cache/index1/size </span></span><br><span class="line">32K</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu1/cache/index2/size </span></span><br><span class="line">256K</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu1/cache/index3/size </span></span><br><span class="line">20480K</span><br></pre></td></tr></table></figure>

<p>这里，index0和index1分别代表L1缓存中的指令缓存和数据缓存，index2是L2缓存，index3就是L3缓存。也可能一个缓存由多个CPU共享，仍然以E5-2620 v4这个8核16线程的CPU为例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu0/cache/index1/shared_cpu_list </span></span><br><span class="line">0,16</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu0/cache/index2/shared_cpu_list </span></span><br><span class="line">0,16</span><br><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu0/cache/index3/shared_cpu_list </span></span><br><span class="line">0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30</span><br></pre></td></tr></table></figure>

<p>笔者的服务器有两颗e5，所以表现为32颗逻辑CPU。由于intel的超线程技术，所以两颗逻辑CPU对应一颗物理CPU。简单插一下何谓超线程技术：由于访问主存的速度太慢，所以intel想了一个主意，就是当CPU在等待从主存中调入数据或者指令时，同时做另一个任务，这样一颗CPU就表现为两颗逻辑CPU，如下图所示： <img src="/2018/08/intel%E8%B6%85%E7%BA%BF%E7%A8%8B%E6%8A%80%E6%9C%AF-1-4.jpg"> 从<code>shared_cpu_list</code>可见，20MB的L3缓存被16颗逻辑CPU（8颗物理CPU）共享，而L2和L1都是由一颗物理CPU独占的。 CPU缓存与主存交换数据每次大小是固定的，我们称其为cpu cache line，在64位系统下通常是64字节，在linux下可以这么获取该值：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@zldfwq103 ~]<span class="comment"># cat /sys/devices/system/cpu/cpu1/cache/index3/coherency_line_size </span></span><br><span class="line">64</span><br></pre></td></tr></table></figure>

<p>在C语言程序里，可以通过sysconf (_SC_LEVEL1_DCACHE_LINESIZE)获取，例如在nginx 1.13.8版本后是这么获取的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">+<span class="meta">#<span class="meta-keyword">if</span> (NGX_HAVE_LEVEL1_DCACHE_LINESIZE)</span></span><br><span class="line">+    size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE);</span><br><span class="line">+    <span class="keyword">if</span> (size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">+        ngx_cacheline_size = size;</span><br><span class="line">+    &#125;</span><br><span class="line">+<span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<p>为什么需要cpu cache line这个数值呢？因为它对提高性能是有用的！比如nginx中存储http header的hash表。假设我们的cache size是64字节，而一个hash bucket是48字节。假如某一个bucket的起始地址是1F7D030，那么它占用的内存就从1F7D030到1F7D05F，而cache size的特性导致只会从64的整数倍地址访问，于是需要访问两次：1F7D000和1F7D040。而如果我们能使得hash bucket大小是cache size的整数倍，那么就不会出现访问一个hash bucket需要两次操作主存的情况。比如，若原本bucket size是32，则设为64；原本为96，则设为128，即向上对齐。nginx有一个向上对齐函数就是做这个事的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_align(d, a)     (((d) + (a - 1)) &amp; ~(a - 1))</span></span><br><span class="line"></span><br><span class="line">    cmcf-&gt;server_names_hash_bucket_size =</span><br><span class="line">            ngx_align(cmcf-&gt;server_names_hash_bucket_size, ngx_cacheline_size);</span><br></pre></td></tr></table></figure>

<p>上面这个ngx_align算法来源于一个数学特性：对于正整数2^n（n&gt;1）来说，存在这样的特性，如果整数X是2^n的整数倍，则X的二进制形式的低n位为0， 如果X不是2^n的整数倍，则X与（~(2^n-1)）进行与运算可以得到一个与X相近的是2^n整数倍的正整数。对于上对齐，则需要先加上2^n-1，再进行上述运算。 事实上，如果hash bucket没有对齐cache line，那么出现访问一个bucket要调用两次载入主存数据的操作可能性非常大！比如上面的例子中hash bucket size是48，即使第一个bucket没有跨cache line，第2个bucket一定会跨从而导致两次主存访问！   当CPU获取数据时，cpu缓存由于已经存有数据，那么核心可以直接使用缓存，不用再去访问内存了，这一过程我们称为cache hit命中！反之，称为cache miss。可见，如果我们的程序在循环或者热点代码中，能够控制数据规模，使之长期落在CPU缓存中，那么性能就可以提升！怎么判断CPU缓存命中率现在是多少呢？在linux下可以通过perf命令轻松实现（centos下通过yum install perf安装），如下所示：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@zldfwq103 <span class="built_in">test</span>]<span class="comment"># perf stat -B -e cache-references,cache-misses ./test5 64</span></span><br><span class="line">time cost: 12283832us</span><br><span class="line"></span><br><span class="line"> Performance counter stats <span class="keyword">for</span> <span class="string">&#x27;./test5 64&#x27;</span>:</span><br><span class="line"></span><br><span class="line">           440,366      cache-references                                            </span><br><span class="line">           157,177      cache-misses              <span class="comment">#   35.692 % of all cache refs    </span></span><br><span class="line"></span><br><span class="line">      12.290852528 seconds time elapsed</span><br></pre></td></tr></table></figure>

<p>当然，perf支持很多事件，包括进程上下文切换等，上面的<code>cache-references,cache-misses</code>两个事件分别代表缓存命中和未命中。perf支持的事件很多，如下表所示：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">branch-instructions OR branches                    [Hardware event]</span><br><span class="line">branch-misses                                      [Hardware event]</span><br><span class="line">bus-cycles                                         [Hardware event]</span><br><span class="line">cache-misses                                       [Hardware event]</span><br><span class="line">cache-references                                   [Hardware event]</span><br><span class="line">cpu-cycles OR cycles                               [Hardware event]</span><br><span class="line">instructions                                       [Hardware event]</span><br><span class="line">ref-cycles                                         [Hardware event]</span><br><span class="line"></span><br><span class="line">alignment-faults                                   [Software event]</span><br><span class="line">context-switches OR cs                             [Software event]</span><br><span class="line">cpu-clock                                          [Software event]</span><br><span class="line">cpu-migrations OR migrations                       [Software event]</span><br><span class="line">dummy                                              [Software event]</span><br><span class="line">emulation-faults                                   [Software event]</span><br><span class="line">major-faults                                       [Software event]</span><br><span class="line">minor-faults                                       [Software event]</span><br><span class="line">page-faults OR faults                              [Software event]</span><br><span class="line">task-clock                                         [Software event]</span><br><span class="line"></span><br><span class="line">L1-dcache-load-misses                              [Hardware cache event]</span><br><span class="line">L1-dcache-loads                                    [Hardware cache event]</span><br><span class="line">L1-dcache-stores                                   [Hardware cache event]</span><br><span class="line">L1-icache-load-misses                              [Hardware cache event]</span><br><span class="line">LLC-load-misses                                    [Hardware cache event]</span><br><span class="line">LLC-loads                                          [Hardware cache event]</span><br><span class="line">LLC-store-misses                                   [Hardware cache event]</span><br><span class="line">LLC-stores                                         [Hardware cache event]</span><br><span class="line">branch-load-misses                                 [Hardware cache event]</span><br><span class="line">branch-loads                                       [Hardware cache event]</span><br><span class="line">dTLB-load-misses                                   [Hardware cache event]</span><br><span class="line">dTLB-loads                                         [Hardware cache event]</span><br><span class="line">dTLB-store-misses                                  [Hardware cache event]</span><br><span class="line">dTLB-stores                                        [Hardware cache event]</span><br><span class="line">iTLB-load-misses                                   [Hardware cache event]</span><br><span class="line">iTLB-loads                                         [Hardware cache event]</span><br><span class="line">node-load-misses                                   [Hardware cache event]</span><br><span class="line">node-loads                                         [Hardware cache event]</span><br><span class="line">node-store-misses                                  [Hardware cache event]</span><br><span class="line">node-stores                                        [Hardware cache event]</span><br></pre></td></tr></table></figure>

<p>使用perf来定位程序性能的瓶颈是个有效的办法！ 下一篇我们来讨论怎样写出能利用好CPU缓存的代码。</p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>ALU</tag>
        <tag>cpu</tag>
        <tag>cpu cache line</tag>
        <tag>cpu缓存</tag>
        <tag>intel</tag>
        <tag>perf</tag>
        <tag>smart cache</tag>
        <tag>多核</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链开源实现fabric快速部署及CLI体验</title>
    <url>/2018/05/22/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0fabric%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E5%8F%8Acli%E4%BD%93%E9%AA%8C/</url>
    <content><![CDATA[<p>本文描述fabric快速部署的步骤，及演示基于官方example02的智能合约进行CLI命令行体验。区块链涉及服务很多，且大量使用docker容器技术，所以请严格遵守以下步骤去部署，以减少各种问题的出现，方便我们先对联盟链有个大概的感觉。本文描述环境是centos7操作系统，请其他版本更正相关的安装工具（如ubuntu操作系统请把yum命令换成apt-get）。</p>
<span id="more"></span>
<h1 id="1、搭建e2e-cli环境快速部署fabric的11个步骤："><a href="#1、搭建e2e-cli环境快速部署fabric的11个步骤：" class="headerlink" title="1、搭建e2e_cli环境快速部署fabric的11个步骤："></a>1、搭建e2e_cli环境快速部署fabric的11个步骤：</h1><p>1、安装docker_ce版。 如果已经安装了老版docker，请先卸载。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum remove docker docker-common docker-selinux docker-engine</span><br></pre></td></tr></table></figure>

<p>再来安装docker：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">sudo yum-config-manager --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">sudo yum-config-manager --enable docker-ce-edge</span><br><span class="line">sudo yum-config-manager --enable docker-ce-test</span><br><span class="line">sudo yum-config-manager --disable docker-ce-edge</span><br><span class="line">sudo yum makecache fast</span><br><span class="line">sudo yum install docker-ce</span><br></pre></td></tr></table></figure>

<p>最后启动docker服务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service docker start</span><br><span class="line">chkconfig docker on</span><br></pre></td></tr></table></figure>

<p>2、配置好docker加速器。 官方docker非常慢，请一定在阿里云等提供docker仓库加速器的网站注册好帐户(比如<a href="https://cr.console.aliyun.com/#/accelerator">https://cr.console.aliyun.com/#/accelerator</a>)，配置好加速器。 3、安装好pip。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install python-pip -y</span><br></pre></td></tr></table></figure>

<p>4、用pip安装docker-compose。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install docker-compose</span><br></pre></td></tr></table></figure>

<p>5、新建存放测试、部署代码的目录。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;opt&#x2F;gopath&#x2F;src&#x2F;github.com&#x2F;hyperledger</span><br></pre></td></tr></table></figure>

<p>6、安装git。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install git -y</span><br></pre></td></tr></table></figure>

<p>7、拉取fabric代码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;gopath&#x2F;src&#x2F;github.com&#x2F;hyperledger</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;hyperledger&#x2F;fabric.git</span><br></pre></td></tr></table></figure>

<p><strong>请切换到最新的1.1分支上。</strong> 8、拉取docker镜像（时间较长）及一些可执行文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;opt&#x2F;gopath&#x2F;src&#x2F;github.com&#x2F;hyperledger&#x2F;fabric&#x2F;scripts&#x2F;bootstrap.sh</span><br></pre></td></tr></table></figure>

<p>9、安装go语言。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install golang -y</span><br></pre></td></tr></table></figure>

<p>并通过在/etc/profile最后追加两行设置好工作目录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin</span><br><span class="line">export GOPATH&#x3D;&#x2F;opt&#x2F;gopath</span><br></pre></td></tr></table></figure>

<p>最后执行下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

<p>10、<strong>修改一个阻塞执行的bug</strong>。（注：fabric最新代码已修复该bug，若你拉取了最新代码，请忽略该步骤！） 修改/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli/base/peer-base.yaml文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">将：</span><br><span class="line">- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE&#x3D;e2ecli_default</span><br><span class="line">修改为：</span><br><span class="line">- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE&#x3D;e2e_cli_default</span><br></pre></td></tr></table></figure>

<p>11、启动服务。 进入/opt/gopath/src/github.com/hyperledger/fabric/examples/e2e_cli目录，执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash network_setup.sh up</span><br></pre></td></tr></table></figure>

<p>如果最后出现下图则部署成功： <img src="/2018/05/fabric_cliexe%E4%BE%8B%E5%AD%90-3.jpg"></p>
<h1 id="2、体验fabric系统功能"><a href="#2、体验fabric系统功能" class="headerlink" title="2、体验fabric系统功能"></a>2、体验fabric系统功能</h1><p>当服务在一台server上启动后，可以看到以下docker实例： <img src="/2018/05/fabric_cliexe-docker%E5%AE%9E%E4%BE%8B-1.jpg"> 可以看到，默认安装了：4个peer（2个是org1的，2个是org2的）节点、4节点构成的kafka集群、3节点构成的zookeeper集群、1个orderer节点。这是因为：fabric提供的共识机制，PBFT目前还未达到生产级别的应用，只能靠kafka+zookeeper实现PAXOS算法下的共识机制（不能有作恶结点）。一般zookeeper是3或者5个结点， fabric提供了SDK和CLI两种交互方式，本文不讨论SDK。 可以进入cli里执行peer命令。如果cli长时间未用退出后，可先启动cli：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker start cli</span><br></pre></td></tr></table></figure>

<p>再进入cli实例里：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it cli bash</span><br></pre></td></tr></table></figure>

<p>接着可执行peer命令，体验区块链的命令行使用方式。</p>
<h2 id="2-1、-peer命令"><a href="#2-1、-peer命令" class="headerlink" title="2.1、 peer命令"></a>2.1、 peer命令</h2><p>peer命令含有五个子命令，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">peer chaincode [option] [flags]</span><br><span class="line">peer channel   [option] [flags]</span><br><span class="line">peer logging   [option] [flags]</span><br><span class="line">peer node      [option] [flags]</span><br><span class="line">peer version   [option] [flags]</span><br></pre></td></tr></table></figure>

<p>每个子命令可使用–help查看详细帮助。 在fabric里，所有的交易必须通过智能合约才能操作，而chaincode链码就是智能合约。chaincode支持以下option操作：</p>
<ul>
<li>  package 智能合约需要打包后才能使用</li>
<li>  install    智能合约必须安装后才能使用</li>
<li>  instantiate   置初始状态。比如设系统一开始用户a有100元，用户b有200元</li>
<li>  invoke  调用智能合约</li>
<li>  query    查询状态</li>
<li>  signpackage  包签名</li>
<li>  upgrade    智能合约升级</li>
<li>  list        显示智能合约</li>
</ul>
<p>智能合约需要先install才能使用。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">peer chaincode install -n mycc -v 1.0 -p github.com&#x2F;hyperledger&#x2F;fabric&#x2F;examples&#x2F;chaincode&#x2F;go&#x2F;chaincode_example02</span><br></pre></td></tr></table></figure>

<p>其中-n表示合约名字，-p指向合约文件目录路径，-v是版本号。</p>
<h2 id="2-2-example02智能合约"><a href="#2-2-example02智能合约" class="headerlink" title="2.2 example02智能合约"></a>2.2 example02智能合约</h2><p>每个智能合约实现Init和Invoke两个方法，其中前者用于初始化，后者是日常调用。</p>
<h3 id="2-2-1-初始化"><a href="#2-2-1-初始化" class="headerlink" title="2.2.1 初始化"></a>2.2.1 初始化</h3><p>example02的Init方法接收4个参数(<code>包括帐户A，余额pA，帐户B，余额pB</code>)，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">peer chaincode instantiate -o orderer.example.com:7050 -C mychannel -n mycc -v 1.0 -c &#39;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]&#125;&#39; -P &quot;OR    (&#39;Org1MSP.peer&#39;,&#39;Org2MSP.peer&#39;)&quot;</span><br></pre></td></tr></table></figure>

<p>其中，-C指向channel名字，-c则是初始构造json格式的消息，-P是背书策略，-o指定共识节点。这里置帐户a初始余额为100，帐户b初始余额为200。其代码实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response &#123;</span><br><span class="line">fmt.Println(&quot;ex02 Init&quot;)</span><br><span class="line">        &#x2F;&#x2F;用args取得命令行的参数</span><br><span class="line">_, args :&#x3D; stub.GetFunctionAndParameters()</span><br><span class="line">var A, B string    &#x2F;&#x2F; Entities</span><br><span class="line">var Aval, Bval int &#x2F;&#x2F; Asset holdings</span><br><span class="line">var err error</span><br><span class="line">      </span><br><span class="line">        &#x2F;&#x2F;简单的例子么，只接收4个参数，包括帐户A，余额pA，帐户B，余额pB</span><br><span class="line">if len(args) !&#x3D; 4 &#123;</span><br><span class="line">return shim.Error(&quot;Incorrect number of arguments. Expecting 4&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Initialize the chaincode</span><br><span class="line">A &#x3D; args[0]</span><br><span class="line">Aval, err &#x3D; strconv.Atoi(args[1])</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return shim.Error(&quot;Expecting integer value for asset holding&quot;)</span><br><span class="line">&#125;</span><br><span class="line">B &#x3D; args[2]</span><br><span class="line">Bval, err &#x3D; strconv.Atoi(args[3])</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return shim.Error(&quot;Expecting integer value for asset holding&quot;)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Printf(&quot;Aval &#x3D; %d, Bval &#x3D; %d\n&quot;, Aval, Bval)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;将A及其余额写入状态数据库</span><br><span class="line">err &#x3D; stub.PutState(A, []byte(strconv.Itoa(Aval)))</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return shim.Error(err.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;将B及其余额写入状态数据库</span><br><span class="line">err &#x3D; stub.PutState(B, []byte(strconv.Itoa(Bval)))</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return shim.Error(err.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return shim.Success(nil)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-查询余额"><a href="#2-2-2-查询余额" class="headerlink" title="2.2.2 查询余额"></a>2.2.2 查询余额</h3><p>接着查询余额，例如查询a帐户的余额：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">peer chaincode query -C mychannel -n mycc -c &#39;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&#39;</span><br></pre></td></tr></table></figure>

<p>这里需要说明，example02的Invoke共支持3种指令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response &#123;</span><br><span class="line">fmt.Println(&quot;ex02 Invoke&quot;)</span><br><span class="line">function, args :&#x3D; stub.GetFunctionAndParameters()</span><br><span class="line">if function &#x3D;&#x3D; &quot;invoke&quot; &#123;</span><br><span class="line">&#x2F;&#x2F; 从A向B帐户转账</span><br><span class="line">return t.invoke(stub, args)</span><br><span class="line">&#125; else if function &#x3D;&#x3D; &quot;delete&quot; &#123;</span><br><span class="line">&#x2F;&#x2F; 从状态数据库中删除帐户</span><br><span class="line">return t.delete(stub, args)</span><br><span class="line">&#125; else if function &#x3D;&#x3D; &quot;query&quot; &#123;</span><br><span class="line">&#x2F;&#x2F; 查询状态数据库中某帐户的余额</span><br><span class="line">return t.query(stub, args)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return shim.Error(&quot;Invalid invoke function name. Expecting \&quot;invoke\&quot; \&quot;delete\&quot; \&quot;query\&quot;&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因此，上述查询我们会得出类似结果： <img src="/2018/05/fabric-cli-example02-query-3.jpg"> 为何结果格式是这样的呢？看下t.query的实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">func (t *SimpleChaincode) query(stub shim.ChaincodeStubInterface, args []string) pb.Response &#123;</span><br><span class="line">var A string &#x2F;&#x2F; Entities</span><br><span class="line">var err error</span><br><span class="line"></span><br><span class="line">if len(args) !&#x3D; 1 &#123;</span><br><span class="line">return shim.Error(&quot;Incorrect number of arguments. Expecting name of the person to query&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">A &#x3D; args[0]  &#x2F;&#x2F;获取帐户的名字</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 从状态数据库中获取帐户的值</span><br><span class="line">Avalbytes, err :&#x3D; stub.GetState(A)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">jsonResp :&#x3D; &quot;&#123;\&quot;Error\&quot;:\&quot;Failed to get state for &quot; + A + &quot;\&quot;&#125;&quot;</span><br><span class="line">return shim.Error(jsonResp)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if Avalbytes &#x3D;&#x3D; nil &#123;</span><br><span class="line">jsonResp :&#x3D; &quot;&#123;\&quot;Error\&quot;:\&quot;Nil amount for &quot; + A + &quot;\&quot;&#125;&quot;</span><br><span class="line">return shim.Error(jsonResp)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">jsonResp :&#x3D; &quot;&#123;\&quot;Name\&quot;:\&quot;&quot; + A + &quot;\&quot;,\&quot;Amount\&quot;:\&quot;&quot; + string(Avalbytes) + &quot;\&quot;&#125;&quot;</span><br><span class="line">        &#x2F;&#x2F;这里是显示在命令行的格式：Query Response:90</span><br><span class="line">fmt.Printf(&quot;Query Response:%s\n&quot;, jsonResp)</span><br><span class="line">return shim.Success(Avalbytes)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-转帐"><a href="#2-2-3-转帐" class="headerlink" title="2.2.3 转帐"></a>2.2.3 转帐</h3><p>比如由B向A转帐50：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">peer chaincode invoke -o orderer.example.com:7050  --tls true --cafile &#x2F;opt&#x2F;gopath&#x2F;src&#x2F;github.com&#x2F;hyperledger&#x2F;fabric&#x2F;peer&#x2F;crypto&#x2F;ordererOrganizations&#x2F;example.com&#x2F;orderers&#x2F;orderer.example.com&#x2F;msp&#x2F;tlscacerts&#x2F;tlsca.example.com-cert.pem  -C mychannel -n mycc -c &#39;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;b&quot;,&quot;a&quot;,&quot;50&quot;]&#125;&#39;</span><br></pre></td></tr></table></figure>

<p>成功后我们会在输屏结果中找到这一行：ESCC invoke result: version:1 response:&lt;status:200 message:”OK” &gt; 其实现为从A和B帐户下用GetStat方法从状态数据库取出余额，与query类似，接着加减相应的值50后，再调用PutStat方法写入状态数据库。 此时我们可以再次查询，可以获得正确结果。   小结：以上只适用于简单体验fabric的功能，对于智能合约、共识算法、世界状态等在接下来的文章中我们再分析。</p>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>fabric</tag>
        <tag>hyperledger</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链开源实现hyperledger fabric架构详解</title>
    <url>/2018/05/26/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0hyperledger-fabric%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>hyperledger fabric是区块链中联盟链的优秀实现，主要代码由IBM、Intel、各大银行等贡献，目前v1.1版的kafka共识方式可达到1000/s次的吞吐量。本文中我们依次讨论：区块链的共通特性、fabric核心概念、fabric的交易执行流程。本文来源于笔者欲对公司部分业务上链而进行培训的PPT，故图多文字少，不要怕太长。</p>
<span id="more"></span>
<h1 id="1、区块链解决方案的特性"><a href="#1、区块链解决方案的特性" class="headerlink" title="1、区块链解决方案的特性"></a>1、区块链解决方案的特性</h1><h2 id="1-1-分布式帐本"><a href="#1-1-分布式帐本" class="headerlink" title="1.1 分布式帐本"></a>1.1 分布式帐本</h2><p>区块链核心概念是分布式帐本，就像下面的图1所示，同样的帐本（全量的交易数据，详见下节）在任意一台节点（不包括客户端）上都有。所以，其优点是数据很难造假，造假后也可以通过追溯记录来追究法律责任。而缺点就是极大的浪费，传统服务每份数据都尽量少存几份，即使存了三份拷贝都已经考虑到诸多异常，并使服务可用性达到N个9了。而区块链这种特性，同时造成的另一个问题是帐本不能太大，至少不能超过区块链网络中最小结点的存储以及处理能力。所以，这制约了总交易数据（下文为方便概念介绍，统称为帐本ledger）的条数，进而也影响了能写入区块链的单条交易数据的大小。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/unnamed-file-3.png"> 图1 区块链分布式帐本示意图 什么是区块链呢？我很喜欢《区块链技术进阶与实战》一书中对它的定义：区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构。如果觉得有点抽象，那么我们再来看看下面的图2。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/unnamed-file-4.jpg"> 图2-区块链数据结构示意 图2中就是账本，它由多个区块构成了一个有时序的链表，而每个区块里含有多条交易trasaction（缩写为tx）构成的链表。图2下方有一个WorldState世界状态，这其实是为了提升性能用的。比如，key1共交易了10000次，为了获取它的当前状态值，需要正向执行这10000次交易，这就得不偿失了。如果这1万次交易里，每次新交易执行完，都同步更新一个数据库（在fabric里用的是levelDB），这样查询当前状态时，只需要查询该数据库即可，如图3所示。 <img src="/2018/05/fabric-levelDB%E7%8A%B6%E6%80%81%E6%95%B0%E6%8D%AE%E5%BA%93-2.jpg"> 图3-fabric levelDB状态数据库 图3中，区块链帐本是在FileSystem文件系统中保存的，而Level DB存放世界状态。</p>
<h2 id="1-2-智能合约smart-contract"><a href="#1-2-智能合约smart-contract" class="headerlink" title="1.2 智能合约smart contract"></a>1.2 智能合约smart contract</h2><p>区块链的发展过程中，一般1.0时代就是数字货币时代，代表是比特币，而2.0时代就是智能合约（现在是3.0时代，各种联盟链即为代表）。 智能合约是运行在区块链上的模块化、可重用的自动执行脚本，有了它我们就可以完成复杂的业务逻辑，例如同一个区块链上有多份合约，而每份合约可以约定不同的参与者（企业或者相关方）。也可以指定每份合约里每个子命令做一批特定的事，大家可以把它想象成关系数据库里的事务。如图4所示，我们可以在合约里指定允许哪些企业的节点可以参与到交易流程中来（在fabric里这叫共识策略）。 <img src="/2018/05/unnamed-file-1-4.png"> 图4-智能合约图示 在fabric中，智能合约叫做chaincode，它有6个状态，如下所示：</p>
<ul>
<li>  Install → Instantiate → invocable → Upgrade → Deinstantiate → Uninstall.</li>
</ul>
<p>实际上智能合约就是一段代码，fabric官方认可的是GO语言。首先我们需要把合约代码上传到区块链上，这一步的状态就叫Install。 接着，需要做初始化操作。比如，现在的数据是存放在mysql中的，那么上线时需要用Instantiate把数据迁移至链上，这也算初始化。初始化后，chaincode就进入invocable可调用状态了。 通用我们可以通过CLI命令行或者程序里用SDK调用合约（v1.1前还有RestApi调用，现已放弃）。 联盟链由于跨多家企业、多个地区甚至国家，很难使得合约保持一致的版本，因此，每个合约都有版本号。而版本升级时，就是Upgrade状态。 最后两个状态对应着合约下链。 智能合约可以在供应链等较复杂的业务场景下起到很大的作用，如下面的图5所示： <img src="/2018/05/unnamed-file-1-2.jpg"> 图5-智能合约技术的应用示意</p>
<h2 id="1-3-数据一致性（共识算法）"><a href="#1-3-数据一致性（共识算法）" class="headerlink" title="1.3 数据一致性（共识算法）"></a>1.3 数据一致性（共识算法）</h2><p>既然区块链是一个去中心化的分布式系统，那么自然只能通过投票来决定一致性了：少数服从多数。当然，多少算多数呢？不同的共识算法下，结果并不相同。比如paxos算法（参见笔者的《<a href="https://www.taohui.pub/paxos%e7%ae%97%e6%b3%95%e5%a6%82%e4%bd%95%e5%ae%b9%e9%94%99%e7%9a%84-%e8%ae%b2%e8%bf%b0%e4%ba%94%e8%99%8e%e5%b0%86%e7%9a%84%e5%ae%9e%e8%b7%b5/">paxos算法如何容错的–讲述五虎将的实践</a>》）就是超过一半，而PBFT则需要三分之二以上。 这里有一个拜占庭将军问题需要注意，如何理解该问题可以参见这份翻译过的<a href="http://www.taohui.pub/wp-content/uploads/2018/05/The_Part-Time_ParliamentPaxos%E7%AE%97%E6%B3%95%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91-3.pdf">The_Part-Time_Parliament(Paxos算法中文翻译)</a>文档。简言之，就是投票的拜占庭将军（服务器）们有2种不可靠的形式。第一是迟钝（数据包延迟）、失忆（数据包丢失以及数据包重发）、失踪（服务器宕机）等不含背叛的行为，第二则是有将军是间谍（服务器被攻破）。如paxos这样的算法属于第一种，Fault-tolerance，它不能容忍服务器上有恶意代码；而如PBFT(Practical Byzantine Fault Tolerance)这样的算法是第二类，Byzantine-Fault-tolerance，它能够容忍一定数量的拜占庭将军节点存在，如PBFT、SBFT、RBFT算法等。 第二类Byzantine-Fault-tolerance共识算法虽然看上去很美，但并不成熟，特别是性能低下，比如PBFT是一个多项式复杂度的算法O(N^2)，节点过多时（大于100）性能急骤下降。第一类通常是O(N)复杂度，在某些场景下使用效果还不错，比如fabric v1.1的kafka共识机制就是这样的算法，下文我们会详述。 像比特币、以太坊等采用的共识算法又有所不同，例如比特币的POW工作量证明算法，它定义一小时内（通过调整运算难度实现，比如调整近似程度）有一个lucky node节点，该节点是通过证明自身的努力（hash值逆解）而幸运选出，选出后它就可以为这段时间的交易做决定（似乎挺像总统选举^_^）。详情参见我这篇文章：<a href="https://www.taohui.pub/%e5%8c%ba%e5%9d%97%e9%93%be%e6%8a%80%e6%9c%af%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/">《区块链技术学习笔记》</a></p>
<h2 id="1-4-非对称加密"><a href="#1-4-非对称加密" class="headerlink" title="1.4 非对称加密"></a>1.4 非对称加密</h2><p>区块链通过非对称加密技术实现身份验证与数据加密。其实就是我们日常在用的SSL技术。 为了方便理解，我们需要先介绍PKI(Public Key Infrastructure)，它是一种遵循标准的利用公钥加密技术为电子商务的开展提供一套安全基础平台的技术和规范。有一个CA（Certificate Authority）权威机构负责向用户（包括服务提供者与使用者）提供数字证书，包括公钥与私钥，同时CA机构还需要提供一个CRL（Certificate Revocation List）证书吊销列表，如下面的图6所示。 <img src="/2018/05/PKI%E8%AF%81%E4%B9%A6%E7%A4%BA%E6%84%8F-1.png"> 图6-CA机构颁发数字证书以及提供CAL 这样，区块链可以通过PKI体系实现安全认证。PKI有三个关键点，我们下面详述。</p>
<h3 id="1-4-1-数字证书-Digital-Certificate"><a href="#1-4-1-数字证书-Digital-Certificate" class="headerlink" title="1.4.1 数字证书 Digital Certificate"></a>1.4.1 数字证书 Digital Certificate</h3><p>比如Mary Morris符合X.509规范的数字证书里，其Subject属性里就含有她的信息，包括国家C=US、所属的州或者省份ST=Michigan、所在城市L=Detroit、所属单位O=Mitchesll Cars、其他信息OU=Manufacturing、公用信息CN=Mary Morris/UID=123456等，也含有其他信息，如下面的图7所示。 <img src="/2018/05/PKI%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6-2.png"> 图7-PKI数字证书</p>
<h3 id="1-4-2-公钥与私钥"><a href="#1-4-2-公钥与私钥" class="headerlink" title="1.4.2 公钥与私钥"></a>1.4.2 公钥与私钥</h3><p>CA颁发了两个证书：公钥与私钥，其中，私钥仅服务提供者保存，而公钥则可被所有人（服务使用者）保存。 所谓非对称加密，就是公钥加密的消息仅私钥可以解密；同理，私钥加密的消息，仅公钥可以解密。对应于前者，可以实现客户端访问服务器时加密消息，例如访问安全级别高的页面时提交的表单信息都需要用公钥加密，确保只有服务器才能解密网络报文。对应于后者，则可实现签名功能，如下面的图8所示。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/PKI%E5%85%AC%E7%A7%81%E9%92%A5-1.png"> 图8-PKI中私钥签名后用公钥验签名 图8中Mary Morris用私钥对一段信息的内容（若内容过大则可先HASH后获得小点的字符串）加密后，生成签名附加在消息中。接收者可从CA机构获取到公钥，用公钥解密签名后，再与内容比对，以确定消息是否来自MaryMorris及内容是否被篡改。对于文件来说也是一样，小文件直接加密，大文件先生成hash再对hash加密，如下面的图9所示。   <img src="/2018/05/unnamed-file-2-2.jpg"> 图9-对文件的签名</p>
<h3 id="1-4-3-证书信任链"><a href="#1-4-3-证书信任链" class="headerlink" title="1.4.3 证书信任链"></a>1.4.3 证书信任链</h3><p>CA证书分为两类：RCA(Root CA)根证书以及ICA（Intermediate CA）中间证书。这些证书由RCA开始构成一个证书信任链，如下面的图10所示。 <img src="/2018/05/PKI%E8%AF%81%E4%B9%A6%E4%BF%A1%E4%BB%BB%E9%93%BE-1.png"> 图10-CA证书信任链条 有许多CA证书权威机构，各自有其RCA。如果RCA得不到信任，那么其下的ICA也无法认证通过。 当然，自己的服务器也可以生成RCA。 在Fabric里，允许不同的企业使用不同的RCA，也可以使用相同的RCA和不同的ICA。这与下文中的MSP密切相关。</p>
<h2 id="1-5-小结"><a href="#1-5-小结" class="headerlink" title="1.5 小结"></a>1.5 小结</h2><p>我们来总结下区块链，它主要是为了解决社会上的信任问题而存在的，为此，它付出了沉重的性能、可用性代价。它怎么做到的呢？通过4点实现：1、数据到处存放；2、操作记录不可更改；3、传输数据可信；4、业务脚本约束。 那么，这个信任问题的解决，带来了2个非功能性的约束：数据一致性和可用性。其中可用性包括两点：1、交易在可接受的时间内达成。比如比特币的分叉就会造成严重问题。2、吞吐量达标。而比特币每秒只能有7次交易，这显然太低了。</p>
<h1 id="2、fabric核心概念"><a href="#2、fabric核心概念" class="headerlink" title="2、fabric核心概念"></a>2、fabric核心概念</h1><p>hyperledger fabric符合上面说过的区块链的所有特性。我们必须先了解它的一些概念，才能进一步理解其架构设计。由于英文资料居多，所以这些概念我都以英文描述为准：</p>
<ul>
<li>  chaincode：智能合约，上文已提到。每个chaincode可提供多个不同的调用命令。</li>
<li>  transaction：交易，每条指令都是一次交易。</li>
<li>  world state：对同一个key的多次交易形成的最终value，就是世界状态。</li>
<li>  endorse：背书。金融上的意义为：指持票人为将票据权利转让给他人或者将一定的票据权利授予他人行使，而在票据背面或者粘单上记载有关事项并签章的行为。通常我们引申为对某个事情负责。在我们的共识机制的投票环节里，背书意味着参与投票。</li>
<li>  endorsement policy：背书策略。由智能合约chaincode选择哪些peer节点参与到背书环节来。</li>
<li>  peer：存放区块链数据的结点，同时还有endorse和commit功能。</li>
<li>  channel：私有的子网络，事实上是为了隔离不同的应用，一个channel可含有一批chaincode。</li>
<li>  PKI：Public Key Infrastructure，一种遵循标准的利用公钥加密技术为电子商务的开展提供一套安全基础平台的技术和规范。</li>
<li>  MSP：Membership Service Provider，联盟链成员的证书管理，它定义了哪些RCA以及ICA在链里是可信任的，包括定义了channel上的合作者。</li>
<li>  org：orginazation，管理一系列合作企业的组织。</li>
</ul>
<h2 id="2-1-开发概念"><a href="#2-1-开发概念" class="headerlink" title="2.1 开发概念"></a>2.1 开发概念</h2><p>fabric联盟链的开发人员主要分为三类：底层是系统运维，负责系统的部署与维护；其次是组织管理人员，负责证书、MSP权限管理、共识机制等；最后是业务开发人员，他们负责编写chaincode、创建维护channel、执行transaction交易等，如下面的图11所示。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/fabric%E5%88%86%E5%B1%82%E8%A7%86%E8%A7%92-1.png"> 图11-fabric技术人员的分层 fabric大致分为底层的网络层、权限管理模块、区块链应用模块，通过SDK和CLI对应用开发者提供服务，如下面的图12所示。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/fabric%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84-1.png"> 图12-fabric开发模块图 我们的开发流程主要包括写智能合约，以及通过SDK调用智能合约，及订阅各类事件，如图13所示。 <img src="/2018/05/fabric%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B-2.jpg"> 图13-开发环节</p>
<h2 id="2-2-MSP"><a href="#2-2-MSP" class="headerlink" title="2.2 MSP"></a>2.2 MSP</h2><p>每个管理协作企业的ORG组织都可以拥有自己的MSP。如下图14所示，组织ORG1拥有的MSP叫ORG1.MSP，而组织ORG2业务复杂，所以维护了3个MSP。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/MSP%E4%B8%8E%E7%BB%84%E7%BB%87%E9%97%B4%E5%85%B3%E7%B3%BB-1.png"> 图14-ORG可管理自己的MSP MSP出现在两个地方：在channel上有一个全局的MSP，而每个peer、orderer、client等角色上都维护有本地的局部MSP，如图15所示。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/MSP%E6%9C%AC%E5%9C%B0%E4%B8%8Echannel-3.png"> 图15-在channel上的Global MSP以及在参与角色上的Local MSP 本地MSP只保存有Global MSP上的子集，内容保存在本地文件系统上，而全局MSP可在逻辑上认为是配置在系统上的，它实际也在每个参与者上保存一份拷贝，但会维持一致性。 MSP也分级，如图16中所示，底层的network MSP负责网络层的准入，其MSP由ORG1拥有，而上面的某个channel的MSP则由ORG1和ORG2共同管理。 <img src="http://www.taohui.pub/wp-content/uploads/2018/05/MSP-levels-1.png"> 图16-MSP是分级的 一个MSP下含有以下结构，如图17所示。 <img src="/2018/05/MSP-structure-1.png"> 图17-MSP结构 可见，MSP结构包括：</p>
<ul>
<li>  RCA根证书</li>
<li>  ICA中间证书</li>
<li>  OU组织单位</li>
<li>  管理员证书</li>
<li>  RCL吊销证书列表</li>
<li>  结点上的具体证书</li>
<li>  存储私钥的keystore</li>
<li>  TLS的根证书与中间证书</li>
</ul>
<h1 id="3、fabric交易提交流程"><a href="#3、fabric交易提交流程" class="headerlink" title="3、fabric交易提交流程"></a>3、fabric交易提交流程</h1><p> </p>
<h2 id="3-1-peer结点的部署"><a href="#3-1-peer结点的部署" class="headerlink" title="3.1 peer结点的部署"></a>3.1 peer结点的部署</h2><p>peer结点上保存有账本ledger以及智能合约，如下图所示： <img src="http://www.taohui.pub/wp-content/uploads/2018/05/fabric-blockchain-network-2.png"> channel是一个逻辑概念，可以通过MSP隔离全网不同组织的参与者，如下图所示： <img src="http://www.taohui.pub/wp-content/uploads/2018/05/fabric-peer%E4%B8%8Echannel-3.png"> 当有多方参与者时，例如4个org组织、8个peer结点时，其中channel连接了P1、P3、P5、P7、P8这五个节点，其他3个节点加入了其他channel，其部署图如下所示： <img src="http://www.taohui.pub/wp-content/uploads/2018/05/fabric-peer%E4%B8%8E%E4%B8%8D%E5%90%8C%E7%BB%84%E7%BB%87-3.png"> 加入MSP来管理身份时，如P1和P2由ORG1.MSP管理，而P3和P4的证书则由ORG2.MSP管理，他们共同使用一个channel，则如下图所示： <img src="/2018/05/fabric-peer%E4%B8%8E%E8%BA%AB%E4%BB%BD-2.png"></p>
<h2 id="3-2-交易的执行流程"><a href="#3-2-交易的执行流程" class="headerlink" title="3.2 交易的执行流程"></a>3.2 交易的执行流程</h2><p>去中心化的设计，必然需要通过投票（多数大于少数）来维持数据一致性，而任何投票都必须经历以下三个过程：</p>
<ol>
<li> 有一方先提出议案proposal，该议案有对应的一批投票者需要对该结果背书，这些投票者依据各自的习惯投票，并将结果反馈；</li>
<li> 统计投票结果，若获得多数同意，才能进行下一步；</li>
<li> 将获得多数同意的议案记录下来，且公之于众。</li>
</ol>
<p>而这三步fabric当然也少不了，当然它的称法就有所不同，其对应的三步如下：</p>
<ol>
<li> 由client上的CLI或者SDK进行proposal议案的提出。client会依据智能合约chaincode根据背书策略endorse policy决定把proposal发往哪些背书的peer节点，而peer节点进行投票，client汇总各背书节点的结果；</li>
<li> client将获得多数同意的议案连同各peer的背书（包括其投票结果以及背书签名）交给orderring service，而orderer会汇总各client递交过来的trasaction交易，排序、打包。</li>
<li> orderer将交易打包成区块block，然后通知所有commit peer，各peer各自验证结果，最后将区块block记录到自己的ledger账本中。</li>
</ol>
<p>我们看一个具体的例子，若channel上有三个peer背书者，client提交流程如下图所示： <img src="/2018/05/Illustration-of-one-possible-transaction-flow-2.png"> 详细解释下上图的流程：</p>
<ol>
<li> 首先，client发起一个transaction交易，含有&lt;clientID, chaincodeID, txPayLoad, timestamp, clientSig&gt;等信息，指明了3W要素：消息是谁who在什么时间when发送了什么what。该消息根据chaincode中的背书策略，发向EP1、EP2、EP3这三个peer节点。</li>
<li> 这三个peer节点模拟执行智能合约，并将结果及其各自的CA证书签名发还client。client收集到足够数量的结果后再进行下一步。</li>
<li> client将含背书结果的tx交易发向ordering service。</li>
<li> ordering service将打包好的block交给committing peer CP1以及EP1、EP2、EP3这三个背书者，背书者此时会校验结果并写入世界状态以及账本中。同时，client由于订阅了消息，也会收到通知。 如果我们从编程的角度来看，则流程会更清楚：</li>
</ol>
<p><img src="/2018/05/fabric%E8%AF%B7%E6%B1%82%E8%BF%9E%E6%8E%A5%E5%9B%BE-1.png"> 参见上图，A是我们的应用程序，其步骤如下：</p>
<ol>
<li> A首先连接到peer。</li>
<li> A调用chaincode发起proposal；与此同时，P1收到后先模拟执行，再产生结果返回给A。</li>
<li> A收到各peer返回的结果。</li>
<li> A向O1发起交易；与此同时，O1产生区块后会通知peer，而peer会更新其账本。</li>
<li> 最后通过订阅事件A收到了结果。</li>
</ol>
<p>最后再细看下这三个阶段。</p>
<h3 id="3-2-1-proposal提案阶段"><a href="#3-2-1-proposal提案阶段" class="headerlink" title="3.2.1 proposal提案阶段"></a>3.2.1 proposal提案阶段</h3><p><img src="/2018/05/fabric%E5%85%B1%E8%AF%86%E6%8F%90%E6%A1%88%E9%98%B6%E6%AE%B5-1.png"> 可以看到，A1发出的&lt;T1, P&gt;，收到了&lt;T1, R1, E1&gt;和&lt;T1, R2, E2&gt;两个结果。</p>
<h3 id="3-2-2-package打包阶段"><a href="#3-2-2-package打包阶段" class="headerlink" title="3.2.2 package打包阶段"></a>3.2.2 package打包阶段</h3><p><img src="/2018/05/fabric%E5%85%B1%E8%AF%86%E6%89%93%E5%8C%85%E9%98%B6%E6%AE%B5-1.png"> O1在一个channel上会收到许多T交易，它会将T排序，在达到block的最大大小（一般应配1M以下，否则性能下降严重，kafka擅长处理小点的消息）或者达到超时时间后，打成区块P2。</p>
<h3 id="3-2-3-验证阶段"><a href="#3-2-3-验证阶段" class="headerlink" title="3.2.3 验证阶段"></a>3.2.3 验证阶段</h3><p><img src="/2018/05/fabric%E5%85%B1%E8%AF%86%E9%AA%8C%E8%AF%81%E9%98%B6%E6%AE%B5-2.png"> O1将含有多条交易T打成区块的B2发往各peer节点，而P1和P2将B2加入各自的L账本中。</p>
<h1 id="4、小结"><a href="#4、小结" class="headerlink" title="4、小结"></a>4、小结</h1><p>本文偏重于概念的解释，由于篇幅所限，未涉及fabric的系统搭建（请参考笔者的这篇文章《<a href="https://www.taohui.pub/%e5%8c%ba%e5%9d%97%e9%93%be%e5%bc%80%e6%ba%90%e5%ae%9e%e7%8e%b0fabric%e5%bf%ab%e9%80%9f%e9%83%a8%e7%bd%b2%e5%8f%8acli%e4%bd%93%e9%aa%8c/">区块链开源实现fabric快速部署及CLI体验</a>》），也未描述共识算法在异常情况下如何维持一致性，这留待下一篇文章解决。fabric的许多思想是值得我们进一步研究的，其优秀的实现可以帮助我们通过fabric获得区块链在信任创新上的思路。</p>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>fabric</tag>
        <tag>hyperledger</tag>
        <tag>区块链</tag>
        <tag>chaincode</tag>
        <tag>channel</tag>
        <tag>MSP</tag>
        <tag>PKI</tag>
        <tag>公钥</tag>
        <tag>比特币</tag>
        <tag>私钥</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链技术学习笔记</title>
    <url>/2017/07/03/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>罗列了想到的6条学习笔记。</p>
<span id="more"></span>
<ol>
<li>区块链技术是一个解决了拜占庭将军（百度百科<a href="http://baike.baidu.com/link?url=AlDGv2eQB6dkraSO8TzN0XylxEfgSW_VN94FOooKYcJrYz9ttpRD1IRWnLA25tM_7QcK_kB_8IfINpYzdBMZcbw51ESxmr3tkC7r6O32EshJ_wL6PExj-UBUJCExD11CuFfoIfaRqzH04cVQAHKOamLbVqcKr-Y_NZhAj4wCNC3">拜占庭将军问题</a>）节点的分布式数据系统！这是它最大的不同，也导致了这个技术存在诸多限制。 为了方便理解，先插个话题。做服务器端开发的程序员，都对zookeeper不陌生，我们解决分布式ACP问题时，寻找一致性解决方案时都会想到它。zookeeper实际使用了paxos的简化版算法（本文不展开，请参考我之前写过的两篇文章：<a href="https://www.taohui.pub/2015/03/27/paxos%e5%88%86%e5%b8%83%e5%bc%8f%e4%b8%80%e8%87%b4%e6%80%a7%e7%ae%97%e6%b3%95-%e8%ae%b2%e8%bf%b0%e8%af%b8%e8%91%9b%e4%ba%ae%e7%9a%84%e5%8f%8d%e7%a9%bf%e8%b6%8a/">paxos分布式一致性算法–讲述诸葛亮的反穿越</a> 以及<a href="/2015/07/27/paxos%E7%AE%97%E6%B3%95%E5%A6%82%E4%BD%95%E5%AE%B9%E9%94%99%E7%9A%84-%E8%AE%B2%E8%BF%B0%E4%BA%94%E8%99%8E%E5%B0%86%E7%9A%84%E5%AE%9E%E8%B7%B5/">paxos算法如何容错的–讲述五虎将的实践</a>）。</li>
</ol>
<p>想搞明白比特币(成于区块链技术)的算法，应先弄明白paxos算法（便于对比），目前商用的方案中，我们都假定服务器内网是不能被攻破的，所以，我们主要解决的是网络传输的不可靠，包括丢包、重发、延迟等问题，以及服务进程的bug导致的服务宕机、重启等。如果内网被攻破，黑客恶意的在某个节点（服务器）伪造网络包，向正常节点发送有问题的数据包，这种场景通常是不考虑的。显然这很合理，企业内网间如果还做大量的安全验证，性能消耗就太大了，基于成本使得商业目标几乎无法达成。 而公有区块链则是不同的，比如目前最成功的比特币，它使用了POW工作量证明算法，这个算法允许网络中存在拜占庭节点！也就是说，网络中即使存在作恶的节点，只要这些作恶的节点小于总节点计算能力的50%，就还能保持一致性！当然这个一致性做得也不怎么样，可能存在分叉好一段时间（1小时甚至更高，其一致性的大小只能获得概率），而且数据的回滚非常糟糕。 </p>
<ol start="2">
<li><p>区块链技术的另一个核心特点是全量帐本。即，每一个节点都保持着全网数据！即，每个节点、每台电脑上都保存着所有的数据。多么恐怖的代价！每台电脑的存储容量是有限的，以网络中最差的那台电脑容量为限制，几十个G就差不多了。存储的浪费是很惊人的！所以，别指望非数字帐户的核心数据也能放到区块链网络上，或者仅放个索引，指向现在的网络存储设施。 当然，区块链的核心优势也是全量帐本，最好的也是最坏的！因为，每个节点都维护全量数据，所以，所有节点本质上都是对等的！即，或许这个区块链网络中既有银联的超级服务器，也有个人开发者的公有云小主机，但大家的数据是相同的，谁也不能说数据出问题了必须以我的为准！ 因此，全量帐本解决了社会信任问题！特别对于金融供应链来说，原本的中心化服务企业可能大家都很难接受，而基于区块链技术后，小企业的顾虑没了，大企业考虑做大这个联盟可能更有利于谈判从而做大蛋糕！ 全量帐本还带来一个副作用，就是数据透明，没有隐私！！！这对很多人来说是不可接受的。每一个节点都有所有人的数据，你敢把你何时何地消费了多少钱放在上面吗？？？ </p>
</li>
<li><p>区块链技术还有个特点，就是所有的交易记录都是不可修改、不可删除的！这是其算法决定的。所以，这对于公益、扶贫、反腐等是很有吸引力的，蚂蚁金服目前也只敢在公益上用用区块链技术。 </p>
</li>
<li><p>区块链技术底层使用了P2P网络技术，大量使用反对称加密技术（相信程序员们没有不知道SSL的）来验证基于公网的消息可靠性，基于哈希算法实现了如快速验证数据未被篡改等诸多特性（POW的工作量证明算法，核心就是哈希算法）。基于多种分布式网络的一致性算法。所以，区块链使用了一堆老技术，实现了新的理念！特别是对公有链和联盟链，这种思维方式打造了技术上的社会信任体系！（私有链从这个角度来说没有任何意义！） </p>
</li>
<li><p>比特币的火爆原因，我认为，除了区块链技术本身的以上特性外，更多的是它的激励机制：挖矿奖励。即，确认出全网前1个小时左右所有交易的节点获取50比特币奖励（由于比特币总数固定，所以奖励额持续下降中）。这利用了人性的特点，而只要越来越多的人认可这个想象共同体，其价值就会出现。 当然，POW算法才是程序员们最感兴趣的。所谓工作量证明算法，就是全网的所有节点（电脑），都在拼命的消耗自己的计算力（其实就是消耗钱，包括买机器、显卡的钱，电费、房屋租金等等），以此证明我是乐意合作的。很难懂？ 其实很简单：第一，所谓消耗计算力，就是挖矿，所有节点都在不停的挖矿，拼命的用CPU和GPU在运算哈希值，试图抢得新比特币奖励。 第二，为什么消耗了计算力，就能证明我是乐意合作的呢？ 先说一个心理学上的囚徒困境。想必大家港产黑帮片看得多吧？警察抓到2个相关的嫌犯时，最怕他们通过其他人、手机等设备互相联络上。如果联络不上，根据囚徒困境原理，双方都会基于为自己获得最大利益从而出卖对方。但是，一旦他们互相间可以沟通时，其中一个多半会通过描述一种对他非常不利的场景（大家可以想象，比如说：如果我出卖了你，一定会XXXX。当然通过言语没有效果，都会描述一种客观事实），向另一个嫌犯证明自己不会背叛他。接着他们就建立了一种信任关系，警察就很难有成果。 所以，先证明对自己不利，将有利于大家可以合作，建立起信任关系。而POW就是认为，51%的计算力都来自于向往合作的好的节点，少数服从多数。而所有节点都在消耗计算力，就是在证明自己是愿意付出的。 所以，一旦出现一家机构掌握了比特币全网51%的计算能力，结果就是灾难性的！ </p>
</li>
<li><p>联盟链目前看是区块链技术商用的最好方式。特别是跨国银行间的汇款等操作！信任问题，在跨越国家、法律、文化等多领域时才会剧烈地凸显出来，区块链的用武之地！</p>
</li>
</ol>
]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>在阿里云ECS上进行vpn ipsec网络对接</title>
    <url>/2017/01/28/%E5%9C%A8%E9%98%BF%E9%87%8C%E4%BA%91ecs%E4%B8%8A%E8%BF%9B%E8%A1%8Cvpn-ipsec%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8E%A5/</url>
    <content><![CDATA[<p>当我们需要与一些安全级别要求很高的服务对接时，服务提供商的网络提供方式可能是使用ipsec点对点对接网络。如果我们不是使用公有云，而是有自己的机房和路由器，这些就只是按照服务方的参数要求配置下路由器的小事情。但对公有云来说（例如阿里云），我们没有自己的路由器，当对接方要求我们使用预共享密匙进行ipsec点对点对接，第一反应什么鬼（之前没接触过的朋友可以看下这篇文章<a href="http://www.ibm.com/developerworks/cn/[Linux]">http://www.ibm.com/developerworks/cn/[Linux]</a>(<a href="http://lib.csdn.net/base/linux">http://lib.csdn.net/base/linux</a> “Linux知识库”)/l-ipsec/，对该概念讲得蛮清楚）？而接下来拥有私有云独立机房的服务提供方则可能要求最简单直接的解决方案：拉条专线接入服务提供者机房（这个开发成本和运维成本都不小，不适合小而美型的敏捷项目！）？或者买个路由器，在办公室找台机器与服务方对接（高可靠性完全无法保障了）？ 本文讲述使用openswan在linux centos 7下进行ipsec vpn网络的对接，由于相对小众中文资料不多，故也是一篇实践总结笔记。</p>
<span id="more"></span>
<p>进行网络对接前，服务方会要求我们提供对接的公网IP，而这是很容易的：公有云物理服务器一般都有两个网卡，其中一个正是为虚拟机的公网访问准备的。而像阿里云ECS，其公网IP可靠性都是比较高的，ECS服务器挂掉后，同可用区内的迁移并不会更换我们的公网IP。然而服务提供方由于会与多个厂商对接网络，所以为方便管理可能会用规划厂商内网IP地址的方案降低管理成本，例如：要求我们使用私网private subnetA上的机器privateA1访问他们的private subnetB上的服务器privateB1，对接的公网IP中publicA就是我们提供的公网地址，而publicB就是服务方的对外公网地址，例如下图：</p>
<p><img src="/2017/01/ipsecvpn-1-1.jpg"> 由于规定了我们的私网地址，我的第一反应是使用阿里云vpc网络，在vpc网络里定义ECS的私网IP非常简单：在阿里云控制台上设置一个虚拟路由器、一个虚拟交换机，配置好subnetA网段到虚拟交换机，再把vpc网络的ecs加到虚拟交换机下，更换ecs的私网IP再重启服务器即可。然而，虽然我购买了这台vpc网络ecs的公网带宽，但在该服务器下用ifconfig却是看不到公网IP的。才想道vpc网络也是在linux下虚拟出来的网络。果然用openswan搭起来的vpn根本与服务提供方对接不了。而且vpc网络与经典网络ECS间内网是不通的（哪怕是同一机房内），且网络性能由于多了一层IP隧道，性能、稳定性都要弱些，只能排除。 换位思考，服务提供方规定厂商的私网IP，只是为了方便其管理，他们也完全无法控制我们的网络行为。所以，可以用最简单的方式，虚拟一个私网IP即可。 而ipsec的对接，用软件方案解决肯定是第一选择，目前strongswan和openswan都是广为使用，而我用yum默认拉下的strongswan版本是5.4.0，总是出现莫名其妙的错误（略过）。这里记录下openswan的使用。 首先yum install openswan安装好。接下来我们可以按照提供方的配置参数要求，去配置openswan使其能够打通ipsec网络。首先编辑ipsec.conf配置文件，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim etc&#x2F;ipsec.conf  </span><br></pre></td></tr></table></figure>

<p>在配置文件下方增加我们这条vpn网络通道的配置参数，如预共享密匙和第1、第2阶段的认证参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">conn 网络名称  </span><br><span class="line">        authby&#x3D;secret  </span><br><span class="line">        auto&#x3D;start  </span><br><span class="line">        ike&#x3D;3des-md5  </span><br><span class="line">        keyexchange&#x3D;ike  </span><br><span class="line">        phase2&#x3D;esp  </span><br><span class="line">        phase2alg&#x3D;3des-md5  </span><br><span class="line">        compress&#x3D;no  </span><br><span class="line">        pfs&#x3D;yes  </span><br><span class="line">        type&#x3D;tunnel  </span><br><span class="line">        left&#x3D;你的公网地址  </span><br><span class="line">        leftsourceip&#x3D;你的公网地址  </span><br><span class="line">        leftsubnet&#x3D;服务方要求的私网子网  </span><br><span class="line">        leftnexthop&#x3D;%defaultroute  </span><br><span class="line">        right&#x3D;服务方公网地址  </span><br><span class="line">        rightsourceip&#x3D;服务方公网地址  </span><br><span class="line">        rightsubnet&#x3D;服务方私网子网  </span><br></pre></td></tr></table></figure>

<p>接下来配置预共享密匙：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;ipsec.secrets  </span><br></pre></td></tr></table></figure>

<p>在其中增加该网络的预共享密匙：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">siteA-public-IP  siteB-public-IP:  PSK  &quot;pre-shared-key&quot;  </span><br></pre></td></tr></table></figure>

<p>现在启动ipsec网络：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipsec start  </span><br></pre></td></tr></table></figure>

<p>好了，现在我们可以看下ipsec网络是否连通，执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipsec status  </span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">000 IKE SAs: total(1), half-open(0), open(0), authenticated(1), anonymous(0)  </span><br><span class="line">000 IPsec SAs: total(1), authenticated(1), anonymous(0)  </span><br><span class="line">000    </span><br><span class="line">000 #195: &quot;your conn name&quot;:500 STATE_QUICK_I2 (sent QI2, IPsec SA established); EVENT_SA_REPLACE in 6599s; newest IPSEC; eroute owner; isakmp#194; idle; import:admin initiate  </span><br></pre></td></tr></table></figure>

<p>ipsec网络已经建立。也可以在对方的路由器上查看到网络已经联通。 现在开始解决privateA1访问privateB1的问题。当然现在去ping服务器私网privateB1肯定是不通的。我们先要虚拟出privateA1地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifconfig eth0:2 privateA1  </span><br></pre></td></tr></table></figure>

<p>现在用ifconfig可以看到多出了一个privateA1地址。再用它去ping对端私网：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping -I privateA1 privateB1  </span><br></pre></td></tr></table></figure>

<p>现在可以看到能ping通。如果知道对方web服务的监听端口，可以再用telnet验证下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">telnet -b privateA privateB port  </span><br></pre></td></tr></table></figure>

<p>如此网络已通。（这样虚拟出的IP重启系统后就没有了，参考该文解决：<a href="https://linuxconfig.org/configuring-virtual-network-interfaces-in-linux%EF%BC%89">https://linuxconfig.org/configuring-virtual-network-interfaces-in-linux）</a> 然而每次要指定privateA作为源IP实在是太不方便了，有些工具还不支持这样指定源IP。解决办法是改路由表，设定访问privateB1所在的子网subnetB时，全部使用privateA作为源地址。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip route add privateSubnetB1 via GW dev eth1  src  privateA1  </span><br></pre></td></tr></table></figure>

<p>再去直接ping privateB1，就已经通了。</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>ipsec</tag>
        <tag>openswan</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title>基于websocket接口的jmeter自动化测试实践（1）</title>
    <url>/2017/03/21/%E5%9F%BA%E4%BA%8Ewebsocket%E6%8E%A5%E5%8F%A3%E7%9A%84jmeter%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%AE%9E%E8%B7%B5%EF%BC%881%EF%BC%89/</url>
    <content><![CDATA[<p>自动化测试对于小团队来说非常重要，特别是技术负责人更偏向于用技术解决问题时（习惯用管理解决问题时，可能会用手动+人海方式）。<br>而在接口测试中，jmeter无疑是一个低成本方案的自动化测试工具。 </p>
<p>为什么呢？因为它在整体设计上把业务逻辑、测试框架、测试数据三者分离了。jmeter进程就是测试框架，而通过如csv等文件提供测试数据，jmx提供包含业务逻辑的测试用例。而jmx脚本，则是以可视化的配置方式来编写（且配置时，可以利用内置函数提供多种功能）。这样的方案，无疑是维护成本最低的。 </p>
<span id="more"></span>
<p>同时，jmeter有大量的第三方插件，得以支持大部分协议。在性能测试方面，jmeter还支持多台机器组成集群对服务器压测，可以部署agent到服务器以拉取服务器指标的监控实时数据，同时还有大量的压测结果分析工具。 从功能测试角度来看，如果jmeter脚本能覆盖大部分接口及组合场景，那么，阅读jmx脚本无疑是最快速了解产品的方法了。</p>
<ol>
<li> 对产品经理而言，通过它可以了解产品的落地细节；</li>
<li> 对前端而言，既可以看到后端接口的使用方式，也能够获得集成用例场景，还可以借此产生大量数据以验证页面；</li>
<li> 对后端而言，可以自动化回归功能，还可以压测得到性能并验证稳定性；</li>
<li> 对运维而言，可以得到性能基线数据。</li>
</ol>
<p>基于此，我选用jmeter来测试后端的websocket接口。 </p>
<h1 id="环境的准备"><a href="#环境的准备" class="headerlink" title="环境的准备"></a>环境的准备</h1><ol>
<li>下载最新版的jdk <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a>，安装。   </li>
<li>下载最新版的jmeter，例如当前最新版为3.1，可在 <a href="http://mirrors.tuna.tsinghua.edu.cn/apache/jmeter/binaries/apache-jmeter-3.1.zip">http://mirrors.tuna.tsinghua.edu.cn/apache//jmeter/binaries/apache-jmeter-3.1.zip</a>下载到压缩包，解压到某目录下即可。   </li>
<li>下载jmeter插件管理器 jmeter要想支持websocket需要安装一堆插件，磨刀不误砍柴功，先装一个插件叫JMeter Plugins Manager，安装方法也很简单，参考<a href="https://www.blazemeter.com/blog/how-install-jmeter-plugins-manager%E6%96%87%E7%AB%A0%EF%BC%8C%E5%8F%AA%E6%98%AF%E6%8A%8Ajar%E5%8C%85%E6%94%BE%E5%9C%A8lib/ext%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8D%B3%E5%8F%AF%E3%80%82%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E5%9C%A8">https://www.blazemeter.com/blog/how-install-jmeter-plugins-manager文章，只是把jar包放在lib/ext目录下即可。下载地址在</a> u<a href="https://jmeter-plugins.org/downloads/all/">https://jmeter-plugins.org/downloads/all/</a>。   </li>
<li>在options里找到Plugin Manager，在available plugins里找到Websocket protocol support点击选中，安装后jmeter会自动重启。 <img src="/2017/03/jmeter%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86-1-1.jpg"> 从可用插件里即可非常方便的得到新的插件。 <img src="/2017/03/jmeter-plugins-manager%E5%8F%AF%E7%94%A8%E6%8F%92%E4%BB%B6-1-1.jpg"> 这个插件可以自动升级，如下： <img src="/2017/03/jmeter-plugins-manager%E5%8F%AF%E5%8D%87%E7%BA%A7-1-1.jpg"> 5）服务基于websocket和json，故点击这两个插件即可获得。   </li>
</ol>
<h1 id="使用websocket-sampler进行测试"><a href="#使用websocket-sampler进行测试" class="headerlink" title="使用websocket sampler进行测试"></a>使用websocket sampler进行测试</h1><p><img src="/2017/03/websocket%E8%AF%B7%E6%B1%82%E8%AE%BE%E7%BD%AE-1-1.jpg"><br>需要注意，虽然这里的WebServer下有Server Name or IP配置，但在HTTP Request Defaults里的Server Name or IP是不支持分享给每个case的，这点很不方便后续维护，一个解决方案是：添加User Defined Variable，其中抽象出Server Name or IP，再把变量testserver放到每个case上！ 另外，backlog表示响应中显示几条message，默认是3。 </p>
<h1 id="使用json解析响应"><a href="#使用json解析响应" class="headerlink" title="使用json解析响应"></a>使用json解析响应</h1><p>测试场景中，协议是以websocket+json格式传递数据，然而，这个websocket插件中却会在response里上面加了一行[Message n]这样一个字符串，导致输出不再是标准的json字符串。所以，添加了jmeter json extractor插件后，后置resposne处理器从非标准的response里提取不出值。例如：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[Message <span class="number">2</span>]</span><br><span class="line">&#123;<span class="attr">&quot;msg&quot;</span>: <span class="string">&quot;成功:登录&quot;</span>, <span class="attr">&quot;data&quot;</span>: &#123;<span class="attr">&quot;user_id&quot;</span>: <span class="number">1</span>, <span class="attr">&quot;sid&quot;</span>: <span class="string">&quot;61875d286b9a1eb329ab5642812216fe&quot;</span>&#125;, <span class="attr">&quot;code&quot;</span>: <span class="number">1000</span>, <span class="attr">&quot;command&quot;</span>: &#123;<span class="attr">&quot;path&quot;</span>: <span class="string">&quot;employee.consumer.Login&quot;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>这样的结果里，用$.data.sid是取不出sid的值的。当然，用正则表达式肯定是能提取出值的，但如果有大量case，且接口返回格式修改的比较频繁，正则表达式就是一个不大不小的坑，调整修改时效率很低下。 目前我使用的解决方案是，先用正则表达式取出第2行开始的json串（前面的[Message 2]信息是插件添加的，非常固定），再把它以jmeter variable的方式传递给json extractor，即可解决。 <img src="/2017/03/json%E6%95%B0%E7%BB%84%E5%8F%96%E5%80%BC-1-1.jpg"> json返回里会有列表，而列表里取第几个的值，如果序号是固定的当然好办，而如果与某个元素的值有关，则可以用?(@.)这种方式来取，如上图所示。   </p>
<h1 id="加入内置函数"><a href="#加入内置函数" class="headerlink" title="加入内置函数"></a>加入内置函数</h1><p>比如常用的取随机数__Random，或者取当前日期和时间__time，如下所示： <img src="/2017/03/jmeter%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0-1-1.jpg"> </p>
<h1 id="加入定时器"><a href="#加入定时器" class="headerlink" title="加入定时器"></a>加入定时器</h1><p><img src="/2017/03/jmeter%E9%9A%8F%E6%9C%BA%E5%AE%9A%E6%97%B6%E5%99%A8-1-1.jpg"> 随机或者固定定时器，都非常有用，模拟各种用户时间尺度上不同的行为。 注意，对单个sampler有效的话，必须把定时器移至sampler的子元素中。 </p>
<h1 id="加入逻辑控制"><a href="#加入逻辑控制" class="headerlink" title="加入逻辑控制"></a>加入逻辑控制</h1><p><img src="https://www.taohui.pub/wp-content/uploads/2017/03/jmeter%E9%80%BB%E8%BE%91%E5%88%A4%E6%96%AD-2.jpg"> 非常好用的逻辑控制器。</p>
]]></content>
      <categories>
        <category>web</category>
        <category>高并发</category>
      </categories>
  </entry>
  <entry>
    <title>基于websocket接口的jmeter自动化测试实践（2）</title>
    <url>/2017/04/05/%E5%9F%BA%E4%BA%8Ewebsocket%E6%8E%A5%E5%8F%A3%E7%9A%84jmeter%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%AE%9E%E8%B7%B5%EF%BC%882%EF%BC%89-2/</url>
    <content><![CDATA[<h1 id="jmeter属性"><a href="#jmeter属性" class="headerlink" title="jmeter属性"></a>jmeter属性</h1><p>通常我们会使用用户自定义变量，把每个用例共用的东西提取出来。然而，当测试环境多起来时，这些写死在jmx脚本里的变量就不那么好用了。例如，对多个环境测试时，难道要复制多个脚本、单独改变量值？ </p>
<p>此时，我们可以使用jmeter<strong>属性</strong>。因为属性是可以通过命令行传递的，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Jtestproperty&#x3D;202</span><br></pre></td></tr></table></figure>
<span id="more"></span>

<p><code>而在需要使用变量的地方直接用$&#123;__P(testproperty,)&#125;使用命令行传递的值。</code> 当然，如果脚本已经大量使用了user defined variable，且可能会有一个默认环境一批默认值，那么，在user defined variable里把变量的值设为${__P(testproperty,30)}携带默认值30即可。<br><img src="https://www.taohui.pub/wp-content/uploads/2017/03/jmeter%E5%B1%9E%E6%80%A7%E7%9A%84%E4%BD%BF%E7%94%A8-2.jpg"> </p>
<h1 id="循环中的计数器"><a href="#循环中的计数器" class="headerlink" title="循环中的计数器"></a>循环中的计数器</h1><p>我们需要循环使用一系列值用于某个用例，且每个值与循环到第几次有关时，可以在循环中使用计数器。 </p>
<p>这时需要注意，如果在thread loop里计数器会一直累加，如果希望在每次thread loop中重新清零，要选择reset。 <img src="https://www.taohui.pub/wp-content/uploads/2017/03/jmeter%E8%AE%A1%E6%95%B0%E5%99%A8-2.jpg"> </p>
<h1 id="浮点随机数"><a href="#浮点随机数" class="headerlink" title="浮点随机数"></a>浮点随机数</h1><p>有时，我们需要构造浮点式的随机数。而jmeter默认的随机数只有整型。此时，可以利用请求中都是字符串，以字符串默认连接组合的方式构造浮点数。 </p>
<h1 id="嵌入java值"><a href="#嵌入java值" class="headerlink" title="嵌入java值"></a>嵌入java值</h1><p>当我们需要构造一些测试值，但自带的jmeter函数并不支持时，可以考虑能够直接使用原生java代码生成变量的beanshell。<br>例如，我们需要构造一个日期为前天，自带的__time只能获取到当前日期。而加入一个beanshell PreProcesser就可以加入java代码得到值。<br>其中，beanshell里生成的变量，可以调用vars.set(key,value)设置到jmeter上下文中。而想使用已经存在的jmeter上下文中的变量时，则可以使用vars.get(key)。需要注意，返回的value是字符串类型。 <img src="https://www.taohui.pub/wp-content/uploads/2017/04/jmeter%E7%9A%84beanshell_PreProcesser-2.jpg"> </p>
<h1 id="组合条件判断"><a href="#组合条件判断" class="headerlink" title="组合条件判断"></a>组合条件判断</h1><p>做条件判断时，我们很可能会做多个条件组合的判断，而默认的jmeter if controller是不支持的。此时可以这么用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;__javaScript($&#123;count&#125;&lt;60 &amp;&amp; $&#123;code&#125;&#x3D;&#x3D;&quot;5001&quot;)&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title>如何用googletest写单元测试</title>
    <url>/2012/01/27/%E5%A6%82%E4%BD%95%E7%94%A8googletest%E5%86%99%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p>googletest是一个用来写C++单元<a href="http://lib.csdn.net/base/softwaretest" title="软件测试知识库">测试</a>的框架，它是跨平台的，可应用在windows、<a href="http://lib.csdn.net/base/linux" title="Linux知识库">Linux</a>、Mac等OS平台上。下面，我来说明如何使用最新的1.6版本gtest写自己的单元测试。 </p>
<p>本文包括以下几部分：<br>1、获取并编译googletest（以下简称为gtest）；<br>2、如何编写单元测试用例；<br>3、如何执行单元测试。<br>4、google test内部是如何执行我们的单元测试用例的。 </p>
<span id="more"></span>
<h1 id="获取并编译gtest"><a href="#获取并编译gtest" class="headerlink" title="获取并编译gtest"></a>获取并编译gtest</h1><p>gtest试图跨平台，理论上，它就应该提供多个版本的binary包。但事实上，gtest只提供源码和相应平台的编译方式，这是为什么呢？google的解释是，我们在编译出gtest时，有些独特的工程很可能希望在编译时加许多flag，把编译的过程下放给用户，可以让用户更灵活的处理。这个仁者见仁吧，反正也是免费的BSD权限。 </p>
<p>源码的获取地址：<a href="http://code.google.com/p/googletest/downloads/list">http://code.google.com/p/googletest/downloads/list</a> </p>
<p>目前gtest提供的是1.6.0版本，我们看看与以往版本1.5.0的区别：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Changes for 1.6.0:  </span><br><span class="line">  </span><br><span class="line">* New feature: ADD_FAILURE_AT() for reporting a test failure at the  </span><br><span class="line">  given source location -- useful for writing testing utilities.  </span><br><span class="line">。。。 。。。  </span><br><span class="line">* Bug fixes and implementation clean-ups.  </span><br><span class="line">* Potentially incompatible changes: disables the harmful &#39;make install&#39;  </span><br><span class="line">  command in autotools.  </span><br></pre></td></tr></table></figure>

<p>就是最下面一行，make install禁用了，郁闷了吧？UNIX的习惯编译方法：./configure;make;make install失灵了，只能说google比较有种，又开始挑战用户习惯了。 那么怎么编译呢？ 先进入gtest目录（解压gtest.zip包过程就不说了），执行以下两行命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">g++ -I.&#x2F;include -I.&#x2F; -c .&#x2F;src&#x2F;gtest-all.cc  </span><br><span class="line">ar -rv libgtest.a gtest-all.o  </span><br></pre></td></tr></table></figure>

<p>之后，生成了libgtest.a，这个就是我们要的东东了。以后写自己的单元测试，就需要libgtest.a和gtest目录下的include目录，所以，这1文件1目录我们需要拷贝到自己的工程中。</p>
<p>编译完成后怎么验证是否成功了呢？（相当不友好！）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd $&#123;GTEST_DIR&#125;&#x2F;make  </span><br><span class="line">  make  </span><br><span class="line">  .&#x2F;sample1_unittest  </span><br></pre></td></tr></table></figure>

<p>如果看到：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Running main() from gtest_main.cc  </span><br><span class="line">[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] Running 6 tests from 2 test cases.  </span><br><span class="line">[----------] Global test environment set-up.  </span><br><span class="line">[----------] 3 tests from FactorialTest  </span><br><span class="line">[ RUN      ] FactorialTest.Negative  </span><br><span class="line">[       OK ] FactorialTest.Negative (0 ms)  </span><br><span class="line">[ RUN      ] FactorialTest.Zero  </span><br><span class="line">[       OK ] FactorialTest.Zero (0 ms)  </span><br><span class="line">[ RUN      ] FactorialTest.Positive  </span><br><span class="line">[       OK ] FactorialTest.Positive (0 ms)  </span><br><span class="line">[----------] 3 tests from FactorialTest (0 ms total)  </span><br><span class="line">  </span><br><span class="line">[----------] 3 tests from IsPrimeTest  </span><br><span class="line">[ RUN      ] IsPrimeTest.Negative  </span><br><span class="line">[       OK ] IsPrimeTest.Negative (0 ms)  </span><br><span class="line">[ RUN      ] IsPrimeTest.Trivial  </span><br><span class="line">[       OK ] IsPrimeTest.Trivial (0 ms)  </span><br><span class="line">[ RUN      ] IsPrimeTest.Positive  </span><br><span class="line">[       OK ] IsPrimeTest.Positive (0 ms)  </span><br><span class="line">[----------] 3 tests from IsPrimeTest (0 ms total)  </span><br><span class="line">  </span><br><span class="line">[----------] Global test environment tear-down  </span><br><span class="line">[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] 6 tests from 2 test cases ran. (0 ms total)  </span><br><span class="line">[  PASSED  ] 6 tests.  </span><br></pre></td></tr></table></figure>

<p>那么证明编译成功了。 </p>
<h1 id="如何编写单元测试用例"><a href="#如何编写单元测试用例" class="headerlink" title="如何编写单元测试用例"></a>如何编写单元测试用例</h1><p>以一个例子来说。我写了一个开地址的哈希表，它有del/get/add三个主要方法需要测试。在测试的时候，很自然，我只希望构造一个哈希表对象，对之做许多种不同组合的操作，以验证三个方法是否正常。所以，gtest提供的TEST方式我不会用，因为多个TEST不能共享同一份数据，而且还有初始化哈希表对象的过程呢。所以我用TEST_F方式。TEST_F是一个宏，TEST_F(classname, casename){}在函数体内去做具体的验证。 <img src="/2012/01/0_13315201124mU9-1-1.png"> 上面是我要执行单元测试的类图。那么，我需要写一系列单元测试用例来测试这个类。用gtest，首先要声明一个类，继承自gtest里的Test类： <img src="http://hi.csdn.net/attachment/201203/12/0_1331520119c35j.gif"> </p>
<p>代码很简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class CHashTableTest : public ::testing::Test &#123;  </span><br><span class="line">protected:  </span><br><span class="line">    CHashTableTest():ht(100)&#123;  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">    virtual void SetUp() &#123;  </span><br><span class="line">        key1 &#x3D; &quot;testkey1&quot;;  </span><br><span class="line">        key2 &#x3D; &quot;testkey2&quot;;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    &#x2F;&#x2F; virtual void TearDown() &#123;&#125;  </span><br><span class="line">    CHashTable ht;  </span><br><span class="line">  </span><br><span class="line">    string key1;  </span><br><span class="line">    string key2;  </span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure>

<p>然后开始写测试用例，用例里可以直接使用上面类中的成员。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TEST_F(CHashTableTest, hashfunc)  </span><br><span class="line">&#123;  </span><br><span class="line">    CHashElement he;  </span><br><span class="line">  </span><br><span class="line">    ASSERT_NE(\  </span><br><span class="line">            ht.getHashKey((char*)key1.c_str(), key1.size(), 0),\  </span><br><span class="line">            ht.getHashKey((char*)key2.c_str(), key2.size(), 0));  </span><br><span class="line">  </span><br><span class="line">    ASSERT_NE(\  </span><br><span class="line">            ht.getHashKey((char*)key1.c_str(), key1.size(), 0),\  </span><br><span class="line">            ht.getHashKey((char*)key1.c_str(), key1.size(), 1));  </span><br><span class="line">  </span><br><span class="line">    ASSERT_EQ(\  </span><br><span class="line">            ht.getHashKey((char*)key1.c_str(), key1.size(), 0),\  </span><br><span class="line">            ht.getHashKey((char*)key1.c_str(), key1.size(), 0));  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>注意，TEST_F宏会直接生成一个类，这个类继承自上面我们写的CHashTableTest类。 gtest提供ASSERT_和EXPECT_系列的宏，用于判断二进制、字符串等对象是否相等、真假等等。这两种宏的区别是，ASSERT_失败了不会往下执行，而EXPECT_会继续。 </p>
<h1 id="如何执行单元测试"><a href="#如何执行单元测试" class="headerlink" title="如何执行单元测试"></a>如何执行单元测试</h1><p>首先，我们自己要有一个main函数，函数内容非常简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;gtest&#x2F;gtest.h&quot;  </span><br><span class="line">  </span><br><span class="line">int main(int argc, char** argv) &#123;  </span><br><span class="line">    testing::InitGoogleTest(&amp;argc, argv);  </span><br><span class="line">  </span><br><span class="line">    &#x2F;&#x2F; Runs all tests using Google Test.  </span><br><span class="line">    return RUN_ALL_TESTS();  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>InitGoogleTest会解析参数。RUN_ALL_TESTS会把整个工程里的TEST和TEST_F这些函数全部作为测试用例执行一遍。 执行时，假设我们编译出的可执行文件叫unittest，那么直接执行./unittest就会输出结果到屏幕，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] Running 4 tests from 1 test case.  </span><br><span class="line">[----------] Global test environment set-up.  </span><br><span class="line">[----------] 4 tests from CHashTableTest  </span><br><span class="line">[ RUN      ] CHashTableTest.hashfunc  </span><br><span class="line">[       OK ] CHashTableTest.hashfunc (0 ms)  </span><br><span class="line">[ RUN      ] CHashTableTest.addget  </span><br><span class="line">[       OK ] CHashTableTest.addget (0 ms)  </span><br><span class="line">[ RUN      ] CHashTableTest.add2get  </span><br><span class="line">testCHashTable.cpp:79: Failure  </span><br><span class="line">Value of: getHe-&gt;m_pNext&#x3D;&#x3D;NULL  </span><br><span class="line">  Actual: true  </span><br><span class="line">Expected: false  </span><br><span class="line">[  FAILED  ] CHashTableTest.add2get (1 ms)  </span><br><span class="line">[ RUN      ] CHashTableTest.delget  </span><br><span class="line">[       OK ] CHashTableTest.delget (0 ms)  </span><br><span class="line">[----------] 4 tests from CHashTableTest (1 ms total)  </span><br><span class="line">  </span><br><span class="line">[----------] Global test environment tear-down  </span><br><span class="line">[&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] 4 tests from 1 test case ran. (1 ms total)  </span><br><span class="line">[  PASSED  ] 3 tests.  </span><br><span class="line">[  FAILED  ] 1 test, listed below:  </span><br><span class="line">[  FAILED  ] CHashTableTest.add2get  </span><br></pre></td></tr></table></figure>

<p>  可以看到，对于错误的CASE，会标出所在文件及其行数。 如果我们需要输出到XML文件，则执行./unittest –gtest_output=xml，那么会在当前目录下生成test_detail.xml 文件，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;  </span><br><span class="line">&lt;testsuites tests&#x3D;&quot;3&quot; failures&#x3D;&quot;0&quot; disabled&#x3D;&quot;0&quot; errors&#x3D;&quot;0&quot; time&#x3D;&quot;0.001&quot; name&#x3D;&quot;AllTests&quot;&gt;  </span><br><span class="line">  &lt;testsuite name&#x3D;&quot;CHashTableTest&quot; tests&#x3D;&quot;3&quot; failures&#x3D;&quot;0&quot; disabled&#x3D;&quot;0&quot; errors&#x3D;&quot;0&quot; time&#x3D;&quot;0.001&quot;&gt;  </span><br><span class="line">    &lt;testcase name&#x3D;&quot;hashfunc&quot; status&#x3D;&quot;run&quot; time&#x3D;&quot;0.001&quot; classname&#x3D;&quot;CHashTableTest&quot; &#x2F;&gt;  </span><br><span class="line">    &lt;testcase name&#x3D;&quot;addget&quot; status&#x3D;&quot;run&quot; time&#x3D;&quot;0&quot; classname&#x3D;&quot;CHashTableTest&quot; &#x2F;&gt;  </span><br><span class="line">    &lt;testcase name&#x3D;&quot;delget&quot; status&#x3D;&quot;run&quot; time&#x3D;&quot;0&quot; classname&#x3D;&quot;CHashTableTest&quot; &#x2F;&gt;  </span><br><span class="line">  &lt;&#x2F;testsuite&gt;  </span><br><span class="line">&lt;&#x2F;testsuites&gt;  </span><br></pre></td></tr></table></figure>

<p>如此，一个简单的单元测试写完。因为太简单，所以不需要使用google mock模拟一些依赖。后续我再写结合google mock来写一些复杂的gtest单元测试。</p>
<p>下面来简单说下gtest的工作流程。 </p>
<h1 id="google-test内部是如何执行我们的单元测试用例的"><a href="#google-test内部是如何执行我们的单元测试用例的" class="headerlink" title="google test内部是如何执行我们的单元测试用例的"></a>google test内部是如何执行我们的单元测试用例的</h1><p>首先从main函数看起。 我们的main函数执行了RUN_ALL_TESTS宏，这个宏干了些什么事呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define RUN_ALL_TESTS()\  </span><br><span class="line">  (::testing::UnitTest::GetInstance()-&gt;Run())  </span><br><span class="line">  </span><br><span class="line">&#125;  &#x2F;&#x2F; namespace testing  </span><br></pre></td></tr></table></figure>

<p>原来是调用了UnitTest静态工厂实例的Run方法！在gtest里，一切测试用例都是Test类的实例！所以，Run方法将会执行所有的Test实例来运行所有的单元测试，看看类图：</p>
<p><img src="http://hi.csdn.net/attachment/201203/12/0_1331520133w5HW.gif"> 为什么说一切单元测试用例都是Test类的实例呢？ 我们有两种写测试用例的方法，一种就是上面我说的TEST_F宏，这要求我们要显示的定义一个子类继承自Test类。在TEST_F宏里，会再次定义一个新类，继承自我们上面定义的子类（两重继承哈）。 第二种就是TEST宏，这个宏里不要求用户代码定义类，但在google test里，TEST宏还是定义了一个子类继承自Test类。 所以，UnitTest的Run方法只需要执行所有Test实例即可。 每个单元测试用例就是一个Test类子类的实例。它同时与TestResult，TestCase，TestInfo关联起来，用于提供结果。 当然，还有EventListen类来监控结果的输出，控制测试的进度等。 <img src="http://hi.csdn.net/attachment/201203/12/0_1331520698FBFC.gif"> 以上并没有深入细节，只是大致帮助大家理解，我们写的几个简单的gtest宏，和单元测试用例，到底是如何被执行的。接下来，我会通过gmock来深入的看看google单元测试的玩法。</p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>gmock</tag>
      </tags>
  </entry>
  <entry>
    <title>这16年来我是如何做系统性能优化的</title>
    <url>/2020/04/27/%E8%BF%9916%E5%B9%B4%E6%9D%A5%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84/</url>
    <content><![CDATA[<p>2019年下半年，极客时间总编辑郭蕾从北京飞来杭州，问我有什么特别想分享给大家的技术。我回顾了下自己这16年来的工作经历，发现无论在华为、腾讯、思科、阿里，我都在与海量数据打交道，这个过程中对性能优化有许多思考，但一直没有系统的写下来。于是我就跟郭蕾说，那就针对分布式系统，讲讲我心中的性能优化方法论吧。这就是《系统性能调优必知必会》这门课的诞生过程。</p>
<span id="more"></span>
<p>我做过两门视频课，《Nginx 核心知识 100 讲》和《Web 协议详解与抓包实战》，这次和你聊聊程序员日常工作中那些<strong>绕不开的系统性能优化问题</strong>。只要技术厉害一点的工程师都知道，性能不只对产品的攻城掠地至关重要，<strong>它也是程序员价值的重要体现，特别是它在工作面试、技术等级晋升上总会扮演重要角色。</strong></p>
<ul>
<li>  比如，在包括阿里在内的大多数拥有技术职级晋升体系的公司里，为了保障公平性，一般会由跨部门的专家组成评委会。那么其他部门的高级专家在不熟悉候选人业务的情况下，要怎么去考察候选人的水平呢？<strong>他们只能去考察底层的硬核知识，而这当中性能问题又是最有区分度的问题。</strong>因此，掌握性能问题将对你的晋升之路有很大助益。如果你始终埋头在业务中，<strong>不关心更通用的性能优化方法论，将在技术等级晋升上非常吃亏。</strong></li>
<li>  再比如，你在面试互联网大厂时，面试官总会问许多超出工作范围的性能问题，为什么会这样呢？当然你可以感慨甚至抱怨，这不就是“面试造火箭，入职拧螺丝”嘛？但从面试官的角度来看，你会发现<strong>性能就是最好的面试题，它从算法到架构，既考察了候选人的潜力，也能考察工程能力。</strong>如果候选人具备系统的性能优化方法论，那么无论在架构设计还是应用模块开发上，他的代码可扩展性都会更好，消耗的计算力、带宽和磁盘等 IT 资源也更少，也自然更容易被面试官青睐。</li>
</ul>
<p>因此，不论是为了满足业务发展的需求，还是在面试、晋升场景中有更好的表现，如果你希望成为高薪高效的 10X 程序员，那么，系统地学习性能优化就是一门必修课。我先把课程海报分享在这，再跟你说说这门课解决的具体问题。</p>
<p><a href="http://www.taohui.pub/2020/04/27/%e8%bf%9916%e5%b9%b4%e6%9d%a5%e6%88%91%e6%98%af%e5%a6%82%e4%bd%95%e5%81%9a%e7%b3%bb%e7%bb%9f%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%9a%84/%e6%b5%b7%e6%8a%a5/"><img src="/2020/04/%E6%B5%B7%E6%8A%A5.jpg"></a></p>
<p>那么，系统性能优化该怎么学呢？</p>
<p>当然是看需求。当下的后端几乎都是<strong>分布式系统</strong>，那么对应的，我们面对的课题也就是<strong>如何全面提升复杂集群的性能</strong>。但当你想要学习分布式系统优化的时候，你却会发现，能找到的资料实在是太少了。</p>
<p>如果你在 Google 上搜索如何优化分布式系统的性能，大概只能找到孤零零的几篇文章，相关的多数书籍也都在讨论容错、事务、流控等概念的实现，却很少有文章介绍如何优化整个分布式系统的性能。</p>
<p>这恰恰就是我推出 <a href="https://time.geekbang.org/column/intro/308?utm_term=zeus8DPOK&utm_source=jikeshijian&utm_medium=tuiwen">《系统性能调优必知必会》</a>这个专栏的初衷。我希望通过这个专栏，把自己这些年来在分布式性能领域所遇到的问题和解决方案，归纳总结，梳理出一条交付给你，告诉你我眼中的性能问题本质是怎样的。</p>
<h1 id="我是谁？"><a href="#我是谁？" class="headerlink" title="我是谁？"></a>我是谁？</h1><p>我是陶辉，杭州智链达数据有限公司 CTO 兼联合创始人，前阿里云高级技术专家、腾讯云 TVP，著有《深入理解 Nginx：模块开发与架构解析》一书。</p>
<p><strong>我 2004 年毕业于西安交通大学，有近 20 年的互联网一线工作经验</strong>：曾在华为中央软件部参与 iMAP 网管系统的研发，熟悉网络设备的工作流程；在腾讯 QQ 空间部门使用自定义的 Qzone 协议传递巨量数据，对如何设计出高性能、可扩展的应用协议有丰富的实践经验；在思科从事 Nginx 服务的研发，对 Web 服务器如何高效地处理 HTTP 协议有全面的认识；在阿里云担任 VPC 网络、ECS 管理与存储系统重构的架构师，对公有云及 IDC 内部网络系统有深刻了解。</p>
<p>工作数年，我始终与性能相伴，目前致力于 Linux 下高性能服务器的开发，以及分布式环境下海量数据存储的设计与开发。</p>
<h1 id="我是如何讲解性能优化的"><a href="#我是如何讲解性能优化的" class="headerlink" title="我是如何讲解性能优化的"></a>我是如何讲解性能优化的</h1><p>如果你需要从架构层面优化整个系统，那么这门课可以拓展你的知识面，告诉你如何优化架构才能让整体服务获得最大性能；如果你刚开始接触性能优化，这门课可以给你打牢基础，告诉你影响性能的底层因素，在实践中优化你的程序，看到立竿见影的效果。</p>
<p>我先给你总结了一份<strong>「系统性能优化核心知识图谱」</strong>：</p>
<p><a href="http://www.taohui.pub/2020/04/27/%e8%bf%9916%e5%b9%b4%e6%9d%a5%e6%88%91%e6%98%af%e5%a6%82%e4%bd%95%e5%81%9a%e7%b3%bb%e7%bb%9f%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%9a%84/%e8%84%91%e5%9b%be/"><img src="/2020/04/%E8%84%91%E5%9B%BE.jpg"></a></p>
<p>你会发现，整个脑图我是从 4 个方面来梳理的，这其实就是我们在提升一个新系统的性能时，可以入手的 4 个层次。</p>
<ol>
<li> 首先，你可以从提升单机进程的性能入手，包括高效地使用主机的 CPU、内存、磁盘等硬件，通过并发编程提升吞吐量，根据业务特性选择合适的算法。</li>
<li> 其次，分布式系统是由各个组件通过网络连接在一起，所以优化传输层网络可以让所有组件同时受益。具体优化时，你可以从降低请求的时延，提升总体吞吐量两个方向入手。</li>
<li> 再次，要对业务消息采用更高效的编码方式，这既包括协议头、包体的优化，也包括 TLS 安全层的性能提升。具体优化时，既要深入静态编码，也要从动态的增量编码上优化。同时，调整消息的交互方式也能提升性能。</li>
<li> 最后，我们再从集群整体上进行架构层面的优化。基于 ACP、AKF、NWR 等分布式理论，我们的优化方向仍然是降低时延和提升吞吐量，但实现方式则要运用分而治之的思想，调度集群中的所有结节协作配合，完成性能优化目标。</li>
</ol>
<p><a href="http://www.taohui.pub/2020/04/27/%e8%bf%9916%e5%b9%b4%e6%9d%a5%e6%88%91%e6%98%af%e5%a6%82%e4%bd%95%e5%81%9a%e7%b3%bb%e7%bb%9f%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%9a%84/%e7%9b%ae%e5%bd%95/"><img src="/2020/04/%E7%9B%AE%E5%BD%95.jpg"></a></p>
]]></content>
      <categories>
        <category>web</category>
        <category>编程语言</category>
        <category>技术人生</category>
        <category>高并发</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>cpu</tag>
        <tag>grpc</tag>
        <tag>kafka</tag>
        <tag>mapreduce</tag>
        <tag>protobuf</tag>
        <tag>storm</tag>
        <tag>优化</tag>
        <tag>内存</tag>
        <tag>分布式</tag>
        <tag>哈希表</tag>
        <tag>性能</tag>
        <tag>时间复杂度</tag>
        <tag>算法复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title>生成一个C++对象的成本</title>
    <url>/2012/01/27/%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AAc%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%88%90%E6%9C%AC-2/</url>
    <content><![CDATA[<p>最近两年C用得多了，C++有些生疏，又常常用<a href="http://lib.csdn.net/base/python" title="Python知识库">Python</a>，或者阅读些<a href="http://lib.csdn.net/base/javase" title="Java SE知识库">Java</a>的代码，感觉C的开发者们由于<a href="http://lib.csdn.net/base/c" title="C语言知识库">C语言</a>在软件工程上的先天缺陷，导致开发效率不高，所以决定拿出C++来看看用用，准备把libevent封装出一个类ACE的C++实现，首先来复读下C++对象模型吧。要了解new一个object的成本，最主要的就是知道，编译器会给对象分配多少内存，知道C++的对象模型无疑就了解这一点了。 </p>
<span id="more"></span>
<p>如果要研究C++的对象模型，大家潜意识都想知道的是，C++比C好在哪里？又比C差在哪里？ </p>
<p>我们主要就是想从C++的对象模型里找到后一个答案。前一个答案在软件工程中是毫无疑义的，面向对象的优越性要比C语言里一堆<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">数据结构</a>+和一堆可能与它们相关的函数，可读性、可用性好很好，对开发大型软件工程，需要几百人开发一个项目来说，C++好太多了。看看JAVA或者python程序员们，他们为什么可以一直站在巨人的肩膀上，想完成任何一个功能都超级方便的调用大师们以前写好的package/API，借用各种设计模式，应用级别程序员们可以非常EASY的使用复杂的设计，一些只有高级C程序员才能掌握的东东。当然，JAVA的很多特性也导致不适应核心服务器的开发，比如它的垃圾回收机制。 </p>
<p>OK，闲话少叙，在看对象模型前，先看几个C++与C语言的典型不同之处。 </p>
<ol>
<li>自然是类的定义了，最大的改变就是类把数据结构与方法捆到一起了，可读性上提升巨大。对成员变量和成员方法，有5种类型：static member, nonstatic member, static function, nonstatic function, virtual function. </li>
<li>继承，这里很有许多细节了，核心解决问题就是动态绑定，也就是virtual关键字。virtual出现的唯一原因就是为了解决继承机制，否则struct里引入方法就足够了，class出现就是为了这。virtual关键字解决了子类实例和父类实例的一些特殊关系，考虑以下场景：软件工程中，很喜欢每个模块专注于自己的事，尽量忽略与自己无关的实现，这样，很可能会用一个父类指针，该指针太可能指向多种不同的子类了，但是现在，使用这个抽象父类指针的模块不想关注细节，当它调用对象的某个方法时，到底是调用父类的方法还是子类的方法呢？动态绑定这个特性就是，开发者可以决定这一点，当你用virtual关键字申明父类方法时，如果子类重定义了该方法，如果这个指针实际指向的是某子类对象，那么调用的方法一定是该子类方法的实现。 举个例子吧，就像什么析构函数总喜欢写成virtual？这个例子应该容易说明virtual的玩法。一段简单的代码：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;  </span><br><span class="line">using namespace std;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">class Father  </span><br><span class="line">&#123;  </span><br><span class="line">public:  </span><br><span class="line">    int m_fMember;  </span><br><span class="line">    Father()&#123;m_fMember&#x3D;1;&#125;  </span><br><span class="line">    ~Father()&#123;cout&lt;&lt;m_fMember&lt;&lt;endl;&#125;  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">class Child : public Father&#123;  </span><br><span class="line">public:  </span><br><span class="line">    int m_cMember;  </span><br><span class="line">    Child()&#123;m_cMember&#x3D;2;&#125;  </span><br><span class="line">    ~Child()&#123;cout&lt;&lt;m_cMember&lt;&lt;endl;&#125;  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">int main(int argc, char** argv)  </span><br><span class="line">&#123;  </span><br><span class="line">    Father* pObj1 &#x3D; new Child();  </span><br><span class="line">    delete pObj1;  </span><br><span class="line">    Child* pObj2 &#x3D; new Child();  </span><br><span class="line">    delete pObj2;     </span><br><span class="line">    return 0;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>这段代码的结果是1 2 1，啥意思呢？就是说，如果不用virtual函数，是没有执行期绑定一说的，比如pObj1这个指针，其实它是Child对象，但是在释放时，<del>Child()方法并没有被调用，仅调用了</del>Father方法。为什么呢？因为没有用virtual，就是编译期绑定，当你在编译时gcc/g++只知道pObj1是个Father对象，所以在delete时就去调用Father的析构了。而如果定义成virtual ~Father时，结果就是一定会析构Child，这就是为什么析构函数都要用virtual，因为没人知道会不会有子类继承，否则一旦继承，发生这样的事，析构函数里万一释放了些资源，比如SOCKET，比如memory，那就是资源泄露了。</p>
<p>那么以上，C++对象模型是怎么做到的呢？画张象征性的图吧。先定义一个类，再看看它的内存布局：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Father  </span><br><span class="line">&#123;  </span><br><span class="line">public:  </span><br><span class="line">    int m_fMember;  </span><br><span class="line">    static int m_sMember;  </span><br><span class="line">    static void testSFunc()&#123;&#125;  </span><br><span class="line">    void testFunc()&#123;&#125;  </span><br><span class="line">    virtual void testVFunc()&#123;&#125;  </span><br><span class="line">    Father()&#123;m_fMember&#x3D;1;&#125;  </span><br><span class="line">    virtual ~Father()&#123;cout&lt;&lt;m_fMember&lt;&lt;endl;&#125;  </span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure>

<p>我们生成一个Father对象，看看它的的内存布局是啥样的（同志们，这只是近似存储布局图，没有把编译和运行的差别放上去，下篇再讲这个）： <img src="/2017/01/0_1324266008rIGL-1-1.jpg"> </p>
<p>这里大家明白了吧？即使一个Child对象在编译时被赋为Father类型，但是实际调用时，virtual方法会被单独的拎出来，在vtbl中指向实际的实现，所以，该对象在delete时会调用Child的析构函数，而如果你像上面例子那样，析构方法不使用virtual，将会用到上图中的最后一个指针，指向类成员函数里，这样就不是执行期绑定了。 </p>
<p>剩下的static成员（还有所有的正常成员函数），都是与对象实例无关的内存布局。这样，其实如果不使用virtual，C++比之C并没有增加成本，尽可放心使用。</p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>vtbl</tag>
        <tag>对象模型</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里云搭建wordpress生产级CMS网站实践</title>
    <url>/2017/01/27/%E9%98%BF%E9%87%8C%E4%BA%91%E6%90%AD%E5%BB%BAwordpress%E7%94%9F%E4%BA%A7%E7%BA%A7cms%E7%BD%91%E7%AB%99%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>搭建cms内容站点时，wordpress是一个很好的选择，不用做任何开发就可以通过配置、插件获得丰富的功能。用<a href="http://lib.csdn.net/base/docker" title="Docker知识库">Docker</a>容器技术部署运维都非常简单，特别是对于wordpress这种我们无需做任何开发的组件。而出于低成本考虑，公有云都是一个最佳选择，这里我选择阿里云。为了提速，wordpress前会有一个nginx作为负载均衡和web加速服务器，将静态内容都由nginx处理。出于高可靠性，我选用阿里云的容器服务（目前免费），由它来管理所有容器。而多容器间的磁盘目录共享，阿里云提供了oss映射和nas盘，oss盘的速度太慢，而nas盘IO与云盘相当，可以作为第一选择。<a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">数据库</a>为了可靠性，如果没有独立的DB运维人员，就选择rds <a href="http://lib.csdn.net/base/mysql" title="MySQL知识库">MySQL</a>好了（目前单机版RDS刚上线，相比双机mysql便宜很多）。 </p>
<span id="more"></span>
<h1 id="搭建基本站点"><a href="#搭建基本站点" class="headerlink" title="搭建基本站点"></a>搭建基本站点</h1><p>一、最初我们验证方案时，总是先从最简单的做起，功能满足要求即可。 </p>
<h2 id="购买ECS"><a href="#购买ECS" class="headerlink" title="购买ECS"></a>购买ECS</h2><p>我们购买好ECS（如果是经典网络一定要含公网带宽，否则接下来用到阿里云容器服务时你会悲催的发现，目前阿里云容器要求集群内的经典网络节点必须含有公网带宽， 否则该ECS无法加入集群中。VPC网络就没有这个问题。在可见的一段时间内，阿里云可能都不会修复这个问题。），<a href="http://lib.csdn.net/base/operatingsystem" title="操作系统知识库">操作系统</a>如果是centos7.0或者7.2，高内核版本支持docker就更简单了。 </p>
<h2 id="创建数据库配置文件"><a href="#创建数据库配置文件" class="headerlink" title="创建数据库配置文件"></a>创建数据库配置文件</h2><p>数据库在centos7.0以上版本时，mariadb比较方便（出于性能考虑，docker容器的db不推荐为生产环境下的数据库）。yum install这个数据库，修改/etc/my.cnf，使其支持utf-8，例如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">init_connect=<span class="string">&#x27;SET collation_connection = utf8_unicode_ci&#x27;</span></span><br><span class="line">init_connect=<span class="string">&#x27;SET NAMES utf8&#x27;</span></span><br><span class="line">character-set-server=utf8</span><br><span class="line">collation-server=utf8_unicode_ci</span><br><span class="line">skip-character-set-client-handshake</span><br><span class="line">[client]</span><br><span class="line">default-character-set=utf8</span><br><span class="line">[mysql]</span><br><span class="line">default-character-set=utf8</span><br></pre></td></tr></table></figure>

<p>用service mariadb start启动数据库。</p>
<h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>用create user命令创建好用户，create database创建好db，grant命令赋予权限，例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database yourdb;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> youruser IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;yourpass&#x27;</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> yourdb.<span class="operator">*</span> <span class="keyword">TO</span> youruser;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<h2 id="用docker运行数据库"><a href="#用docker运行数据库" class="headerlink" title="用docker运行数据库"></a>用docker运行数据库</h2><p>用docker pull wordpress命令拉下官方最新版本的image，然后用docker run将其启动。-p端口映射到主机的80端口上。注意，很多image都会通过提供环境变量来修改配置，而wordpress也是如此，这里我们主要是修改其连接哪个数据库，通常这四个环境变量配置好即可。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-e WORDPRESS_DB_HOST=...</span><br><span class="line">-e WORDPRESS_DB_USER=...</span><br><span class="line">-e WORDPRESS_DB_PASSWORD=...</span><br><span class="line">-e WORDPRESS_DB_NAME=...</span><br></pre></td></tr></table></figure>

<h2 id="解析域名"><a href="#解析域名" class="headerlink" title="解析域名"></a>解析域名</h2><p>接下来我们将购买的域名在阿里云的云解析页面上，配置到该公网IP上。（wordpress里需要配置域名，直接使用域名比IP方便）。</p>
<h2 id="在浏览器上安装wordpress"><a href="#在浏览器上安装wordpress" class="headerlink" title="在浏览器上安装wordpress"></a>在浏览器上安装wordpress</h2><p>在页面上打开域名，显示wordpress的安装站点页面。根据提示傻瓜化的安装这个wordpress，接下来我们就可以体验下wordpress强大的CMS功能了。 </p>
<h1 id="优化站点"><a href="#优化站点" class="headerlink" title="优化站点"></a>优化站点</h1><p>二、接下来，我们需要一个更美观的站点，而wordpress提供主题自定义功能。我们可以在google上找到很多免费或者收费的主题。接下来美化这个站点，使之符合功能需求。 </p>
<ol>
<li>首先找到符合要求的主题，下载后一般是一个zip文件。 </li>
<li>在wordpress的/wp-admin页面下进入管理界面，由外观-&gt;主题-&gt;添加-&gt;上传主题页面里，点击选择文件，将zip主题包上传。 </li>
</ol>
<p>通常在这个步骤中，我们可能会看到上传失败的结果。提示上传文件过大（特别是你下载的zip主题包达到几十M的时候）。这是<a href="http://lib.csdn.net/base/php" title="PHP知识库">PHP</a>服务默认允许的上传文件过小所致。要想解决，首先得改image的配置。此时，我们首先要重新运行docker，把容器的/var/www/html目录映射到主机目录中（用-v 主机目录：容器目录，这个volumes命令可以把容器的磁盘内容映射到主机目录中供我们修改）。我们在映射目录下创建.htaccess文件，在此文件中输入以下配置项：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">php_value upload_max_filesize 64M</span><br><span class="line">php_value post_max_size 64M</span><br><span class="line">php_value max_execution_time 300</span><br><span class="line">php_value max_input_time 300</span><br></pre></td></tr></table></figure>

<p>这里把上传文件的大小增加到64M。再启动docker容器，上传并安装新主题即可。</p>
<h1 id="提升性能"><a href="#提升性能" class="headerlink" title="提升性能"></a>提升性能</h1><p>三、接着，多半会发现这个站点太慢了，体验很差，我们希望网站速度更快一点。 </p>
<ol>
<li>去除头像拉取<br>用浏览器的debug模式可以发现，最慢的请求从url看都是获取gravatar头像，请求之所以慢与墙有关（提供头像服务的机器网络不稳定）。最简单的解决办法是在wp-content/themes/your-theme-using目录下，在functions.php文件的结尾加上以下几行（参见<a href="http://www.dmeng.net/wordpress-replace-gravatar-host.html">http://www.dmeng.net/wordpress-replace-gravatar-host.html</a>）：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function dmeng_get_https_avatar($avatar)&#123;</span><br><span class="line">    $avatar &#x3D; str_replace(array(&quot;www.gravatar.com&quot;, &quot;0.gravatar.com&quot;, &quot;1.gravatar.com&quot;, &quot;2.gravatar.com&quot;), &quot;secure.gravatar.com&quot;, $avatar);</span><br><span class="line">    return $avatar;</span><br><span class="line">&#125;</span><br><span class="line">add_filter(&#39;get_avatar&#39;, &#39;dmeng_get_https_avatar&#39;);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>用Nginx处理静态资源<br>增加一台nginx，域名直接指向nginx所在的机器，由nginx将动态请求反向代理给wordpress容器。而静态内容由nginx处理。</li>
</ol>
<p>此时我们可能会遇到网站无法访问的情况，在nginx的日志里可以看到是301重定向过多导致。解决办法还是在上面的functions.php文件的结尾加上一行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">remove_filter(&#39;template_redirect&#39;, &#39;redirect_canonical&#39;);</span><br></pre></td></tr></table></figure>

<p>我们还可能遇到上传新的主题文件时得到413错误，这是nginx拒绝所致，记得在nginx.conf里加上client_max_body_size 60M; 3、nginx还可以配成http2，但后面得用阿里云的slb防单点。 </p>
<h1 id="提升可用性"><a href="#提升可用性" class="headerlink" title="提升可用性"></a>提升可用性</h1><p>四、一台访问速度和功能都满足我们需求的CMS站点出现了，接下来，我们开始解决可靠性问题。首先，我们需要把单点数据库改为RDS数据库（如果你的数据库有人全职维护那就不需要）。购买一个rds实例，建议与你的ECS在同一个可用区（同一机房内，带宽高又稳定）。目前RDS单实例对于使用wordpress作为站点的公司来说应该够了吧？ </p>
<ol>
<li>在web站点上初始化root用户密码（注意，阿里云的RDS用户权限比自建的小了很多!）。 </li>
<li>加上访问白名单。通常我们是ECS内网访问数据库（便宜安全），所以将ECS内网IP加入白名单。 </li>
<li>迁移数据。<br>这里我悲催了，阿里云RDS提供的迁移工具只能是mysql对mysql迁移，而我之前用的是相似的mariadb，迁移工具执行失败，提工单后售后反馈暂时不支持。 </li>
</ol>
<p>不同种类数据库的迁移这种情况下，用sql导入肯定是可行的。于是准备用mysqldump把mariadb中数据库的数据导出sql文件，出现错误： mysqldump: Error: Binlogging on server not active 在my.cnf上加入</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">log_bin=mysql-bin</span><br></pre></td></tr></table></figure>

<p>再执行：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mysqldump --databases yourdb --user=youruser -hyourhost --password --master-data &gt; transfer.sql</span><br></pre></td></tr></table></figure>

<p>先用root登上RDS，建数据库建用户。再导入时发现还是不行：ERROR 1227 (42000) at line 22: Access denied; you need (at least one of) the SUPER privilege(s) for this operation 这是生成的sql文件里有RDS不支持的操作。将其中最上面的两行删掉：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER <span class="keyword">TO</span> MASTER_LOG_FILE<span class="operator">=</span><span class="string">&#x27;mysql-bin.000001&#x27;</span>, MASTER_LOG_POS<span class="operator">=</span><span class="number">191500</span>;</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE <span class="comment">/*!32312 IF NOT EXISTS*/</span> `yourdb` <span class="comment">/*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci */</span>;</span><br></pre></td></tr></table></figure>

<p>再执行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql <span class="operator">-</span>u youruser <span class="operator">-</span>h yourhost yourdb <span class="operator">-</span>p <span class="operator">&lt;</span> transfer.sql</span><br></pre></td></tr></table></figure>

<p>即完成数据库的迁移。<br>4、最后将docker wordpress容器通过环境变量指向RDS数据库。 </p>
<h1 id="搭建wordpress集群"><a href="#搭建wordpress集群" class="headerlink" title="搭建wordpress集群"></a>搭建wordpress集群</h1><p>五、数据库单点解决掉后，再来解决wordpress <a href="http://lib.csdn.net/base/docker" title="Docker知识库">Container</a>容器的单点与运维。这里有个待解决的问题是wordpress容器如果有多个实例，且跨ECS主机，那么就需要共享磁盘去映射容器中的/var/www/html目录（特别是其中包括uploads上传文件的目录）。 </p>
<p>1、首先，我们要利用阿里云容器将dockoer容器运维起来的优势，将wordpress放在容器服务里运行。 </p>
<p>2、其次，阿里云容器支持OSS或者NAS盘映射到集群内每一台ECS机器上某个目录。即，如果我们配置数据卷支持OSS和NAS（当然需要先购买这两种服务），集群内每个ECS都将自动的多出/mnt/acs_mnt/nas和/mnt/acs_mnt/ossfs目录，方便我们每个contain容器进行映射。 这里需要注意，如果是oss映射为磁盘，必须在其他参数里增加“-o umask=000”，否则docker容器每次新生成的文件其权限是有问题的，无法访问，这个BUG阿里云可能以后会解决吧。 另外，大家会强烈的感受到用oss去映射/var/www/html目录网站就会非常慢，这是因为oss本身的时延就高，而改成nas盘就会好多了。（但oss盘比nas盘便宜很多） </p>
<p>当然，用oss可以非常方便的使用cdn，nas就没有这么便利了。 <img src="/2017/01/unnamed-file.jpg"> 最终<a href="http://lib.csdn.net/base/architecture" title="大型网站架构知识库">架构</a>如上所示。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>高可用</tag>
        <tag>wordpress</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>公开课：K8S Ingress Controller技术细节探讨</title>
    <url>/2021/05/17/k8s/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B%EF%BC%9AK8S-Ingress-Controller%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E6%8E%A2%E8%AE%A8/</url>
    <content><![CDATA[<p>对于许多企业来说，将生产环境转移到Kubernetes集群上，会让应用程序的流量管理变得复杂且具有挑战性。</p>
<p>而Ingress Controller允许通过Yaml编排脚本提供高可用的七层负载均衡、Waf防火墙或者API Gateway，它是Kubernetes集群对外服务的核心组件。</p>
<p>Ingress-nginx是Kubernetes Ingress Controller开源版本中的一种，它使用了NGINX作为反向代理和负载均衡器，生态完善、功能丰富，性能与稳定性也是极优秀的。</p>
<p>这是Nginx开源论坛上的第10季课程，这里我会详细介绍基于Nginx开发的Ingress Controller，包括Kubernetes社区及Nginx官方提供的2种开源Controller，对比它们各自的优缺点。<br><img src="/images/k8s/k8s%E7%A4%BE%E5%8C%BAController%E6%9E%B6%E6%9E%84.png"></p>
<span id="more"></span>
<p>这个主题同样包含4次课程，每次大约1个小时的视频课程，包括：</p>
<h1 id="Ingress-Controller-的工作原理"><a href="#Ingress-Controller-的工作原理" class="headerlink" title="Ingress Controller 的工作原理"></a>Ingress Controller 的工作原理</h1>

<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">

<iframe src="//player.bilibili.com/player.html?aid=757661904&bvid=BV1r64y1m72f&cid=327993545&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>



<h1 id="Ingress-Controller与Master的通讯机制"><a href="#Ingress-Controller与Master的通讯机制" class="headerlink" title="Ingress Controller与Master的通讯机制"></a>Ingress Controller与Master的通讯机制</h1>

<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">

<iframe src="//player.bilibili.com/player.html?aid=290346141&bvid=BV1Cf4y1p7pw&cid=331017365&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>



<h1 id="K8s官方NGINX-Ingress-Controller的核心特性"><a href="#K8s官方NGINX-Ingress-Controller的核心特性" class="headerlink" title="K8s官方NGINX Ingress Controller的核心特性"></a>K8s官方NGINX Ingress Controller的核心特性</h1>

<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">

<iframe src="//player.bilibili.com/player.html?aid=845568767&bvid=BV1c54y1L7bj&cid=338055610&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>


<h1 id="Nginx官方Controller开源版的核心特性"><a href="#Nginx官方Controller开源版的核心特性" class="headerlink" title="Nginx官方Controller开源版的核心特性"></a>Nginx官方Controller开源版的核心特性</h1>

<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">

<iframe src="//player.bilibili.com/player.html?aid=758257982&bvid=BV1K64y1o7ey&cid=345131476&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>


<h1 id="课件下载"><a href="#课件下载" class="headerlink" title="课件下载"></a>课件下载</h1><p>这四次课程的PPT在这里：<a href="/pdf/%E7%AC%AC%E5%8D%81%E5%AD%A3-K8S-IngressController%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E6%8E%A2%E8%AE%A8.pdf" title="第十季 - K8S Ingress Controller技术细节探讨">点击下载</a> 。</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>kubernates</tag>
        <tag>ingress</tag>
        <tag>ingress controller</tag>
        <tag>client-go</tag>
      </tags>
  </entry>
  <entry>
    <title>公开课：探索NGINX_UNIT</title>
    <url>/2021/05/18/k8s/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B%EF%BC%9A%E6%8E%A2%E7%B4%A2NGINX-UNIT/</url>
    <content><![CDATA[<blockquote>
<p>UNIT是NGINX于2017年推出的Web容器方案，它提供了REST JSON接口动态修改服务配置，目前为Python、Java、Ruby、Perl、NodeJS、GOLang、WebAssembly等语言提供了生产环境级别的高性能Web容器，适用于大规模分布式环境中的微服务管理。从3月11日到4月1日，我分享了关于UNIT的4次课程。</p>
</blockquote>
<p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1/nginx_unit/nginx-unit-1-0-architecture.png"><br>微服务架构中，由于开发语言多样化、服务实例数量多，这就需要一种统一的服务治理方法，将配置更改、服务启停、网络协议适配、日志搜集等通用功能低成本的管理起来。K8S是一种解决方案，而NGINX UNIT针对Web场景也提供了上述功能，而且由于它仅针对Web容器场景，所以性能也更高。这4次视频课程如下：</p>
<span id="more"></span>
<h1 id="3月11日-用Unit实现应用的动态配置"><a href="#3月11日-用Unit实现应用的动态配置" class="headerlink" title="3月11日 用Unit实现应用的动态配置"></a>3月11日 用Unit实现应用的动态配置</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=545033810&bvid=BV1Ni4y1A7xi&cid=323088993&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>



<h1 id="3月18日-Unit的负载均衡配置"><a href="#3月18日-Unit的负载均衡配置" class="headerlink" title="3月18日 Unit的负载均衡配置"></a>3月18日 Unit的负载均衡配置</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=204792850&bvid=BV1mh411S77W&cid=317217863&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="3月25日-Unit架构设计"><a href="#3月25日-Unit架构设计" class="headerlink" title="3月25日 Unit架构设计"></a>3月25日 Unit架构设计</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=672288361&bvid=BV1rU4y1a7Pw&cid=317184368&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="4月01日-Unit源代码解读"><a href="#4月01日-Unit源代码解读" class="headerlink" title="4月01日 Unit源代码解读"></a>4月01日 Unit源代码解读</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=544887394&bvid=BV1Xi4y1P7Qu&cid=320481412&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

</div>


<h1 id="课件下载"><a href="#课件下载" class="headerlink" title="课件下载"></a>课件下载</h1><p>这四次课程的PPT在这里：<a href="/pdf/%E7%AC%AC%E4%B9%9D%E5%AD%A3-%E6%8E%A2%E7%B4%A2NGINX_UNIT.pdf" title="第九季-探索NGINX_UNIT">点击下载</a> 。</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>微服务</tag>
        <tag>unit</tag>
        <tag>cgroup</tag>
      </tags>
  </entry>
  <entry>
    <title>十分钟搭建好K8S集群</title>
    <url>/2020/12/22/k8s/%E5%8D%81%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BA%E5%A5%BDk8s%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>虽然网上有大量从零搭建K8S的文章，但大都针对老版本，若直接照搬去安装最新的1.20版本会遇到一堆问题。故此将我的安装步骤记录下来，希望能为读者提供copy and paste式的集群搭建帮助。 我是在腾讯云CentOS的2台服务器上，在不翻墙的情况下使用kubeadm（最简单的部署工具）搭建K8S集群。其中，容器网络使用flannel，最终安装好可以外网访问的2.0.4版本的dashboard。不走弯路的话，4步即可完成：</p>
<span id="more"></span>

<h2 id="准备系统环境"><a href="#准备系统环境" class="headerlink" title="准备系统环境"></a>准备系统环境</h2><p>对这2台新购的云虚拟机，都需要安装docker：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">yum install docker -y</span><br></pre></td></tr></table></figure>

<p>安装kubeadm前，需要先添加kubeadm的yum源：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&gt;</span> <span class="string">/etc/yum.repos.d/kubernetes.repo</span> <span class="string">&lt;&lt;EOF</span></span><br><span class="line">[<span class="string">kubernetes</span>]</span><br><span class="line"><span class="string">name=Kubernetes</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">repo_gpgcheck=0</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>接着安装目前最新版的kubeadm：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install kubeadm-1.20.1-0.x86_64</span><br></pre></td></tr></table></figure>

<p>其中，kubeadm依赖的kubelet（K8S最核心的组件）、kubectl、kubernetes-cni网络插件等会自动安装。 最后启用这2个服务：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable kubelet.service</span><br><span class="line">systemctl start docker.service</span><br></pre></td></tr></table></figure>

<p>腾讯云主机默认已经将bridge-nf-call-iptables和ip_forward置为1，如果你的主机值为0，需要先将功能开启：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sysctl -w net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">sysctl -w net.ipv4.ip_forward=1</span><br></pre></td></tr></table></figure>

<p>接着，针对部署K8S master节点的主机，还需要做些工作。由于腾讯云默认的主机名并不是域名格式（不符合master节点要求），所以需要修改为你自定义的域名。这需要2个步骤：</p>
<ol>
<li> 将设计好的主机名写入/etc/hostname文件；</li>
<li> 将/etc/hosts中原主机名替换掉。</li>
</ol>
<h2 id="部署master节点"><a href="#部署master节点" class="headerlink" title="部署master节点"></a>部署master节点</h2><p>kubeadm的init命令即可初始化以单节点部署的master。为了避免翻墙，我<strong>使用了<code>registry.aliyuncs.com/google_containers</code>源</strong>。虽然可以在kubeadm命令行中输入源，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm init --image-repository registry.aliyuncs.com&#x2F;google_containers</span><br></pre></td></tr></table></figure>

<p>但将其写入资源编排文件更易维护，我将其命名为kubeadm.yaml：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.20.1</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line">  <span class="attr">podSubnet:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line"><span class="attr">controllerManager:</span></span><br><span class="line">        <span class="attr">ExtraArgs:</span></span><br><span class="line">                <span class="attr">horizontal-pod-autoscaler-use-rest-clients:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">                <span class="attr">horizontal-pod-autoscaler-sync-period:</span> <span class="string">&quot;10s&quot;</span></span><br><span class="line">                <span class="attr">node-monitor-grace-period:</span> <span class="string">&quot;10s&quot;</span></span><br></pre></td></tr></table></figure>

<p>注意，这个编排文件有4个细节：</p>
<ul>
<li>  接口版本使用了v1beta2；</li>
<li>  为flannel分配的网段是<code>10.244.0.0/16</code>；</li>
<li>  选择的kubernetes版本是当前最新的1.20.1；</li>
<li>  加入了<code>controllerManager</code>的水平扩容功能。</li>
</ul>
<p>接着，使用编排文件执行init命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubeadm init --config ./kubeadm.yaml</span><br></pre></td></tr></table></figure>

<p>注意，执行成功后kubeadm会返回类似下面的字样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br></pre></td></tr></table></figure>

<p>之后，还有2条重要的信息： 1、后续kubectl默认控制集群时，需要使用到CA密钥，通过TLS协议保障通讯的安全性。我们要通过下面3行命令拷贝密钥信息，这样，kubectl执行时会首先访问当前用户的.kube目录，使用这些授权信息访问集群：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure>

<p>2、之后添加worker节点时，要通过token才能保障安全性。因此，先把显示的这行命令保存下来：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubeadm join 172.27.0.11:6443 --token xxxxxxxxxxxx \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxx</span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="部署flannel网络"><a href="#部署flannel网络" class="headerlink" title="部署flannel网络"></a>部署flannel网络</h2><p>flannel网络需要指定IP地址段，在上一步中已经通过编排文件设置为<code>10.244.0.0/16</code>。部署flannel只需要一行命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl apply -f ./kube-flannel.yml</span><br></pre></td></tr></table></figure>

<p>其中，由于原本可以直接下载的文件必须翻墙，所以我把文件内容列在下方，保存为上述命令的kube-flannel.yml文件（参见第5小节）： 此时，调用get pods命令，可以看到master节点的组件和flannel网络都牌Running状态：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@k8s]<span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-7f89b7bc75-g8c42              1/1     Running   0          118s</span><br><span class="line">coredns-7f89b7bc75-z2p7c              1/1     Running   0          118s</span><br><span class="line">etcd-taohui.tech                      1/1     Running   0          2m6s</span><br><span class="line">kube-apiserver-taohui.tech            1/1     Running   0          2m6s</span><br><span class="line">kube-controller-manager-taohui.tech   1/1     Running   0          2m6s</span><br><span class="line">kube-flannel-ds-kfzrg                 1/1     Running   0          13s</span><br><span class="line">kube-proxy-qbdz5                      1/1     Running   0          118s</span><br><span class="line">kube-scheduler-taohui.tech            1/1     Running   0          2m6s</span><br></pre></td></tr></table></figure>

<p>接着，登入另一台服务器上，通过之前保存的kubeadm join命令，将其加入K8S集群。通过get nodes命令可以看到集群中已有2个节点：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME              STATUS   ROLES                  AGE   VERSION</span><br><span class="line">taohui.tech       Ready    control-plane,master   14h   v1.20.0</span><br><span class="line">workernode        Ready    &lt;none&gt;                 12h   v1.20.1</span><br></pre></td></tr></table></figure>

<p>至此集群部署成功！如果有参数错误需要修改，你也可以在reset后重新init集群：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubeadm reset</span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="部署dashboard的"><a href="#部署dashboard的" class="headerlink" title="部署dashboard的"></a>部署dashboard的</h2><p>我们可以用以WEB页面的可视化dashboard，监控集群的状态。部署时同样面临翻墙和版本匹配的问题，这里我将2个镜像源替换后保存为dashboard.yaml编排文件（参见第6小节）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl apply -f dashboard.yaml</span><br></pre></td></tr></table></figure>

<p>执行成功后，你可以查看到service：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get svc -n kubernetes-dashboard</span></span><br><span class="line">NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">dashboard-metrics-scraper   ClusterIP   10.100.6.83     &lt;none&gt;        8000/TCP   13h</span><br><span class="line">kubernetes-dashboard        ClusterIP   10.99.243.226   &lt;none&gt;        443/TCP    13h</span><br></pre></td></tr></table></figure>

<p>注意，dashboard默认不允许外网访问。即使我们通过kubectl proxy允许外网访问，但dashboard又只允许HTTPS访问，这样kubeadm init时自签名的CA证书是不被浏览器承认的。我采用的方案是Nginx作为反向代理，使用Lets Encrypt提供的有效证书对外提供服务，再经由proxy_pass指令反向代理到kubectl proxy上，例如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubectl proxy --port=8888 --accept-hosts=<span class="string">&#x27;^*$&#x27;</span></span><br></pre></td></tr></table></figure>

<p>此时，本地可经由8888访问到dashboard。再通过Nginx访问它：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">proxy_pass http:&#x2F;&#x2F;localhost:8888;</span><br></pre></td></tr></table></figure>

<p>这样，当在外网根据我的域名访问如下URL：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;mydomain&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kubernetes-dashboard&#x2F;services&#x2F;https:kubernetes-dashboard:&#x2F;proxy&#x2F;#&#x2F;login</span><br></pre></td></tr></table></figure>

<p>就会展现2种登陆方式： <a href="/2020/12/22/%E5%8D%81%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BA%E5%A5%BDk8s%E9%9B%86%E7%BE%A4/k8s_dashboard_login/"><img src="/2020/12/k8s_dashboard_login.jpg"></a> 接下来采用token方式。首先要创建管理员帐户：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&lt;&lt;EOF</span>  <span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="bullet">-</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>执行完后，serviceaccount/admin-user用户已经创建。接着，将用户绑定已经存在的集群管理员角色：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&lt;&lt;EOF</span>  <span class="string">kubectl</span> <span class="string">apply</span> <span class="string">-f</span> <span class="bullet">-</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">admin-user</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>最后，获取可用户于访问的token：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret  grep admin-user  awk &#39;&#123;print $1&#125;&#39;)</span><br></pre></td></tr></table></figure>

<p>将token粘贴到登录页面，就可以看到dashboard了（下图是node页面）： <a href="/2020/12/22/%E5%8D%81%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BA%E5%A5%BDk8s%E9%9B%86%E7%BE%A4/k8s_dashboard_node/"><img src="/2020/12/k8s_dashboard_node.jpg"></a></p>
<h2 id="用于部署flannel网络的资源编排文件"><a href="#用于部署flannel网络的资源编排文件" class="headerlink" title="用于部署flannel网络的资源编排文件"></a>用于部署flannel网络的资源编排文件</h2><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">policy/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodSecurityPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">psp.flannel.unprivileged</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">seccomp.security.alpha.kubernetes.io/allowedProfileNames:</span> <span class="string">docker/default</span></span><br><span class="line">    <span class="attr">seccomp.security.alpha.kubernetes.io/defaultProfileName:</span> <span class="string">docker/default</span></span><br><span class="line">    <span class="attr">apparmor.security.beta.kubernetes.io/allowedProfileNames:</span> <span class="string">runtime/default</span></span><br><span class="line">    <span class="attr">apparmor.security.beta.kubernetes.io/defaultProfileName:</span> <span class="string">runtime/default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">configMap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">secret</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">emptyDir</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hostPath</span></span><br><span class="line">  <span class="attr">allowedHostPaths:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/etc/cni/net.d&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/etc/kube-flannel&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/run/flannel&quot;</span></span><br><span class="line">  <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Users and groups</span></span><br><span class="line">  <span class="attr">runAsUser:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">supplementalGroups:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">fsGroup:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="comment"># Privilege Escalation</span></span><br><span class="line">  <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">defaultAllowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Capabilities</span></span><br><span class="line">  <span class="attr">allowedCapabilities:</span> [<span class="string">&#x27;NET_ADMIN&#x27;</span>, <span class="string">&#x27;NET_RAW&#x27;</span>]</span><br><span class="line">  <span class="attr">defaultAddCapabilities:</span> []</span><br><span class="line">  <span class="attr">requiredDropCapabilities:</span> []</span><br><span class="line">  <span class="comment"># Host namespaces</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">hostIPC:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPorts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">min:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">  <span class="comment"># SELinux</span></span><br><span class="line">  <span class="attr">seLinux:</span></span><br><span class="line">    <span class="comment"># SELinux is unused in CaaSP</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">&#x27;RunAsAny&#x27;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&#x27;extensions&#x27;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&#x27;podsecuritypolicies&#x27;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&#x27;use&#x27;</span>]</span><br><span class="line">  <span class="attr">resourceNames:</span> [<span class="string">&#x27;psp.flannel.unprivileged&#x27;</span>]</span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes/status</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">cni-conf.json:</span> </span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;cbr0&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;cniVersion&quot;:</span> <span class="string">&quot;0.3.1&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;plugins&quot;:</span> [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;delegate&quot;:</span> &#123;</span><br><span class="line">            <span class="attr">&quot;hairpinMode&quot;:</span> <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">&quot;isDefaultGateway&quot;:</span> <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;portmap&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;capabilities&quot;:</span> &#123;</span><br><span class="line">            <span class="attr">&quot;portMappings&quot;:</span> <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="attr">net-conf.json:</span> </span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;Network&quot;:</span> <span class="string">&quot;10.244.0.0/16&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;Backend&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;Type&quot;:</span> <span class="string">&quot;vxlan&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/os</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">priorityClassName:</span> <span class="string">system-node-critical</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.13.1-rc1</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.13.1-rc1</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">            <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>, <span class="string">&quot;NET_RAW&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br></pre></td></tr></table></figure>

<p> </p>
<h2 id="用于部署dashboard的资源编排文件dashboard-yaml"><a href="#用于部署dashboard的资源编排文件dashboard-yaml" class="headerlink" title="用于部署dashboard的资源编排文件dashboard.yaml"></a>用于部署dashboard的资源编排文件dashboard.yaml</h2><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Copyright 2017 The Kubernetes Authors.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8443</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard-certs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard-csrf</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">csrf:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard-key-holder</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard-settings</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="comment"># Allow Dashboard to get, update and delete Dashboard exclusive secrets.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;secrets&quot;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&quot;kubernetes-dashboard-key-holder&quot;</span>, <span class="string">&quot;kubernetes-dashboard-certs&quot;</span>, <span class="string">&quot;kubernetes-dashboard-csrf&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line">    <span class="comment"># Allow Dashboard to get and update &#x27;kubernetes-dashboard-settings&#x27; config map.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;configmaps&quot;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&quot;kubernetes-dashboard-settings&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">    <span class="comment"># Allow Dashboard to get metrics.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;services&quot;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&quot;heapster&quot;</span>, <span class="string">&quot;dashboard-metrics-scraper&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;proxy&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;services/proxy&quot;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&quot;heapster&quot;</span>, <span class="string">&quot;http:heapster:&quot;</span>, <span class="string">&quot;https:heapster:&quot;</span>, <span class="string">&quot;dashboard-metrics-scraper&quot;</span>, <span class="string">&quot;http:dashboard-metrics-scraper&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="comment"># Allow Metrics Scraper to get metrics from the Metrics server</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;metrics.k8s.io&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>, <span class="string">&quot;nodes&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">registry.cn-shanghai.aliyuncs.com/jieee/dashboard:v2.0.4</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8443</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--auto-generate-certificates</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--namespace=kubernetes-dashboard</span></span><br><span class="line">            <span class="comment"># Uncomment the following line to manually specify Kubernetes API server Host</span></span><br><span class="line">            <span class="comment"># If not specified, Dashboard will attempt to auto discover the API server and connect</span></span><br><span class="line">            <span class="comment"># to it. Uncomment only if the default does not work.</span></span><br><span class="line">            <span class="comment"># - --apiserver-host=http://my-address:port</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kubernetes-dashboard-certs</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/certs</span></span><br><span class="line">              <span class="comment"># Create on-disk volume to store exec logs</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">tmp-volume</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">8443</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">30</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span></span><br><span class="line">            <span class="attr">runAsUser:</span> <span class="number">1001</span></span><br><span class="line">            <span class="attr">runAsGroup:</span> <span class="number">2001</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kubernetes-dashboard-certs</span></span><br><span class="line">          <span class="attr">secret:</span></span><br><span class="line">            <span class="attr">secretName:</span> <span class="string">kubernetes-dashboard-certs</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tmp-volume</span></span><br><span class="line">          <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">&quot;kubernetes.io/os&quot;:</span> <span class="string">linux</span></span><br><span class="line">      <span class="comment"># Comment the following tolerations if Dashboard must not be deployed on master</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">          <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8000</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8000</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">seccomp.security.alpha.kubernetes.io/pod:</span> <span class="string">&#x27;runtime/default&#x27;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dashboard-metrics-scraper</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">registry.cn-shanghai.aliyuncs.com/jieee/metrics-scraper:v1.0.4</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8000</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTP</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">8000</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">30</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">tmp-volume</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">            <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">true</span></span><br><span class="line">            <span class="attr">runAsUser:</span> <span class="number">1001</span></span><br><span class="line">            <span class="attr">runAsGroup:</span> <span class="number">2001</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">&quot;kubernetes.io/os&quot;:</span> <span class="string">linux</span></span><br><span class="line">      <span class="comment"># Comment the following tolerations if Dashboard must not be deployed on master</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">          <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tmp-volume</span></span><br><span class="line">          <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>kubernates</tag>
        <tag>dashboard</tag>
        <tag>k8s</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title>构建弹性网络之分布式负载均衡技术(一)：特点与功能</title>
    <url>/2024/07/18/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%84%E5%BB%BA%E5%BC%B9%E6%80%A7%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%8A%80%E6%9C%AF-%E4%B8%80-%EF%BC%9A%E7%89%B9%E7%82%B9%E4%B8%8E%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>本文首发于《中国金融电脑》第420期，金网在线<a href="https://www.fcc.com.cn/art/kjzx/69/12390.shtml">地址链接</a>。</p>
<h1 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h1><p>随着云原生、微服务的飞速发展，传统的负载均衡技术已逐渐难以满足日益复杂的业务需求。为了应对这一挑战，分布式负载均衡技术应运而生，它以其卓越的弹性、自助操作和可观测性，成为现代数据中心网络设计的核心。<br>本系列文章旨在深入探讨分布式负载均衡系统的多维度价值，从基础概念到技术实现，再到实际应用案例的全面分析。我希望通过这一系列的深入剖析，为读者提供一个全面的视角，理解分布式负载均衡技术如何为企业构建一个更加稳定、灵活和高效的网络环境。</p>
<p>系列概览：</p>
<ol>
<li>   构建弹性网络之分布式负载均衡技术（一）：概念与功能<br>在本篇中，我将介绍分布式负载均衡的基本概念，探讨其核心功能以及它如何为企业网络带来革命性的改进。</li>
<li>   构建弹性网络之分布式负载均衡技术（二）：技术与实现<br>第二篇文章将深入技术层面，分析分布式负载均衡的关键技术要素，以及如何实现这些技术，确保网络的高性能和高可用性。</li>
<li>   构建弹性网络之分布式负载均衡技术（三）：案例与分析<br>最后一篇将通过实际案例展示分布式负载均衡技术的应用效果，分析其在不同业务场景下的表现和优势。<br>通过本系列文章，我期望读者能够获得必要的知识，以评估和实施分布式负载均衡解决方案，从而提升自身网络的弹性和响应能力，满足不断变化的业务需求。<span id="more"></span>

</li>
</ol>
<p>在当今数字化时代，数据中心已成为企业运营的核心支柱，而负载均衡则是这座大厦的智慧中枢，通过流量调度提升了现代应用的性能、弹性、容灾、可靠性等关键指标，为用户提供了更加流畅、稳定的访问体验。</p>
<h1 id="传统负载均衡的3个主要问题"><a href="#传统负载均衡的3个主要问题" class="headerlink" title="传统负载均衡的3个主要问题"></a>传统负载均衡的3个主要问题</h1><p>随着技术的进步、市场环境的竞争加剧、系统复杂度的增加等因素，云原生、微服务、DevOps等应运而生，然而，面对这些提升开发效率的新技术，历史悠久的传统负载均衡却出现了水土不服，主要体现在以下3个方面：</p>
<h2 id="1）无法满足现代应用的交付速度。"><a href="#1）无法满足现代应用的交付速度。" class="headerlink" title="1）无法满足现代应用的交付速度。"></a>1）无法满足现代应用的交付速度。</h2><p>在数字化浪潮的推动下，应用交付速度的有了显著提升，这得益于多方面因素的共同作用。首先，市场竞争的加剧促使企业在蓝海市场中追求更精细的用户体验，以满足用户对个性化服务的高标准要求，这造就了APP的百花齐放。其次，随着系统架构从紧耦合向微服务等解耦模式转变，开发人员得以释放创造力，实现应用组件的独立快速迭代，显著提升了发布频率。再者，全球化带来的多样化市场需求，要求企业能够定制化交付应用，以适应不同地区用户的特定偏好。最后，低代码平台、云原生技术以及人工智能等创新技术的运用，大幅降低了开发门槛，提高了开发效率，从而加速了从概念到产品的整个开发流程。这些因素层层递进，共同塑造了一个应用与服务快速、灵活、高效发布的新纪元。<br>可是，<strong>传统负载均衡却拖慢了这种交付速度</strong>。传统负载均衡往往被视为“黑盒子”，因为仅有少数专业人员掌握其操作和配置的复杂性。业务开发人员在快速迭代的背景下，还得向这些专业人员来递交负载均衡需求，而<strong>少量的负载均衡维护人员则根本无法及时响应百倍于他们的业务人员</strong>。这种依赖性导致开发人员不得不在等待负载均衡配置的过程中，寻求更为灵活的替代方案，例如开源的NGINX。然而，当这些替代方案需要迁移到正式的生产环境时，又必须重新适配和配置传统的负载均衡设备，这个过程不仅增加了额外的工作负担，还可能导致配置错误和测试周期的延长，从而阻碍了快速应用交付的实现。</p>
<h2 id="2）既抬高了静态IT成本，应对突发流量时又无能为力。"><a href="#2）既抬高了静态IT成本，应对突发流量时又无能为力。" class="headerlink" title="2）既抬高了静态IT成本，应对突发流量时又无能为力。"></a>2）既抬高了静态IT成本，应对突发流量时又无能为力。</h2><p>传统负载均衡只能静态将各业务配置到负载均衡设备上，而由于业务创新的不确定性，很难预先判断哪个应用程序会突然火爆，这使得负载维护人员在配置业务时必须依赖业务团队对未来峰值流量的评估。这种评估往往<strong>偏向于高估</strong>，以避免因低估流量而导致服务中断的风险，从而增加了资源的预置和成本的支出。<br>然而，当某个应用出乎意料地成为爆款时，实际流量可能会迅速超过传统负载均衡器的最大处理能力，导致服务能力不足，影响用户体验和业务表现。在这种情况下，由于传统负载均衡器通常需要人工更换硬件，这在几小时内完成几乎是不可能的。此外，传统负载均衡器通常采用双机主备模式，这意味着大多数时间内只有主设备在提供服务，而<strong>备机则处于闲置状态或仅承载非关键业务</strong>，这限制了资源的有效利用并增加了单位流量的成本。<br>最后，在技术快速进步的背景下，传统负载均衡关键元器件的技术老化和更新滞后的问题日益凸显。硬件的固定性和更新周期的缓慢，使得它们难以适应快速变化的市场需求和技术进步，进一步加剧了TCO（Total Cost of Ownership, TCO）的上升。</p>
<h2 id="3）可观测性与自动化的缺失，导致故障定位缓慢、运维成本居高不下"><a href="#3）可观测性与自动化的缺失，导致故障定位缓慢、运维成本居高不下" class="headerlink" title="3）可观测性与自动化的缺失，导致故障定位缓慢、运维成本居高不下"></a>3）可观测性与自动化的缺失，导致故障定位缓慢、运维成本居高不下</h2><p>首先，可观测性的实现必须<strong>建立在易用性的基础上</strong>，因为只有深入业务的一线人员最清楚自己负责的业务潜在的问题及其解决方案。如果负载的可观测性不向业务人员开放，故障定位过程往往会陷入网络、运维、开发和测试团队之间的无效循环，这不仅延长了问题解决时间，也严重影响了客户体验和满意度。而需要专业人员维护的传统负载均衡是无法向全体研发人员开放的。<br>其次，传统负载均衡器在API对外开放程度上存在明显不足，与第三方运维系统的集成能力有限，且许多关键功能的API也未对外开放，这使得自动化故障处理和性能瓶颈分析变得极为困难。在这种环境下，运维团队往往需要依赖人工干预来监控系统状态、识别问题并执行修复，这不仅增加了运维人员的数量，也导致了故障定位的效率低下和响应速度缓慢。<br>此外，由于缺乏自动化工具和集成方案，运维工作往往重复而繁琐，难以适应快速变化的业务需求和市场环境。这种依赖人工操作的模式不仅增加了人力成本，也提高了出错的风险，限制了企业在面对业务高峰或突发事件时的响应能力。<br>因此，为了降低运维成本、提高故障定位速度和优化客户体验，迫切需要引入新一代的负载均衡技术，这些技术应具备更强的可观测性、更开放的集成能力和更高效的自动化功能，以支持业务的快速迭代和IT运维的智能化转型。通过这种方式，企业能够更有效地利用技术资源，减少对人工干预的依赖，实现更加敏捷和可靠的业务交付。</p>
<h1 id="分布式负载均衡的5个特点"><a href="#分布式负载均衡的5个特点" class="headerlink" title="分布式负载均衡的5个特点"></a>分布式负载均衡的5个特点</h1><p>面对当下传统负载均衡技术的不足，我们需要一种新一代的负载均衡技术解决方案，我将其简称为“分布式负载”，它既不是简单的“硬负载软件化”，也不是“软负载集群化”，因为要想解决以上3个问题，唯有具备以下5个特点，这才能称为分布式负载均衡。</p>
<h2 id="1）具备完整的OSI七层网络协议管理能力"><a href="#1）具备完整的OSI七层网络协议管理能力" class="headerlink" title="1）具备完整的OSI七层网络协议管理能力"></a>1）具备完整的OSI七层网络协议管理能力</h2><p>在构建高效且灵活的分布式负载均衡系统的过程中，首要的要求便是对OSI七层协议的完整管理能力。这是因为，为了有效应对突发流量的挑战和降低静态IT成本，负载均衡系统必须能够作为一套分布式系统<strong>实现自身的可伸缩性</strong>。这种能力要求负载均衡不仅在第四层（传输层）上进行流量的分配和管理，而且需要向下延伸至第二层（数据链路层）和第三层（网络层），以实现对聚合网口、VLAN、IP地址和路由等基础网络元素的精细控制。<br>具备这种全面的协议管理能力，分布式负载均衡系统能够更智能地识别和处理各种网络流量，确保在不同网络层次上实现前端流量的高效分配。这不仅提高了网络的整体性能和可靠性，而且为实现自动化的流量管理、灵活的资源调度和高效的故障恢复提供了坚实的基础。在多云和异构网络环境中，这种深层次的协议管理能力是实现负载均衡系统高度可伸缩性和灵活性的关键，也是支持现代IT架构向更高层次发展的重要技术支撑。</p>
<h2 id="2）具备弹性"><a href="#2）具备弹性" class="headerlink" title="2）具备弹性"></a>2）具备弹性</h2><p>分布式负载均衡的弹性是指系统能够根据流量的实际需求，动态调整虚拟服务所绑定的VIP（虚拟IP地址）的处理能力，既可以在流量高峰时扩展流量上限以应对增长的需求，也可以在流量减少时相应缩减资源以节约成本和机器使用。实现这种弹性的核心在于负载均衡系统要脱离主备模式的束缚，能够在二层广播域内或跨二层的三层网络中部署多台负载均衡转发节点，并确保它们能够协同工作，实现无缝的流量管理。在业务流量较低时，系统仅利用单一转发节点来提供服务，而随着流量的增长，系统应能够自动扩展，利用更多的转发节点来共同承担负载，从而实现服务的平滑扩展和高效分配。<br>此外，为了进一步提升弹性，分布式负载均衡系统需要能够与私有云（如OpenStack）或公有云的IaaS层进行深度集成。这种集成允许系统在检测到当前转发引擎节点不足时，自动在有效的账户和配额内购买或释放更多的虚拟机资源，以支持弹性服务的需求。通过这种方式，分布式负载均衡系统不仅能够在物理资源层面实现伸缩，还能够在云计算资源层面实现按需分配，从而为企业提供更加灵活、成本效益更高的服务。<br>    这种弹性可以有效降低企业的TCO成本，如某金融机构在应用了弹性方案后，将负载均衡使用的X86 CPU核心数降低了40%。</p>
<h2 id="3）API驱动的管理面与数据面分离"><a href="#3）API驱动的管理面与数据面分离" class="headerlink" title="3）API驱动的管理面与数据面分离"></a>3）API驱动的管理面与数据面分离</h2><p>传统负载均衡中管理功能和数据转发功能通常集成在同一设备上，这种设计限制了系统的灵活性和扩展性。通过将管理面与数据面分离，分布式负载均衡系统能够为企业提供一个集中化的管理界面，同时为不同的业务需求提供各自独有的数据转发平面，所有数据面均由统一的管理面进行调度和控制。<br>这种API驱动的分离架构的优势在于3点：</p>
<ul>
<li>集中式资源调度：分离架构允许通过单一的管理面，以一个统一的视角对所有IT资源进行统一资源调度。这种设计使得上述的“弹性”更有效率！</li>
<li>降低学习成本：由于管理面提供了统一的交互界面和标准化的操作流程，多套业务的运维人员可以采用相同的方式来管理和操作，极大地降低了学习和适应不同系统的成本。</li>
<li>简化网络部署成本：API驱动的管理面分离为自动化运维提供了技术基础。通过开放的API接口，分布式负载系统能够与第三方系统和工具无缝集成，实现自动化的配置管理、状态监控和故障恢复。而通过单一管理面简化了第三方系统网络部署的复杂性，并为实现自动化运维提供了便利。</li>
</ul>
<p>这种API驱动下的单一管理面对运维人力成本有巨大的降低，比如某媒体巨头在应用了分布式负载后，不仅应用部署时间下降了2个数量级，运营支出还节省了45%。</p>
<h2 id="4）业务人员能够自助操作负载均衡系统"><a href="#4）业务人员能够自助操作负载均衡系统" class="headerlink" title="4）业务人员能够自助操作负载均衡系统"></a>4）业务人员能够自助操作负载均衡系统</h2><p>分布式负载均衡系统的第四个核心优势是支持业务人员的自助操作，如下图所示，不同部门、不同角色的用户可以在单一管理下使用负载均衡系统。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9F%BA%E4%BA%8E%E7%A7%9F%E6%88%B7%E7%9A%84%E8%B4%A6%E6%88%B7%E4%BD%93%E7%B3%BB.png" alt="分布式负载基于租户的账户体系"><br>分布式负载均衡系统通过提供租户的概念，可以隔离不同部门用户的管理上下文，保证操作的独立性。比如上图中用户C、D同属于应用管理员，但他们却因为分属组织的不同，只能看到各自负责的虚拟服务、流量调度策略等配置。<br>但在某些情况下，如IP资源管理或者安全管理，可能需要跨业务的统一视图和控制。比如上图中的安全管理员E往往需要横向管理所有业务的安全策略，以确保整个企业网络的一致性和安全性。而用户C、D、F则需要同时使用E上传的SSL证书。再比如租户管理员B，能够统一管理租户1和租户2的IP地址资源。<br>不同业务的数据面通常需要进行隔离，以确保业务间的独立性和安全性。比如上图中的应用部和开发部，他们的业务运行在不同的转发引擎集群中。然而，根据业务特性和流量模式，某些业务可能共享同一数据面，从而实现IT资源的优化利用和成本节约。比如图中开发部的应用1组和应用2组的业务可以跑在集群1内实现资源的高效调度，以节约IT资源的使用，此时开发部可由具备角色的用户B统一管理这两个租户。<br>通过实现这些能力，分布式负载均衡系统为业务人员提供了一个既安全又易于操作的平台，使他们能够根据业务需求自助地管理网络流量和服务。这种自助操作模式不仅提高了运维效率，降低了对专业运维人员的依赖，也使得业务团队能够更加敏捷地响应市场变化，加速业务创新和交付。比如某零售商通过分布式负载的这个特性，将研发团队的开发效率提高了25%。</p>
<h2 id="5）适用于分布式系统的可观测性"><a href="#5）适用于分布式系统的可观测性" class="headerlink" title="5）适用于分布式系统的可观测性"></a>5）适用于分布式系统的可观测性</h2><p>分布式负载均衡系统的第五个关键特性是其为分布式环境量身定制的可观测性。这一特性对于确保系统的可靠性和优化用户体验至关重要：</p>
<ol>
<li>   结构化的监控数据<br>由于分布式负载均衡需要为企业完整的业务系统提供服务，所以其自身便是一个分布式集群，传统负载均衡的单机监控和问题定位方法已不再适用。因此，系统必须能够将监控数据进行结构化处理，并按照业务逻辑组织，使之能够清晰地呈现给运维人员，以便快速准确地定位问题。例如，抓包操作不应仅限于单机，而应在集群范围内批量进行，并能够自动关联到业务，以便于问题的诊断和解决。</li>
<li>   垂直与横向的全面监控<br>负载均衡系统由于其在网络中的核心位置，具有垂直观测OSI七层协议的能力，能够深入分析客户端到服务器的完整通信过程。同时，它也能够横向收集同一业务集群内所有转发节点的监控数据。这种能力使得负载均衡系统可以天然地将不同维度的数据进行有效联动和整合，从而快速地定位故障源头和识别性能瓶颈。</li>
<li>   自动化的分析与响应<br>除了数据的收集和整合，分布式负载均衡系统还应具备自动化分析的能力，能够实时监控网络流量和业务性能，智能识别异常模式，并触发预警或自愈机制。这不仅极大地提高了故障响应速度，也减轻了运维人员的工作负担。<br>通过这些高级的可观测性功能，分布式负载均衡系统为运维人员提供了一个全面、深入且自动化的监控和管理平台。这不仅加强了系统的透明度和可控性，也为企业的IT运营提供了强大的技术支撑，确保了业务的连续性和稳定性，同时也为业务的优化和创新提供了数据驱动的洞察。比如某IT服务商，通过将负载均衡的部分运维能力开放给第三方技术支持公司，便大幅降低了故障定位时间。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在数字化时代，传统负载均衡技术已无法满足现代应用的快速交付、成本效益和自动化需求。分布式负载均衡技术应运而生，它能够更智能地处理网络流量，实现资源的灵活调度和高效的故障恢复，同时降低运维成本，提高故障定位速度，优化客户体验，支持业务的快速迭代和IT运维的智能化转型，为企业提供了一个全面、深入且自动化的监控和管理平台。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
        <tag>OSI</tag>
        <tag>分布式负载</tag>
        <tag>DevOps</tag>
        <tag>可观测性</tag>
        <tag>弹性</tag>
        <tag>TCO</tag>
      </tags>
  </entry>
  <entry>
    <title>构建弹性网络之分布式负载均衡技术（二）：技术与实现</title>
    <url>/2024/08/01/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%84%E5%BB%BA%E5%BC%B9%E6%80%A7%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%8A%80%E6%9C%AF%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>本文首发于《中国金融电脑》第421期，今日头条<a href="https://www.toutiao.com/article/7410992908502827532/?app=news_article&timestamp=1725509891&use_new_style=1&req_id=2024090512181010B5EE9493AEB4704350&group_id=7410992908502827532&wxshare_count=1&tt_from=weixin&utm_source=weixin&utm_medium=toutiao_android&utm_campaign=client_share&share_token=291ca5eb-cb57-4b16-8ab2-f78a1a03d44c&source=m_redirect&wid=1725515434781">地址链接</a>。</p>
<p>随着信息技术的飞速发展，企业对于网络的依赖程度日益加深。传统的负载均衡技术曾经是企业数据中心的“守护神”，如今却在应对现代应用的快速交付、成本效益和自动化运维方面面临前所未有的挑战。分布式负载均衡技术可为企业网络带来革命性的改变。本文将深入分析从技术层面实现分布式负载均衡的关键要素，从弹性地址、“N+1”高可用系统到数据面与管理面的通信，介绍分布式负载均衡技术如何克服传统负载均衡技术的局限性，以确保网络的高性能和高可用性。</p>
<span id="more"></span>
<h1 id="一、二层广播域弹性地址的实现"><a href="#一、二层广播域弹性地址的实现" class="headerlink" title="一、二层广播域弹性地址的实现"></a>一、二层广播域弹性地址的实现</h1><p>传统负载均衡设备诞生于一个对资源成本敏感度较低、对稳定性有一定要求，但尚未普遍面临大规模并发和动态扩展需求的时代。所以，传统负载均衡设备采用双机主从架构的设计思路，仅提供基本的故障转移能力，控制面与数据面没有分离，设备也不会从组织管理层面开放给各个业务团队。传统负载均衡设备通常基于图1所示的架构实现。</p>
<h2 id="1-传统负载均衡架构的主要技术细节"><a href="#1-传统负载均衡架构的主要技术细节" class="headerlink" title="1.传统负载均衡架构的主要技术细节"></a>1.传统负载均衡架构的主要技术细节</h2><p>一是两台主机通过独立的心跳线互联，基于类似虚拟路由冗余协议（Virtual Router Redundancy Protocol,VRRP）监控状态、选举主从节点。<br>二是两台设备必须在一个广播域内，由选出的主设备广播免费ARP（Gratuitous ARP,GARP）消息，从设备则不回应ARP或者ICMP查询，这种实现方案依赖于交换机维护的虚拟IP（Virtual IP,VIP）与MAC地址的映射表。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E4%BC%A0%E7%BB%9F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%AE%BE%E5%A4%87%E5%8F%8C%E6%9C%BA%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.png" alt="传统负载均衡设备双机主从架构"></p>
<h2 id="2-传统双机主从架构存在的问题"><a href="#2-传统双机主从架构存在的问题" class="headerlink" title="2.传统双机主从架构存在的问题"></a>2.传统双机主从架构存在的问题</h2><ul>
<li><p>（1）资源利用率低<br>VIP在局域网内只能对应主设备，从设备对VIP而言处于完全闲置状态，所以资源利用率较低。</p>
</li>
<li><p>（2）基础容量上限低<br>一旦虚拟服务消耗的带宽、并发连接数等超过主设备上限，必须要通过升级硬件或者迁移设备才能解决问题。</p>
</li>
<li><p>（3）七层负载均衡功能需要分离<br>虽然传统负载均衡设备支持完备的OSI七层协议，然而，正则表达式匹配、ASCII码压缩等行为都很消耗CPU资源，因此，运维人员在双机CPU核心数极为有限的情况下，只能将消耗CPU的七层API网关从负载均衡设备集群上移除，将网络结构从一层分离为两层（如下图所示），从而提升了运维复杂度，增加了请求时延。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E4%BC%A0%E7%BB%9F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%E8%A7%84%E6%A8%A1%E4%B8%8A%E9%99%90%E5%B8%A6%E6%9D%A5%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%88%86%E5%B1%82%E7%8E%B0%E8%B1%A1.png" alt="传统负载均衡集群规模上限带来的负载分层现象"></p>
</li>
<li><p>（4）容错能力有限<br>如果两台负载均衡设备因为某种原因停止通信，就可能发生所谓的“脑裂”（Split-brain）现象。在这种情况下，每台设备都认为自己是主设备，并且独立地处理请求，导致数据不一致。当双机集群最终恢复通信时，由于在脑裂期间两台设备可能已经独立地进行了状态更新或数据写入，这种数据不一致的问题无法通过自动化方案来解决，需要人工干预进行数据的同步和一致性校验，以确保系统的完整性和可靠性。这与当下的自动化运维DevOps方案格格不入。</p>
</li>
<li><p>（5）网络部署结构限制性大<br>如果两台负载均衡设备分属不同的广播域，就无法构成高可用集群。</p>
</li>
</ul>
<h2 id="3-一主多辅架构的实现技术"><a href="#3-一主多辅架构的实现技术" class="headerlink" title="3.一主多辅架构的实现技术"></a>3.一主多辅架构的实现技术</h2><p>早期网络规模有限时，网络缺乏弹性对其并没有太大影响，但在当下网络规模庞大的情况下，缺乏弹性会极大影响资源与运维效率。双机主从架构存在的上述问题，其根源在于VIP实现的技术局限性，阻碍了服务的弹性扩展和高可用性的最大化。为突破这些限制，分布式负载均衡系统分离了控制面与数据面，使其各自实现了“多活”VIP技术。<br>数据面分别在OSI七层协议模型的第二层（数据链路层）和第三层（网络层）实现了“多活”VIP地址。为方便区分控制面与数据面，后续涉及分布式负载均衡架构时，其数据面的设备将称为“转发引擎”，管理面的设备称为“管理节点”。分布式负载均衡架构如下图所示。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%9E%B6%E6%9E%84.png" alt="分布式负载均衡架构"></p>
<p>在二层广播域内，分布式负载均衡架构采用了“一主多辅”架构，在处理以下场景时，该架构能够充分利用多设备的处理能力优化资源分配，即入流量小而出流量大的业务、消耗大量CPU资源的业务（如SSL卸载、实时数据压缩等），以及并发连接数超出单个转发引擎内存的限制时。一主多辅架构的实现技术如下：<br>一是主引擎通过向局域网内的交换机广播GARP报文，声明自己是VIP的拥有者，这样所有流向该VIP的流量都会被交换机定向到主转发引擎。<br>二是主引擎依据TCP/IP五元组（源IP、源端口、目的IP、目的端口和协议类型）对流量执行哈希运算，以确保来自同一客户端的连接能够被均匀且持续地分配到自身及辅转发引擎上。<br>需要强调的是，一旦连接建立，辅转发引擎的响应流量无需再经过主引擎返回，减少了网络延迟和主转发引擎的处理负担，提高了整体的响应速度和系统吞吐量。这种设计特别适合出流量大、大量消耗CPU和磁盘等资源、对响应时间敏感的静态资源服务，可有效缓解主从架构下的性能瓶颈问题，提升系统的扩展性和可用性。<br>一主多辅架构在容灾、故障恢复的平滑度上也优于主从架构。以一主三辅架构为例，此时四台转发引擎共同服务于一个VIP，当一台转发引擎发生故障时，其对整体服务的影响被限定在25%左右，即使主转发引擎发生故障，上述结论仍然成立。由于每台辅转发引擎都独立维护着连接状态表，系统可以从集群空闲转发引擎中选出新的主转发引擎，其可以通过整合连接状态表无缝接管服务，确保除了原主转发引擎处理的那部分流量受到影响外，其余流量可以被继续处理。相比主从模式中主设备故障即导致服务完全中断的情况，一主多辅架构有效缩短了故障带来的服务中断时间，缩小了服务中断范围，提升了用户体验和业务连续性。</p>
<h1 id="二、三层网络层弹性地址的实现"><a href="#二、三层网络层弹性地址的实现" class="headerlink" title="二、三层网络层弹性地址的实现"></a>二、三层网络层弹性地址的实现</h1><p>一主多辅架构只能提升二层广播域内的性能和容灾能力，当面对更大规模的集群部署或复杂的网络架构时，仅仅局限于二层的技术无法满足业务的弹性需求，此时可以通过等价路由（Equal-Cost Multi-Path,ECMP）技术在三层网络层实现“多活”VIP。ECMP技术不仅可扩展集群的地理覆盖范围，还突破了单一广播域的容量天花板，在真正意义上实现了大规模分布式系统的无边界扩展。</p>
<h2 id="1-ECMP技术的应用"><a href="#1-ECMP技术的应用" class="headerlink" title="1.ECMP技术的应用"></a>1.ECMP技术的应用</h2><p>ECMP的工作原理是基于路由协议（如BGP、OSPF）在多台设备之间分配等价的多条路径。当多条路径成本相同时，网络设备（如路由器或三层交换机）会利用ECMP算法自动将流入的流量按照预设规则均匀地分发到这些路径上。这样一来，每条路径上的转发引擎都可以作为主转发引擎同时处理流入的流量，并消除了单点故障和容量上限的限制。<br>图3中三层VIP是怎么实现的呢？每台转发引擎都会配置相同的VIP地址，并通过路由协议宣告此地址可达，路由器会根据ECMP算法，将去往这个VIP的流量均衡地分发到转发引擎上。在实际的应用中， ECMP算法通常由基于TCP/IP五元组的哈希算法实现，这样的设计具有以下四方面的显著优势。</p>
<ul>
<li>一是会话保持。基于TCP/IP五元组的哈希算法能够确保属于同一会话的数据包始终被同一路径处理，这对于维持TCP连接的连贯性和避免乱序至关重要。</li>
<li>二是负载均衡。通过将TCP/IP五元组映射到不同的路径，运用哈希算法能够较为均匀地分散流量，实现有效的负载均衡，避免某条路径过载。</li>
<li>三是扩展性与灵活性。随着网络规模的增长，只需增加新的路径并确保其成本等价，即可无缝扩展网络处理能力，无需调整现有网络配置。</li>
<li>四是故障恢复。当某条路径失效时，原本通过该路径的数据包会根据哈希规则被重新分配到其他有效路径上，从而快速实现故障绕行和网络恢复。<br>相对于一主多辅方案，ECMP方案允许每台设备独立处理流量，无需通过单一主设备中转，减少了网络延迟，提升了数据处理效率。由于ECMP技术无法应用在广播域内，所以需要将二层广播域的一主多辅架构与三层网络层的ECMP技术相结合，才能为弹性VIP地址的实现提供完整的技术支撑，在不同的网络层次上实现负载均衡和故障转移。<h2 id="2-扩容和迁移策略"><a href="#2-扩容和迁移策略" class="headerlink" title="2.扩容和迁移策略"></a>2.扩容和迁移策略</h2>当VIP地址足够灵活后，就可以通过扩容、缩容、迁移实现虚拟服务的弹性。例如，当监控系统检测到某个转发引擎的CPU使用率在最近15分钟内持续超过85%，则表明该转发引擎可能需要更强的处理能力来应对当前的负载，这时系统管理员或自动化工具可以采取扩容或迁移两种策略来提升处理能力。<br>扩容策略是指在现有的转发引擎上纵向增加计算资源（如修改虚拟机的配置），或者横向添加新的转发引擎实例来分担负载，其中新实例既可以是所属转发引擎集群中的空闲实例，也可以直接对接IaaS层的OpenStack、Kubernetes Master以分配新的转发引擎实例。迁移策略则是指将转发引擎上的虚拟服务动态灰度地迁移到其他转发引擎上。<br>选择扩容还是迁移策略，要看这台转发引擎上有没有消耗CPU资源的“大户”。为此，需要监控转发引擎上每个虚拟服务的资源消耗指标，如每秒处理报文数（Packets Per Second,PPS）。如果有1个虚拟服务的PPS占比超过70%，表明迁移很难解决问题，需要为该虚拟服务扩容才可以更有效地分配资源。反之，意味着多个虚拟服务共同导致了CPU的高负载，这时迁移策略就显得更为合适。通过将其中一个虚拟服务迁移到其他空闲的转发引擎上，可以减轻当前转发引擎的负担，优化资源分配。如果虚拟服务在多个转发引擎上的CPU使用率都相对较低，则可能意味着当前的资源配置超出了需求。在这种情况下，可以采取缩容措施，自动减少转发引擎的实例数量，从而节省资源、降低成本。弹性虚拟服务的扩容、迁移策略如下图所示。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E5%BC%B9%E6%80%A7%E8%99%9A%E6%8B%9F%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%89%A9%E5%AE%B9%E3%80%81%E8%BF%81%E7%A7%BB%E7%AD%96%E7%95%A5%E7%A4%BA%E6%84%8F.png" alt="弹性虚拟服务的扩容、迁移策略示意"></li>
</ul>
<h1 id="三、高可用管理面的实现"><a href="#三、高可用管理面的实现" class="headerlink" title="三、高可用管理面的实现"></a>三、高可用管理面的实现</h1><p>当转发引擎宕机后，需要将其上的虚拟服务迁移到另一台正常运行的转发引擎，为了确保服务的连续性和一致性，需要满足以下两个前提条件。<br>首先，数据面必须保持无状态，这意味着每个转发引擎在处理数据包时，不应该依赖于任何持久化的状态信息。转发引擎应该专注于数据的快速转发，独立地处理流量，不需要访问存储在其他引擎上的状态信息。这样不仅可以提高转发效率，也简化了故障恢复过程，即使某个转发引擎发生故障，其他引擎也能够无缝地接管服务。<br>其次，管理面必须具备高可用性。这意味着管理组件需要能够容忍故障，并且能够在发生故障时快速恢复。由于传统负载均衡设备的双机集群无法解决脑裂问题，一台设备宕机后集群的写入能力是无法保障的。为了解决这一问题，需要使用“N+1”高可用模型，保持至少1个冗余节点，在1个管理节点宕机时，管理面仍然能够保持服务可读可写。因此，至少要具备3个管理节点，才能在集群分成两个独立组时，通过少数服从多数的投票策略，使集群仍然可以正常提供服务。<br>分布式系统的CAP理论（如图5所示）指出，系统在任何时刻只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）中的两个性能。这意味着需要存储数据的管理集群只能优先选择分区容错性和数据强一致性，而要牺牲部分可用性。<br><img src="/images/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%AF%B9%E4%B8%80%E8%87%B4%E6%80%A7%E3%80%81%E5%8F%AF%E7%94%A8%E6%80%A7%E3%80%81%E5%88%86%E5%8C%BA%E5%AE%B9%E9%94%99%E6%80%A7%E7%9A%84%E6%9D%83%E8%A1%A1.png" alt="分布式系统对一致性、可用性、分区容错性的权衡"></p>
<p>分布式负载管理面的核心功能是协调和控制，而不是处理高流量的业务数据，因此可以降低其对性能的要求。管理面主要是通过API与外部系统或转发引擎进行通信，这些操作对实时性的要求较低。<br>对于需要高度一致性的决策过程，可以采用Paxos之类的共识算法。这些算法通过两个阶段的提交机制来确保数据的持久化和一致性。在第一阶段，提案（数据变更）被提出并由集群中的大多数成员进行投票；在第二阶段，如果提案获得多数票，就会被提交并应用到所有成员的状态中。这样的机制确保了部分节点宕机时整个系统仍然能够就数据变更达成一致，从而实现系统的高可靠性。此外，Raft协议改进了Paxos算法，通过设计简单、直观的Leader选举、线性一致的日志复制机制，降低了数据变更时的冲突概率，在确保数据强一致性的同时提升了系统性能，是管理面的首选算法之一。</p>
<h1 id="四、管理面与数据面的通信"><a href="#四、管理面与数据面的通信" class="headerlink" title="四、管理面与数据面的通信"></a>四、管理面与数据面的通信</h1><p>要实现管理面与数据面之间的通信，必须解决以下四个问题。</p>
<ol>
<li>   高并发通信需求<br>由于数据面的集群规模可能非常庞大，管理节点需要与转发引擎集群维持并发连接，同时，七层负载的功能还需要快速迭代，所以采用灵活的协程机制可以确保通信的高效和稳定。</li>
<li>   复杂网络结构下的通信安全<br>由于集中式的管理面需要跨越IDC、云与所有转发引擎通信，所以除网络环境的安全之外，管理面与数据面通信必须充分考虑安全认证、加密传输等因素，以保障数据传输的安全性和可靠性。</li>
<li>   多租户管理<br>分布式负载均衡系统同时服务于众多业务团队，这就要求系统能够通过多租户机制来隔离不同团队的管理上下文。因此，分布式负载均衡设备上配置的所有元素都需要添加租户标签，以租户为粒度管理虚拟服务及其他配置元素。<br>在数据面上，租户既可以通过独立部署各自的转发引擎集群实现服务隔离，也可以选择共享转发引擎资源，以提高资源利用率和降低成本，这适合规模较小或成本敏感型的应用，可在保障一定隔离性的同时优化资源分配和效率。<br>由于分布式负载系统涉及OSI七层协议中从物理层到应用层的网络资源，因此还必须通过定义具有不同权限的角色来控制租户内部以及跨租户的资源访问。</li>
<li>   遥测（Telemetry）数据上报<br>为了有效管理和分析大规模数据面集群产生的遥测数据，数据上报策略应明确将数据划分为以下三类。<br>一是实时上报数据。这类数据具备转发引擎的健康状态变化等关键指标，它们对于即时监控系统状态至关重要，需要实时或近实时地上报，以便快速响应可能发生的任何问题。<br>二是周期上报数据。这类数据包括CPU负载、内存使用率、网络流量等定期收集的性能指标数据，通常按照一定的时间间隔上报，用于长期的性能监控和趋势分析。<br>三是事件触发上报数据。这类数据的上报是由特定事件触发的，例如管理员对某个虚拟服务执行抓包操作，或者API调用请求拉取用户访问日志以分析故障原因。事件触发的数据上报通常按需进行，与特定的用户行为或系统事件相关。<br>通过这种分类方法，可以确保监控系统既能够快速响应紧急情况，又能够有效地进行长期性能分析，同时还能够灵活地处理由特定事件触发的数据收集需求。<br>另外，由于一台虚拟服务由多台转发引擎共同处理流量，因此需对这些遥测数据进行标签化以及结构化分层，以便进行横跨复杂网络的故障分析，这对于维护大规模分布式系统的稳定性和性能至关重要。<br>综上所述，管理面与数据面之间的通信需要进行系统化的全面设计，综合考虑并发处理能力、网络安全、多租户支持以及跨网络服务的监控需求，以确保整个集群的高效、安全和稳定运行。</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文首先从OSI模型的数据链路层和网络层，通过”一主多辅”和ECMP技术实现了弹性虚拟服务，有效支持了大规模网络的并发处理和动态扩展。为了减少容灾场景的影响范围，介绍了传输层的会话连接表，提升了故障恢复的效率。对于七层负载在应用层的CPU消耗问题，介绍了自动缩扩容与迁移技术，以应对业务需求的波动，避免了四、七层负载集群的分层。<br>在数据面外，文章还讨论了通过共识算法实现高可用的管理面集群，以及数据面如何与管理面通讯，才能保障不同租户产生的大量遥测数据，能够在不影响业务的情况下，为监控、分析和管理大规模分布式系统提供高效、安全、稳定的支持。<br>本文为分布式负载均衡技术系列的第二篇，下一篇将通过具体的案例进一步分析这些技术在实际应用中的表现和效果。通过这一系列的深入剖析，我们期望读者能够获得必要的知识，以评估和实施分布式负载均衡解决方案，从而提升自身网络的弹性和响应能力，满足不断变化的业务需求。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
        <tag>OSI</tag>
        <tag>分布式负载</tag>
        <tag>DevOps</tag>
        <tag>可观测性</tag>
        <tag>弹性</tag>
        <tag>TCO</tag>
      </tags>
  </entry>
  <entry>
    <title>APISIX架构分析：如何动态管理Nginx集群？</title>
    <url>/2021/08/10/nginx/APISIX%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90%EF%BC%9A%E5%A6%82%E4%BD%95%E5%8A%A8%E6%80%81%E7%AE%A1%E7%90%86Nginx%E9%9B%86%E7%BE%A4%EF%BC%9F/</url>
    <content><![CDATA[<p>开源版Nginx最为人诟病的就是不具备动态配置、远程API及集群管理的能力，而APISIX作为CNCF毕业的开源七层网关，基于etcd、Lua实现了对Nginx集群的动态管理。<br><img src="/images/nginx/apisix%E5%AE%98%E6%96%B9%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="apisix架构图"></p>
<p>让Nginx具备动态、集群管理能力并不容易，因为这将面临以下问题：</p>
<ul>
<li>微服务架构使得上游服务种类多、数量大，这导致路由规则、上游Server的变更极为频率。而Nginx的路由匹配是基于静态的<strong>Trie前缀树、哈希表、正则数组</strong>实现的，一旦server_name、location变动，不执行reload就无法实现配置的动态变更；</li>
<li>Nginx将自己定位于ADC边缘负载均衡，因此它对上游并不支持HTTP2协议。这增大了OpenResty生态实现etcd gRPC接口的难度，因此通过watch机制接收配置变更必然效率低下；</li>
<li>多进程架构增大了Worker进程间的数据同步难度，必须选择1个低成本的实现机制，保证每个Nginx节点、Worker进程都持有最新的配置；</li>
</ul>
<p>等等。</p>
<p>APISIX基于Lua定时器及lua-resty-etcd模块实现了配置的动态管理，本文将基于APISIX2.8、OpenResty1.19.3.2、Nginx1.19.3分析APISIX实现REST API远程控制Nginx集群的原理。</p>
<span id="more"></span>

<p>接下来我将分析APISIX的解决方案。</p>
<h1 id="基于etcd-watch机制的配置同步方案"><a href="#基于etcd-watch机制的配置同步方案" class="headerlink" title="基于etcd watch机制的配置同步方案"></a>基于etcd watch机制的配置同步方案</h1><p>管理集群必须依赖中心化的配置，etcd就是这样一个数据库。APISIX没有选择关系型数据库作为配置中心，是因为etcd具有以下2个优点：</p>
<ol>
<li>etcd采用类Paxos的Raft协议保障了数据一致性，它是去中心化的分布式数据库，可靠性高于关系数据库；</li>
<li>etcd的watch机制允许客户端监控某个key的变动，即，若类似/nginx/http/upstream这种key的value值发生变动，watch的客户端会立刻收到通知，如下图所示：</li>
</ol>
<p><img src="/images/nginx/%E5%9F%BA%E4%BA%8Eetcd%E5%90%8C%E6%AD%A5nginx%E9%85%8D%E7%BD%AE.jpg" alt="基于etcd同步nginx配置"></p>
<p>因此，不同于<a href="https://github.com/orlabs/orange">Orange</a>采用MySQL、<a href="https://konghq.com/">Kong</a>采用PostgreSQL作为配置中心（这二者同样是基于OpenResty实现的API Gateway），APISIX采用了etcd作为中心化的配置组件。</p>
<p>因此，你可以在生产环境的APISIX中通过etcdctl看到如下的类似配置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># etcdctl get  &quot;/apisix/upstreams/1&quot;</span></span><br><span class="line">/apisix/upstreams/1</span><br><span class="line">&#123;<span class="string">&quot;hash_on&quot;</span>:<span class="string">&quot;vars&quot;</span>,<span class="string">&quot;nodes&quot;</span>:&#123;<span class="string">&quot;httpbin.org:80&quot;</span>:1&#125;,<span class="string">&quot;create_time&quot;</span>:1627982128,<span class="string">&quot;update_time&quot;</span>:1627982128,<span class="string">&quot;scheme&quot;</span>:<span class="string">&quot;http&quot;</span>,<span class="string">&quot;type&quot;</span>:<span class="string">&quot;roundrobin&quot;</span>,<span class="string">&quot;pass_host&quot;</span>:<span class="string">&quot;pass&quot;</span>,<span class="string">&quot;id&quot;</span>:<span class="string">&quot;1&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>其中，/apisix这个前缀可以在conf/config.yaml中修改，比如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">etcd:</span></span><br><span class="line">  <span class="attr">host:</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;http://127.0.0.1:2379&quot;</span>   </span><br><span class="line">  <span class="attr">prefix:</span> <span class="string">/apisix</span>                 <span class="comment"># apisix configurations prefix</span></span><br></pre></td></tr></table></figure>
<p>而upstreams/1就等价于nginx.conf中的http { upstream 1 {} }配置。类似关键字还有/apisix/services/、/apisix/routes/等，不一而足。</p>
<p>那么，Nginx是怎样通过watch机制获取到etcd配置数据变化的呢？有没有新启动一个agent进程？它通过HTTP/1.1还是gRPC与etcd通讯的？</p>
<h2 id="ngx-timer-at定时器"><a href="#ngx-timer-at定时器" class="headerlink" title="ngx.timer.at定时器"></a>ngx.timer.at定时器</h2><p>APISIX并没有启动Nginx以外的进程与etcd通讯。它实际上是通过ngx.timer.at这个定时器实现了watch机制。为了方便对OpenResty不太了解的同学，我们先来看看Nginx中的定时器是如何实现的，它是watch机制实现的基础。</p>
<h3 id="Nginx的红黑树定时器"><a href="#Nginx的红黑树定时器" class="headerlink" title="Nginx的红黑树定时器"></a>Nginx的红黑树定时器</h3><p>Nginx采用了epoll + nonblock socket这种多路复用机制实现事件处理模型，其中每个worker进程会循环处理网络IO及定时器事件：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//参见Nginx的src/os/unix/ngx_process_cycle.c文件</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">ngx_worker_process_cycle(<span class="keyword">ngx_cycle_t</span> *cycle, <span class="keyword">void</span> *data)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> ( ;; ) &#123;</span><br><span class="line">        ngx_process_events_and_timers(cycle);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参见ngx_proc.c文件</span></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">ngx_process_events_and_timers(<span class="keyword">ngx_cycle_t</span> *cycle)</span><br><span class="line">&#123;</span><br><span class="line">    timer = ngx_event_find_timer();</span><br><span class="line">    (<span class="keyword">void</span>) ngx_process_events(cycle, timer, flags);</span><br><span class="line">    ngx_event_process_posted(cycle, &amp;ngx_posted_accept_events);</span><br><span class="line">    ngx_event_expire_timers();</span><br><span class="line">    ngx_event_process_posted(cycle, &amp;ngx_posted_events);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ngx_event_expire_timers函数会调用所有超时事件的handler方法。事实上，定时器是由红黑树（一种平衡有序二叉树）实现的，其中key是每个事件的绝对过期时间。这样，只要将最小节点与当前时间做比较，就能快速找到过期事件。</p>
<h3 id="OpenResty的Lua定时器"><a href="#OpenResty的Lua定时器" class="headerlink" title="OpenResty的Lua定时器"></a>OpenResty的Lua定时器</h3><p>当然，以上C函数开发效率很低。因此，OpenResty封装了Lua接口，通过ngx.timer.at将ngx_timer_add这个C函数暴露给了Lua语言：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//参见OpenResty /ngx_lua-0.10.19/src/ngx_http_lua_timer.c文件</span></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">ngx_http_lua_inject_timer_api(lua_State *L)</span><br><span class="line">&#123;</span><br><span class="line">    lua_createtable(L, <span class="number">0</span> <span class="comment">/* narr */</span>, <span class="number">4</span> <span class="comment">/* nrec */</span>);    <span class="comment">/* ngx.timer. */</span></span><br><span class="line"></span><br><span class="line">    lua_pushcfunction(L, ngx_http_lua_ngx_timer_at);</span><br><span class="line">    lua_setfield(L, <span class="number">-2</span>, <span class="string">&quot;at&quot;</span>);</span><br><span class="line"></span><br><span class="line">    lua_setfield(L, <span class="number">-2</span>, <span class="string">&quot;timer&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span></span><br><span class="line">ngx_http_lua_ngx_timer_at(lua_State *L)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> ngx_http_lua_ngx_timer_helper(L, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span></span><br><span class="line">ngx_http_lua_ngx_timer_helper(lua_State *L, <span class="keyword">int</span> every)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">ngx_event_t</span>             *ev = <span class="literal">NULL</span>;</span><br><span class="line">    ev-&gt;handler = ngx_http_lua_timer_handler;</span><br><span class="line">    ngx_add_timer(ev, delay);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因此，当我们调用ngx.timer.at这个Lua定时器时，就是在Nginx的红黑树定时器里加入了ngx_http_lua_timer_handler回调函数，这个函数不会阻塞Nginx。</p>
<p>下面我们来看看APISIX是怎样使用ngx.timer.at的。</p>
<h3 id="APISIX基于定时器实现的watch机制"><a href="#APISIX基于定时器实现的watch机制" class="headerlink" title="APISIX基于定时器实现的watch机制"></a>APISIX基于定时器实现的watch机制</h3><p>Nginx框架为C模块开发提供了许多钩子，而OpenResty将部分钩子以Lua语言形式暴露了出来，如下图所示：<br><img src="/images/nginx/openresty%E9%92%A9%E5%AD%90.png" alt="openresty钩子"></p>
<p>APISIX仅使用了其中8个钩子（注意，APISIX没有使用set_by_lua和rewrite_by_lua，rewrite阶段的plugin其实是APISIX自定义的，与Nginx无关），包括：</p>
<ul>
<li>init_by_lua：Master进程启动时的初始化；</li>
<li>init_worker_by_lua：每个Worker进程启动时的初始化（包括privileged agent进程的初始化，这是实现java等多语言plugin远程RPC调用的关键）；</li>
<li>ssl_certificate_by_lua：在处理TLS握手时，openssl提供了一个钩子，OpenResty通过修改Nginx源码以Lua方式暴露了该钩子；</li>
<li>access_by_lua：接收到下游的HTTP请求头部后，在此匹配Host域名、URI、Method等路由规则，并选择Service、Upstream中的Plugin及上游Server；</li>
<li>balancer_by_lua：在content阶段执行的所有反向代理模块，在选择上游Server时都会回调init_upstream钩子函数，OpenResty将其命名为 balancer_by_lua；</li>
<li>header_filter_by_lua：将HTTP响应头部发送给下游前执行的钩子；</li>
<li>body_filter_by_lua：将HTTP响应包体发送给下游前执行的钩子；</li>
<li>log_by_lua：记录access日志时的钩子。<br>准备好上述知识后，我们就可以回答APISIX是怎样接收etcd数据的更新了。</li>
</ul>
<h4 id="nginx-conf的生成方式"><a href="#nginx-conf的生成方式" class="headerlink" title="nginx.conf的生成方式"></a>nginx.conf的生成方式</h4><p>每个Nginx Worker进程都会在init_worker_by_lua阶段通过http_init_worker函数启动定时器：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">init_worker_by_lua_block &#123;</span><br><span class="line">    apisix.http_init_worker()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于nginx.conf配置语法，你可以参考我的这篇文章<a href="https://www.taohui.pub/2020/12/23/nginx/%E4%BB%8E%E9%80%9A%E7%94%A8%E8%A7%84%E5%88%99%E4%B8%AD%E5%AD%A6%E4%B9%A0nginx%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9A%E5%88%B6%E6%8C%87%E4%BB%A4/">《从通用规则中学习nginx模块的定制指令》</a>。你可能很好奇，下载APISIX源码后没有看到nginx.conf，这段配置是哪来的？</p>
<p><strong>这里的nginx.conf实际是由APISIX的启动命令实时生成的</strong>。当你执行make run时，它会基于Lua模板apisix/cli/ngx_tpl.lua文件生成nginx.conf。请注意，这里的模板规则是OpenResty自实现的，语法细节参见lua-resty-template。生成nginx.conf的具体代码参见apisix/cli/ops.lua文件：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> template = <span class="built_in">require</span>(<span class="string">&quot;resty.template&quot;</span>)</span><br><span class="line"><span class="keyword">local</span> ngx_tpl = <span class="built_in">require</span>(<span class="string">&quot;apisix.cli.ngx_tpl&quot;</span>)</span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">init</span><span class="params">(env)</span></span></span><br><span class="line">    <span class="keyword">local</span> yaml_conf, err = file.read_yaml_conf(env.apisix_home)</span><br><span class="line">    <span class="keyword">local</span> conf_render = template.compile(ngx_tpl)</span><br><span class="line">    <span class="keyword">local</span> ngxconf = conf_render(sys_conf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> ok, err = util.write_file(env.apisix_home .. <span class="string">&quot;/conf/nginx.conf&quot;</span>,</span><br><span class="line">                                    ngxconf)</span><br></pre></td></tr></table></figure>
<p>当然，APISIX允许用户修改nginx.conf模板中的部分数据，具体方法是模仿conf/config-default.yaml的语法修改conf/config.yaml配置。其实现原理参见read_yaml_conf函数：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.read_yaml_conf</span><span class="params">(apisix_home)</span></span></span><br><span class="line">    <span class="keyword">local</span> local_conf_path = profile:yaml_path(<span class="string">&quot;config-default&quot;</span>)</span><br><span class="line">    <span class="keyword">local</span> default_conf_yaml, err = util.read_file(local_conf_path)</span><br><span class="line"></span><br><span class="line">    local_conf_path = profile:yaml_path(<span class="string">&quot;config&quot;</span>)</span><br><span class="line">    <span class="keyword">local</span> user_conf_yaml, err = util.read_file(local_conf_path)</span><br><span class="line">    ok, err = merge_conf(default_conf, user_conf)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>可见，ngx_tpl.lua模板中仅部分数据可由yaml配置中替换，其中conf/config-default.yaml是官方提供的默认配置，而conf/config.yaml则是由用户自行覆盖的自定义配置。<strong>如果你觉得仅替换模板数据还不够，大可以直接修改ngx_tpl模板。</strong></p>
<h4 id="APISIX获取etcd通知的方式"><a href="#APISIX获取etcd通知的方式" class="headerlink" title="APISIX获取etcd通知的方式"></a>APISIX获取etcd通知的方式</h4><p>APISIX将需要监控的配置以不同的前缀存入了etcd，目前包括以下11种：</p>
<ul>
<li>/apisix/consumers/：APISIX支持以consumer抽象上游种类；</li>
<li>/apisix/global_rules/：全局通用的规则；</li>
<li>/apisix/plugin_configs/：可以在不同Router间复用的Plugin；</li>
<li>/apisix/plugin_metadata/：部分插件的元数据；</li>
<li>/apisix/plugins/：所有Plugin插件的列表；</li>
<li>/apisix/proto/：当透传gRPC协议时，部分插件需要转换协议内容，该配置存储protobuf消息定义；</li>
<li>/apisix/routes/：路由信息，是HTTP请求匹配的入口，可以直接指定上游Server，也可以挂载services或者upstream；</li>
<li>/apisix/services/：可以将相似的router中的共性部分抽象为services，再挂载plugin；</li>
<li>/apisix/ssl/：SSL证书公、私钥及相关匹配规则；</li>
<li>/apisix/stream_routes/：OSI四层网关的路由匹配规则；</li>
<li>/apisix/upstreams/：对一组上游Server主机的抽象；</li>
</ul>
<p>这里每类配置对应的处理逻辑都不相同，因此APISIX抽象出apisix/core/config_etcd.lua文件，专注etcd上各类配置的更新维护。在http_init_worker函数中每类配置都会生成1个config_etcd对象：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.init_worker</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> err</span><br><span class="line">    plugin_configs, err = core.<span class="built_in">config</span>.new(<span class="string">&quot;/plugin_configs&quot;</span>, &#123;</span><br><span class="line">        automatic = <span class="literal">true</span>,</span><br><span class="line">        item_schema = core.schema.plugin_config,</span><br><span class="line">        checker = plugin_checker,</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>而在config_etcd的new函数中，则会循环注册_automatic_fetch定时器:</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.new</span><span class="params">(key, opts)</span></span></span><br><span class="line">    ngx_timer_at(<span class="number">0</span>, _automatic_fetch, obj)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>_automatic_fetch函数会反复执行sync_data函数（包装到xpcall之下是为了捕获异常）：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">_automatic_fetch</span><span class="params">(premature, self)</span></span></span><br><span class="line">    <span class="keyword">local</span> ok, err = <span class="built_in">xpcall</span>(<span class="function"><span class="keyword">function</span><span class="params">()</span></span></span><br><span class="line">        <span class="keyword">local</span> ok, err = sync_data(<span class="built_in">self</span>)</span><br><span class="line">    <span class="keyword">end</span>, <span class="built_in">debug</span>.<span class="built_in">traceback</span>)</span><br><span class="line">    ngx_timer_at(<span class="number">0</span>, _automatic_fetch, <span class="built_in">self</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>sync_data函数将通过etcd的watch机制获取更新，它的实现机制我们接下来会详细分析。</p>
<p>总结下：</p>
<blockquote>
<p>APISIX在每个Nginx Worker进程的启动过程中，通过ngx.timer.at函数将_automatic_fetch插入定时器。_automatic_fetch函数执行时会通过sync_data函数，基于watch机制接收etcd中的配置变更通知，这样，每个Nginx节点、每个Worker进程都将保持最新的配置。如此设计还有1个明显的优点：<strong>etcd中的配置直接写入Nginx Worker进程中，这样处理请求时就能直接使用新配置，无须在进程间同步配置</strong>，这要比启动1个agent进程更简单！</p>
</blockquote>
<h2 id="lua-resty-etcd库的HTTP-1-1协议"><a href="#lua-resty-etcd库的HTTP-1-1协议" class="headerlink" title="lua-resty-etcd库的HTTP/1.1协议"></a>lua-resty-etcd库的HTTP/1.1协议</h2><p>sync_data函数到底是怎样获取etcd的配置变更消息的呢？先看下sync_data源码：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> etcd         = <span class="built_in">require</span>(<span class="string">&quot;resty.etcd&quot;</span>)</span><br><span class="line">etcd_cli, err = etcd.new(etcd_conf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">sync_data</span><span class="params">(self)</span></span></span><br><span class="line">    <span class="keyword">local</span> dir_res, err = waitdir(<span class="built_in">self</span>.etcd_cli, <span class="built_in">self</span>.key, <span class="built_in">self</span>.prev_index + <span class="number">1</span>, <span class="built_in">self</span>.timeout)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">waitdir</span><span class="params">(etcd_cli, key, modified_index, timeout)</span></span></span><br><span class="line">    <span class="keyword">local</span> res_func, func_err, http_cli = etcd_cli:watchdir(key, opts)</span><br><span class="line">    <span class="keyword">if</span> http_cli <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">local</span> res_cancel, err_cancel = etcd_cli:watchcancel(http_cli)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>这里实际与etcd通讯的是<a href="https://github.com/api7/lua-resty-etcd">lua-resty-etcd</a>库。它提供的watchdir函数用于接收etcd发现key目录对应value变更后发出的通知。</p>
<p>watchcancel函数又是做什么的呢？这其实是OpenResty生态的缺憾导致的。etcd v3已经支持高效的gRPC协议（底层为HTTP2协议）。你可能听说过，HTTP2不但具备多路复用的能力，还支持服务器直接推送消息，关于HTTP2的细节可以参照我的这篇文章<a href="https://www.taohui.pub/2021/02/04/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90HTTP3%E5%8D%8F%E8%AE%AE/">《深入剖析HTTP3协议》</a>，从HTTP3协议对照理解HTTP2：<br><img src="/images/http/http2_stream_frame_conn.png" alt="http2的多路复用与服务器推送"></p>
<p>然而，<strong>Lua生态目前并不支持HTTP2协议！</strong>所以lua-resty-etcd库实际是通过低效的HTTP/1.1协议与etcd通讯的，因此接收/watch通知也是通过带有超时的/v3/watch请求完成的。这个现象其实是由2个原因造成的：</p>
<ol>
<li>Nginx将自己定位为边缘负载均衡，因此上游必然是企业内网，时延低、带宽大，所以对上游协议不必支持HTTP2协议！</li>
<li>当Nginx的upstream不能提供HTTP2机制给Lua时，Lua只能基于cosocket自己实现了。HTTP2协议非常复杂，目前还没有生产环境可用的HTTP2 cosocket库。</li>
</ol>
<p>使用HTTP/1.1的lua-resty-etcd库其实很低效，如果你在APISIX上抓包，会看到频繁的POST报文，其中URI为/v3/watch，而Body是Base64编码的watch目录：</p>
<p><img src="/images/http/APISIX%E4%B8%8Eetcd%E9%80%9A%E8%BF%87HTTP1%E9%80%9A%E8%AE%AF.JPG" alt="APISIX与etcd通过HTTP1通讯"></p>
<p>我们可以验证下watchdir函数的实现细节：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- lib/resty/etcd/v3.lua文件</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.watchdir</span><span class="params">(self, key, opts)</span></span></span><br><span class="line">    <span class="keyword">return</span> watch(<span class="built_in">self</span>, key, attr)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">watch</span><span class="params">(self, key, attr)</span></span></span><br><span class="line">    callback_fun, err, http_cli = request_chunk(<span class="built_in">self</span>, <span class="string">&#x27;POST&#x27;</span>, <span class="string">&#x27;/watch&#x27;</span>,</span><br><span class="line">                                                opts, attr.timeout <span class="keyword">or</span> <span class="built_in">self</span>.timeout)</span><br><span class="line">    <span class="keyword">return</span> callback_fun</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">request_chunk</span><span class="params">(self, method, path, opts, timeout)</span></span></span><br><span class="line">    http_cli, err = utils.http.new()</span><br><span class="line">    <span class="comment">-- 发起TCP连接</span></span><br><span class="line">    endpoint, err = http_request_chunk(<span class="built_in">self</span>, http_cli)</span><br><span class="line">    <span class="comment">-- 发送HTTP请求</span></span><br><span class="line">    res, err = http_cli:request(&#123;</span><br><span class="line">        method  = method,</span><br><span class="line">        <span class="built_in">path</span>    = endpoint.api_prefix .. <span class="built_in">path</span>,</span><br><span class="line">        body    = body,</span><br><span class="line">        query   = query,</span><br><span class="line">        headers = headers,</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">http_request_chunk</span><span class="params">(self, http_cli)</span></span></span><br><span class="line">    <span class="keyword">local</span> endpoint, err = choose_endpoint(<span class="built_in">self</span>)</span><br><span class="line">    ok, err = http_cli:connect(&#123;</span><br><span class="line">        scheme = endpoint.scheme,</span><br><span class="line">        host = endpoint.host,</span><br><span class="line">        port = endpoint.port,</span><br><span class="line">        ssl_verify = <span class="built_in">self</span>.ssl_verify,</span><br><span class="line">        ssl_cert_path = <span class="built_in">self</span>.ssl_cert_path,</span><br><span class="line">        ssl_key_path = <span class="built_in">self</span>.ssl_key_path,</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> endpoint, err</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>可见，APISIX在每个worker进程中，通过ngx.timer.at和lua-resty-etcd库反复请求etcd，以此保证每个Worker进程中都含有最新的配置。</p>
<h1 id="APISIX配置与插件的远程变更"><a href="#APISIX配置与插件的远程变更" class="headerlink" title="APISIX配置与插件的远程变更"></a>APISIX配置与插件的远程变更</h1><p>接下来，我们看看怎样远程修改etcd中的配置。</p>
<p>我们当然可以直接通过gRPC接口修改etcd中相应key的内容，再基于上述的watch机制使得Nginx集群自动更新配置。然而，这样做的风险很大，因为<strong>配置请求没有经过校验</strong>，进面导致配置数据与Nginx集群不匹配！</p>
<h2 id="通过Nginx的-apisix-admin-接口修改配置"><a href="#通过Nginx的-apisix-admin-接口修改配置" class="headerlink" title="通过Nginx的/apisix/admin/接口修改配置"></a>通过Nginx的/apisix/admin/接口修改配置</h2><p>APISIX提供了这么一种机制：访问任意1个Nginx节点，通过其Worker进程中的Lua代码校验请求成功后，再由/v3/dv/put接口写入etcd中。下面我们来看看APISIX是怎么实现的。</p>
<p>首先，make run生成的nginx.conf会自动监听9080端口（可通过config.yaml中apisix.node_listen配置修改），当apisix.enable_admin设置为true时，nginx.conf就会生成以下配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">9080</span> default_server reuseport;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">location</span> /apisix/admin &#123; </span><br><span class="line">        <span class="section">content_by_lua_block</span> &#123;</span><br><span class="line">            apisix.http_admin()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样，Nginx接收到的/apisix/admin请求将被http_admin函数处理：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- /apisix/init.lua文件</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.http_admin</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> ok = router:dispatch(get_var(<span class="string">&quot;uri&quot;</span>), &#123;method = get_method()&#125;)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>admin接口能够处理的API参见<a href="https://github.com/apache/apisix/blob/release/2.8/docs/zh/latest/admin-api.md">github文档</a>，其中，当method方法与URI不同时，dispatch会执行不同的处理函数，其依据如下：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- /apisix/admin/init.lua文件</span></span><br><span class="line"><span class="keyword">local</span> uri_route = &#123;</span><br><span class="line">    &#123;</span><br><span class="line">        paths = <span class="string">[[/apisix/admin/*]]</span>,</span><br><span class="line">        methods = &#123;<span class="string">&quot;GET&quot;</span>, <span class="string">&quot;PUT&quot;</span>, <span class="string">&quot;POST&quot;</span>, <span class="string">&quot;DELETE&quot;</span>, <span class="string">&quot;PATCH&quot;</span>&#125;,</span><br><span class="line">        handler = run,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        paths = <span class="string">[[/apisix/admin/stream_routes/*]]</span>,</span><br><span class="line">        methods = &#123;<span class="string">&quot;GET&quot;</span>, <span class="string">&quot;PUT&quot;</span>, <span class="string">&quot;POST&quot;</span>, <span class="string">&quot;DELETE&quot;</span>, <span class="string">&quot;PATCH&quot;</span>&#125;,</span><br><span class="line">        handler = run_stream,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        paths = <span class="string">[[/apisix/admin/plugins/list]]</span>,</span><br><span class="line">        methods = &#123;<span class="string">&quot;GET&quot;</span>&#125;,</span><br><span class="line">        handler = get_plugins_list,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        paths = reload_event,</span><br><span class="line">        methods = &#123;<span class="string">&quot;PUT&quot;</span>&#125;,</span><br><span class="line">        handler = post_reload_plugins,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>比如，当通过/apisix/admin/upstreams/1和PUT方法创建1个Upstream上游时：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl &quot;http://127.0.0.1:9080/apisix/admin/upstreams/1&quot; -H &quot;X-API-KEY: edd1c9f034335f136f87ad84b625c8f1&quot; -X PUT -d &#x27;</span></span><br><span class="line">&gt; &#123;</span><br><span class="line">&gt;   <span class="string">&quot;type&quot;</span>: <span class="string">&quot;roundrobin&quot;</span>,</span><br><span class="line">&gt;   <span class="string">&quot;nodes&quot;</span>: &#123;</span><br><span class="line">&gt;     <span class="string">&quot;httpbin.org:80&quot;</span>: 1</span><br><span class="line">&gt;   &#125;</span><br><span class="line">&gt; &#125;<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&#123;&quot;action&quot;:&quot;set&quot;,&quot;node&quot;:&#123;&quot;key&quot;:&quot;\/apisix\/upstreams\/1&quot;,&quot;value&quot;:&#123;&quot;hash_on&quot;:&quot;vars&quot;,&quot;nodes&quot;:&#123;&quot;httpbin.org:80&quot;:1&#125;,&quot;create_time&quot;:1627982128,&quot;update_time&quot;:1627982128,&quot;scheme&quot;:&quot;http&quot;,&quot;type&quot;:&quot;roundrobin&quot;,&quot;pass_host&quot;:&quot;pass&quot;,&quot;id&quot;:&quot;1&quot;&#125;&#125;&#125;</span></span><br></pre></td></tr></table></figure>
<p>你会在error.log中会看到如下日志（想看到这行日志，必须将config.yaml中的nginx_config.error_log_level设为INFO）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2021&#x2F;08&#x2F;03 17:15:28 [info] 16437#16437: *23572 [lua] init.lua:130: handler(): uri: [&quot;&quot;,&quot;apisix&quot;,&quot;admin&quot;,&quot;upstreams&quot;,&quot;1&quot;], client: 127.0.0.1, server: _, request: &quot;PUT &#x2F;apisix&#x2F;admin&#x2F;upstreams&#x2F;1 HTTP&#x2F;1.1&quot;, host: &quot;127.0.0.1:9080&quot;</span><br></pre></td></tr></table></figure>
<p>这行日志实际是由/apisix/admin/init.lua中的run函数打印的，它的执行依据是上面的uri_route字典。我们看下run函数的内容：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- /apisix/admin/init.lua文件</span></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">run</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">local</span> uri_segs = core.utils.split_uri(ngx.var.uri)</span><br><span class="line">    core.<span class="built_in">log</span>.info(<span class="string">&quot;uri: &quot;</span>, core.json.delay_encode(uri_segs))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> seg_res, seg_id = uri_segs[<span class="number">4</span>], uri_segs[<span class="number">5</span>]</span><br><span class="line">    <span class="keyword">local</span> seg_sub_path = core.<span class="built_in">table</span>.<span class="built_in">concat</span>(uri_segs, <span class="string">&quot;/&quot;</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> resource = resources[seg_res]</span><br><span class="line">    <span class="keyword">local</span> code, data = resource[method](seg_id, req_body, seg_sub_path,</span><br><span class="line">                                        uri_args)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>这里resource[method]函数又被做了1次抽象，它是由resources字典决定的：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- /apisix/admin/init.lua文件</span></span><br><span class="line"><span class="keyword">local</span> resources = &#123;</span><br><span class="line">    routes          = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.routes&quot;</span>),</span><br><span class="line">    services        = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.services&quot;</span>),</span><br><span class="line">    upstreams       = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.upstreams&quot;</span>),</span><br><span class="line">    consumers       = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.consumers&quot;</span>),</span><br><span class="line">    schema          = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.schema&quot;</span>),</span><br><span class="line">    ssl             = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.ssl&quot;</span>),</span><br><span class="line">    plugins         = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.plugins&quot;</span>),</span><br><span class="line">    proto           = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.proto&quot;</span>),</span><br><span class="line">    global_rules    = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.global_rules&quot;</span>),</span><br><span class="line">    stream_routes   = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.stream_routes&quot;</span>),</span><br><span class="line">    plugin_metadata = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.plugin_metadata&quot;</span>),</span><br><span class="line">    plugin_configs  = <span class="built_in">require</span>(<span class="string">&quot;apisix.admin.plugin_config&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因此，上面的curl请求将被/apisix/admin/upstreams.lua文件的put函数处理，看下put函数的实现：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- /apisix/admin/upstreams.lua文件</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.put</span><span class="params">(id, conf)</span></span></span><br><span class="line">    <span class="comment">-- 校验请求数据的合法性</span></span><br><span class="line">    <span class="keyword">local</span> id, err = check_conf(id, conf, <span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">local</span> key = <span class="string">&quot;/upstreams/&quot;</span> .. id</span><br><span class="line">    core.<span class="built_in">log</span>.info(<span class="string">&quot;key: &quot;</span>, key)</span><br><span class="line">    <span class="comment">-- 生成etcd中的配置数据</span></span><br><span class="line">    <span class="keyword">local</span> ok, err = utils.inject_conf_with_prev_conf(<span class="string">&quot;upstream&quot;</span>, key, conf)</span><br><span class="line">    <span class="comment">-- 写入etcd</span></span><br><span class="line">    <span class="keyword">local</span> res, err = core.etcd.set(key, conf)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- /apisix/core/etcd.lua</span></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">set</span><span class="params">(key, value, ttl)</span></span></span><br><span class="line">    <span class="keyword">local</span> res, err = etcd_cli:set(prefix .. key, value, &#123;prev_kv = <span class="literal">true</span>, lease = data.body.ID&#125;)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>最终新配置被写入etcd中。可见，Nginx会校验数据再写入etcd，这样其他Worker进程、Nginx节点都将通过watch机制接收到正确的配置。上述流程你可以通过error.log中的日志验证：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2021&#x2F;08&#x2F;03 17:15:28 [info] 16437#16437: *23572 [lua] upstreams.lua:72: key: &#x2F;upstreams&#x2F;1, client: 127.0.0.1, server: _, request: &quot;PUT &#x2F;apisix&#x2F;admin&#x2F;upstreams&#x2F;1 HTTP&#x2F;1.1&quot;, host: &quot;127.0.0.1:9080&quot;</span><br></pre></td></tr></table></figure>
<h2 id="为什么新配置不reload就可以生效？"><a href="#为什么新配置不reload就可以生效？" class="headerlink" title="为什么新配置不reload就可以生效？"></a>为什么新配置不reload就可以生效？</h2><p>我们再来看admin请求执行完Nginx Worker进程可以立刻生效的原理。</p>
<p>开源版Nginx的请求匹配是基于3种不同的容器进行的：</p>
<ol>
<li>将静态哈希表中的server_name配置与请求的Host域名匹配，详见<a href="https://www.taohui.pub/2021/08/09/nginx/HTTP%E8%AF%B7%E6%B1%82%E6%98%AF%E5%A6%82%E4%BD%95%E5%85%B3%E8%81%94Nginx-server-%E5%9D%97%E7%9A%84%EF%BC%9F/">《HTTP请求是如何关联Nginx server{}块的？》</a>；</li>
<li>其次将静态Trie前缀树中的location配置与请求的URI匹配，详见<a href="https://www.taohui.pub/2021/08/09/nginx/URL%E6%98%AF%E5%A6%82%E4%BD%95%E5%85%B3%E8%81%94location%E9%85%8D%E7%BD%AE%E5%9D%97%E7%9A%84%EF%BC%9F/">《URL是如何关联Nginx location配置块的？》</a>；<br><img src="/images/nginx/location%E5%89%8D%E7%BC%80%E6%A0%91%E7%9A%84%E5%8C%B9%E9%85%8D%E6%B5%81%E7%A8%8B2.png"></li>
<li>在上述2个过程中，如果含有正则表达式，则基于数组顺序（在nginx.conf中出现的次序）依次匹配。</li>
</ol>
<p>上述过程虽然执行效率极高，却是写死在find_config阶段及Nginx HTTP框架中的，<strong>一旦变更必须在nginx -s reload后才能生效！</strong>因此，APISIX索性完全抛弃了上述流程!</p>
<p>从nginx.conf中可以看到，访问任意域名、URI的请求都会匹配到http_access_phase这个lua函数：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">server_name</span> _;</span><br><span class="line">    <span class="attribute">location</span> / &#123;</span><br><span class="line">        <span class="section">access_by_lua_block</span> &#123;</span><br><span class="line">            apisix.http_access_phase()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="attribute">proxy_pass</span>      $upstream_scheme://apisix_backend$upstream_uri;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而在http_access_phase函数中，将会基于1个用C语言实现的基数前缀树匹配Method、域名和URI（仅支持通配符，<strong>不支持正则表达式</strong>），这个库就是<a href="https://github.com/api7/lua-resty-radixtree">lua-resty-radixtree</a>。每当路由规则发生变化，Lua代码就会重建这棵基数树：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.match</span><span class="params">(api_ctx)</span></span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cached_version <span class="keyword">or</span> cached_version ~= user_routes.conf_version <span class="keyword">then</span></span><br><span class="line">        uri_router = base_router.create_radixtree_uri_router(user_routes.values,</span><br><span class="line">                                                             uri_routes, <span class="literal">false</span>)</span><br><span class="line">        cached_version = user_routes.conf_version</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>这样，路由变化后就可以不reload而使其生效。Plugin启用、参数及顺序调整的规则与此类似。</p>
<p>最后再提下Script，它与Plugin是互斥的。之前的动态调整改的只是配置，事实上Lua JIT的及时编译还提供了另外一个杀手锏loadstring，它可以将字符串转换为Lua代码。因此，在etcd中存储Lua代码并设置为Script后，就可以将其传送到Nginx上处理请求了。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Nginx集群的管理必须依赖中心化配置组件，而高可靠又具备watch推送机制的etcd无疑是最合适的选择！虽然当下Resty生态没有gRPC客户端，但每个Worker进程直接通过HTTP/1.1协议同步etcd配置仍不失为一个好的方案。</p>
<p>动态修改Nginx配置的关键在于2点：Lua语言的灵活度远高于nginx.conf语法，而且Lua代码可以通过loadstring从外部数据中导入！当然，为了保障路由匹配的执行效率，APISIX通过C语言实现了前缀基数树，基于Host、Method、URI进行请求匹配，在保障动态性的基础上提升了性能。</p>
<p>APISIX拥有许多优秀的设计，本文仅讨论了Nginx集群的动态管理，下篇文章再来分析Lua Plugin的设计。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>apisix</tag>
        <tag>网关</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>10分钟快速认识Nginx</title>
    <url>/2020/12/17/nginx/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/</url>
    <content><![CDATA[<p>Nginx是当下最流行的Web服务器，通过官方以及第三方C模块，以及在Nginx上构建出的Openresty，或者在Openresty上构建出的Kong，你可以使用Nginx生态满足任何复杂Web场景下的需求。Nginx的性能也极其优秀，它可以轻松支持百万、千万级的并发连接，也可以高效的处理磁盘IO，因而通过静态资源或者缓存，能够为Tomcat、Django等性能不佳的Web应用扛住绝大部分外部流量。   但是，很多刚接触Nginx的同学，对它的理解往往失之偏颇，不太清楚Nginx的能力范围。比如：</p>
<ul>
<li>  你可能清楚Nginx对上游应用支持Google的gRPC协议，但对下游的客户端是否支持gRPC协议呢？</li>
<li>  Openresty中的Nginx版本是单号的，而Nginx官网中的stable稳定版本则是双号的，我们到底该选择哪个版本的Nginx呢？</li>
<li>  安装Nginx时，下载Nginx docker镜像，或者用yum/apt-get安装，都比下载源代码再编译出可执行文件要简单许多，那到底有必要基于源码安装Nginx吗？</li>
<li>  当你下载完Nginx源码后，你清楚每个目录与文件的意义吗？</li>
</ul>
<p>  本文是《从头搭建1个静态资源服务器》系列文章中的第1篇，也是我在6月4日晚直播内容的文字总结，在这篇文章中我将向你演示：Nginx有什么特点，它的能力上限在哪，该如何获取Nginx，Nginx源代码中各目录的意义又是什么。  </p>
<span id="more"></span>
<h2 id="Nginx到底是什么？"><a href="#Nginx到底是什么？" class="headerlink" title="Nginx到底是什么？"></a>Nginx到底是什么？</h2><p>Nginx是一个集<strong>静态资源</strong>、<strong>负载均衡</strong>于一身的<strong>Web</strong>服务器，这里有3个关键词，我们一一来分析。</p>
<ul>
<li>  Web</li>
</ul>
<p>我爱把互联网服务的访问路径，与社会经济中的供应链放在一起做类比，这样很容易理解“上下游”这类比较抽象的词汇。比如，购买小米手机时，实体或者网上店铺是供应链的下游，而高通的CPU则是上游。类似地，<strong>浏览器作为终端自然是下游，关系数据库则是上游</strong>，而Nginx位于源服务器和终端之间，如下图所示： <a href="/2020/12/17/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/nginx%E4%B8%8A%E4%B8%8B%E6%B8%B8/"><img src="/2020/12/nginx%E4%B8%8A%E4%B8%8B%E6%B8%B8.png"></a> 弄明白了上下游的概念后，我们就清楚了“Web服务器”的外延：Nginx的下游协议是Web中的HTTP协议，而上游则可以是任意协议，比如python的网关协议uwsgi，或者C/C++爱用的CGI协议，或者RPC服务常用的gRPC协议，等等。   在Nginx诞生之初，它的下游协议仅支持HTTP/1协议，但随着版本的不断迭代，现在下游还支持HTTP/2、MAIL邮件、TCP协议、UDP协议等等。   Web场景面向的是公网，所以非常强调信息安全。而Nginx对TLS/SSL协议的支持也非常彻底，它可以轻松的对下游或者上游装载、卸载TLS协议，并通过Openssl支持各种安全套件。  </p>
<ul>
<li>  静态资源</li>
</ul>
<p>Web服务器必须能够提供图片、Javascript、CSS、HTML等资源的下载能力，由于它们多数是静态的，所以通常直接存放在磁盘上。Nginx很擅长读取本机磁盘上的文件，并将它们发送至下游客户端！<strong>你可能会觉得，读取文件并通过HTTP协议发送出去，这简直不要太简单，Nginx竟然只是擅长这个？这里可大有文章！</strong>   比如，你可能了解零拷贝技术，Nginx很早就支持它，这使得发送文件时速度可以至少提升一倍！可是，零拷贝对于特大文件很不友好，占用了许多PageCache内存，但使用率却非常低，因此Nginx用Linux的原生异步IO加上直接IO解决了这类问题。再比如，小报文的发送降低了网络传输效率，而Nginx通过Nagle、Cork等算法，以及应用层的postpone_out指令批量发送小报文，这使得Nginx的性能远远领先于Tomcat、Netty、Apache等竞争对手，因此主流的CDN都是使用Nginx实现的。  </p>
<ul>
<li>  负载均衡</li>
</ul>
<p>在分布式系统中，用加机器扩展系统，是提升可用性的最有效方法。但扩展系统时，需要在应用服务前添加1个负载均衡服务，使它能够将请求流量分发给上游的应用。这一场景中，除了对负载均衡服务的性能有极高的要求外，它还必须能够处理应用层协议。<strong>在OSI网络体系中，IP网络层是第3层，TCP/UDP传输层是第4层，而HTTP等应用层则是第7层，因此，在Web场景中，需求量最大的自然是7层负载均衡</strong>，而Nginx非常擅长应用层的协议处理，这体现在以下4个方面：</p>
<ol>
<li> 通过多路复用、事件驱动等技术，Nginx可以轻松支持C10M级别的并发；</li>
<li> 由C语言编写，与操作系统紧密结合的Nginx（紧密结合到什么程度呢？Nginx之父Igor曾经说过，他最后悔的就是让Nginx支持windows操作系统，因为它与类Unix系统差异太大，这使得紧密结合的Nginx必须付出很大代价才能实现），能够充分使用CPU、内存等硬件，极高的效率使它可以同时为几十台上游服务器提供负载均衡功能；</li>
<li> Nginx的架构很灵活，它允许任何第三方以C模块的形式，与官方模块互相协作，给用户提供各类功能。因此，丰富的生态使得Nginx支持多种多样的应用层协议（你可以在Github上搜索到大量的C模块），你也可以直接开发C模块定制Nginx。</li>
<li> Nginx使用了非常开放的2-clause BSD-like license源码许可协议，它意味着你在修改Nginx源码后，还可以作为商业用途发布，TEngine就受益于这一特性。当Lua语言通过C模块注入Nginx后，就诞生了Openresty及一堆Lua语言模块，这比直接开发C语言模块难度下降了很多。而在Lua语言之上，又诞生了Kong这样面向微服务的生态。</li>
</ol>
<p>  从上述3个关键词的解释，我相信你已经明白了Nginx的能力范围。接下来，我们再来看看如何安装Nginx。  </p>
<h2 id="怎样获取Nginx？"><a href="#怎样获取Nginx？" class="headerlink" title="怎样获取Nginx？"></a>怎样获取Nginx？</h2><p>Nginx有很多种获取、安装的方式，我把它们分为以下两类：</p>
<ul>
<li>  <strong>非定制化安装</strong></li>
</ul>
<p>主要指下载编译好的二进制文件，再直接安装在目标系统中，比如：</p>
<ul>
<li>  拉取含有Nginx的docker镜像；</li>
<li>  在操作系统的应用市场中直接安装，比如用apt-get/yum命令直接安装Nginx；</li>
<li>  获取到网上编译好的Nginx压缩包后，解压后直接运行；</li>
</ul>
<p> </p>
<ul>
<li>  <strong>定制化安装</strong></li>
</ul>
<p>在<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a>上或者<a href="https://www.nginx-cn.net/product">https://www.nginx-cn.net/product</a>上下载Nginx源代码，调用configure脚本生成定制化的编译选项后，执行make命令编译生成可执行文件，最后用make install命令安装Nginx。   非定制化安装虽然更加简单，但这样的Nginx默认缺失以下功能：</p>
<ul>
<li>  不支持更有效率的HTTP2协议；</li>
<li>  不支持TCP/UDP协议，不能充当4层负载均衡；</li>
<li>  不支持TLS/SSL协议，无法跨越公网保障网络安全；</li>
<li>  未安装stub_status模块，无法实时监控Nginx连接状态；</li>
</ul>
<p>你可以通过configure –help命令给出的–with-XXX-module说明，找到Nginx默认不安装的官方模块，例如：（dynamic是动态模块，在后续文章中我会演示其用法）</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">--with-http_ssl_module             <span class="built_in">enable</span> ngx_http_ssl_module</span><br><span class="line">--with-http_v2_module              <span class="built_in">enable</span> ngx_http_v2_module</span><br><span class="line">--with-http_realip_module          <span class="built_in">enable</span> ngx_http_realip_module</span><br><span class="line">--with-http_addition_module        <span class="built_in">enable</span> ngx_http_addition_module</span><br><span class="line">--with-http_xslt_module            <span class="built_in">enable</span> ngx_http_xslt_module</span><br><span class="line">--with-http_xslt_module=dynamic    <span class="built_in">enable</span> dynamic ngx_http_xslt_module</span><br><span class="line">--with-http_image_filter_module    <span class="built_in">enable</span> ngx_http_image_filter_module</span><br><span class="line">--with-http_image_filter_module=dynamic <span class="built_in">enable</span> dynamic ngx_http_image_filter_module</span><br><span class="line">--with-http_geoip_module           <span class="built_in">enable</span> ngx_http_geoip_module</span><br><span class="line">--with-http_geoip_module=dynamic   <span class="built_in">enable</span> dynamic ngx_http_geoip_module</span><br><span class="line">--with-http_sub_module             <span class="built_in">enable</span> ngx_http_sub_module</span><br><span class="line">--with-http_dav_module             <span class="built_in">enable</span> ngx_http_dav_module</span><br><span class="line">--with-http_flv_module             <span class="built_in">enable</span> ngx_http_flv_module</span><br><span class="line">--with-http_mp4_module             <span class="built_in">enable</span> ngx_http_mp4_module</span><br><span class="line">--with-http_gunzip_module          <span class="built_in">enable</span> ngx_http_gunzip_module</span><br><span class="line">--with-http_gzip_static_module     <span class="built_in">enable</span> ngx_http_gzip_static_module</span><br><span class="line">--with-http_auth_request_module    <span class="built_in">enable</span> ngx_http_auth_request_module</span><br><span class="line">--with-http_random_index_module    <span class="built_in">enable</span> ngx_http_random_index_module</span><br><span class="line">--with-http_secure_link_module     <span class="built_in">enable</span> ngx_http_secure_link_module</span><br><span class="line">--with-http_degradation_module     <span class="built_in">enable</span> ngx_http_degradation_module</span><br><span class="line">--with-http_slice_module           <span class="built_in">enable</span> ngx_http_slice_module</span><br><span class="line">--with-http_stub_status_module     <span class="built_in">enable</span> ngx_http_stub_status_module</span><br></pre></td></tr></table></figure>

<p>    因此，从功能的全面性上来说，我们需要从源码上安装Nginx。   你可能会想，那为什么不索性将所有模块都编译到默认的Nginx中呢？按需编译模块，至少有以下4个优点：</p>
<ul>
<li>  执行速度更快。例如，通过配置文件关闭功能，就需要多做一些条件判断。</li>
<li>  减少nginx可执行文件的大小。</li>
<li>  有些模块依赖项过多，在非必要时启用它们，会增加编译、运行环境的复杂性。</li>
<li>  给用户提供强大的自定义功能，比如在configure时设定配置文件、pid文件、可执行文件的路径，根据实际情况重新指定编译时的优化参数等等。</li>
</ul>
<p>  当然，<strong>最重要的还是可以通过configure –add-module选项任意添加自定义模块，这赋予Nginx无限的可能。</strong>   由于Nginx有许多分支和版本，该如何选择适合自己的版本呢？这有两个技巧，我们先来看mainline和stable版本的区别，在<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a>上你会看到如下页面： <a href="/2020/12/17/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/nginx%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD/"><img src="/2020/12/nginx%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD.png"></a> 这里，<strong>mainline是含有最新功能的主线版本，它的迭代速度最快</strong>。另外，你可能注意到mainline是单号版本，而Openresty由于更新Nginx的频率较低，所以为了获得最新的Nginx特性，它通常使用mainline版本。   <strong>stable是mainline版本稳定运行一段时间后，将单号大版本转换为双号的稳定版本</strong>，比如1.18.0就是由1.17.10转换而来。   Legacy则是曾经的稳定版本。如果从头开始使用Nginx，那么你只需要选择最新的stable或者mainline版本就可以了。但如果你已经在使用某一个Legacy版本的Nginx，现在是否把它升级到最新版本呢？毕竟在生产环境上升级前要做完整的功能、性能测试，成本并不低。此时，我们要从CHANGES变更文件中，寻找每个版本的变化点。点开CHANGES文件，你会看到如下页面： <a href="/2020/12/17/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/nginx-changes/"><img src="/2020/12/nginx-changes.png"></a> 这里列出了每个版本的发布时间，以及发布时的变更。这些变更共分为以下4类：</p>
<ul>
<li>  Feature新功能，比如上图HTTP框架新增的auth_delay指令。</li>
<li>  Bugfix问题修复，我们尤其要关注一些重大Bug的修复。</li>
<li>  Change已知特性的变更，比如之前允许HTTP请求头部中出现多个Host头部，但在17.9这个Change后，就认定这类HTTP请求非法了。</li>
<li>  Security安全问题的升级，比如15.6版本就修复了CVE-2018-16843等3个安全问题。</li>
</ul>
<p>  从Feature、Bugfix、Change、Security这4个方面，我们就可以更有针对性的升级Nginx。  </p>
<h2 id="认识Nginx的源码目录"><a href="#认识Nginx的源码目录" class="headerlink" title="认识Nginx的源码目录"></a>认识Nginx的源码目录</h2><p>当获取到Nginx源码压缩包并解压后，你可能对这些目录一头雾水，这里我对它们做个简单说明。比如1.18.0版本的源代码目录是这样的： <a href="/2020/12/17/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/nginx%E6%BA%90%E7%A0%81%E7%9B%AE%E5%BD%95/"><img src="/2020/12/nginx%E6%BA%90%E7%A0%81%E7%9B%AE%E5%BD%95.png"></a> 其中包含5个文件和5个目录，我们先来看单个文件的意义：</p>
<ul>
<li>  CHANGES：即上面介绍过的版本变更文件。</li>
<li>  ru：由于Igor是俄罗斯人，所以除了上面的英文版变更文件外，还有个俄文版的变更文件。</li>
<li>configure：如同其他Linux源码类软件一样，这是编译前的必须执行的核心脚本，它包含下面4个子功能：<ul>
<li>  解析configure脚本执行时传入的各种参数，包括定制的第三方模块；</li>
<li>  针对操作系统、体系架构、编译器的特性，生成特定的编译参数；</li>
<li>  生成Makefile、c等文件；</li>
<li>  在屏幕上显示汇总后的执行结果。</li>
</ul>
</li>
<li>  LICENSE：这个文件描述了Nginx使用的<a href="https://opensource.org/licenses/BSD-2-Clause">2-clause BSD-like license</a>许可协议。</li>
<li>  README：它只是告诉你去使用<a href="http://nginx.org官网查询各模块的用法./">http://nginx.org官网查询各模块的用法。</a></li>
</ul>
<p>  再来看各个目录的意义：</p>
<ul>
<li>  auto：configure只是一个简单的入口脚本，真正的功能是由auto目录下各个脚本完成的。</li>
<li>  conf：当安装完Nginx后，conf目录下会有默认的配置文件，这些文件就是从这里的conf目录复制过去的。</li>
<li>  contrib：包含了Nginx相关的周边小工具，比如下一讲将要介绍vim中如何高亮显示Nginx语法，就依赖于其中的vim子目录。</li>
<li>  html：安装完Nginx并运行后，会显示默认的欢迎页面，以及出现错误的500页面，这两个页面就是由html目录拷贝到安装目录的。</li>
<li>  man：目录中仅包含8一个文件，它其实是为Linux系统准备的man帮助文档，使用man -l nginx.8命令，可以看到Nginx命令行的使用方法：</li>
</ul>
<p><a href="/2020/12/17/10%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E8%AE%A4%E8%AF%86nginx/nginx-man/"><img src="/2020/12/nginx-man.png"></a></p>
<ul>
<li>  src：放置所有Nginx源代码的目录。关于src下的子目录，后续我分析源码时再详细介绍它们。</li>
</ul>
<p>  以上就是官方压缩包解压后的内容，当你执行完configure脚本后，还会多出Makefile文件以及objs目录，在下一篇文章中我会介绍它们。  </p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最后，对《从头搭建静态资源服务器》系列第1篇做个总结。   Nginx是集静态资源与负载均衡与一身的Web服务器，它支持C10M级别的并发连接，也通过与操作系统的紧密结合，能够高效的使用系统资源。除性能外，Nginx通过优秀的模块设计，允许第三方的C模块、Lua模块等嵌入到Nginx中运行，这极大丰富了Nginx生态。   下载源码编译安装Nginx，可以获得定制Nginx的能力。这样不仅用助于性能的提升，还通过各类模块扩展了Nginx的功能。   Nginx源代码中有5个文件和5个一级目录，其中configure脚本极为关键，在它执行后，还会生成Makefile文件和objs目录，它们与定制化的模块、系统的高性能参数密切相关，此后才能正式编译Nginx。   下一篇，我们将介绍configure脚本的用法，配置文件的语法格式，以及如何配置出静态资源服务。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>configure</tag>
        <tag>man</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP请求是如何关联Nginx server{}块的？</title>
    <url>/2021/08/09/nginx/HTTP%E8%AF%B7%E6%B1%82%E6%98%AF%E5%A6%82%E4%BD%95%E5%85%B3%E8%81%94Nginx-server-%E5%9D%97%E7%9A%84%EF%BC%9F/</url>
    <content><![CDATA[<p>Nginx是企业内网的对外入口，它常常同时对接许多应用，因此，Nginx上会同时监听多个端口、为多个域名提供服务。然而，匹配多级域名并不简单，Nginx为此准备了字符串精确匹配、前缀通配符、后缀通配符、正则表达式，当它们同时出现时，弄清楚HTTP请求会被哪个server{ }下的指令处理，就成了一件困难的事。</p>
<p>这是因为基于域名规范，请求匹配server{ }配置块时，并不会按照它们在nginx.conf文件中的出现顺序作为选择依据。而且对于不支持Host头部、没有域名的HTTP/1.0请求和无法匹配到合适server{ }的异常请求，我们都要区别对待。</p>
<p>另外，为了加快匹配速度，Nginx将字符串域名、前缀通配符、后缀通配符都放在了哈希表中，该设计充分使用了CPU的批量载入主存功能。如果不了解这些流程，既有可能导致请求没有被正确的server{ }块处理，也有可能降低了原本非常高效地哈希表查询性能。</p>
<span id="more"></span>
<p>本文将沿着Nginx处理HTTP请求的流程，介绍一个请求是如何根据listen、server_name等配置关联到server{ }块的。我们将从TCP连接的建立、Nginx从哪些字段取出域名、域名是怎样与server_name匹配的，讲清楚Nginx如何为请求找到处理它的server{ }块。在实际运维中，大部分问题都是由于请求匹配指令错误造成的，搞清楚这一匹配流程，对我们掌握Nginx非常重要。</p>
<h1 id="listen指令对server-块的第1次关联"><a href="#listen指令对server-块的第1次关联" class="headerlink" title="listen指令对server{ }块的第1次关联"></a>listen指令对server{ }块的第1次关联</h1><p>为了让一台服务器可以处理访问多个域名的不同请求，我们用“虚拟主机”来定义一种域名的处理方式，在Nginx中这对应着一个server{ }块。因此，HTTP请求到达时，Nginx首先要找到处理它的server{ }配置块。</p>
<p>请求关联server{ }块时主要依据listen和server_name这两个指令，其中listen指令发生在TCP连接建立完成时，它对server{ }块进行首次匹配，等到接收HTTP请求头部时，server_name再进行第二次匹配，这样就可以决定请求由哪个server{ }块中的指令处理。我们先来看listen指令是如何匹配请求的。</p>
<p>Nginx启动时创建socket并监听listen指令告知的端口（包括绑定IP地址）。当运行在TCP协议之上的HTTP请求到达服务器时，操作系统首先收到了TCP三次握手请求。我们知道，TCP这种传输层协议是由内核实现的，因此，由内核完成TCP的三次握手后，就会通过“读事件”经由Linux的Epoll通知到Nginx的worker进程以及具体监听的socket。</p>
<p>比如，我们在nginx.conf中配置了以下两个server：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">192.168.1.5:80</span>; </span><br><span class="line">&#125;</span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">127.0.0.1:80</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是本机进程发来的HTTP请求（在Linux中可以用curl或者telnet发起请求），它的IP报文头部目的IP地址就是127.0.0.1，而TCP报文头部的目的端口就是80。这样，Linux内核就找到了相应的socket，进而通过epoll_wait函数唤醒Nginx进程，而Nginx也就找到了对应的listen指令以及其所属的server{ }块。<br><img src="/images/nginx/Nginx%E7%9B%91%E5%90%AC80%E7%AB%AF%E5%8F%A3%E5%AF%B9%E5%BA%94TCP%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.jpg"></p>
<p>你可能注意到，有些server{ }块没有listen指令也可以正常的工作。这是因为Nginx认为每个server{}都应该监听TCP端口，当你没有显式的配置listen指令时，Nginx会默认帮你打开80端口。</p>
<h1 id="Nginx是怎样从HTTP请求中取出域名的？"><a href="#Nginx是怎样从HTTP请求中取出域名的？" class="headerlink" title="Nginx是怎样从HTTP请求中取出域名的？"></a>Nginx是怎样从HTTP请求中取出域名的？</h1><p>Nginx允许多个server{ }块监听相同的端口，所以当访问相同端口、不同域名的请求到达时，还需要根据请求中的域名做第2次匹配，以决定最终关联的server{ }块。</p>
<p>这里我们先要搞清楚域名是怎么从HTTP请求中取出来的。在HTTP/1.0协议中并没有Host头部，这是因为互联网起步时，HTTP的设计者并没有考虑到域名的数量会远多于服务器。对于HTTP/1.0请求而言，只能从absolute URL中携带域名。</p>
<p>举个例子，下面这个没有携带Host头部的请求可以取到<a href="http://www.taohui.pub域名：">www.taohui.pub域名：</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET http:&#x2F;&#x2F;www.taohui.pub&#x2F;index.html HTTP&#x2F;1.0</span><br></pre></td></tr></table></figure>

<p>如果你不清楚HTTP协议的格式，建议你先观看下我在极客时间上的视频课程<a href="https://time.geekbang.org/course/intro/175">《Web协议详解与抓包实战》</a>第12课<a href="https://time.geekbang.org/course/detail/175-94392">《详解HTTP的请求行》</a>。</p>
<p>互联网业务的推动导致一台服务器必须要处理大量域名，于是HTTP/1.1协议推出了描述访问域名的Host头部。对于不含有Host头部的HTTP/1.1请求，RFC规范要求服务器必须返回400错误码（Nginx也正是这么做的）。当Host头部与上述absolute URL中的域名同时出现时，将会以后者为准。例如对于下面这个请求，Nginx会取出<a href="http://www.taohui.tech作为匹配域名：">www.taohui.tech作为匹配域名：</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET http:&#x2F;&#x2F;www.taohui.tech&#x2F;index.html HTTP&#x2F;1.0</span><br><span class="line">Host: www.taohui.pub</span><br></pre></td></tr></table></figure>

<p>另外，对于使用了TLS/SSL协议的HTTPS请求来说，还可以从TLS握手中获取到域名。关于TLS握手及相关插件我会在后续的文章中再详述。</p>
<p>获取到请求的域名后，Nginx就会将其与上一节中listen指令匹配成功的server块进行第2次匹配，其中匹配依据就是server_name指令后的选项。我们暂且不谈server_name指令的匹配语法，先来看server_name匹配完成后的3种可能情况：</p>
<ol>
<li>   域名恰好与1个server{ }块中的server_name相匹配，选用该server{ }中的指令处理与请求；</li>
<li>   有多个server{ }块匹配上了域名，此时按server_name规定的优先级选中一个server{ }块即可；</li>
<li>   所有server{ }块都没有匹配上域名，此时必须有一个默认server { }块来处理这个请求。</li>
</ol>
<p>其中在第3种情况里，Nginx是这么定义默认server { }的：</p>
<ol>
<li>   当listen指令后明确的跟着default_server选项时，它所属的server{ }就是默认server。</li>
<li>   如果监听同一个端口的所有server{ }都没有通过listen指令显式设置default_server，那么这些server{ }配置块中，在nginx.conf配置文件里第1个出现的就是默认server。</li>
</ol>
<p>注意，你不能把监听相同端口、地址对的两个server{ }块同时设为默认server，否则nginx将无法启动，并给出类似下方的错误输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx: [emerg] a duplicate default server for 0.0.0.0:80 in &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf:40</span><br></pre></td></tr></table></figure>

<p>这就是请求匹配server{ }块的总体流程，下面我们来看server_name与域名的匹配，这也是最复杂的环节。</p>
<h1 id="server-name指令对server-块的第2次关联"><a href="#server-name指令对server-块的第2次关联" class="headerlink" title="server_name指令对server{ }块的第2次关联"></a>server_name指令对server{ }块的第2次关联</h1><p>如果你购买过域名肯定清楚，虽然只买到一个域名，但你会有无数个子域名可以使用。比如我买到的是taohui.pub二级域名（pub是一级域名），我就可以配置出blog.taohui.pub这个三级域名，甚至自己搭建一个子域名解析服务，再配置出四级域名nginx.blog.taohui.pub，甚至五级、六级域名都能使用，如下图所示：<br><img src="/images/DNS/%E5%A4%9A%E7%BA%A7%E5%9F%9F%E5%90%8D.png"></p>
<p>由于多级域名的存在，关联域名的server_name指令也相应地复杂起来，下面我们从3个层次看看server_name的选项种类。</p>
<p>首先，server_name支持精确地完全匹配，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name blog.taohui.pub;</span><br></pre></td></tr></table></figure>

<p>其次，server_name可以通过*符号作为通配符来匹配一类域名，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name *.taohui.pub;</span><br></pre></td></tr></table></figure>
<p>既可以匹配blog.taohui.pub，也可以匹配image.taohui.pub。由于*通配符在前方，所以我把它叫做前缀通配符。server_name还支持后缀通配符，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name www.taohui.*;</span><br></pre></td></tr></table></figure>
<p>它既可以匹配<a href="http://www.taohui.pub，也可以匹配www.taohui.tech域名。注意，server_name支持的通配符只能出现在最前方或者最后方，它不能出现在域名的中间，例如：">www.taohui.pub，也可以匹配www.taohui.tech域名。注意，server_name支持的通配符只能出现在最前方或者最后方，它不能出现在域名的中间，例如：</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name www.*.pub;</span><br></pre></td></tr></table></figure>
<p>就是非法的选项。</p>
<p>最后，当遇到通配符无法解决的场景时，可以使用正则表达式来匹配域名。当然，使用正则表达式的前提是将pcre开发库编译进Nginx（在CentOS下安装pcre开发库很简单，执行yum install pcre-devel -y即可。当有多个pcre版本并存时，可以通过configure –with-pcre=指定编译具体的pcre库）。</p>
<p>使用正则表达式时，需要在server_name选项前加入~符号，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name ~^ww\d.\w+.taohui.tech;$</span><br></pre></td></tr></table></figure>
<p>它可以匹配如ww3.blog.taohui.tech这样的域名。</p>
<p>当然，想一次写对正则表达式并不容易。pcre库提供的pcretest工具可以让我们提前测试正则表达式。注意，你用yum等工具安装pcre时，并不会自动安装pcretest工具，这需要你下载源代码（最新的pcre2-10.34下载地址参见<a href="https://ftp.pcre.org/pub/pcre/pcre2-10.34.tar.gz">这里</a>，帮助文档参见<a href="https://www.pcre.org/original/doc/html/pcretest.html">这里</a>）自行编译获得。本文不会讨论正则表达式的语法，也不会讨论pcretest工具的用法，关于Nginx中如何使用这两者，你可以观看下我在极客时间上的视频课程<a href="https://time.geekbang.org/course/intro/138">《Nginx核心知识100讲》</a>第46课<a href="https://time.geekbang.org/course/detail/138-71460">《Nginx中的正则表达式》</a>。</p>
<p>Nginx中的正则表达式通常会提供提取变量的能力，server_name指令也不例外！我们可以通过小括号将域名中的信息取出来，交给后续的指令使用，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    server_name ~^(ww\d).(?&lt;domain&gt;\w+).taohui.tech$;</span><br><span class="line">    return 200 &#39;regular variable: $1 $domain&#39;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时发起访问域名ww3.blog.taohui.tech的请求，由于第1个小括号我通过$1变量获取值为ww3，而第2个小括号我通过domain名称获得值为blog（通过$2也可以获得相同的内容），因此return指令发来的响应将会是regular variable: ww3 blog。</p>
<p>说完这3种域名选项后，我们再来看它们同时出现且匹配命中时，Nginx是怎样根据优先级来选择server{ }块的。域名的总体匹配优先级，与server{ }块在nginx.conf中的出现顺序无关，也与server_name指令在server{ }块中的出现顺序无关。事实上，对于监听同一地址、端口的server{ }块而言，Nginx会在进程启动时在收集所有server_name后，将精确匹配的字符串域名、前缀通配符、后缀通配符分别构建出3个哈希表，并将正则表达式构建为一个链表。我们看下请求到达时的匹配流程：</p>
<ol>
<li>   匹配域名时，首先在字符串域名构成的哈希表上做精确查询，如果查询到了，就直接返回，因此，完全匹配的字符串域名优先级是最高的；</li>
<li>   其次，将在前缀通配符哈希表上，按照每级域名的值分别查询哈希表，完成最长通配符的匹配。比如，blog.taohui.tech同时可以匹配以下2个前缀通配符：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_name *.tech;</span><br><span class="line">server_name *.taohui.tech;</span><br></pre></td></tr></table></figure>
但Nginx会匹配命中*.taohui.tech。</li>
<li>   其次，会在后缀通配符哈希表上做查询，完成最长通配符的匹配。</li>
<li>   最后，会按照正则表达式在nginx.conf中出现的顺序，依次进行正则表达式匹配，这一步的性能比起前3步要慢许多。</li>
</ol>
<p>这就是域名匹配的核心流程。</p>
<h1 id="关于域名匹配你还需要了解的技巧"><a href="#关于域名匹配你还需要了解的技巧" class="headerlink" title="关于域名匹配你还需要了解的技巧"></a>关于域名匹配你还需要了解的技巧</h1><p>事实上，还有一些域名匹配的小技巧需要你掌握。</p>
<p>首先，就像前面说过的HTTP/1.0协议是没有Host头部的，所以使用relative URL的HTTP/1.0请求并没有域名。按照之前的流程，它只能被默认server{ }块处理，这大大限制了默认server {}块的功能。</p>
<p>在Nginx 0.7.11之后的版本，你可以通过server_name “”指定空字符串，来匹配没有域名的请求，这就解放了默认server { }的职责。</p>
<p>其次，当Nginx对内网提供HTTP服务时，许多客户端会通过网络可达的主机名发起请求，这样客户端填写的域名就是主机名。如果必须由管理员先用hostname命令获取到主机名，再改写server_name指令，这就太不方便了。因此，server_name后还可以填写$hostname变量，这样Nginx启动时，会自动把$hostname替换为真正的主机名。<br>server_name $hostname;</p>
<p>最后一点，上文说过非正则表达式的server_name选项都会存放在哈希表中，这样哈希表中每个bucket桶大小就限制了域名的最大长度。当我们使用长域名或者多级域名时，默认的桶大小很可能就不够了，这时需要提升server_name的桶大小。</p>
<p>桶大小由server_names_hash_bucket_size配置控制，由于CPU从内存中读入数据时是按批进行的，其中每批字节数是cpu cache line，因此为了一次可以载入一个哈希桶，server_names_hash_bucket_size的默认值被定为cpu cache line。目前多数CPU的cache line值是64字节，所以若域名较长时需要增加桶的大小。</p>
<p>当你增大桶大小时，需要保证server_names_hash_bucket_size是cpu cache line的整数倍，这样读取哈希桶时，会尽量少地读取主存。毕竟操作主存的速度通常在100纳秒左右，这比CPU的速度慢得多！</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>最后对本文做个小结。</p>
<p>当TCP三次握手完成后，Linux内核就会按照内核的负载均衡算法，唤醒监听相应端口的某个Nginx worker进程。而从读事件及socket句柄上，Nginx可以找到对应的listen指令及所属的server{ }块，这完成了初次匹配。</p>
<p>接着，Nginx会接收HTTP请求，从absolute URL、 Host域名或者TLS插件中取出域名，再将域名与server_name进行匹配。其中匹配优先级是这样的：精确的字符串匹配优先级最高，其次是前缀通配符和后缀通配符匹配（这两者匹配时，如果多个通配符命中，会选择最长的server_name），最后才是正则表达式匹配。</p>
<p>如果以上情况皆未匹配上，请求会被默认server{ }处理。其中默认server {}是监听同一端口、地址的一系列server{ }块中，第1个在nginx.conf中出现的那个server{ }。当然，通过listen default_server也可以显示地定义默认server{ }。</p>
<p>最后留给你一个思考题，为什么有人用server_name _;来处理未匹配上的请求？欢迎你留言一起探讨。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
        <tag>正则表达式</tag>
        <tag>server_name</tag>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx的字节级限速原理</title>
    <url>/2023/09/13/nginx/Nginx%E9%99%90%E9%80%9F%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90%EF%BC%9A%E4%BB%8E%E5%AD%97%E8%8A%82%E5%88%B0%E8%AF%B7%E6%B1%82%E7%9A%84%E7%B2%BE%E7%A1%AE%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<p>有同学反馈：在配置Nginx四层限速时，proxy_upload_rate和proxy_download_rate有一定的概率不生效。我按照他的步骤也能复现，但这与官方Nginx很稳定（相对其他开源软件）的印象并不相符，是不是Nginx的官方BUG呢？这里的真实原因，其实是Nginx字节限速机制与时间更新频率的协商导致的，这篇文章我们就来研究下Nginx的字节限速。</p>
<p>首先看下测试场景：基于UDP协议搭建四层代理（UDP协议更简单，更容易复现BUG），在nginx.conf中配置每秒最大上传10个字节：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">proxy_upload_rate</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
<p>客户端先发送10字节，服务器接收到后（用回包触发）客户端立刻再次发送10字节，预期服务器将在1秒后收到第2个报文，但实际上服务器有可能立刻收到报文，即proxy_upload_rate未生效或者不可控！一旦配置项处于不可解释的状态，这对于严谨的应用场景是不可接受的。而这个现象的原因，本质上是目前Nginx实现机制所致，接下来我会基于1.21版本的源码上解释其原理。</p>
<h1 id="基于字节的限速实现原理"><a href="#基于字节的限速实现原理" class="headerlink" title="基于字节的限速实现原理"></a>基于字节的限速实现原理</h1><p>首先，我们要明确上例属于Nginx中的哪种限速。由于Nginx使用了内核协议栈，因此Nginx既不能对Packet级别的报文、也不能对TCP连接建立进行限速，而是只能在用户态基于调用socket编程API的时机，在字节转发速率、应用层协议的HTTP请求上（如官方的limit_req）做限制。<br><img src="/images/tcp/socket%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.png" alt="socket与TCP协议栈"></p>
<span id="more"></span>

<p>对于TCP协议的限速，当限速低于当前TCP连接的传输速率时，是通过零通告窗口来降低传输速率的。其具体作用原理为：作为接收端的Nginx所在服务器上，会有一个接收缓冲区，比如Linux中的tcp_rmem：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_rmem = 4096	131072	6291456</span><br></pre></td></tr></table></figure>

<p>tcp_rmem由TCP滑动窗口和socket读缓冲区共用，当Nginx在Epoll返回“可读”IO事件时，却不去读取socket数据，那么，当tcp_rmem被接收到的数据占满后，接收滑动窗口就会变为0，此时TCP连接的对端就会收到零窗口通知，进而停止发送数据，如下图所示：<br><img src="/images/tcp/%E9%9B%B6%E7%AA%97%E5%8F%A3%E6%8E%A2%E6%B5%8B.png" alt="零窗口探测"></p>
<p>UDP协议与之类似，只不过因为没有重传机制，新收到的UDP报文会被直接丢弃。</p>
<p>对于字节转发速率的限制，Nginx正是通过上述机制生效的。无论是四层的proxy_upload_rate和proxy_download_rate，或者是七层的limit_rate，Nginx都是基于每秒转发字节数进行限速的，区别只在于，四层的2个指令都是在socket接收时生效，而七层则在socket发送到下游客户端（单向）时生效（这里并不基于TCP滑动窗口生效，因为Nginx只需保证降低发送HTTP响应的速率即可达到设计目标）。</p>
<p>下图是我以STREAM四层为例，画出的限速流程示意图：<br><img src="/images/nginx/nginx%E5%AD%97%E8%8A%82%E9%99%90%E9%80%9F%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="nginx字节限速流程图"></p>
<p>可以看到，在执行socket.read函数前会先计算一次限速公式，如果已经达到限速阈值，则根据计算出的等待时间添加定时器退出，此后就有可能出现TCP零窗口或者UDP报文丢弃；反之，才会将socket缓冲区中的数据拷贝到用户态转发。当然，在接收完数据后，还会做一次限速计算，此操作不影响本次数据的转发，只影响当前事件下是否会连续多次读取socket缓冲区。</p>
<p>开篇提到的<strong>限速失效问题</strong>关键就在于图中的限速公式。</p>
<h1 id="Nginx的限速计算公式"><a href="#Nginx的限速计算公式" class="headerlink" title="Nginx的限速计算公式"></a>Nginx的限速计算公式</h1><p>先来看Nginx计算限速的关键代码，它在ngx_stream_proxy_module.c文件的ngx_stream_proxy_process函数中：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (limit_rate) &#123; </span><br><span class="line">    <span class="comment">//limit_rate就是proxy_upload_rate（上行）或者proxy_download_rate（下行）的值</span></span><br><span class="line">    limit = (<span class="keyword">off_t</span>) limit_rate * (ngx_time() - u-&gt;start_sec + <span class="number">1</span>)</span><br><span class="line">            - *received;</span><br><span class="line">    <span class="comment">//limit&lt;=0就达到了限速条件</span></span><br><span class="line">    <span class="keyword">if</span> (limit &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        delay = (<span class="keyword">ngx_msec_t</span>) (- limit * <span class="number">1000</span> / limit_rate + <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//delay定时器到达后，才会继续转发数据</span></span><br><span class="line">        ngx_add_timer(src-&gt;read, delay);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个公式同时适用于上、下游的数据转发，当从下游客户端转发数据时，limit_rate值为nginx.conf配置文件的proxy_upload_rate指令，而从上游服务器转发数据时，limit_rate值则为配置文件的proxy_download_rate指令，而received指针指向已接收到的字节总数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (from_upstream) &#123;</span><br><span class="line">    limit_rate = u-&gt;download_rate;</span><br><span class="line">    received = &amp;u-&gt;received;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    limit_rate = u-&gt;upload_rate;</span><br><span class="line">    received = &amp;s-&gt;received;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个公式的设计思想是：如果ngx_time()当前时间与u-&gt;start_sec请求处理的起始时间的时间差内，转发的字节数received超出了limit_rate限制，就要立刻停止转发数据，其中暂停的时间是delay毫秒。虽然这个公式由STREAM四层使用，但HTTP七层也差不多，参见ngx_http_write_filter_module.c文件：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (r-&gt;limit_rate) &#123;</span><br><span class="line">    limit = (<span class="keyword">off_t</span>) r-&gt;limit_rate * (ngx_time() - r-&gt;start_sec + <span class="number">1</span>)</span><br><span class="line">            - (c-&gt;sent - r-&gt;limit_rate_after);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (limit &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        c-&gt;write-&gt;delayed = <span class="number">1</span>;</span><br><span class="line">        delay = (<span class="keyword">ngx_msec_t</span>) (- limit * <span class="number">1000</span> / r-&gt;limit_rate + <span class="number">1</span>);</span><br><span class="line">        ngx_add_timer(c-&gt;write, delay);</span><br><span class="line"></span><br><span class="line">        c-&gt;buffered |= NGX_HTTP_WRITE_BUFFERED;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> NGX_AGAIN;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为了方便理解，我们继续以四层代码为例说明问题。当应该限速时，公式返回的limit变量就会大于0，而本文开头提到的测试场景，第2秒发送10字节时，*received的值肯定是10（第1秒转发），而ngx_time() - u-&gt;start_sec预期为1，所以limit的值预期为10*(1+1)-10，也就是10，进而delay值应为1秒才对。但实测结果却是有很大概率limit为0，导致Nginx没有限速。这是什么原因呢？</p>
<h1 id="Nginx的时间更新方式"><a href="#Nginx的时间更新方式" class="headerlink" title="Nginx的时间更新方式"></a>Nginx的时间更新方式</h1><p>其实公式中的“变量”只可能是时间，毕竟limit_rate是配置文件中的指令，*received是已转发字节，这两者都不可能出错。所以，问题肯定出在u-&gt;start_sec或者ngx_time()的<strong>精准度</strong>上！前者u-&gt;start_sec的赋值很简单，参见ngx_stream_proxy_handler函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">ngx_stream_proxy_handler(<span class="keyword">ngx_stream_session_t</span> *s)</span><br><span class="line">&#123;</span><br><span class="line">    u-&gt;start_sec = ngx_time();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当Nginx接收到下游客户端的数据，准备向上游服务器建立会话连接时，u-&gt;start_sec就被初始化为当前时间。再来看ngx_time函数是如何返回系统时间的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">volatile</span> <span class="keyword">ngx_time_t</span>  *ngx_cached_time;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_time()           ngx_cached_time-&gt;sec</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_timeofday()      (ngx_time_t *) ngx_cached_time</span></span><br></pre></td></tr></table></figure>

<p>Nginx在新版本实现中为了优化性能，使用了缓存时间ngx_cached_time（即使调用ngx_timeofday函数返回的也是缓存时间），这带来了2个问题：</p>
<ol>
<li>ngx_time函数只取了秒，直接舍弃了毫秒精度（连<strong>四舍五入</strong>也没有考虑）；</li>
<li>ngx_cached_time的更新频率必然影响限速的时间精度。</li>
</ol>
<p>本文开头问题与上述二者都有关系。<strong>忽略毫秒必然带来最大1秒的时间误差</strong>，而ngx_cached_time的更新频率会在此基础上放大ngx_time() - u-&gt;start_sec的误差，再来看下ngx_cached_time是如何更新的。</p>
<p>ngx_time_update函数负责更新ngx_cached_time，在谈其调用频率之前，先来看看它在多线程上的锁优化设计，这也有微小的时间精度降低：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ngx_gettimeofday(tp)  (void) gettimeofday(tp, NULL);</span></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">ngx_time_update(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">ngx_tm_t</span>         tm, gmt;</span><br><span class="line">    <span class="keyword">time_t</span>           sec;</span><br><span class="line">    <span class="keyword">ngx_uint_t</span>       msec;</span><br><span class="line">    <span class="keyword">ngx_time_t</span>      *tp;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span>   <span class="title">tv</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//加锁</span></span><br><span class="line">    <span class="keyword">if</span> (!ngx_trylock(&amp;ngx_time_lock)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//真实执行操作系统的gettimeofday系统调用</span></span><br><span class="line">    ngx_gettimeofday(&amp;tv);</span><br><span class="line"></span><br><span class="line">    sec = tv.tv_sec;</span><br><span class="line">    msec = tv.tv_usec / <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">    tp = &amp;cached_time[slot];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tp-&gt;sec == sec) &#123;</span><br><span class="line">        tp-&gt;msec = msec;</span><br><span class="line">        ngx_unlock(&amp;ngx_time_lock);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//循环复用cached_time数组</span></span><br><span class="line">    <span class="keyword">if</span> (slot == NGX_TIME_SLOTS - <span class="number">1</span>) &#123;</span><br><span class="line">        slot = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        slot++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tp = &amp;cached_time[slot];</span><br><span class="line"></span><br><span class="line">    tp-&gt;sec = sec;</span><br><span class="line">    tp-&gt;msec = msec;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//volatile类型的原子操作</span></span><br><span class="line">    ngx_cached_time = tp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//解锁</span></span><br><span class="line">    ngx_unlock(&amp;ngx_time_lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Nginx支持多线程（虽然用得不多），因此为了减少加锁操作，Nginx使用了含有64个元素的数组cached_time循环复用保存时间，这样读时间时就省去了加锁操作，只在更新时才会加锁并通过变更slot的值移动循环数组：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NGX_TIME_SLOTS   64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">ngx_time_t</span>        cached_time[NGX_TIME_SLOTS];</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">ngx_uint_t</span>        slot;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">ngx_atomic_t</span>      ngx_time_lock;</span><br><span class="line"></span><br><span class="line"><span class="keyword">volatile</span> <span class="keyword">ngx_time_t</span>     *ngx_cached_time;</span><br></pre></td></tr></table></figure>

<p>ngx_time_update调用完成后，ngx_cached_time就会保存最新的时间。<br>再来看ngx_time_update函数的调用时机，这里主要参见Linux epoll多路复用机制中的ngx_epoll_process_events函数（这是更新时间的固定代码段）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">ngx_int_t</span></span><br><span class="line">ngx_epoll_process_events(<span class="keyword">ngx_cycle_t</span> *cycle, <span class="keyword">ngx_msec_t</span> timer, <span class="keyword">ngx_uint_t</span> flags)</span><br><span class="line">&#123;</span><br><span class="line">    events = epoll_wait(ep, event_list, (<span class="keyword">int</span>) nevents, timer);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (flags &amp; NGX_UPDATE_TIME || ngx_event_timer_alarm) &#123;</span><br><span class="line">        ngx_time_update();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见，每处理一批IO事件时，只要flags参数中携带了NGX_UPDATE_TIME标志，就会更新时间。那么，究竟何时会携带NGX_UPDATE_TIME标志位呢？这里要参见worker进程中循环调用的ngx_process_events_and_timers函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span></span><br><span class="line">ngx_process_events_and_timers(<span class="keyword">ngx_cycle_t</span> *cycle)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">ngx_uint_t</span>  flags;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ngx_timer_resolution) &#123;</span><br><span class="line">        flags = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        flags = NGX_UPDATE_TIME;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    (<span class="keyword">void</span>) ngx_process_events(cycle, timer, flags);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里又多出了一个ngx_timer_resolution，这又是什么鬼？从<a href="https://nginx.org/en/docs/ngx_core_module.html#timer_resolution">官方文档</a>中可以看到：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line">Syntax:	timer_resolution interval;</span><br><span class="line">Default:	—</span><br><span class="line">Context:	main</span><br><span class="line"><span class="attribute">Reduces</span> timer resolution in worker processes, thus reducing the number of gettimeofday() system calls made. By default, gettimeofday() is called each time a kernel event is received.</span><br></pre></td></tr></table></figure>

<p>timer_resolution是用于降低时间更新频率的。当然，默认情况下我们并不会配置timer_resolution，此时每批Epoll IO事件都会更新一次时间。</p>
<p>到这里，终于可以彻底回答本文开头的问题了。虽然Nginx的限速公式没有问题，但是Nginx时间精度却有2个问题，导致公式中的时间差ngx_time() - u-&gt;start_sec存在<strong>秒级的计算误差</strong>：<br>1、在系统不繁忙时，舍弃毫秒会导致最大1秒的误差;<br>2、时间更新频率则受到timer_resolution指令、epoll事件的批次数量、锁优化设计下的时间数组更新误差、worker进程的延迟调度等因素综合影响。</p>
<p>所以，我们在验证或者设计测试场景时，需要将上述2个因素都纳入考虑。同时，在Nginx更新版本时，综合评估Nginx源码设计的变动，就能更准确的掌握限速的要理。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>udp</tag>
        <tag>limit_rate</tag>
        <tag>限速</tag>
        <tag>零窗口</tag>
        <tag>滑动窗口</tag>
        <tag>协议栈</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>URL是如何关联Nginx location配置块的？</title>
    <url>/2021/08/09/nginx/URL%E6%98%AF%E5%A6%82%E4%BD%95%E5%85%B3%E8%81%94location%E9%85%8D%E7%BD%AE%E5%9D%97%E7%9A%84%EF%BC%9F/</url>
    <content><![CDATA[<p>上一篇文章介绍了HTTP请求匹配server{ }配置块的过程，接着请求会继续匹配location{ }配置块，并最终决定哪些指令及Nginx模块处理请求。本文将介绍location的匹配规则，以及rewrite指令与location匹配顺序的关系。<br><img src="/images/nginx/location%E5%89%8D%E7%BC%80%E6%A0%91%E7%9A%84%E5%8C%B9%E9%85%8D%E6%B5%81%E7%A8%8B2.png"><br>生产环境中的nginx.conf往往含有上百条location，这是因为Nginx常常身兼多职：充当提供静态资源CDN、作为负载均衡为分布式集群提供扩展性、作为API gateway提供接口服务等等。location一旦配置错误，Nginx上巨大的并发连接数会将错误放大上万倍，很容易导致严重的线上事故。</p>
<p>而location也很容易配置错误，它既支持前缀匹配，也支持正则表达式匹配，当二者同时出现时，为了获得更高的性能，Nginx设计了复杂的location匹配优先级。这是因为前缀匹配是对静态的location多叉树检索完成的，它的性能要比正则表达式高得多，唯有搞清楚具体的匹配流程，我们才能设计出匹配速度更快的location。</p>
<p>而且rewrite指令修改URL的功能也让location匹配变得更为复杂。特别是rewrite出现在server{ }和location{ } 里，会导致完全不同的结果。设计location时，我们还需要考虑到rewrite的效率，以及它是否会导致循环重定向。</p>
<span id="more"></span>
<p>这篇文章将从底层讲清楚URL匹配location { }配置块的流程，以及rewrite指令修改URL后，Nginx又是怎样重新匹配location的。</p>
<h1 id="如何匹配前缀location？"><a href="#如何匹配前缀location？" class="headerlink" title="如何匹配前缀location？"></a>如何匹配前缀location？</h1><p>location { }中定义了哪些Nginx模块会处理以及如何处理HTTP请求，因此，URL与location的匹配关系到功能的正确性，它是学好Nginx的必要条件。</p>
<p>location有两类匹配URL的方式，一类是前缀匹配，一类是正则表达式匹配。我们先来看前缀匹配。</p>
<p>URL通过/正斜杠符号分隔对象，因此URL从前至后具有天然的层级关系。比如，/wp-content/uploads/2019/07/test.jpg就具备以下意义：第1级wp-content说明它属于wordpress的内容，第2级uploads说明这是用户自行上传的文件，第3、4级2019/07描述了它的上传日期，第5级则是文件名称及格式。所以，从前至后进行前缀匹配最自然不过，像location /wp-content/uploads { } 就可以匹配wordpress中所有用户上传的文件。</p>
<p>当请求同时匹配上多个location时，Nginx会选择前缀最长的location { }处理请求。比如，location /wp-content/uploads { }和location /wp-content/uploads/2019 { }同时存在时，/wp-content/uploads/2019/07/test.jpg请求只会命中后者。<strong>最长前缀匹配，是location匹配的核心原则。</strong></p>
<p>由于许多location处于包含关系，因此很容易出现重复匹配，那么，当数百个前缀location同时配置时，Nginx怎样基于最长前缀原则，最有效率的关联URL呢？<strong>事实上，Nginx会在启动过程中，将server{ }内的所有location基于前缀的包含关系，建立一颗多叉树。</strong></p>
<p>比如，如下12个location将会构造出1颗4层的静态树，其中<strong>子树中的所有location，都是比父结节更长的前缀location；在同一层的结点中，它们互不相属，但却是基于字母表有序的（注意，同级location的排序与长度无关）</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">location &#x2F;test &#123;root html;&#125;</span><br><span class="line">location &#x2F;res &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;res&#x2F;img &#123;root html&#x2F;res&#x2F;img;&#125;</span><br><span class="line">location &#x2F;res&#x2F;video &#123;root html&#x2F;res&#x2F;video;&#125;</span><br><span class="line">location &#x2F; &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;resource&#x2F;js &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;resource&#x2F;image &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;his &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;his&#x2F;20 &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;his&#x2F;2020 &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x2F;his&#x2F;20&#x2F;02 &#123;root html&#x2F;res;&#125;</span><br><span class="line">location &#x3D; &#x2F;50x.html &#123;&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/images/nginx/location%E5%89%8D%E7%BC%80%E6%A0%91%E7%9A%84%E5%8C%B9%E9%85%8D%E6%B5%81%E7%A8%8B.png"></p>
<p>举个例子，location = /50x.html和location /res都是/结点的子结点，因此它们处于树的第2层。且因为首字母5的ASCII码比r要小，因此50x.html是res的左兄弟结点。为了提高检索效率，Nginx会在构造树的过程中，取每一层兄弟结点中间的那一个，作为父结点的直接子结点。就像50x.html、his、res、test四个结点并存时，res将作为/的直接子结点，这能够减少检索的时间复杂度。</p>
<p>我们以一个具体的例子来看下location树的匹配流程。比如/his/2001/test.jpg请求到达时，它的匹配顺序如下图蓝色箭头所示：<br><img src="/images/nginx/location%E5%89%8D%E7%BC%80%E6%A0%91%E7%9A%84%E5%8C%B9%E9%85%8D%E6%B5%81%E7%A8%8B2.png"></p>
<p>事实上，/his/2001/test.jpg请求的匹配共包含6步：</p>
<ol>
<li>   请求首先命中/，暂时/将被设置为最长前缀，再进入子树看看有没有更长的前缀；</li>
<li>   未匹配上直接子结点res，由于h在字母表的顺序小于r，因此到左兄弟结点his中继续匹配；</li>
<li>   匹配上his后，此时/his被设置为最长前缀；</li>
<li>   <strong>匹配上直接子树/his/20，将其设为最长前缀</strong>，仍然进入子树尝试更长的前缀匹配；</li>
<li>   未匹配上直接子树20，由于1在字母表的顺序中小于2，因此到左兄弟结点中去看看；</li>
<li>   /20未匹配命中，且在字母表中/先于1，匹配到此结束。这时，最长匹配是/his/20，于是使用此location处理请求/his/2001/test.jpg。</li>
</ol>
<p>这样我们搞清楚了最长前缀匹配的底层逻辑，接下来再来看正则表达式location的用法。</p>
<h1 id="如何匹配正则表达式location？"><a href="#如何匹配正则表达式location？" class="headerlink" title="如何匹配正则表达式location？"></a>如何匹配正则表达式location？</h1><p>当遇到前缀匹配无法覆盖的URL时，可以使用正则表达式匹配请求。当然，与上一篇介绍过的server_name类似，使用正则表达式的前提是将pcre开发库编译进Nginx。一次写对正则表达式很难，在Linux下我建议你用pcretest命令行工具提前测试正则表达式。关于正则表达式和pcretest工具的用法，你可以观看下我在极客时间上的视频课程<a href="https://time.geekbang.org/course/intro/138">《Nginx核心知识100讲》</a>第46课<a href="https://time.geekbang.org/course/detail/138-71460">《Nginx中的正则表达式》</a>。</p>
<p>在location中使用正则表达式，只需要在表达式前加入<del>或者</del>*符号，其中前者表示字母大小写敏感，而后者对大小写不敏感，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">location ~* *\.(gif|jpg|png|webp|)$</span><br></pre></td></tr></table></figure>
<p>它可以匹配各类图片，且忽略文件格式后缀的大小写。</p>
<p>多个正则表达式location之间的匹配次序很简单，按照它们在server{ }块中出现的位置，依次匹配，直接使用最先命中的location即可。所以<strong>使用正则表达式要小心，当上方的正则表达式匹配范围过大时，下方的正则表达式location可能永远也无法命中</strong>。</p>
<p>当正则表达式与前缀location同时出现时，事情就变得复杂起来。我们前面介绍过，前缀location构成的多叉树匹配效率很高，而正则表达式的匹配要慢得多。因此，Nginx会优先进行前缀location匹配，再进行正则表达式location的匹配，而且Nginx额外给前缀location提供了2个跳过正则表达式匹配的武器：=和^~。</p>
<p>在执行前缀匹配时，如果URL与location完全相等，那么Nginx不会再检索子树寻找更长的前缀匹配，但还会执行正则表达式匹配。如果你希望URL完全相等后，不必再匹配正则表达式location，那么可以在location前增加=号。比如，当location = / {}与location / {}同时出现时，前者是为了匹配访问首页的请求，而后者可以匹配任何请求，常用来兜底。因此，<strong>如果某些页面访问频率非常高，你应该用=号加快location的匹配速度</strong>。</p>
<p>另外，^<del>也可以跳过正则表达式匹配阶段，加快location的执行速度，而且它比=号的应用范围更广，^</del>不需要URL完全相等，只需要匹配上前缀即可跳过后续的正则表达式。注意，<strong>只有最长匹配上携带^~符号，才能够跳过正则表达式</strong>。比如，你觉得/res/blog/js/1.js访问下面3个location时会获得什么响应？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">location ^~ &#x2F;res&#x2F;blog &#123;return 200 &#39;res blog&#39;;&#125;</span><br><span class="line">location &#x2F;res&#x2F;blog&#x2F;js &#123;return 200 &#39;res blog js&#39;;&#125;</span><br><span class="line">location ~* .*\.js &#123;return 200 &#39;js&#39;;&#125;</span><br></pre></td></tr></table></figure>

<p>答案是’js’！虽然这个请求同时命中了3个location，但2个前缀location中，/res/blog虽然带有^~符号，可惜它却不是最长的前缀匹配；而/res/blog/js虽然是最长前缀，但又不能阻止正则表达式；*<em>最终第3个location ~</em> .*.js匹配上了URL！ **</p>
<p>简单的总结下location匹配规则（见下图）：<br><img src="/images/nginx/location%E7%9A%84%E5%8C%B9%E9%85%8D%E6%B5%81%E7%A8%8B.png"></p>
<ol>
<li>   先对前缀location执行最长前缀匹配</li>
<li>   若最长前缀location前，携带有=或者^~，那么使用此location配置块处理请求；</li>
<li>   按server{ }中正则表达式的出现顺序，依次匹配。成功后就选中此location；</li>
<li>   若所有正则表达式皆未匹配上，则使用第1步中检索出的最长前缀location处理请求。</li>
</ol>
<p>你可能会问，如果第1步中就没有找到能匹配上的前缀location，那该怎么办？很简单，Nginx会直接返回404。当然，为了避免这种情况发生，通常我们都会添加location / { }兜底，它可以匹配任意URL。</p>
<p>注意：location中的正则表达式，就像server_name中一样，可以用小括号()提取变量，供后续其他Nginx模块的指令使用。</p>
<p>配置location时，还有一个技巧需要你掌握：由于客户端的URL中可能含有重复的正斜杠/，因此Nginx会自动合并连续的重复正斜杠/。比如，//res/blog///a.js会被合并成/res/blog/a.js。如果你想关闭这一功能，可以添加下面这行配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">merge_slashes off;</span><br></pre></td></tr></table></figure>

<p>由于location的匹配规则相当复杂，所以Nginx会在debug级别的日志中，打印出最终选中了哪个location。比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test location: &quot;&#x2F;&quot;</span><br><span class="line">test location: &quot;res&quot;</span><br><span class="line">test location: &quot;&#x2F;blog&quot;</span><br><span class="line">using configuration &quot;&#x2F;res&#x2F;blog&quot;</span><br></pre></td></tr></table></figure>

<p>其中，using configuration指明了最终选择了哪个location。当然，要想开启debug日志，除了在nginx.conf里将error_log的日志级别设为debug外，还需要在configure时加入了—with-debug选项。</p>
<h1 id="rewrite指令是如何工作的"><a href="#rewrite指令是如何工作的" class="headerlink" title="rewrite指令是如何工作的"></a>rewrite指令是如何工作的</h1><p>虽然我们已经清楚了location的匹配规则，但是，匹配的URL未必是客户端的原始URL，因为rewrite指令可以修改URL！因此，我们还需要了解rewrite指令的用法，这样才能全面掌握location的匹配规则。</p>
<p>当系统升级、维护或者数据迁移时，往往需要重写URL后，再执行location匹配。rewrite指令就是用来重写URL的，它的用法非常简单，比如下面这行指令就可以将/reg1/a.js修改为/reg2/a.js：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rewrite &#x2F;reg1&#x2F;(.*) &#x2F;reg2&#x2F;$1;</span><br></pre></td></tr></table></figure>

<p>显然，rewrite可以反复地修改URL，并导致location被反复匹配命中。因此，<strong>为了防止不当的rewrite指令导致死循环，Nginx在代码层面将1个请求的rewrite次数限制为10次，超过后会直接返回500错误码</strong>：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NGX_HTTP_MAX_URI_CHANGES           10</span></span><br></pre></td></tr></table></figure>

<p>rewrite指令既可以直接出现在server{ }块中，也可以出现在location { }块中，但它们的工作流程却完全不同！比如，你觉得下面的rewrite会导致请求/reg1/a.js无限循环吗？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rewrite &#x2F;reg1&#x2F;(.*) &#x2F;reg2&#x2F;$1;</span><br><span class="line">location &#x2F;reg2 &#123;rewrite &#x2F;reg2&#x2F;(.*) &#x2F;reg1&#x2F;$1;&#125;</span><br></pre></td></tr></table></figure>

<p>其实不会，因为server{ }中的rewrite指令只会执行1次。要说清楚rewrite、location的执行时机，我们得先清楚HTTP请求的11个执行阶段。</p>
<p>当Nginx接收完HTTP头部后，会让各Nginx模块基于Pipe And Filter模型依次处理请求。其中，为了让模块的处理次序更加可控，Nginx基于Web语义将其分为11个阶段，每个Nginx模块通常会选择1个阶段介入请求的处理流程。rewrite与location涉及到其中的4个阶段，下面看看它们究竟做了些什么：<br><img src="/images/nginx/rewrite%E4%B8%8Elocation%E5%BE%AA%E7%8E%AF%E5%8C%B9%E9%85%8D%E7%9A%84%E6%B5%81%E7%A8%8B.png"></p>
<p>我们依次分析这4个阶段：</p>
<ol>
<li>   server{ }块中的rewrite指令，将在NGX_HTTP_SERVER_REWRITE_PHASE阶段执行。从图中可以看到，它只会执行1次；</li>
<li>   前2节介绍的location匹配流程，就发生在NGX_HTTP_FIND_CONFIG_PHASE阶段；</li>
<li>   location{ }块中的rewrite指令，在NGX_HTTP_REWRITE_PHASE阶段执行；</li>
<li>   NGX_HTTP_POST_REWRITE_PHASE阶段中，判断location中的rewrite指令是否重写了URL，如果是，那么跳转到NGX_HTTP_FIND_CONFIG_PHASE阶段再做1次location匹配，否则继续向下，由其他Nginx模块处理请求。</li>
</ol>
<p>因此，不同于server{ }块，location中的rewrite指令是可能反复执行多次的。</p>
<p>其实，rewrite指令还可以携带4种不同的flag参数，它还将影响if、set等其他脚本类指令的执行。本文聚焦于location的匹配，后续我在脚本指令的介绍文章中，还会讲到rewrite指令的其他用法。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文介绍了HTTP请求匹配location的流程。</p>
<p>location支持URL按最长前缀进行location匹配。Nginx启动时会将所有前缀location构造出一颗静态的多叉树，其中子树中的结点都是父结点的更长前缀，而兄弟结点间则按字母表排序。这样，前缀URL的匹配效率就很高。</p>
<p>相比起来，正则表达式则按照在nginx.conf中的出现顺序进行匹配，效率要低得多。当二者同时出现时，虽然正则表达式优先级更高，但=号和^~号可以让前缀location跳过正则表达式匹配，提升性能。然而这样让location匹配更容易出错，如果你在开发环境中，可以借助debug级别的error.log日志，通过using configuration确认Nginx究竟选择了什么location来处理请求。</p>
<p>rewrite指令可以反复修改URL，其中server{ }块中的rewrite指令只会执行1次，而location中的rewrite则可能最多执行10次，超出后Nginx会返回500错误码。只有理解了11个HTTP阶段的执行顺序，才能掌握rewrite与location的匹配关系。</p>
<p>你可能知道，location { }配置块内可以嵌套location { }，虽然这不是一种推荐的配置方式，但它确实是被语法规则支持的。那么，在嵌套发生时，基于本文的理论，location是如何匹配的？rewrite指令又是怎样工作的？欢迎你在帖子下方留言，与我一起探讨更好的热部署实现方案。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>URI</tag>
        <tag>Trie树</tag>
        <tag>前缀树</tag>
        <tag>location</tag>
        <tag>rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx怎样隐藏上游错误</title>
    <url>/2021/02/22/nginx/Nginx%E6%80%8E%E6%A0%B7%E9%9A%90%E8%97%8F%E4%B8%8A%E6%B8%B8%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<p>当上游出错时，作为负载均衡的Nginx可以实时更换Server，在客户端无感知的情况下重新转发HTTP请求。这一功能在Nginx指令中称为next upstream，本文将详细介绍其用法及实现原理。</p>
<p>在OSI网络模型中，传输层的TCP协议通过内核提供的<strong>系统调用</strong>向Nginx反馈错误，表示层的TLS/SSL协议通过<strong>openssl库</strong>向Nginx返回错误，而应用层的HTTP协议（或者uwsgi、gRPC、CGI、memcached等协议）通过Response的<strong>Decode解码流程</strong>返回错误。当Nginx能够通过重试解决这些错误时，<strong>我们可以使用next upstream机制对客户端隐藏个别上游Server由于宕机、网络异常产生的错误，这可以极大的提升整个分布式系统的可用性</strong>。</p>
<span id="more"></span>
<p>如果我们不清楚它处理协议错误及重试转发的原理，就很容易在实际场景中发现next upstream没有发挥作用，比如： </p>
<ul>
<li><strong>proxy_request_buffering功能关闭后</strong>，一旦Nginx转发了请求包体，它就会释放掉内存中缓存的内容，从而失去了next upstream的重试能力。</li>
<li>从上游接收到完整的HTTP头部后Nginx就会向下游客户端转发，由于TCP协议是有序字符流，一经发出就无法更改，此时从<strong>HTTP语法层面</strong>上也会失去next upstream能力。</li>
<li>POST方法属于idempotent<strong>非幂等方法</strong>，所以从<strong>HTTP语义层面</strong>上next upstream功能也不会开启（默认配置下）。<br>等等。可见，next upstream是否能够按预期工作（遵照proxy_next_upstream_tries、proxy_next_upstream_timeout等指令），需要我们对它有深入的理解。</li>
</ul>
<p>本文将介绍Nginx作为代理服务器转发请求时，next upstream机制检测错误并重新转发给上游的执行流程。虽然本文例子中的指令属于HTTP/1模块，但在最后我会将官方提供的6个代理模块放在一起做个比较，在对比中你会更深入的了解upstream机制。同时，本文也是<a href="https://www.nginx.org.cn/course/series/22">Nginx开源社区基础培训系列课程第二季</a>，即7月23日晚第3次直播课的文字总结。</p>
<h1 id="TCP传输层的错误处理"><a href="#TCP传输层的错误处理" class="headerlink" title="TCP传输层的错误处理"></a>TCP传输层的错误处理</h1><p>作为负载均衡，Nginx可以在OSI网络模型的多个层级中检测、处理错误，我们首先来看Nginx在TCP传输层是如何应用next upstram机制的。</p>
<p>TCP层的错误主要体现在三次握手与数据传输中，是否能够及时接收到对方返回的ACK确认帧。由于TCP协议实现了有序字节流的可靠传输，所以HTTP、gRPC、CGI、memcached等协议都是基于TCP实现的。因此，Nginx向上游转发请求前，需要先通过三次握手建立TCP连接。关于3次握手的流程，你可以参见下图，这里不再详述。<br><img src="/images/tcp/tcp_guide_%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png"></p>
<p>当Nginx作为客户端发起三次握手时，它会向上游Server监听的端口上发送SYN报文。在以下2种情况下，Nginx会认为3次握手建立失败：<br>    接收到对方返回的RST重置报文。通常，这发生在上游对应的应用程序未启动，或者进程没有监听相应的端口；<br>    在proxy_connect_timeout时间内（默认60秒），没有接收到对方返回的SYN+ACK报文。</p>
<p>在以上场景中，Nginx默认会开启next upstream功能。这是因为，XXX_next_upstream指令拥有默认值error和timeout，其中error对应了协议层错误，而timeout则将Nginx指令定义的超时错误单独拎了出来。所有基于TCP的应用层协议都有这一特性，下面以HTTP/1代理模块为例，探究各指令的用法：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_next_upstream error | timeout | invalid_header | </span><br><span class="line"><span class="attribute">http_500</span> | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | </span><br><span class="line">non_idempotent | <span class="literal">off</span> ...;</span><br><span class="line">Default:	proxy_next_upstream error timeout;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>一旦连接建立成功，Nginx就会基于代理模块适配的应用层协议转发请求。TCP协议要求对于发送的每个字节，接收端都要通过ACK报文中的累计确认序列号进行反馈，一旦在RTO（TCP Retransmission Timeout）时间内未收到ACK确认，操作系统的内核就会重发TCP报文，如下图所示：<br><img src="/images/tcp/tcp_guide_%E8%B6%85%E6%97%B6%E9%87%8D%E4%BC%A0.png"></p>
<p>内核会为每个socket建立发送、接收缓冲区。<strong>如果大量发送报文得不到确认，那么发送缓冲区（它是动态调整的，可通过tcp_wmem修改范围）就没有空闲位置，这样一旦Nginx中的epoll_wait函数在proxy_send_timeout秒内都没有返回写事件，就会触发timeout错误</strong>：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_send_timeout time;</span><br><span class="line">Default:	proxy_send_timeout 60s;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>当转发完请求，接收响应的过程中，<strong>如果epoll_wait两次返回读事件的间隔超过了proxy_read_timeout秒，也会触发timeout错误</strong>：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_read_timeout time;</span><br><span class="line">Default:	proxy_read_timeout 60s;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>当Nginx未完成完整的转发流程时，服务器接收到的RST或者FIN报文会试图关闭TCP连接，此时都会通过epoll_wait函数触发error错误。只要proxy_next_upstream指令后加入了error和timeout选项，且Nginx还拥有转发完整请求的能力，next upstream机制就会生效，Nginx会基于负载均衡规则，重新挑选1个可用Server转发请求。</p>
<p>Nginx还提供了proxy_next_upstream_tries指令，用于限制重试次数（默认值是0，表示不加限制）：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_next_upstream_tries number;</span><br><span class="line">Default:	proxy_next_upstream_tries 0;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>通过proxy_next_upstream_timeout指令还可以限制更换上游Server转发请求的总时长（默认不加限制）。<strong>注意，该时长的起始时间是从首次转发请求算起（而不是每次更换上游Server时重新计算），而截止时间则是最后1次检测next upstream是否允许使用的时刻</strong>：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_next_upstream_timeout time;</span><br><span class="line">Default:	proxy_next_upstream_timeout 0;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>任何时候Nginx与下游的TCP连接出错时，next upstream机制都会失效，因为Nginx失去了转发HTTP响应的能力。</p>
<h1 id="TLS表示层的错误处理"><a href="#TLS表示层的错误处理" class="headerlink" title="TLS表示层的错误处理"></a>TLS表示层的错误处理</h1><p>再来看Nginx如何处理表示层TLS/SSL协议的错误。TLS会话的建立需要通过握手完成，如下所示：<br><img src="/images/tls/TLS%E6%8F%A1%E6%89%8B.png"></p>
<p><strong>TLS握手需要完成密钥协商和证书验证工作，通常需要2个RTT的时延（TLS1.3需要1个RTT），这一过程会复用proxy_connect_timeout指令标识的超时时间</strong>。一旦TLS握手超时，同样遵循timeout错误的处理方式。</p>
<p>在TLS握手过程中，Nginx还可以核验上游Server返回的证书链，以及SNI（Server Name Indication）插件中的域名（参见RFC6066）。你可以在proxy_ssl_verify指令中打开这一功能：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_ssl_verify on | off;</span><br><span class="line">Default:	proxy_ssl_verify off;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>Nginx会将服务器发来证书中SNI插件中的域名，与proxy_ssl_name指令中的变量做比较：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_ssl_name name;</span><br><span class="line">Default:	proxy_ssl_name $proxy_host;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>proxy_ssl_name的默认值是proxy_host变量，它等于proxy_pass指令后的域名。<strong>需要注意，一旦证书链或者SNI域名验证失败，next upstream机制将按error错误处理</strong>。</p>
<h1 id="应用层错误处理"><a href="#应用层错误处理" class="headerlink" title="应用层错误处理"></a>应用层错误处理</h1><p>一旦应用层在协议层面返回了正确的Response响应，但从语义上却是错误的，Nginx同样可以启用next upstream机制。下图是TCP层、TLS层与应用层结合在一起后，next upstream的工作流程示意图：<br><img src="/images/nginx/next_upstream%E7%A4%BA%E6%84%8F%E5%9B%BE.png"></p>
<p>我们先以HTTP/1协议为例介绍应用层错误的处理方式，再通过它来对比其他应用层协议。对于符合REST规范的HTTP消息，响应码应当能够准确地描述应用层错误，比如，2xx错误码通常表示成功，4xx错误码表示请求参数有问题，而5xx错误码表示服务器出现故障。基于RFC中对各错误码的定义，Nginx允许对以下7种可以进行重试的错误码启用next upstream功能：</p>
<table>
<thead>
<tr>
<th>响应码</th>
<th>字符串描述</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>403</td>
<td>Forbidden</td>
<td>服务器理解请求的含义，但没有权限执行此请求</td>
</tr>
<tr>
<td>404</td>
<td>Not Found</td>
<td>服务器没有找到对应的资源</td>
</tr>
<tr>
<td>429</td>
<td>Too Many Requests</td>
<td>客户端发送请求的速率过快（Nginx版本 &gt;= 1.11.13时提供）。</td>
</tr>
<tr>
<td>500</td>
<td>Internal Server Error</td>
<td>服务器内部错误，且不属于其他5xx错误类型</td>
</tr>
<tr>
<td>502</td>
<td>Bad Gateway</td>
<td>代理服务器无法获取到合法响应</td>
</tr>
<tr>
<td>503</td>
<td>Server Unavailable</td>
<td>服务器资源尚未准备好处理当前请求</td>
</tr>
<tr>
<td>504</td>
<td>Gateway Timeout</td>
<td>代理服务器无法及时的从上游获得响应</td>
</tr>
</tbody></table>
<p>当然， Nginx默认会将以上错误响应码及包体转发给客户端。有些时候，你可能只是想转换这些错误码，以另一种方式向用户体现业务的处理结果，而不是换一个上游Server重新转发请求。比如，当上游返回404错误时，改为通过200返回一张找不到资源的图片。此时，可以通过proxy_intercept_errors指令完成这一功能：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_intercept_errors on | off;</span><br><span class="line">Default:	proxy_intercept_errors off;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>当proxy_intercept_errors开启后，对于上游返回的大于等于300响应码的请求，都可以基于error_page指令继续处理：<br>Syntax:    error_page code … [=[response] uri;<br>Default:    -<br>Context:    http, server, location, if in location</p>
<p>比如，对于上游返回的404错误码，以200的方式返回一个本地文件404_not_found.html，就可以做如下配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">location</span> /ih &#123;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://ihBackend;</span><br><span class="line">        <span class="attribute">proxy_intercept_errors</span> <span class="literal">on</span>;</span><br><span class="line">        <span class="attribute">error_page</span> <span class="number">404</span> = /<span class="number">404</span>.html;</span><br><span class="line">&#125;</span><br><span class="line"><span class="attribute">location</span> = /<span class="number">404</span>.html &#123;</span><br><span class="line">        <span class="attribute">alias</span> html/404_not_found.html;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你希望对这7个错误码启用next upstream机制，可以在proxy_next_upstream指令的选项中添加相应的错误码，比如http_500就表示上游Server返回的500错误码：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:	proxy_next_upstream error | timeout | invalid_header | </span><br><span class="line"><span class="attribute">http_500</span> | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | </span><br><span class="line">non_idempotent | <span class="literal">off</span> ...;</span><br><span class="line">Default:	proxy_next_upstream error timeout;</span><br><span class="line">Context:	http, server, location</span><br></pre></td></tr></table></figure>

<p>由于HTTP协议分为头部和包体两部分，对于头部有特定的格式要求，如果上游返回的HTTP头部不符合规范（在error.log日志中可以看到“upstream sent invalid header”字样的log），你可以通过invalid_header选项开启next upstream功能。另外，服务器需要在内存中缓存完整的HTTP头部，才能决定包体的处理方式，如果上游返回的HTTP头部体积超过了proxy_buffer_size指令设置的值（在error.log日志中可以看到“upstream sent too big header”字样的log），也会遵照invalid_header选项的处理方式。</p>
<p>对于HTTP请求方法而言，如果严格遵照REST架构，那么如GET/HEAD这样获取资源的方法是具备幂等性idempotent（参见<a href="https://tools.ietf.org/html/rfc7231">RFC7231</a>）的，即无论执行多少次，都会获得相同的结果。PUT方法会整体覆盖资源，DELETE是删除资源，这两个方法也具有幂等性。对于在语义上具备幂等性的请求，Nginx默认会启动next upstream功能。</p>
<p>然而，POST方法通过FORM表单修改资源属性，PATCH方法以补丁方式修改资源的部分内容，LOCK方法基于WebDAV规范对资源加锁，这3个方法都不具备幂等性，所以Nginx默认并不会对这3个方法启用next upstream机制。你可以通过proxy_next_upstream中的non_idempotent选项对非幂等方法启用该功能。</p>
<p>官方提供的七层反向代理除了HTTP/1协议外，还有fastcgi、scgi、uwsgi、memcached、grpc这5个模块，它们都使用了TCP协议，且可以与HTTP协议互相转换，因此它们的next upstream与上述HTTP协议的指令极为相似。唯一的差别在于_next_upstream指令后的选项，我把它们的差别列在下表中：</p>
<table>
<thead>
<tr>
<th>_next_upstream</th>
<th>http</th>
<th>fastcgi</th>
<th>scgi</th>
<th>uwsgi</th>
<th>memcached</th>
<th>grpc</th>
</tr>
</thead>
<tbody><tr>
<td>error</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
</tr>
<tr>
<td>timeout</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
</tr>
<tr>
<td>invalid_header</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;/invalid_response</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_500</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_502</td>
<td>&radic;</td>
<td>x</td>
<td>x</td>
<td>x</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_503</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_504</td>
<td>&radic;</td>
<td>x</td>
<td>x</td>
<td>x</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_403</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_404</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;/not_found</td>
<td>&radic;</td>
</tr>
<tr>
<td>http_429</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>x</td>
<td>&radic;</td>
</tr>
<tr>
<td>non_idempotent</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>&radic;</td>
<td>x</td>
<td>&radic;</td>
</tr>
</tbody></table>
<p>这里&radic;表示纵轴对应的协议具有proxy_next_upstream选项中的功能，而x则因为协议做过转换后，不再提供这一选项。其中，memcached由于不存在HTTP头部，所以通过invalid_response选项表示invalide_header错误，并以not_found表示了与HTTP_404同样的含义。而fastcgi、scgi、uwsgi通常是与本机进程通讯，所以没有502、504这两种与网络密切相关的错误码。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>最后对本文内容做个总结。</p>
<p>当Nginx检测到系统调用返回的传输层错误、openssl返回的表示层错误或者协议解码返回的应用层错误时，在逻辑上允许重试的前提下，可以通过next upstream机制更换上游Server，在客户端无感知的情况下完成请求的转发，大大提升了系统可用性。</p>
<p>HTTP/1、gRPC、scgi、fastcgi、uwsgi、memcached等所有Nginx代理模块，都支持next upstream机制，但由于它们基于不同的通讯协议，所以在语法、语义上有不同的表现，这些会反映在_next_upstream指令的选项上。当你熟悉了1种协议的next upstream工作原理，可以触类旁通地理解其他协议。</p>
<p>下一篇，我们将讨论如何在应用层实时控制Nginx代理的行为。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>ssl</tag>
        <tag>upstream</tag>
        <tag>next_upstream</tag>
        <tag>tls</tag>
        <tag>三次握手</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx核心知识100讲课件</title>
    <url>/2018/12/27/nginx/nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2%E8%AF%BE%E4%BB%B6/</url>
    <content><![CDATA[<p>当前编译参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;configure --with-http_auth_request_module --with-http_realip_module --with-http_v2_module --with-debug --add-module&#x3D;&#x2F;home&#x2F;web&#x2F;nginx-http-concat&#x2F; --with-http_random_index_module --with-http_sub_module --with-http_addition_module --with-http_secure_link_module --with-http_geoip_module --with-http_ssl_module --with-stream_ssl_module --with-stream_realip_module --with-stream_ssl_preread_module --with-stream --add-module&#x3D;&#x2F;home&#x2F;web&#x2F;ngx_cache_purge&#x2F; --with-http_slice_module --with-google_perftools_module --with-threads --with-ld-opt&#x3D;-ltcmalloc --with-http_gzip_static_module --with-http_gunzip_module --with-http_stub_status_module</span><br></pre></td></tr></table></figure>

<p>课件下载地址： </p>
<ul>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第一部分课件</a> </li>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第二部分课件</a> </li>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第三部分课件</a> </li>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第四部分课件</a> </li>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第五部分课件</a> </li>
<li><a href="/pdf/Nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2-%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E8%AF%BE%E4%BB%B6.pdf">Nginx核心知识100讲-第六部分课件</a> </li>
</ul>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>CSDI2018广州关于《Nginx》的分享（附文字速录与PPT）</title>
    <url>/2018/07/09/nginx/csdi2018%E5%B9%BF%E5%B7%9E%E5%85%B3%E4%BA%8E%E3%80%8Anginx%E3%80%8B%E7%9A%84%E5%88%86%E4%BA%AB%EF%BC%88%E9%99%84ppt%EF%BC%89/</url>
    <content><![CDATA[<p>应百林哲笑含的邀请，于2018.6.9号至7.1号前往广州白云国际会议中心参加《CSDI Summit 中国软件研发管理行业技术峰会》。会上认识了很多互联网一线老师是最大的收获： <img src="/2018/07/unnamed-file-7.jpg"> 本次我分享的主题是《兼顾灵活与性能的nginx》：</p>
<span id="more"></span>
<p> <img src="/2018/07/1-%E6%BC%94%E8%AE%B2%E7%85%A7-2.jpg"> </p>
<p>意外的惊喜是CSDI的讲师证书非常精美： <img src="/2018/07/CSDI%E8%AF%81%E4%B9%A6-2.jpg"><br>最后附上本次演讲的PPT内容： <a href="/2018/07/nginx-6.pptx">兼顾灵活与性能的nginx</a> 以下为文字速录内容： </p>
<p>大家好，我是杭州市智链达数据有限公司的联合创始人和CTO，为什么又要介绍一下？因为我们公司是一个互联网服务企业，但是我们面向的客户是建筑企业，所以在座的各位都不是我的潜在客户，所以接下来不会有任何介绍关于我们产品的推广和介绍：-）。从我的这个分享的标题中可以看到，这里其实有两个关键词，一个是性能，一个是灵活，我们接下来讨论这两点中nginx是怎么做到的。当前nginx已经是所有的互联网企业的一个标配底层组件，所以能分享这样一个大众化的广为使用的工具，我个人感到很荣幸。不管是小流量还是大流量场景使用了nginx后都可以有一个立竿见影的效果。 </p>
<p>那么本来的话nginx介绍这部分可以没有，但是我相信在座的各位应该在生产环境中时实际操作过nginx的同学应该不是很多吧？能不能请在生产环境中直接使用过nginx，或者你带的团队负责nginx的同学，能不能举一下手？我看一下还是有一半以上的同学没有操作过nginx的，所以我会用五分钟的时间先做个简单的介绍。 </p>
<p>首先我们肯定是先看它的使用场景，那么场景的话呢先从这个最右边的这个静态资源来看，我们现在不管是开发一个web页面或者是开发一个APP webview，都会去拉取大量的CSS、JS、小图片等资源，这些资源的空间占用量其实很大，也很难放在内存中，所以只能放在磁盘上。nginx非常擅长把磁盘中的内容以http协议的方式返回给客户端，所以这是nginx第一个场景。第二个场景中，如果我们的应用服务是用python写的，可能也就几百QPS，JAVA写的服务可能有上千QPS，如果是GOLANG写的可能有上万QPS，但是nginx拥有上百万QPS的系统能力，所以如果我们需要尽量提高我们的这个系统容量，那么需要把很多的应用服务组成一个集群来对用户提供服务，在早期的时候，我们可能会用DNS等手段做负载均衡，而现在呢都是采用nginx做反向代理，因为它卓越的单机性能很适合该场景。那么在反向代理使用场景中就会有另外一个问题，负载均衡，我们经常会需要扩容，宕机容灾时这个负载均衡可以发挥很好的作用。那么有了反向代理后又会引出另外一个问题就是缓存。 </p>
<p>因为其实在互联网行业中，只要我们想提升用户的体验，基本上都是在缓存上下功夫，而缓存基本上你是放在离用户越近的地方效果越好。比如说你放在手机APP的存储上，或者放在浏览器的storage里，这样的用户体验最好！或者说再差一点到网络中了，那么放在cdn效果也是很好，但如果请求到了我们企业内网中，这个时候，往往离用户最近效果最好，比如说像mysql数据库它虽然专注于只做一件事，以致于他的这个缓存做的是非常厉害，但是他的能力再强也没有用，因为数据库前面会有一个业务应用服务，应用服务强调的是快速迭代，它强调的是对程序员友好以提升开发效率，所以呢你想它性能好是不可能的。所以这个时候呢我们在这个nginx上做缓存，因为反向代理协议就很简单，做缓存也很方便，我们最后也可以拿到好的结果。 </p>
<p>第三个场景呢就是中间这个广场。有一些高频的接口调用，比如说像用户鉴权，还有像前天有一位阿里巴巴国际部的老师说他们的流量导流等应用，这些东西都需要这个nginx要发挥自己的特长，然后不要跟慢吞吞的应用服务扯上关系。就像我刚刚说的，其实数据库例如mysql他的能力是很强的，那么如果这些业务可以直接在nginx上实现，那么其实我们就可以提供一个API。那么API服务实现上有几个难点，第一个呢以前的nginx往往是通过每个第三方模块自行定义它自己独特的配置格式，以此实现复杂的业务功能，但这种模式是会有很多问题，因为你是独特的不是通用的，而且且学习成本很高，扩展性也不好。所以呢以通用编程语言实现是一个好思路，官方还搞了一个javascript版本，而openresty搞了一个lua版本，那么因为引入了编程语言，那么你可以很方便的调用工具SDK，所以做API服务就有了可行性，这是最主要的应用场景。</p>
<p>OK那么再看一下nginx的进程架构，我相信在坐的各位都知道nginx的master/worker进程模型。但是我不知道大家有没有想到为什么是一个多进程的架构？可以横向对比一下，比如说nodejs，比如说redis，他们都有一个明显的问题：就是没有办法使用多核。那么nginx呢，因为他在定义核心目标时，他想做的事就是在我们企业内网最外层，获取这台服务器的极限能力以实现上述功能，所以nginx希望能够有效的耗尽cpu、内存等资源。那么master进程它其实非常轻量级，他只是去监控，只是去管理，虽然master也提供了钩子方法供第三方模块介入，但其实像很多第三方模块并不会在master里面做文章，因为只要你有业务在master里就引入了不确定性，master是不能挂，挂了以后你没有办法管理实际工作的worker进程。如果我们做缓存的时候，其实又多了两个进程cache manager和cache loader，这两个进程也是不处理实际请求的。</p>
<p><img src="/2018/07/nginx%E8%BF%9B%E7%A8%8B%E6%9E%B6%E6%9E%84-1.png"></p>
<p>再看一下编译方式。nginx通常是采用把官方的源代码和这个第三方模块的源码放在一起编译出一个二进制可执行文件，那怎么编译？官方他会提供一个叫bash脚本叫configure，而Tengine或者openresty也会提供自己的configure脚本，它负责把这些源代码以有序的方式整合在一起（下面会说到）。那么编译出来这个二进制文件之后呢我们就可以运行了。近期的版本nginx向大家提供了动态模块的功能，就像windows操作系统中的dll，或者linux操作系统中的so，它们又提供了一层封装，降低了耦合度。就像图中所示，这时候就会把这个动态库打开，把其代码加载至nginx的进程地址空间中，那么有了这个动态模块好处在哪里？如果说我只修改了一个模块，并未对其他模块发生变动，那么就不用重新编译出新的可执行文件了，我只要去换一下这个动态库就可以。</p>
<p><img src="/2018/07/nginx%E5%8A%A8%E6%80%81%E6%A8%A1%E5%9D%97-1.png"></p>
<p>灰度发布可能大家都比较清楚，这是nginx的基本功能了，我们简单过一下。比如说上面这张图，master进程上拉起了四个绿色的worker进程，这四个worker进程用的是老配置文件里的配置，然后呢我们修改了nginx.conf配置文件，调用了-s reload命令后，master进程会起四个黄色的worker进程，这四个黄色的worker进程使用了新的配置文件里的内容。如果我们自己去写一个应用程序实现配置修改时，不知道大家会怎么写？那我可能会想，把应用进程kill掉，再重新拉起读取配置不就完了吗？那是nginx不能这么做，因为它上面真的跑了几十万个tcp连接，所以如果他被kill掉，实际上几十万的客户端都会收到RST复位包，体验是非常差的。所以nginx要采用这么一个复杂的形式，就是绿色的worker进程还在处理老的连接与请求，而黄色的worker进程就只处理新建立的连接与请求，等到绿色的老worker进程处理完老连接上的请求后，我们再停掉worker进程就没有问题了。但是说起来很简单，其实还是有许多问题要处理，比如说如果是HTTP这样的请求那还比较好，即使是keepalive连接也OK，但如果是websocket协议或者其他TCP协议怎么办？nginx不解析协议内容，不知道什么时候可以准确的判断处理完一个请求，这样粗暴的方式就可能直接断用户连接。worker_shutdown_timeout这个配置就是做这个事的。</p>
<p><img src="/2018/07/nginx%E4%BC%98%E9%9B%85%E7%9A%84%E6%94%B9%E9%85%8D%E7%BD%AE-1.png"></p>
<p>那我们现在进入第二部分谈谈nginx的模块化。模块化决定了nginx的能力，比如说TCP这个协议，它是上世纪70年代就发明了，我们中间可能有各种各样的改进，比如说拥塞控制等等，但是到了现在还是非常好用。其实nginx也一样，我们掌握了它的模块化思想，就理解了它的底层能力。nginx的模块我不知道如果让你去设计，你会怎么思考？看下这个图，首先它会有核心模块core，这下面的四个模块是框架与工具模块，比如说这个errlog是记录错误日志的。这上面这四个核心模块，每一个都定义了一类新模块。这个就比较关键，那么像这个mail等模块并不重要，我们重点还是看http模块。所有的http模块他们其实就构成了一张数组列表，这个列表里面的第一个元素也是第一个http模块都有个关键字_core_，包括mail、stream模块都是一样的。那么每类模块列表里的第一个core模块存在的意义在哪里呢？它们负责处理本类模块里的共性规则。第一个共性的东西就是协议，比如http协议，一定先是一个请求，请求中先收到url及版本号等，再收到header包头，那发送响应的时候也是先发送line再发送header再发送body。那么我就可以把这个逻辑抽象出来。接下来我们会重点看逻辑是如何抽象出来的。然后呢可能还有一些公共的工具，也可以由第一个core模块来做。</p>
<p><img src="/2018/07/nginx%E5%A4%84%E7%90%86http%E8%AF%B7%E6%B1%82%E7%9A%84%E6%B5%81%E7%A8%8B-1.png"></p>
<p>那么http response的响应过滤也有许多共性的抽像，因为我们返回http协议内容的时候可以做很多事情，比如说做压缩、生成缩略图，这个时候呢其实就是在body和header上做文章，所以nginx又引申出来一个概念叫响应过滤模块。我们现在看这张图，先看左边这边传播非常广泛的官网图片，从这上面到达一个internet request，首先读完它的header头部，读完以后呢，这时候判断我的安全模块是否应生效，包括用location正则表达式匹配url决定用哪些配置，我可能会做一些限速。生成response响应内容就是generate content，可能我读本地的磁盘文件实现，也可能我跟上游的一个服务交互获取其内容等等，这个事情做完以后，我拿到了http response，此时开始对header和body进行过滤模块的处理，做完以后呢记录access日志，这个日志用来做监控运维，最后把response返回给用户。</p>
<p>再来看HTTP模块抽象出的11个阶段。比如说现在有一个realip模块，如果需要你去实现这个模块去获取用户的真实IP，我不知道你会把该模块放在哪个阶段？因为实际TCP连接它实际上是个四元组，当nginx与用户中间有反向代理的话，其实你从连接的source ip获取到的地址不是用户的，怎么办呢？除了复杂的proxy protocol等方案外，应用层的HTTP协议很有办法，它可以通过把用户的原始ip在request http header中带来。所以如果我们去实现这样的一个http模块，可以搞一个nginx变量去存取header头部的ip值，这个http模块到底放在11个阶段的哪个阶段就是个问题，因为前面的这些模块都有可能去改http header的，只要其他http模块有能力去改，realip模块获取到的ip可能就有问题。所以，在post_read模块，顾名思义，就是刚读取完http request header，此时去处理最合适。再到下面是rewrite相关的三个阶段，一个叫find config在其中。rewrite模块是官方模块处理的。</p>
<p>接下来看访问控制相关的3个阶段。比如说输入用户名和密码自然在access阶段，但是如果说你要做流控，你肯定要在他之前，否则的话这个流控可能就失效了，请求流量有机会打到access阶段这里。因此流控必须在pre_access阶段。OK现在看一下这个http模块的工作流程，我做了一个动画，怎么看呢？先从左边看这个绿框，这个绿框表示master进程在启动，它首先读取nginx.conf配置文件，这里会依次从上至下读取这个ascii文件，当它发现events {}配置时，自动将大括号里的内容交给event事件模块解析，而发现http{}时就交给http模块处理，stream{}里的内容自然交给stream模块处理。对于http模块而言，有些http模块会根据配置项决定是否将其钩子函数添加至处理流程中。http core模块会负责将所有的location建立为一颗树以加快访问速度，最后还要将listen后跟着的端口加入容器中，接着读完配置文件就开始listen打开监听端口，再fork出子进程。子进程worker会继承父进程已经打开的句柄，自然也包含端口。master进程接下来就只监控worker子进程，以及等待接收信号命令好了。而worker进程则只处理事件以及接收master发来的信号命令。当worker进程收到SYN包，开始建立连接，请求处理流程就开始了。首先用HTTP状态机确保接收到完整的HTTP的header头部，再依次调用刚刚介绍过的11个阶段的HTTP模块去处理请求，在content阶段处理完后生成了http resposne，再调用各http filter模块加工response，最后发送出去。</p>
<p>再看看怎么找到location下的配置去处理请求的。tcp连接是四元组，所以可以根据lister时的ip address去获取连接，寻找由哪些server{}去建立连接，就像图中的最左边，其配置如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">listen localhost:80; listen 8000;</span><br><span class="line"> server_name zlddata.com zlddata.cn;</span><br><span class="line">location &#x2F;static &#123; ... &#125;    location &#x2F; &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line">Server &#123;</span><br><span class="line"> listen      80;</span><br><span class="line">        server_name fuzhong.pub;      ….</span><br></pre></td></tr></table></figure>

<p>接着，我们接收完http request header后，可以从HOST头部获取到域名，而这可以匹配server_name配置后的虚拟主机域名列表，这样就唯一确定了一个server{}配置块。从URL中还可以再次匹配location后的正则表达式，这样我们就找到了具体的location配置。</p>
<p>再看这张图，我们谈谈11个阶段间http模块间的配合。这里仅以官方模块举例。当一个请求读完http header后，我们先进入preaccess阶段，这一阶段里有两个模块：limit_conn和limit_req模块。前前限连接，后者限请求。可见，前后顺序乱不得，否则就导致limit_conn无法正常生效了。当limit_conn模块决定请求不受限制后，它会返回NGX_OK给钩子函数，这样进入当前preaccess阶段的下一个模块limit_req模块继续处理。而limit_req模块也认为不受限制，可以继续处理，因为当前preaccess阶段没有其他模块了，故进入下一阶段access阶段继续处理。而在access阶段中，若第一个模块auth_basic认为无须进入下一个access模块处理，那么它可以返回NGX_AGAIN给钩子函数的调用者，这样access阶段其后的模块是得不到执行的。可见http模块还是很灵活的。当content阶段生成内容后，首先由header filter模块处理。为什么呢？因为http是流式协议，先返回header，再返回body。比如我需要做压缩，那么就需要先在header中添加content-encoding头部，再压缩body。这里需要注意的是，这些模块间也有顺序要求！比如现有一张图片，你只能先做缩略做再压缩，如果反过来，压缩后是没办法做缩略图的。所以这个顺序也是由configure这个脚本决定的，大家可以看源码时看到里面的注释明确的写着不能改order顺序。 <img src="/2018/07/openresty%E6%8C%87%E4%BB%A4%E9%98%B6%E6%AE%B5-1.png"> </p>
<p>这张图是openresty官方的图。用好openresty的关键是，搞清楚指令与sdk。其中sdk比较简单，就是形如ngx.xxx这样的函数，可以在lua代码中调用。它实际上就是lua与C语言的交互，通过先在nginx模块中提供相应的函数，再封装给lua作为lua函数即可，目前主要在用ffi方式，最新的openresty都在用ffi方式重构。而指令就是nginx配置，它会决定其中｛｝大括号内的代码在什么时候执行。这张图中，有初始nginx启动阶段、有rewrite/access阶段、有content阶段以及log阶段。这与我们之前的所说的11个阶段有什么关系呢？ 我们来看这张图，有点复杂，最上面的绿框是nginx启动过程，其中黑色的框是master进程，而紫色的框是worker进程，中间的红点是钩子函数。中间的紫色框是worker进程在处理请求。最下面的绿色框是nginx在退出。可以看到，当nginx启动在，通过在配置文件中各第三方模块可以介入，在init_module回调函数实现东西也可以介入nginx的启动。当派生出worker子进程后，仍然可以通过回调init_master、init_process等回调方法介入启动过程。而实际处理请求时，先可以通过8个http阶段介入与请求的处理，在content阶段还可以使用排他性的r-&gt;content_handler（用于反向代理）来生成响应内容。在生成响应内容时，还可以通过init_upstream钩子函数决定选择哪一台上游服务器。生成响应内容后，通过filter过滤模块也可以介入请求的处理，最后在access log阶段也可以介入请求的处理。在nginx退出时仍然可以介入处理。 而openresty的指令就是像图中这么介入处理的。例如，rewrite_by_lua实际是在post_read阶段介入处理的，因为就像上面说过的，rewrite阶段都是官方模块在处理，所以openresty实际是在postread阶段，所以这个指令是相当靠前的。而balance_by_lua实际是在init_upstream钩子里介入的。 </p>
<p>最后我们看一下nginx变量。有一类模块会生成新的nginx变量，它们通过处理http请求时定义的取值方法，生成了变量名对应的变量值，并以$符号或者lua中的ngx.var等方式提供给使用变量的模块。这些模块既包含C模块，也包括lua模块。C模块更关注高效，往往提供变量的模块都是C模块，而lua模块关注业务。所以，这两类语言最好的解耦方法就是使用变量。 最后我们看看第三部分nginx性能的优化。我们希望nginx可以把一台服务器的性能压榨到极致，主要从5个方面入手。首先是不能有长时占有CPU的代码段。因为nginx是事件驱动的、非阻塞的、异步架构代码，就像图中所示，nginx把本来操作系统应该做的事：切换不同的请求处理，改为在nginx进程内部处理了。怎么讲呢？传统的进程是同一时间只处理一个请求，所有处理请求的方法都是阻塞的，所以在处理完一个请求前不会处理下一个请求。因此，当大量并发请求存在时，意味着大量运行中的进程或者线程。操作系统希望最大化吞吐量，它就会切换不同的进程到CPU上执行，当一个进程因为阻塞请求导致的系统调用不满足时，例如读取磁盘转头磁头，就会被切换到内存中等待下次执行。而nginx采用的事件驱动，则是把这一过程放在nginx的用户态代码内了，首先用非阻塞系统调用检测到条件不满足，如果执行会导致操作系统执行进程间切换时，就会把该请求切到内存中等待下次执行，而nginx会选择条件满足的请求继续执行。因此，如果处理一个请求时消耗了大量的CPU时间，就会导致其他请求长时间得不到处理，以至于大量超时，形成恶性循环。所以，遇到某些第三方模块会大量消耗CPU时务必谨慎使用，真有这样的场景也不应当在nginx中做，可以用nginx反向代理到多线程应用中处理。因为操作系统会为每个进程分配5ms-800ms的时间片，它也会区分IO型或者CPU型进程，而上述进程是明显的CPU型进程，上下文切换不会很频繁。 第二个优化点就是减少上下文切换。在这页PPT中我们提到一个工具叫pidstat，它可以清晰的看到主动切换与被动切换。何谓主动切换呢？就是执行了某些阻塞式系统调用，当条件不满足时内核就会把进程切换出去，叫做cswch/s。而操作系统微观上串行宏观上并行实现的多任务，是使用抢占式内核实现的，它为每个进程分配时间片，时间片耗尽必须切出，这就叫nvswch/s。我们通过增加进程的静态优先级来增大时间片的大小。静态优先级分为40级，默认进程是0级，最大是-19，我们可以在nginx.conf里修改静态优先级。另外，还可以通过把worker进程绑定CPU，减少在多核服务器上的进程间切换代价。对于主动切换，则需要减少使用类似nginx模块的场景。有时这很难避免，例如读取静态文件，当频繁读取的内容打破内存缓存时，使用nio或者sendfile也没有用，仍然退化为阻塞式调用，此时用threadpool线程池就很有意义了，官方有个博客上提到此种场景下线程池有9倍的性能提升。当然，目前线程池只能用于读取静态资源。 第三个优化是减少内存的使用。很多并发的连接是不活跃的，但它们还是会在内核态、用户态占有大量的内存，而总内存其实很有限，所以我们的内存大小及各种内存相关配置影响了我们的并发量。先从连接谈起，在Nginx进程内为每个连接会分配一个ngx_connection_t结构体，每个ngx_connection_t各分配一个ngx_event_t结构体用作读、写事件，在64位操作系统下以上结构体每个连接（无论是TCP还是UDP）消耗的内存是232+96*2字节。在操作系统内核中，为了处理复杂的TCP协议，必须分配读、写缓冲用于进程的读写、滑动窗口、拥塞窗口等相关的协议收发，而linux为了高效使用内存，设立了普通模式和压力模式，即内存宽裕情况下为每个连接多分配一些缓存以提高吞吐量，在压力模式下则每个连接少分配一些缓存以提高并发连接数，这是通过tcp_moderate_rcvbuf开关控制的，而调整幅度可通过tcp_adv_win_scale控制，调整区间在读写缓存上设置。Nginx中含有大量内存池，形如*_pool_size都是在控制初始内存分配，即必须分配出去的内存。还有一类分配如8 4K这样的多块不连续内存，比如对于large header或者gzip buffer等，它们使用ngx_buffers_t结构体存储。共享内存是用于跨worker进程通讯的，而openresty里的share_dict就是通过共享内存实现的，当然使用共享内存通常要用slab伙伴系统管理内存块，再用rbtree红黑树或者链表等数据结构管理实际的逻辑。Nginx中还会用到大量的hash表，比如存储server_names等，这里会定义桶大小和桶个数。 第四个是优化网络。我们先从TCP层面看，无非是读、写消息、建立与关闭连接等功能。如果是读消息，我们需要关注tcp_rmem设置缓存区的大小，需要关注初始拥塞窗口rwnd的大小以提升网络可以快速达到最优值。在nginx上还有许多控制读取到固定消息的超时时间，在读取上游服务发来的响应时还可以通过limit_rate限流。在发送消息时，同样可以设置tcp_wmem设置缓存区大小，通过iptables命令对cwnd来提升初始窗口，nodelay和nopush都是为了提升吞吐量的算法，当然它们的副产品就是牺牲了及时性增大了latency。总体来说对于大流量场景应该打开它们。当然nopush只对sendfile有效。当发送响应给客户端时，也可以通过limit_rate进行流控。作为服务器建立连接时，Tcp Fast Open技术可以在SYN包里就携带请求，这减少了一次RTT，但有可能带来反复收到相同包的情况，一般不打开；使用Defered可以减少nginx对某连接的唤醒次数，提升CPU使用效率；reuseport可以提高负载均衡效果，使多worker进程更好的协同工作；backlog可以增大半连接与全连接队列，特别是新连接很多而Nginx worker非常繁忙时。关闭连接最复杂，特别是nginx主动关连接时，fin_wait_1状态下linger可以控制关连接的时机以减少RST包的发送；tcp_orphan_retries控制发送次数。fin_wait_2状态下可通过tcp_fin_timeout控制超时时间。在time_wait状态下通常会打开tcp_tw_reuse提升端口的利用率，但tcp_tw_recycle会使得time_wait状态近乎消失，这会带来端口复用时被丢包补发的FIN包关闭连接。 最后是减少IO调用。这只对读取本地的静态资源有效，例如打开sendfile采用了零拷贝技术就减少了内存拷贝次数以及进程间上下文切换次数。 </p>
<p>最后对今天的演讲做个总结。我前阵子听梁宁的30堂产品课，上面说到看待产品或者人都是从5个层面，我觉得很适用于nginx。首先从表面层。例如相亲时先对异性的长相、谈吐、衣着，而看nginx则是看它的配置文件格式、access.log日志格式、进程启动方式等。第二层是角色层，例如与一个同事沟通，那么他是HR或者是前端工程师，都会影响他的谈吐以及沟通方式。而nginx的角色层就是最开始提到的静态资源服务、反向代理、API服务器，这影响它的表现层。第三层是资源层，对人则是人脉资源、精神资源、知识结构等，而对nginx则是它的大量的第三方模块、社区等。第四则是能力圈，对人就是一个人的能力大小，对nginx就是上文提到的nginx的核心架构、模块化、设计思路、算法、容器等。第五层是最内核的存在感，对人则是什么状态能让人满足，对nginx则是它的设计意义，就是我们前面提到的把一台服务器的硬件能力使用到极限以提供强大的web服务能力。这里底层总是在影响着上层，所以当我们掌握了nginx的底层，无论上层怎么变都很容易理解。</p>
<p>OK最后我在这里做个广告，智链达是一家杭州的创业公司，是希望助力一个行业实现转型升级的互联网服务公司，目前各种岗位都在招聘，我们其实面向的是一个蓝海行业，希望各位有兴趣的同学考虑加入。行，那我今天的介绍到这。</p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>CSDI</tag>
        <tag>性能</tag>
        <tag>模块化</tag>
      </tags>
  </entry>
  <entry>
    <title>《Nginx核心知识100讲》--我在极客时间的视频课</title>
    <url>/2018/11/06/nginx/%E3%80%8Anginx%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B100%E8%AE%B2%E3%80%8B-%E6%88%91%E5%9C%A8%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E7%9A%84%E8%A7%86%E9%A2%91%E8%AF%BE/</url>
    <content><![CDATA[<p>Nginx 很火，火到无论是创业公司，还是 BAT 等一线互联网公司，都会使用 Nginx。因为它就像一个万能药，在任何存在性能需求的场合总能找见它的身影。<strong>它可以轻松在百万并发连接下实现高吞吐量的 Web 服务，同时诸多应用场景下的问题都可以通过种种 Nginx 模块得以解决，而我们所需的工作量也并不大</strong>。 实战出真知。 2010 年初，我在思科第一次使用了 Nginx。那时我们的文档上传下载服务需要做重构，于是我在调研了 Lighthttpd、Nginx 等开源组件后，决定选择 Nginx 重构服务。因为我在阅读完 Nginx 的源码后，被其设计哲学、类 Linux 内核的代码风格所吸引，且模块设计极其稳定，6 年的快速发展也几乎未有何变化。 </p>
<span id="more"></span>
<p><strong>Nginx 天生就适合在 Linux 服务器上处理百万、千万级的并发连接，而优秀的架构使得它未来不需要重构，所以它的生态圈内的第三方模块长期有效</strong>。而长年的发展下日益增多的第三方模块进一步赋能 Nginx，使 Nginx 适用于更多的场景，甚至渗透到 LVS 的领域与 F5 这样的硬件产品竞争！同时，如 OpenResty 或者 Tengine 这样的第三方模块群，进一步发展出了新生态，使 Nginx 的应用进一步向应用防火墙、CDN 等领域扩展。 下图，是 Nginx 的三个主要应用场景。 <img src="/2018/11/unnamed-file-6.jpg"> 我也经常提醒身边的朋友，学好 Nginx，可以让你在工作中获得立竿见影的效果。</p>
<ul>
<li>  如果你是一个前端工程师，在用 Node.js 写 Web 程序，使用 Nginx 可以让你高效处理静态资源文件；</li>
<li>  如果你是一个运维工程师，那么在你有效配置 Nginx 后，可以为公司节省大量的 IT 成本；</li>
<li>  如果你是一个后端开发工程师，遇到性能瓶颈时，你完全可以使用 Nginx 的第三方模块或 OpenResty 的 Lua 模块，非常高效地解决你的性能瓶颈。</li>
</ul>
<p>可在我与 Nginx 打交道的近 10 年里，遇到不少会用却不善用 Nginx 的开发者，就好比你有一把好剑，可你却拿它来砍柴，这是一件很可惜的事情。打个比方，高并发导致多个请求过来，有些开发者会用最繁杂的程序来配置转发，却不知其中还有更轻便更有技巧性的设置。这种情况的发生，时常会让自己开发效率极低，且显得笨拙。 我是谁 我是陶辉，杭州智链达数据有限公司担任 CTO 兼联合创始人，著有《深入理解 Nginx：模块开发与架构解析》一书。 我决定制作这门课，是因为我的职业经历允许我从体系化的视角重新解读 Nginx。</p>
<ul>
<li>  我早年在华为网管软件中负责网络中间件，这让我对 Nginx 这样的平台及中间件所应用的开发方法有许多共鸣；</li>
<li>  后来在腾讯，我开始处理亿级用户海量数据，深度挖掘 linux 极限性能的过程与 Nginx 非常相似；</li>
<li>  在思科时，我大量编写了 Nginx 模块，出版了《深入理解 Nginx：模块开发与架构解析》一书；</li>
<li>  在阿里云，我在 ECS 的优化中深入硬件性能的提升，以及对大量服务器构成的集群做架构设计，这使得我可以在更深的视角看待 Nginx；</li>
<li>  在杭州智链达数据有限公司，我更关注在如何有限的团队规模下，使用 Nginx 来保持开发效率，以提供高可用性。</li>
</ul>
<p>但网络上关于 Nginx 的使用介绍非常多，但往往有两个问题：</p>
<ol>
<li> 仅从如何使用层面介绍，没有把离散的知识点串成线，这导致大家难以应对未出现过的、个性化的定制场景；</li>
<li> 没有成体系的性能优化知识介绍，在企业生产环境下我们需要从应用到系统的完整优化方案。</li>
</ol>
<p>因此，我相信在“如何学好 Nginx”这件事上，我可以给你系统的指导，而这十年积累，都浓缩到我在极客时间开设的<strong>《Nginx 核心知识 100 讲》</strong>视频课程中。 <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/11/2-5.jpg" alt="点击图片试看或订阅"></a> 通过这门课，你可以学到什么？ 《Nginx 核心知识 100 讲》视频课程共 100 讲，<strong>我会结合多年 Nginx 研发经验，为你从 HTTP 应用层的视角、分布式集群的视角、硬件及操作系统内核优化的视角为大家解读 Nginx 的核心知识</strong>。 我会将 Nginx 的常用知识点、常用模块，在 Nginx 的设计方法论下从请求的处理流程中为大家解读，帮助大家从 Nginx 的初级使用者成长为高阶使用者。 学完这门课，你将彻底明确 Nginx 的能力模型，了解 Nginx 的工作原理，清楚怎样使用 Nginx 搭建出定制化的 Web 服务器或者微服务集群的负载均衡服务，并理解什么样的 API 服务适合用 Nginx 编写，<strong>同时清楚如何在 linux 操作系统上优化 Nginx，使 Nginx 可以轻松应付百万并发连接</strong>。 简而言之，你将收获到以下四个方面：</p>
<ol>
<li> <strong>基础知识详解及核心架构剖析</strong></li>
<li> <strong>搭建支持百万高并发的 Nginx 服务</strong></li>
<li> <strong>从内核优化到源码解读的全方位拆解</strong></li>
<li> <strong>OpenResty + Nginx 开发实战</strong></li>
</ol>
<p>只要跟着我学，你就可以把关于 Nginx 的零零散散的知识点串成一条线，再将网络、操作系统、磁盘等知识与 Nginx 相关知识组成一个知识网，从而可以在工作中灵活运用这些知识和技能，使用 Nginx 最大化地利用好服务器的性能，搭建出更稳定的服务。</p>
<p>订阅福利</p>
<p>福利一：限时<strong>优惠 ¥68</strong>，原价 ¥129，11 月 17 日恢复原价 福利二：每邀请一位好友购买，你可获得 <strong>24 元现金返现</strong>，多邀多得，上不封顶，随时提现。（提现流程：极客时间 App - 我的 - 分享有赏） <strong>彩蛋</strong>：关注「极客时间」微信公众号，回复关键词【<strong>Nginx</strong>】。即可<strong>免费</strong>获取陶辉《Nginx 核心知识 100 讲》的<strong>全部 PDF 课件</strong>。 点击「<strong>阅读原文</strong>」或下图海报，即可试看或订阅此课程。 <a href="/2018/12/27/nginx%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86100%E8%AE%B2%E8%AF%BE%E4%BB%B6/poster/"><img src="/2018/12/poster.jpg"></a></p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>极客时间</tag>
        <tag>极客邦</tag>
        <tag>百万并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Udp的反向代理：nginx</title>
    <url>/2018/04/08/nginx/udp%E7%9A%84%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%EF%BC%9Anginx/</url>
    <content><![CDATA[<p>在实时性要求较高的特殊场景下，简单的UDP协议仍然是我们的主要手段。UDP协议没有重传机制，还适用于同时向多台主机广播，因此在诸如多人会议、实时竞技游戏、DNS查询等场景里很适用，视频、音频每一帧可以允许丢失但绝对不能重传，网络不好时用户可以容忍黑一下或者声音嘟一下，如果突然把几秒前的视频帧或者声音重播一次就乱套了。使用UDP协议作为信息承载的传输层协议时，就要面临反向代理如何选择的挑战。通常我们有数台企业内网的服务器向客户端提供服务，此时需要在下游用户前有一台反向代理服务器做UDP包的转发、依据各服务器的实时状态做负载均衡，而关于UDP反向代理服务器的使用介绍网上并不多见。本文将讲述udp协议的会话机制原理，以及基于nginx如何配置udp协议的反向代理，包括如何维持住session、透传客户端ip到上游应用服务的3种方案等。</p>
<span id="more"></span>
<h1 id="UDP协议简介"><a href="#UDP协议简介" class="headerlink" title="UDP协议简介"></a>UDP协议简介</h1><p>许多人眼中的udp协议是没有反向代理、负载均衡这个概念的。毕竟，udp只是在IP包上加了个仅仅8个字节的包头，这区区8个字节又如何能把session会话这个特性描述出来呢？  <br><img src="/2018/04/UDP%E6%8A%A5%E6%96%87%E7%9A%84%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82-1.png"><br>图1 UDP报文的协议分层 在TCP/IP或者 OSI网络七层模型中，每层的任务都是如此明确：</p>
<ul>
<li>  物理层专注于提供物理的、机械的、电子的数据传输，但这是有可能出现差错的；</li>
<li>  数据链路层在物理层的基础上通过差错的检测、控制来提升传输质量，并可在局域网内使数据报文跨主机可达。这些功能是通过在报文的前后添加Frame头尾部实现的，如上图所示。每个局域网由于技术特性，都会设置报文的最大长度MTU（Maximum Transmission Unit），用netstat -i(linux)命令可以查看MTU的大小：<img src="/2018/04/MTU%E5%A4%A7%E5%B0%8F-1.png"></li>
<li>  而IP网络层的目标是确保报文可以跨广域网到达目的主机。由于广域网由许多不同的局域网，而每个局域网的MTU不同，当网络设备的IP层发现待发送的数据字节数超过MTU时，将会把数据拆成多个小于MTU的数据块各自组成新的IP报文发送出去，而接收主机则根据IP报头中的Flags和Fragment Offset这两个字段将接收到的无序的多个IP报文，组合成一段有序的初始发送数据。IP报头的格式如下图所示：<img src="/2018/04/IP%E6%8A%A5%E6%96%87%E5%A4%B4%E9%83%A8-1.png"></li>
</ul>
<p>图2 IP报文头部 IP协议头（本文只谈IPv4）里最关键的是Source IP Address发送方的源地址、Destination IP Address目标方的目的地址。这两个地址保证一个报文可以由一台windows主机到达一台linux主机，但并不能决定一个chrome浏览的GET请求可以到达linux上的nginx。 4、传输层主要包括TCP协议和UDP协议。这一层最主要的任务是保证端口可达，因为端口可以归属到某个进程，当chrome的GET请求根据IP层的destination IP到达linux主机时，linux操作系统根据传输层头部的destination port找到了正在listen或者recvfrom的nginx进程。所以传输层无论什么协议其头部都必须有源端口和目的端口。例如下图的UDP头部：<br><img src="/2018/04/UDP%E7%9A%84%E5%A4%B4%E9%83%A8-1.png"><br>图3 UDP的头部<br>TCP的报文头比UDP复杂许多，因为TCP除了实现端口可达外，它还提供了可靠的数据链路，包括流控、有序重组、多路复用等高级功能。由于上文提到的IP层报文拆分与重组是在IP层实现的，而IP层是不可靠的所有数组效率低下，所以TCP层还定义了MSS（Maximum Segment Size）最大报文长度，这个MSS肯定小于链路中所有网络的MTU，因此TCP优先在自己这一层拆成小报文避免的IP层的分包。而UDP协议报文头部太简单了，无法提供这样的功能，所以基于UDP协议开发的程序需要开发人员自行把握不要把过大的数据一次发送。 </p>
<p>对报文有所了解后，我们再来看看UDP协议的应用场景。相比TCP而言UDP报文头不过8个字节，所以UDP协议的最大好处是传输成本低（包括协议栈的处理），也没有TCP的拥塞、滑动窗口等导致数据延迟发送、接收的机制。但UDP报文不能保证一定送达到目的主机的目的端口，它没有重传机制。所以，应用UDP协议的程序一定是可以容忍报文丢失、不接受报文重传的。如果某个程序在UDP之上包装的应用层协议支持了重传、乱序重组、多路复用等特性，那么他肯定是选错传输层协议了，这些功能TCP都有，而且TCP还有更多的功能以保证网络通讯质量。因此，通常实时声音、视频的传输使用UDP协议是非常合适的，我可以容忍正在看的视频少了几帧图像，但不能容忍突然几分钟前的几帧图像突然插进来：-）</p>
<h1 id="UDP协议的会话保持机制"><a href="#UDP协议的会话保持机制" class="headerlink" title="UDP协议的会话保持机制"></a>UDP协议的会话保持机制</h1><p>有了上面的知识储备，我们可以来搞清楚UDP是如何维持会话连接的。对话就是会话，A可以对B说话，而B可以针对这句话的内容再回一句，这句可以到达A。如果能够维持这种机制自然就有会话了。UDP可以吗？当然可以。例如客户端（请求发起者）首先监听一个端口Lc，就像他的耳朵，而服务提供者也在主机上监听一个端口Ls，用于接收客户端的请求。客户端任选一个源端口向服务器的Ls端口发送UDP报文，而服务提供者则通过任选一个源端口向客户端的端口Lc发送响应端口，这样会话是可以建立起来的。但是这种机制有哪些问题呢？ 问题一定要结合场景来看。比如：</p>
<ol>
<li>如果客户端是windows上的chrome浏览器，怎么能让它监听一个端口呢？端口是会冲突的，如果有其他进程占了这个端口，还能不工作了？</li>
<li>如果开了多个chrome窗口，那个第1个窗口发的请求对应的响应被第2个窗口收到怎么办？</li>
<li>如果刚发完一个请求，进程挂了，新启的窗口收到老的响应怎么办？等等。可见这套方案并不适合消费者用户的服务与服务器通讯，所以视频会议等看来是不行。 </li>
</ol>
<p>有其他办法么？有！如果客户端使用的源端口，同样用于接收服务器发送的响应，那么以上的问题就不存在了。像TCP协议就是如此，其connect方的随机源端口将一直用于连接上的数据传送，直到连接关闭。 这个方案对客户端有以下要求：不要使用sendto这样的方法，几乎任何语言对UDP协议都提供有这样的方法封装。应当先用connect方法获取到socket，再调用send方法把请求发出去。这样做的原因是既可以在内核中保存有5元组（源ip、源port、目的ip、目的端口、UDP协议），以使得该源端口仅接收目的ip和端口发来的UDP报文，又可以反复使用send方法时比sendto每次都上传递目的ip和目的port两个参数。 </p>
<p>对服务器端有以下要求：不要使用recvfrom这样的方法，因为该方法无法获取到客户端的发送源ip和源port，这样就无法向客户端发送响应了。应当使用recvmsg方法（有些编程语言例如python2就没有该方法，但python3有）去接收请求，把获取到的对端ip和port保存下来，而发送响应时可以仍然使用sendto方法。   接下来我们谈谈nginx如何做udp协议的反向代理。 </p>
<p>Nginx的stream系列模块核心就是在传输层上做反向代理，虽然TCP协议的应用场景更多，但UDP协议在Nginx的角度看来也与TCP协议大同小异，比如：nginx向upstream转发请求时仍然是通过connect方法得到的fd句柄，接收upstream的响应时也是通过fd调用recv方法获取消息；nginx接收客户端的消息时则是通过上文提到过的recvmsg方法，同时把获取到的客户端源ip和源port保存下来。我们先看下recvmsg方法的定义：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">ssize_t</span> <span class="title">recvmsg</span><span class="params">(<span class="keyword">int</span> sockfd, struct msghdr *msg, <span class="keyword">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure>

<p>相对于recvfrom方法，多了一个msghdr结构体，如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">msghdr</span> &#123;</span>    </span><br><span class="line">    <span class="keyword">void</span>         *msg_name;       <span class="comment">/* optional address */</span>    </span><br><span class="line">    <span class="keyword">socklen_t</span>     msg_namelen;    <span class="comment">/* size of address */</span>    </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">iovec</span> *<span class="title">msg_iov</span>;</span>        <span class="comment">/* scatter/gather array */</span>    </span><br><span class="line">    <span class="keyword">size_t</span>        msg_iovlen;     <span class="comment">/* # elements in msg_iov */</span>    </span><br><span class="line">    <span class="keyword">void</span>         *msg_control;    <span class="comment">/* ancillary data, see below */</span>    </span><br><span class="line">    <span class="keyword">size_t</span>        msg_controllen; <span class="comment">/* ancillary data buffer len */</span>    </span><br><span class="line">    <span class="keyword">int</span>           msg_flags;      <span class="comment">/* flags on received message */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中msg_name就是对端的源IP和源端口（指向sockaddr结构体）。以上是C库的定义，其他高级语言类似方法会更简单，例如python里的同名方法是这么定义的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(data, ancdata, msg_flags, address) &#x3D; socket.recvmsg(bufsize[, ancbufsize[, flags]])</span><br></pre></td></tr></table></figure>

<p>其中返回元组的第4个元素就是对端的ip和port。</p>
<h1 id="配置nginx为UDP反向代理服务"><a href="#配置nginx为UDP反向代理服务" class="headerlink" title="配置nginx为UDP反向代理服务"></a>配置nginx为UDP反向代理服务</h1><p>以上是nginx在udp反向代理上的工作原理。实际配置则很简单：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Load balance UDP-based DNS traffic across two servers</span><br><span class="line">stream &#123;    </span><br><span class="line">    upstream dns_upstreams &#123;        </span><br><span class="line">        server 192.168.136.130:53;        </span><br><span class="line">        server 192.168.136.131:53;    </span><br><span class="line">    &#125;     </span><br><span class="line">    server &#123;        </span><br><span class="line">        listen 53 udp;        </span><br><span class="line">        proxy_pass dns_upstreams;        </span><br><span class="line">        proxy_timeout 1s;        </span><br><span class="line">        proxy_responses 1;        </span><br><span class="line">        error_log logs&#x2F;dns.log;    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在listen配置中的udp选项告诉nginx这是udp反向代理。而proxy_timeout和proxy_responses则是维持住udp会话机制的主要参数。 UDP协议自身并没有会话保持机制，nginx于是定义了一个非常简单的维持机制：客户端每发出一个UDP报文，通常期待接收回一个报文响应，当然也有可能不响应或者需要多个报文响应一个请求，此时proxy_responses可配为其他值。而proxy_timeout则规定了在最长的等待时间内没有响应则断开会话。</p>
<h1 id="如何通过nginx向后端服务传递客户真实IP"><a href="#如何通过nginx向后端服务传递客户真实IP" class="headerlink" title="如何通过nginx向后端服务传递客户真实IP"></a>如何通过nginx向后端服务传递客户真实IP</h1><p>最后我们来谈一谈经过nginx反向代理后，upstream服务如何才能获取到客户端的地址？如下图所示，nginx不同于IP转发，它事实上建立了新的连接，所以正常情况下upstream无法获取到客户端的地址： <img src="/2018/04/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%8E%A9%E7%9B%96%E4%BA%86%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84IP-1.png"> 图4 nginx反向代理掩盖了客户端的IP 上图虽然是以TCP/HTTP举例，但对UDP而言也一样。而且，在HTTP协议中还可以通过X-Forwarded-For头部传递客户端IP，而TCP与UDP则不行。Proxy protocol本是一个好的解决方案，它通过在传输层header之上添加一层描述对端的ip和port来解决问题，例如：<br><img src="/2018/04/Proxy-protocol-1.png"> 但是，它要求upstream上的服务要支持解析proxy protocol，而这个协议还是有些小众。最关键的是，目前nginx对proxy protocol的支持则仅止于tcp协议，并不支持udp协议，我们可以看下其代码： <img src="/2018/04/nginx%E5%A4%84%E7%90%86proxy-protocol-1.png"> 可见nginx目前并不支持udp协议的proxy protocol（笔者下的nginx版本为1.13.6）。 <img src="/2018/04/proxy-protocol%E5%AE%9E%E9%99%85%E6%94%AF%E6%8C%81udp-1.png"> 虽然proxy protocol是支持udp协议的。怎么办呢？</p>
<h2 id="方案1：IP地址透传"><a href="#方案1：IP地址透传" class="headerlink" title="方案1：IP地址透传"></a>方案1：IP地址透传</h2><p>可以用IP地址透传的解决方案。如下图所示： <img src="/2018/04/nginx%E4%BD%9C%E4%B8%BA%E5%9B%9B%E5%B1%82%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%90%91upstream%E5%B1%95%E7%A4%BA%E5%AE%A2%E6%88%B7%E7%AB%AFip%E6%97%B6%E7%9A%84ip%E9%80%8F%E4%BC%A0%E6%96%B9%E6%A1%88-1.png"> 图5 nginx作为四层反向代理向upstream展示客户端ip时的ip透传方案 这里在nginx与upstream服务间做了一些hack的行为：</p>
<ul>
<li>  nginx向upstream发送包时，必须开启root权限以修改ip包的源地址为client ip，以让upstream上的进程可以直接看到客户端的IP。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;    </span><br><span class="line">     listen 53 udp;</span><br><span class="line">     proxy_responses 1;</span><br><span class="line">     proxy_timeout 1s;</span><br><span class="line">     proxy_bind $remote_addr transparent;     </span><br><span class="line">     proxy_pass dns_upstreams;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>  upstream上的路由表需要修改，因为upstream是在内网，它的网关是内网网关，并不知道把目的ip是client ip的包向哪里发。而且，它的源地址端口是upstream的，client也不会认的。所以，需要修改默认网关为nginx所在的机器。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># route del default gw 原网关ip</span><br><span class="line"># route add default gw nginx的ip</span><br></pre></td></tr></table></figure>

<ul>
<li>  nginx的机器上必须修改iptable以使得nginx进程处理目的ip是client的报文。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ip rule add fwmark 1 lookup 100</span><br><span class="line"># ip route add local 0.0.0.0&#x2F;0 dev lo table 100 </span><br><span class="line"># iptables -t mangle -A PREROUTING -p tcp -s 172.16.0.0&#x2F;28 --sport 80 -j MARK --set-xmark 0x1&#x2F;0xffffffff</span><br></pre></td></tr></table></figure>

<p>这套方案其实对TCP也是适用的。</p>
<h2 id="方案2：DSR（上游服务无公网）"><a href="#方案2：DSR（上游服务无公网）" class="headerlink" title="方案2：DSR（上游服务无公网）"></a>方案2：DSR（上游服务无公网）</h2><p>除了上述方案外，还有个Direct Server Return方案，即upstream回包时nginx进程不再介入处理。这种DSR方案又分为两种，第1种假定upstream的机器上没有公网网卡，其解决方案图示如下： <img src="/2018/04/nginx%E5%81%9Audp%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E7%9A%84DSR%E6%96%B9%E6%A1%88%EF%BC%88upstream%E6%97%A0%E5%85%AC%E7%BD%91%EF%BC%89-1.png"> 图6 nginx做udp反向代理时的DSR方案（upstream无公网） 这套方案做了以下hack行为： 1、在nginx上同时绑定client的源ip和端口，因为upstream回包后将不再经过nginx进程了。同时，proxy_responses也需要设为0。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 53 udp; proxy_responses 0;</span><br><span class="line">    proxy_bind $remote_addr:$remote_port transparent;</span><br><span class="line">     proxy_pass dns_upstreams;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2、与第一种方案相同，修改upstream的默认网关为nginx所在机器（任何一台拥有公网的机器都行）。 3、在nginx的主机上修改iptables，使得nginx可以转发upstream发回的响应，同时把源ip和端口由upstream的改为nginx的。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># tc qdisc add dev eth0 root handle 10: htb</span><br><span class="line"># tc filter add dev eth0 parent 10: protocol ip prio 10 u32 match ip src 172.16.0.11 match ip sport 53 action nat egress 172.16.0.11 192.168.99.10</span><br><span class="line"># tc filter add dev eth0 parent 10: protocol ip prio 10 u32 match ip src 172.16.0.12 match ip sport 53 action nat egress 172.16.0.12 192.168.99.10</span><br><span class="line"># tc filter add dev eth0 parent 10: protocol ip prio 10 u32 match ip src 172.16.0.13 match ip sport 53 action nat egress 172.16.0.13 192.168.99.10</span><br><span class="line"># tc filter add dev eth0 parent 10: protocol ip prio 10 u32 match ip src 172.16.0.14 match ip sport 53 action nat egress 172.16.0.14 192.168.99.10</span><br></pre></td></tr></table></figure>

<h2 id="方案3：DSR（上游服务有公网）"><a href="#方案3：DSR（上游服务有公网）" class="headerlink" title="方案3：DSR（上游服务有公网）"></a>方案3：DSR（上游服务有公网）</h2><p>DSR的另一套方案是假定upstream上有公网线路，这样upstream的回包可以直接向client发送，如下图所示： <img src="/2018/04/nginx%E5%81%9Audp%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%97%B6%E7%9A%84DSR%E6%96%B9%E6%A1%88%EF%BC%88upstream%E6%9C%89%E5%85%AC%E7%BD%91%EF%BC%89-1.png"> 图6 nginx做udp反向代理时的DSR方案（upstream有公网） 这套DSR方案与上一套DSR方案的区别在于：由upstream服务所在主机上修改发送报文的源地址与源端口为nginx的ip和监听端口，以使得client可以接收到报文。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># tc qdisc add dev eth0 root handle 10: htb</span><br><span class="line"># tc filter add dev eth0 parent 10: protocol ip prio 10 u32 match ip src 172.16.0.11 match ip sport 53 action nat egress 172.16.0.11 192.168.99.10</span><br></pre></td></tr></table></figure>

<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>以上三套方案皆可以使用开源版的nginx向后端服务传递客户端真实IP地址，但都需要nginx的worker进程跑在root权限下，这对运维并不友好。从协议层面，可以期待后续版本支持proxy protocol传递客户端ip以解决此问题。在当下的诸多应用场景下，除非业务场景明确无误的拒绝超时重传机制，否则还是应当使用TCP协议，其完善的流量、拥塞控制都是我们必须拥有的能力，如果在UDP层上重新实现这套机制就得不偿失了。</p>
]]></content>
      <categories>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>udp</tag>
        <tag>proxy</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title>NGINX网络协议栈优化</title>
    <url>/2023/01/30/nginx/NGINX%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<blockquote>
<p><strong>文章简介</strong>： 本文是我在《F5 NGINX Sprint 2022》大会分享的文字版整理。《NGINX网络协议栈优化》有两个关键词，第一个是网络协议，因此不涉及 NGINX 的业务模块。第二个关键词是性能优化，目标是让NGINX的性能达到目前硬件架构的极限。</p>
</blockquote>
<p>很高兴大家回到这次深潜之旅，让我们继续挖掘 NGINX 的潜力。今天我的分享包括四个部分。首先从整体上来看一下 NGINX的协议栈如何进行优化。接着我们将按照 OSI七层网络模型，自上而下依次讨论HTTP协议栈、TLS/SSL协议栈以及TCP/IP协议栈。</p>
<p>首先要明确NGINX的优化方向。优化的目标在我看来可以用三个词表示——<strong>快、多、省</strong>。</p>
<ul>
<li>“<strong>快</strong>”是指降低请求的时延，请求时延是用户能够感知到的最明显因素。</li>
<li>“<strong>多</strong>”指的是 NGINX正在处理的所有TCP连接数量以及收发的总字节数，比如总吞吐量能否打满网卡。</li>
<li>“<strong>省</strong>”指处理一个 TCP 连接时所消耗的资源要尽量的少，这样我们的并发连接才能够达到千万、亿级别。</li>
</ul>
<p>在做协议栈优化时，我们必须同时兼顾知识<strong>深度</strong>和<strong>广度</strong>。开发习惯从实现的角度看问题，知识面倾向深度。而运维更关注服务部署、运行，比如要了解IDC地理位置、网络规划、服务器硬件配置等情况，因此知识面是倾向广度的。NGINX运行在 Linux 或者 FreeBSD 等操作系统上，操作系统的内核协议栈和进程调度机制都会影响 NGINX 性能，所以优化内核参数时相对更需要深度。了解 NGINX 所在网络环境，针对丢包率、网卡特性、CPU特性、交换机和防火墙的规格、协议特性等要素优化 NGINX 时，相对又会偏重广度。</p>
<h1 id="NGINX-协议栈优化方法论"><a href="#NGINX-协议栈优化方法论" class="headerlink" title="NGINX 协议栈优化方法论"></a>NGINX 协议栈优化方法论</h1><p>首先我们看下面两张图，先同步下思路。</p>
<h2 id="NGINX架构"><a href="#NGINX架构" class="headerlink" title="NGINX架构"></a>NGINX架构</h2><p>第一张图由 NGINX 官方提供，我们从三个层面来解读它。<br><img src="/images/nginx/ppt2022/%E5%AE%98%E6%96%B9%E6%9E%B6%E6%9E%84.png" alt="官方架构"></p>
<span id="more"></span>

<p>第1个层面是左下角的 3 个关键词。</p>
<ol>
<li><p><strong>事件驱动Event-driven</strong>： 什么是事件呢？比如接收到TCP握手的SYN或者FIN报文，或者接收到ACK（发送缓冲区被释放出来），或者某个定时器执行结束，这些都是事件，而NGINX对请求的处理是由这些事件触发的。</p>
</li>
<li><p><strong>非阻塞Non- blocking</strong>： 指当你将socket设为非阻塞模式后，操作系统提供的POSIX API就能在未完成任务的情况下返回，比如建立连接的connect系统调用可以在未完成三次握手时就返回成功。</p>
</li>
<li><p><strong>异步Asynchronous</strong>： 面向开发人员的一种编程模式，它需要为每个请求维护上下文，并频繁更换状态机，非常复杂。当然，如果你使用了Lua协程，这种同步模式会降低复杂度，但在NGINX的C框架层仍然是异步的。</p>
</li>
</ol>
<p>通过这三个关键词可以看到，NGINX 即使不做优化，性能也还不错。</p>
<p>第2个层面，再来从左至右看图中的网络流向。左边是下游客户端与 NGINX 之间的流量，主要是指HTTP协议。右边是 NGINX 与 IDC 内的各 Web server 传输的流量，它的交互协议种类比较丰富，但都能与HTTP协议进行语义转换。比如，当上游服务是Memcached 或者Redis时，存取缓存元素可以对应HTTP中的GET或者PUT方法（参见Roy Fielding的<a href="https://en.wikipedia.org/wiki/Representational_state_transfer">RestFul架构风格</a>）。</p>
<p>第3个层面看进程架构。NGINX 有一个 <strong>master 父进程</strong>、多个 <strong>worker 子进程</strong>以及可选的<strong>cache manage</strong>和<strong>cache loader子进程</strong>。当然，如果你使用了NGINX的二次开发生态，还会多出一些进程，比如OpenResty可能产生的<strong>privileged agent子进程</strong>。master进程不处理网络流量，实际工作的是 worker 子进程，其他子进程都是用于配合worker进程处理请求的。比如HTTP缓存会存放在本地磁盘中，cache manage负责缓存的定时淘汰工作，而cache loader则在NGINX重启时载入磁盘文件。</p>
<p>NGINX也可以作为Web server使用，本次分享不涉及这块。今天主要讨论NGINX作为负载均衡的优化方法，除网络协议外，还会涉及一些磁盘 IO 知识。 </p>
<p>再来看第二张图，它是OSI网络七层模型与真实的TCP/IP协议间的对应关系。<strong>模型是为了方便我们理解概念，而解决问题必须分析真实的协议。</strong><br><img src="/images/nginx/ppt2022/%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82.png" alt="协议分层"></p>
<p>比如，应用层中我们最常使用的是HTTP协议，它是由NGINX框架代码执行编解码的。表示层中常用的是TLS/SSL协议，它由NGINX进程中的openssl库执行编解码。传输层常用的是TCP协议，网络层是IP协议。网络层与链路层之间的定义则没有那么清晰，比如VLAN（802.1q）、ARP协议等可以近似归到这两层。以上传输层、网络层、链路层中的协议默认是由操作系统内核处理的，它们通过socket及一些系统工具（如ifconfig、route）提供给NGINX使用。</p>
<h2 id="协议栈优化场景"><a href="#协议栈优化场景" class="headerlink" title="协议栈优化场景"></a>协议栈优化场景</h2><p>接下来我们用4张图，看看协议栈优化的具体场景。<br><img src="/images/nginx/ppt2022/%E5%9C%BA%E6%99%AF1.png" alt="场景1"><br>第一张图最常见。当网络报文到达服务器时，首先会从网卡来到内核的 TCP / IP 协议栈，处理完毕后经由右边的 socket 及 listen()、 bind()、recv()、send()等系统调用进入 NGINX worker 进程，再由 NGINX 框架调用 openssl库卸载TLS 协议，然后基于 http 状态机解析协议。获取到http 请求行、请求头后，NGINX框架就会依次调用各个NGINX http模块处理请求，包括过滤模块和处理模块，以及OpenResty用户常用的 Lua模块。</p>
<p>基于stream模块还可以将NGINX当作 4 层负载均衡使用，当然，这里的“<strong>4层</strong>”虽然指的就是OSI体系中的传输层，但与传统的4层负载均衡并不是一回事。例如，LVS作为4层负载均衡会部分参与到TCP协议的编解码（仅包含相对简单的握手阶段，不涉及复杂的滑动窗口与拥塞控制），即它会接管内核的TCP协议，而NGINX只是通过socket使用内核处理过的TCP协议。</p>
<p>第二张图可以看到<strong>TLS/SSL协议栈同时运行在用户态与内核态代码</strong>中，这是怎么回事呢？<br><img src="/images/nginx/ppt2022/%E5%9C%BA%E6%99%AF2.png" alt="场景2"><br>TLS/SSL协议通常运行在用户态进程更合适，这是因为：首先它处于TCP与应用层协议之间，其次它又是消耗CPU的计算密集型协议，所以放在用户态进程中，既能提升应用开发效率，也不会影响性能。然而，在非常规场景下，TLS/SSL运行在内核中性能更高。比如，当NGINX作为CDN缓存服务运行时，缓存文件是放在磁盘中的，一旦HTTP请求命中缓存，接下来将磁盘文件发送到网卡这件工作，就可以通过sendfile零拷贝在内核中完成任务。可是一旦开启了HTTPS服务（当下全站加密是主流），零拷贝功能就无法使用，因为openssl是运行在NGINX进程中的。此时上图中的kTLS方案就有了用武之地。</p>
<p>再来看第三张图。<br><img src="/images/nginx/ppt2022/%E5%9C%BA%E6%99%AF3.png" alt="场景3"><br>2022年 6 月份，HTTP3协议的正式RFC文档就已经发布，这给协议栈的优化又带来了变数。HTTP3为了解决HTTP2的<strong>队头阻塞</strong>、<strong>连接迁移</strong>问题，改用内核中的UDP协议解决进程调度，而将TCP协议中的可靠传输功能放在了用户态的quic协议栈中。因此，我们不再需要通过有限的sysctl指令优化复杂的TCP协议栈参数。</p>
<p>Go、Rust等语言都实现了 HTTP3协议库，但 NGINX 正式版却迟迟没有提供，仅有一个无法在生产环境中使用的quic分支。这里的原因很多，除了开源NGINX非常强调稳定性外，还因为NGINX的多进程架构，它使得连接迁移必须通过eBPF模块，才能在worker子进程间正确地分发报文，这就与操作系统内核紧密耦合起来，进一步延迟了正式版的发布。</p>
<p>另外，常见的TLS/SSL协议都是运行在TCP之上，而现在quic既需要使用TLS/SSL协议，又是跑在UDP协议上，这就改变了TLS/SSL的工作方式。比如，<strong>TLS不能对UDP payload整体加密</strong>，否则正、反向代理就无法通过connection-ID正确地执行会话保持或者负载均衡（quic不再基于四元组定义连接，而是通过1个64比特的connection-ID定义连接）。</p>
<p>最后来看第四张图，我们深入内核与硬件看协议栈如何优化。<br><img src="/images/nginx/ppt2022/%E5%9C%BA%E6%99%AF4.png" alt="场景4"></p>
<p>对NGINX熟悉的同学都了解，使用worker_cpu_affinity 指令将worker 进程与CPU绑定时性能最高，因为这样就可以提升CPU的一、二级缓存命中率。但如果我们换个角度想，这意味着<strong>每个 worker 进程都有自己独立的HTTP协议栈</strong>！然而，这些 worker 进程却共享了操作系统的TCP协议栈，因此listen reuseport指令才有负载均衡的效果。共享提升了开发效率，但却因为加解锁操作降低了运行效率，因此在高并发、高吞吐时，你会发现ksoftirq进程占用的 CPU 很高。</p>
<p>对于更底层的IP 协议栈，它的共享影响范围就更大了，比如listen指令如果没有显示指定IP地址，那么你用 ifconfig 新增地址后，NGINX 就能马上处理新地址上的请求，可以想见这种灵活性的代价：对于满载、多IP的服务器，这种玩法一定会降低性能。IP层之下的数据链路层也有这个问题，通过brctl新增的网桥（做云原生的同学应该很熟悉）和802.1q 协议中的vlan也是可以立刻使用的。</p>
<p>有了总体视角，我们来看应用层的 HTTP 协议栈优化。</p>
<h1 id="HTTP协议栈优化"><a href="#HTTP协议栈优化" class="headerlink" title="HTTP协议栈优化"></a>HTTP协议栈优化</h1><p>从互联网的整体发展，我们先来看看HTTP/1.1协议栈的优化点，再来看HTTP2和HTTP3解决了哪些问题。下面这张图是从上世纪80年代起，以太网网卡带宽的演进速度。<br><img src="/images/nginx/ppt2022/%E5%B8%A6%E5%AE%BD%E4%B8%8E%E6%97%B6%E5%BB%B6.png" alt="带宽与时延的变化趋势"></p>
<p>可以看到，在 TCP 协议刚出现的80年代初，网卡带宽只有10Mb/s。到了HTTP/1.0协议出现、互联网开始飞速发展的95年，带宽已经达到100Mb/s，之后网卡进步明显加速，2004年出现了万兆网卡，2010 年 100G网卡，2018年时400G 网卡都出现了。当然，这些百G网卡目前都只在IDC数据中心出现，但这给协议开发人员的信号非常明显：<strong>如何才能用满越来越大的单机带宽呢？</strong></p>
<p>与此同时，受制于物理规律（光速），报文在光纤中的传输速度并没有多大变化。必要的交换机中转所带来的“<strong>最后一公里</strong>”问题，是另一个让网络延迟居高不下的因素。因此，时延几乎不变，带宽却不断增大，协议设计者们有事可做了！</p>
<p>举个例子，十多年前我在设计服务器之间的传输协议时，还会使用gzip之类的压缩技术，因为那时带宽比CPU紧张。而现在IDC内部的带宽提升这么多后，就不再需要浪费CPU在两台服务器上压缩、解压缩数据了，而且消息传递速度还更快。</p>
<p>再比如，早期互联网大厂IDC内的资源利用率很低，因为在线业务的高峰与低谷流量差距太大，为了应对早晚、节假大促日、热点流量的变化，IDC必须预留大量空闲资源。这在早期的蓝海市场没有多大问题，但随着大数据时代的到来，在线业务的数据量以及引发的离线计算量增加的幅度越来越快，必须想办法提升IDC资源利用率。而在百G单机带宽的情况下，<strong>存储计算分离</strong>这种架构就有了用武之地，通过在线业务与离线计算服务的混合部署，谷歌IDC的 CPU 平均利用率达到惊人的 60% （参见<a href="https://dl.acm.org/doi/pdf/10.1145/3342195.3387517">论文Borg: the next generation</a>，与此同时，国内许多IDC只有10%的平均使用率）。</p>
<p>理解了这两个例子，我们就能清晰的看到HTTP协议栈的优化方向：<strong>增带宽、降时延</strong>。</p>
<h2 id="HTTP1的降时延"><a href="#HTTP1的降时延" class="headerlink" title="HTTP1的降时延"></a>HTTP1的降时延</h2><p>先从HTTP1的降时延谈起。单个页面上的资源数以百计，如果下载每个资源都使用独立的TCP连接，就有2个增大时延的因素：<strong>TCP握手</strong>与<strong>TCP慢启动</strong>。简单解释下。</p>
<p>一次HTTP资源下载包括2条HTTP消息：请求与响应，客户端在等待响应的过程中，承载HTTP会话的TCP连接只能处于空闲状态，这是HTTP的简单性设计理念决定的。所以，单一页面上百个资源下载任务，只能在并发范围内依次执行。如果每个HTTP会话都启动新的TCP连接，那么在TCP三次握手中，至少要浪费1个RTT，这就是数百毫秒。</p>
<p>TCP慢启动则是为了解决网络拥堵问题。就像公路上必须有红绿灯一样，TCP连接之间会在不通过第三方仲裁的情况下，自行监控丢包与延迟的变化解决网络拥塞。其中一个重要手段，就是连接刚建立时先不要满载发送字节流（慢慢提升拥塞窗口的大小），这就是“慢启动”。可以想见，对于百G大带宽的服务器而言，一次只能发送10个MSS大小（即15KB，假定MSS为1500字节）的报文有多浪费。</p>
<p>因此，早在HTTP1.0时代，就有了KeepAlive长连接技术，到了HTTP/1.1更是直接写入RFC标准里。简而言之，就是传输完1个HTTP请求后，不要关闭TCP连接，继续将它复用在下一个HTTP请求中，下图是NGINX上配置KeepAlive的方法：<br><img src="/images/nginx/ppt2022/%E9%95%BF%E8%BF%9E%E6%8E%A5.png" alt="HTTP长连接"></p>
<p>上图左边是客户端与NGINX间的长连接配置，右边是应用服务器与NGINX间的长连接配置，可以看到，它们并不完全相同。其中，相同的配置是keepalive_requests、keepalive_time和keepalive_timeout，分别放在server{}或者upstream{}配置块中，表示1个TCP连接最多可以承载 1000 个请求、保持 1 小时或者 60 秒的最大空闲时长，一旦不满足任一条件，连接就会关闭。比起RFC标准来，似乎复杂了不少，但<strong>这是做软件工程必备的思维方式</strong>，因为NGINX需要处理各种意外情况，有了这些限制，单一用户就不会占用太多资源。</p>
<p>而对于IDC内的上游服务器，NGINX必须在客户端关闭HTTP会话后，继续维护TCP连接池，这其实对于上游的应用服务器带来了一些压力，所以又多了一个 keepalive 配置，它可以限制连接池内的TCP连接数量。</p>
<h2 id="HTTP2的增带宽"><a href="#HTTP2的增带宽" class="headerlink" title="HTTP2的增带宽"></a>HTTP2的增带宽</h2><p>上文说了如何减少报文的往返次数，我们再来看如何增带宽。其实传输层与网络层也能做到，比如以太网MTU默认 1500 字节，但<a href="https://zh.m.wikipedia.org/zh-hans/%E5%B7%A8%E5%9E%8B%E5%B8%A7"><strong>巨型帧</strong></a>技术早已成熟，服务器之间单个报文可以增加到 9000 字节。而且在 IPV6 协议中，IP报文更是超过了 65535 字节的限制。当然，今天的重点还是在应用层协议上。</p>
<p>2015年推出的HTTP2协议有很多新特性，但相对HTTP1最大的提升就是增加了单TCP连接的传输带宽，下图可以清晰的看到它带来的变化，从左边的14秒到右边的2秒，差不多有一个数量级的提升！<br><img src="/images/nginx/ppt2022/http2%E5%B9%B6%E5%8F%91.png" alt="http2提升了TCP连接的并发吞吐量"></p>
<p>解释下上图的测试上下文：这张高清地球图片被拆成了大约 380 张图片，因此需要发起380个HTTP请求才能用JavaScript拼接成完整的图片。 我的验证环境是Chrome浏览器，因此左边的 HTTP 1.1 会同时并发 6 个 TCP 连接，每个连接依次传输60多张图片。右边的HTTP 2 则仅使用1个TCP连接，同时传输380个小图片（实际上是380个STREAM），这样带宽便可以充分使用，消除了HTTP语义简单性带来的响应等待问题。</p>
<p>HTTP 2还有很多优点，比如浏览器解析完HTML资源（例如 index.html ）获得DOM 树后，会分析待下载的 CSS 、JavaScript或者多媒体资源，评价资源间的依赖程度和用户体验，从而对不同的STREAM设置优先级，这样可以在有限的总带宽下更有效的分配资源。再比如资源推送，当客户端下载了play.html后，服务器知道接下来浏览器一定需要jquery.js文件，于是就可以主动推送资源，如下图所示：<br><img src="/images/http/http2%E6%8E%A8%E9%80%81%E6%B6%88%E6%81%AF.png" alt="http2消息推送"></p>
<p>在NGINX上开启HTTP2非常简单，只要在listen指令最后添加http2参数即可。</p>
<p>当然HTTP 2协议并不是完美的，它的最大问题在于“<strong>队头阻塞</strong>”，如下图所示：<br><img src="/images/http/%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E%E7%9A%84%E8%A7%A3%E5%86%B3.jpg" alt="队头阻塞的解决"></p>
<p>上图a场景的HTTP 1 协议中，蓝色报文的丢失并不会影响红色、绿色请求，但到了b场景的HTTP2协议，由于红、蓝、绿请求都承载在同1个 TCP 连接上，而TCP 又是一个有序字节流协议，所以蓝色报文的丢失不只影响了蓝色请求，还影响了红色、绿色请求，这就叫队头阻塞。HTTP3协议则通过UDP和quic层解决了这个问题，关于HTTP3我们后面再说。</p>
<h1 id="TLS协议栈优化"><a href="#TLS协议栈优化" class="headerlink" title="TLS协议栈优化"></a>TLS协议栈优化</h1><p>接下来我们再来看 OSI表示层协议TLS/SSL的优化。在全栈加密的今天，绝大部分公网流量都是经由TLS协议加密的，而优化TLS除了在先进算法与兼容性、性能与安全性之间做权衡外，还要考虑系统架构约束的变化。</p>
<h2 id="建立会话"><a href="#建立会话" class="headerlink" title="建立会话"></a>建立会话</h2><p>先来看TLS会话握手，这是最消耗CPU性能的过程，通常单颗CPU核心的每秒新建数不过一千多，但更为关键的是，握手消耗的RTT时间更多，参见下图：<br><img src="/images/tls/tcp%E4%B8%8Etls%E6%8F%A1%E6%89%8B%E5%AF%B9%E6%AF%94.png" alt="tcp与tls握手对比"><br>上图中右侧是以TLS1.2协议为例看会话建立过程的，相对于图左侧在TCP握手中消耗1个RTT（蓝色线条）之外，右侧共消耗了3个RTT（蓝色与绿色线条），这就接近1秒时延了。怎么解决呢？参见下图的TLS 1.3方案：<br><img src="/images/tls/tls1.3%E6%8F%A1%E6%89%8B%E5%AF%B9%E6%AF%94.jpg" alt="tls1.3握手对比"></p>
<p>上图左侧，TLS1.2通过Client Hello、Server Hello、Client Key Exchange、Finished（或者可选的Server Key Exchange）4条消息在2个RTT中完成了握手。我们要分析下，为什么交换密钥不能从2次RTT降为1次RTT呢？这其实是能做到的，只要大幅减少加密算法（在TLS中被称为安全套件）的数量，就可以把Client Hello这个协商算法的消息与Client Key Exchange合并为一条消息，这就变成右图中的TLS 1. 3握手了。我们可以通过ssl_protocols指令配置NGINX支持的协议版本，但目前至少需要同时支持TLS 1.2和TLS 1.3，因为还有很多古老的客户端不兼容TLS1.3协议。</p>
<h2 id="传输数据"><a href="#传输数据" class="headerlink" title="传输数据"></a>传输数据</h2><p>再来看传输加密数据的过程，我们可以基于内核的kTLS提升性能。在介绍kTLS之前，咱们需要先回顾下HTTP缓存，这实际上是HTTP协议栈的优化内容，可又是NGINX使用kTLS的前置知识点，所以我放在这里简要介绍。</p>
<p><img src="/images/http/%E4%B8%8D%E5%90%8C%E4%BD%8D%E7%BD%AE%E7%9A%84%E7%BC%93%E5%AD%98.png" alt="不同位置的缓存"><br>上图中，cache缓存可以存放在浏览器上，这时它的属性是private，只针对一个用户有效。缓存还可以存放在正向代理（参考科学上网）、反向代理（参考CDN）上，此时它的属性是public，可以被多个用户共享。缓存通过将内容放在空间上距离用户更近的位置上，降低用户下载内容的时间。</p>
<p>我们知道，NGINX可以使用Linux等操作系统提供的零拷贝技术（参见<a href="https://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile">sendfile指令</a>），将磁盘上的文件不通过worker进程就发送到网卡上。然而，openssl是运行在worker进程上的，一旦下游客户端走的是TLS流量，零拷贝就失效了，因为必须把磁盘上的文件读取到worker进程的内存空间上，才能使用openssl加密文件，然后再经由内核把加密后的字节流发送到网卡。所以，只要在内核中使用TLS协议加密流量，就可以继续使用零拷贝技术，如下图所示：<br><img src="/images/nginx/ktls.png" alt="kTLS"></p>
<p>NGINX 1.21.4版本开始支持kTLS功能，通过ssl_conf_command Options KTLS;指令即可开启零拷贝TLS流量功能，具体参见这篇<a href="https://www.nginx.com/blog/improving-nginx-performance-with-kernel-tls/">官方博客https://www.nginx.com/blog/improving-nginx-performance-with-kernel-tls/</a>。</p>
<p>事实上如果不使用kTLS，在内核与worker进程间反复拷贝数据，造成的CPU消耗会越来越可观！关于这点，我们要从下图的内存发展趋势谈起：<br><img src="/images/nginx/ppt2022/%E5%86%85%E5%AD%98%E5%AE%B9%E9%87%8F%E5%B8%A6%E5%AE%BD%E4%B8%8E%E6%97%B6%E5%BB%B6%E5%AF%B9%E6%AF%94.png" alt="内存容量带宽与时延对比"></p>
<p>上图中，红色的线是内存访问时延，绿色的线是内存访问带宽，黑色的线是内存容量。可以看到，从1999年到2017年，内存容量翻了 100 多倍，而访问带宽只升了20 倍，内存访问时延则基本没有变化！这对开发人员提出了要求：缓存的作用越来越大，但是内存拷贝是次数必须降低。因此，当我们把加密过程通过kTLS放到内核中，压根不跟worker 进程接触后，就会有10% 到 20% 的性能提升（参考官网测试数据）。</p>
<h1 id="TCP-IP协议栈优化"><a href="#TCP-IP协议栈优化" class="headerlink" title="TCP/IP协议栈优化"></a>TCP/IP协议栈优化</h1><p>最后来看TCP / IP协议栈的优化。摩尔定律的失效，对TCP/IP协议栈的优化影响很大，如下图所示，CPU在向多核心方向发展：<br><img src="/images/nginx/ppt2022/CPU%E5%A4%9A%E6%A0%B8%E5%BF%83%E8%B6%8B%E5%8A%BF.png" alt="CPU多核心趋势"></p>
<p>上图我们重点看绿、蓝、黑 3 条曲线。绿色曲线是 CPU 频率，从2004 年以后基本就不变了。蓝色曲线是CPU单核性能，略有提升是CPU架构优化和缓存带来的。黑色曲线则是CPU核心数，它的不断增加对开发人员的要求很高。具体到TCP/IP协议，就是操作系统的共享协议栈设计，带来的锁竞争概率直接上升！</p>
<p>现代OS都是分时操作系统，单核心CPU一样可以通过微观上的串行任务，实现宏观上的并发，而且这时的并行多任务<strong>在使用自旋锁时，几乎没有锁竞争问题</strong>。然而，一旦服务器使用了64核等CPU时，微观上就会有64个线程并行执行，对于高负载的NGINX来说锁冲突概率会非常高。此时你升级CPU，是不会带来线性性能提升的，与此同时，CPU的SI软中断百分比会急剧变大。</p>
<p>内核协议栈的设计，除了锁竞争问题外，还会引入3个问题。如下图所示，内核协议栈必须通过socket和系统调用与NGINX传递消息，因此系<strong>统调用导致的上下文切换、内核态与用户态间的内存拷贝、硬件NIC网卡与协议栈协同引入的软中断</strong>，都是不可忽视的因素：<br><img src="/images/tcp/socket%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.png" alt="socket与TCP协议栈"></p>
<p>当然，上图的设计优点也很多，比如大幅减少了应用开发的难度，增强了操作系统的稳定性等。但当我们关注性能、优化协议栈时，就不得不使用诸如零拷贝、kTLS等特性，还要不断关注软中断进程ksoftirq的CPU占用率。这里简单解释下什么是软中断，如下图所示：<br><img src="/images/nginx/ppt2022/%E8%BD%AF%E4%B8%AD%E6%96%AD.png" alt="软中断"></p>
<p>上图有6 个步骤，其中第1、2、3步是从网络中接收的报文复制到 sk_buffer 中，并发起硬中断通知操作系统；第4、5步则是操作系统收到软中断后，通过协议栈处理报文，此时 ksoftirq 进程是在工作的。把两个步骤分开是一种异步化设计，毕竟网卡是硬件，处理报文的速度必须足够快，而ksoftirq则可以有延迟。第6步就是NGINX通过epoll_wait 拿到就绪的socket，或者经由read 或者 write 等函数拷贝报文数据。可见，在这个过程中，软中断对我们的消耗是可观的。</p>
<p>那么，当服务器CPU核心增多时，如何解决上述问题呢？Intel dpdk加上用户态协议栈是一条可选的路径。如下图所示，dpdk允许用户态进程直接从网卡上读取接收到的报文，或者拷贝数据到网卡来发送报文，绕过内核协议栈：<br><img src="/images/nginx/ppt2022/f-stack%E6%96%B9%E6%A1%88.png" alt="f-stack方案"></p>
<p>上图是腾讯f-stack给出的方案，它改造了freebsd操作系统的TCP/IP协议栈，对下通过dpdk与网卡交互，对上则以POSIX API的静态库形式，在 worker进程内为传输层之上提供服务。可以看到，由于每个NGINX worker进程内的IP、TCP协议栈都是独立的，所以当你修改IP地址时，不能使用操作系统的ifconfig或者nmcli命令，而是必须执行f-stack封装的ff_ifconfig命令，而且必须为每个worker进程分别执行脚本（使用-p指定进程ID），因此，管理每个worker进程的<strong>配置一致性</strong>是比较复杂的。</p>
<p>熟悉NGINX的同学都知道，<strong>所有worker子进程之间的地位是相同的</strong>。然而到了上图中的方案时，情况就不一样了。在多进程架构中，<strong>dpdk要求必须分清主次</strong>，也就是第1个fork出的worker子进程是主进程，它必须负责管理大页内存（huge page，dpdk必须使用这种管理模式，当然dpdk无锁内存池的设计非常高明！），而其他worker子进程则只是使用大页内存。这种设计导致NGINX reload模式会出问题，因为主worker退出、新建这段时间内，其他worker进程是不能提供服务的，这样NGINX的“<strong>热加载</strong>”功能就要大打折扣了。</p>
<p>worker进程的数量与网卡的数量并不一致，因此worker进程间必须通过哈希算法，各自处理网卡上收到的报文。由于每个worker进程绑定了一颗CPU核心，所以图中的cpu队列等价于worker进程处理报文的队列（dpdk是高性能网络框架，它只针对CPU设计独立的报文队列）。上图中，当蓝色报文到达网卡1时，会根据TCP四元组（在dpdk初始化时可通过f-stack.conf配置）分发到CPU1队列。worker0和worker1都会循环获取CPU队列中的报文，但worker0只取CPU0队列，所以worker1进程会获取到CPU1队列上的蓝色报文，经由进程内的独立TCP/IP协议栈（<strong>无须中断、无须加锁</strong>）处理完毕后，交由NGINX的epoll、各HTTP模块处理。可见，这种架构去除了软中断、系统调用、内核态用户态切换，大幅减少了内存拷贝次数，即使单worker性能也会有不少提升。但它的最大优势是多核心CPU，尤其是CPU核心达到32、64甚至更高时，无锁化设计带来的优势非常明显，可以轻松达到百万级CPS（每秒新建连接数）、上亿并发连接。</p>
<p><strong>当然，这种带来高性能的独立协议栈设计，还引入了一个大麻烦</strong>：NGINX作为负载均衡使用时，一个会话上的客户端、上游服务器报文都必须在同一个worker进程内处理，这是普通的哈希算法无法做到的，如下图所示：<br><img src="/images/nginx/ppt2022/%E7%8B%AC%E7%AB%8B%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%88%86%E5%8F%91%E9%9A%BE%E9%A2%98.png" alt="独立协议栈带来的分发难题"></p>
<p>客户端发起的TCP连接由worker1进程处理，但worker1与上游服务器建立的连接，回包经由哈希算法，可能会落到worker0进程处理，这样数据就乱了！如何解决这个问题呢？f-stack和dpvs都给出了不太完美的方案。</p>
<p>f-stack在向上游发起TCP连接时，本地端口并不像从前一样找出一个空闲端口直接使用，而是从小到大反复测试（最大到65535），判断TCP四元组经由哈希函数的结果，如果本地端口导致哈希值没有落在当前worker进程上，就换一个，直到符合为止（<strong>O(n)时间复杂度！</strong>）。这套解决方案<strong>优点是与硬件无关，缺点则是性能非常差！</strong></p>
<p>Dpvs的解决方案则必须使用支持fdir（Intel® Ethernet Flow Director）的网卡。Fdir技术允许程序基于TCP目的端口（其他四元组元素当然也可以）设置CPU队列的分发规则，比如，worker0进程发起的TCP连接本地端口只从1-10000（实际当然不是基于整数区间，而是按二进制bit位规划的），而worker1进程的本地端口则只从10001到20000，这样两个进程发送SYN报文时，就可以确保来自上游的SYN+ACK报文可以回到原worker进程了。这套方案的优点是性能很好，缺点则是绑定了硬件和应用代码（预留端口），而且dpdk的版本还必须与网卡配套才能正常工作。</p>
<p>事实上HTTP 3协议也面临类似的问题，只是它的表现形式在于“<strong>连接复用</strong>”功能！为了解决移动设备频繁更换IP地址导致的TCP断网重连问题，HTTP 3不再基于TCP四元组定义连接，而是设计了1个64位的connection ID，只要该ID不变，客户端在一段时间内（例如1分钟）断网重连后，依然可以复用原先的连接。然而，目前的操作系统内核只会基于TCP目的端口分发进程，并不知道每个worker进程上具体处理的connection ID，这也是NGINX迟迟无法推出HTTP3版本的原因（解决方案是高度耦合的eBPF模块，因此QUIC分支目前仍没有合并到主干）。</p>
<p>最后总结一下。今天我介绍了HTTP协议栈、TLS/SSL 协议栈和 TCP/IP 协议栈的优化思路，最终如何应用还要根据实际的应用场景来拍板，但取舍前一定要先了解当前协议栈的性能天花板在哪。好，谢谢大家，祝大家今天下午后面的旅程一切顺利！</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>OSI</tag>
        <tag>F5</tag>
      </tags>
  </entry>
  <entry>
    <title>《深入理解Nginx：模块开发与架构解析》示例代码下载</title>
    <url>/2017/01/27/nginx/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3nginx%EF%BC%9A%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%E3%80%8B%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81%E4%B8%8B/</url>
    <content><![CDATA[<h1 id="第三章示例源代码"><a href="#第三章示例源代码" class="headerlink" title="第三章示例源代码"></a>第三章示例源代码</h1><p><a href="/zip/chapter3.zip">chapter3</a> </p>
<h1 id="第四章示例源代码"><a href="#第四章示例源代码" class="headerlink" title="第四章示例源代码"></a>第四章示例源代码</h1><p><a href="/zip/chapter4.zip">chapter4</a> </p>
<h1 id="第五章示例源代码"><a href="#第五章示例源代码" class="headerlink" title="第五章示例源代码"></a>第五章示例源代码</h1><p><a href="/zip/chapter5.zip">chapter5</a> </p>
<h1 id="第六章示例源代码"><a href="#第六章示例源代码" class="headerlink" title="第六章示例源代码"></a>第六章示例源代码</h1><p><a href="/zip/chapter6.zip">chapter6</a></p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>从通用规则中学习Nginx模块的定制指令</title>
    <url>/2020/12/23/nginx/%E4%BB%8E%E9%80%9A%E7%94%A8%E8%A7%84%E5%88%99%E4%B8%AD%E5%AD%A6%E4%B9%A0nginx%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9A%E5%88%B6%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<p><a href="https://www.taohui.pub/2020/12/22/%e5%a6%82%e4%bd%95configure%e5%ae%9a%e5%88%b6%e5%87%ba%e5%b1%9e%e4%ba%8e%e4%bd%a0%e7%9a%84nginx%ef%bc%9f/">上一篇文章</a>中，我介绍了如何定制属于你自己的Nginx，本文将介绍nginx.conf文件的配置语法、使用方式，以及如何学习新模块提供的配置指令。</p>
<p>每个Nginx模块都可以定义自己的配置指令，所以这些指令的格式五花八门。比如content_by_lua_block后跟着的是Lua语法，limit_req_zone后则跟着以空格、等号、冒号等分隔的多个选项。这些模块有没有必然遵循的通用格式呢？如果有，那么掌握了它，就能快速读懂生产环境复杂的nginx.conf文件。</p>
<span id="more"></span>
<p>其次，我们又该如何学习个性化十足的模块指令呢？其实，所有Nginx模块在介绍它的配置指令时，都遵循着相同的格式：Syntax、Default、Context、Description，这能降低我们的学习门槛。如果你还不清楚这一套路，那就只能学习其他文章翻译过的二手知识，效率很低。</p>
<p>比如搭建静态资源服务用到的root、alias指令，该如何找到、阅读它的帮助文档？为什么官方更推荐使用root指令？alias指令又适合在哪些场景中使用呢？</p>
<p>nginx.conf配置文件中的语法就像是一门脚本语言，你既可以定义变量（set指令），也可以控制条件分支（if指令），还有作用域的概念（server{}块、location{}块等）。所以，为复杂的业务场景写出正确的配置文件，并不是一件很容易的事。为此，<strong>Nginx特意针对vim编辑器提供了语法高亮功能</strong>，但这需要你手动打开，尤其是include文件散落在磁盘各处时。</p>
<p>本文将会系统地介绍nginx.conf配置文件的用法，并以搭建静态资源服务时用到的root、alias指令为例，看看如何阅读Nginx模块的指令介绍。同时，本文也是Nginx开源社区基础培训系列课程第一季，即6月11日晚第2次视频直播的部分文字总结。</p>
<h2 id="快速掌握Nginx配置文件的语法格式"><a href="#快速掌握Nginx配置文件的语法格式" class="headerlink" title="快速掌握Nginx配置文件的语法格式"></a>快速掌握Nginx配置文件的语法格式</h2><p>Nginx是由少量框架代码、大量模块构成的，其中，Nginx框架会按照特定的语法，将配置指令读取出来，再交由模块处理。<strong>因此，Nginx框架定义了通用的语法规则，而Nginx模块则定义了每条指令的语法规则，</strong>作为初学者，如果将学习目标定为掌握所有的配置指令，方向就完全错了，而且这是不可能完成的任务。</p>
<p>比如，ngx_http_lua_module模块定义了content_by_lua_block指令，只要它符合框架定义的{}块语法规则，哪怕大括号内是一大串Lua语言代码，框架也会把它交由ngx_http_lua_module模块处理。因此，下面这行指令就是合法的：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">content_by_lua_block &#123;ngx.say(&quot;Hello World &quot;)&#125;</span><br></pre></td></tr></table></figure>

<p>再比如，ngx_http_limit_req_module模块定义了limit_req_zone指令，只要它符合指令行语法（以分号;结尾），框架就会将指令后的选项将由模块处理。所以，即使下面这行指令出现了r/s（每秒处理请求数）这样新定义的单位，仍然是合法的：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">limit_req_zone</span> $binary_remote_addr zone=one:<span class="number">10m</span> rate=1r/s;</span><br></pre></td></tr></table></figure>

<p>所以，在我看来，只要弄清楚了以下2点，就能快速掌握Nginx配置文件，：</p>
<h3 id="1-配置基本格式"><a href="#1-配置基本格式" class="headerlink" title="1. 配置基本格式"></a>1. 配置基本格式</h3><p><strong>Nginx框架定义了每条指令的基本格式，这是所有模块必须遵守的规则</strong>，这包括以下5条语法：</p>
<ul>
<li>  通过{}大括号作为分隔符的配置块语法。比如http{ }、location{ }、upstream{ }等等，至于配置块中究竟是放置Javascript语言、Lua语言还是字符串、数字，这完全由定义配置块的Nginx模块而定。</li>
<li>  通过;分号作为分隔符的指令语法。比如root html;就打开了静态资源服务。</li>
<li>  以#作为关键字的注释语法。比如#pid logs/nginx.pid;指令就是不会生效的。</li>
<li>  以$作为关键字的变量语法。变量是Nginx模块之间能够互相配合的核心要素，也是Nginx与管理员之间的重要接口，通过$变量名的形式，就可以灵活控制Nginx模块的行为。下一篇文章我会详细介绍Nginx变量。</li>
<li>  include指令可以将其他配置文件载入到nginx.conf中，这样可以提升配置的可维护性。例如includemime.types;语句，就将Content-Type与文件后缀名的映射关系，放在了独立的mime.types文件中，降低了耦合性。</li>
</ul>
<h3 id="2-数值单位"><a href="#2-数值单位" class="headerlink" title="2. 数值单位"></a>2. 数值单位</h3><p><strong>Nginx框架为了提高模块解析指令选项的效率，提供了一系列通用的工具函数，绝大多数模块都会使用它们</strong>，毕竟这降低了模块开发的难度以及用户的学习成本。比如，当配置文件中包含字节数时，Nginx框架提供了ngx_conf_set_size_slot函数， 各模块通过它就可以解析以下单位：</p>
<table>
<thead>
<tr>
<th>空间单位</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>k/K</td>
<td>KB</td>
</tr>
<tr>
<td>m/M</td>
<td>MB</td>
</tr>
<tr>
<td>g/G</td>
<td>GB</td>
</tr>
</tbody></table>
<p>因此，limit_req_zone指令中zone=one:10m中就定义10MB的共享内存，这替代了很不好理解的10485760字节。</p>
<p>再比如，读取时间可以使用以下单位：</p>
<table>
<thead>
<tr>
<th>时间单位</th>
<th>意义</th>
</tr>
</thead>
<tbody><tr>
<td>ms</td>
<td>毫秒</td>
</tr>
<tr>
<td>s</td>
<td>秒</td>
</tr>
<tr>
<td>m</td>
<td>分钟</td>
</tr>
<tr>
<td>h</td>
<td>小时</td>
</tr>
<tr>
<td>d</td>
<td>天</td>
</tr>
<tr>
<td>w</td>
<td>周</td>
</tr>
<tr>
<td>M</td>
<td>月</td>
</tr>
<tr>
<td>y</td>
<td>年</td>
</tr>
</tbody></table>
<p>这样，ssl_session_cache shared:SSL:2h;指令就设置TLS会话信息缓存2小时后过期。</p>
<p>除以上规则外，如果编译了pcre开发库后，你还可以在nginx.conf中使用正则表达式，它们通常以~符号打头。</p>
<h2 id="如何使用Nginx配置文件？"><a href="#如何使用Nginx配置文件？" class="headerlink" title="如何使用Nginx配置文件？"></a>如何使用Nginx配置文件？</h2><p>掌握了语法规则后，nginx.conf配置文件究竟是放在哪里的呢？</p>
<p>编译Nginx时，configure脚本的–prefix选项可以设置Nginx的运行路径，比如：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./configure –prefix=/home/nginx</span><br></pre></td></tr></table></figure>

<p>此时，安装后的Nginx将会放在/home/nginx目录，而配置文件就会在/home/nginx/conf目录下。</p>
<p>如果你没有显式的指–prefix选项，默认路径就是/usr/local/nginx。由于OpenResty修改了configure文件，因此它的默认路径是/usr/local/openresty/nginx。在默认路径确定后，nginx.conf配置文件就会放在conf子目录中。当然，通过–conf-path选项，你可以分离它们。</p>
<p>另外在运行Nginx时，你还可以通过nginx -c PATH/nginx.conf选项，指定任意路径作为Nginx的配置文件。</p>
<p>由于配置语法比较复杂，因此Nginx为<a href="https://zh.wikipedia.org/zh-hans/Vim">vim编辑器</a>准备了语法高亮功能。在Nginx源代码中，你可以看到contrib目录，其中vim子目录提高了语法高亮功能：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[contrib]<span class="comment"># tree vim</span></span><br><span class="line">vim</span><br><span class="line">-- ftdetect</span><br><span class="line"> `-- nginx.vim</span><br><span class="line">-- ftplugin</span><br><span class="line"> `-- nginx.vim</span><br><span class="line">-- indent</span><br><span class="line"> `-- nginx.vim</span><br><span class="line">`-- syntax</span><br><span class="line">`-- nginx.vim</span><br></pre></td></tr></table></figure>

<p>当你将contrib/vim/* 复制到<del>/.vim/目录时（</del>表示你当前用户的默认路径，如果.vim目录不存在时，请先用mkdir创建），再打开nginx.conf你就会发现指令已经高亮显示了：</p>
<p><a href="/2020/12/nginx-vim%E8%AF%AD%E6%B3%95%E9%AB%98%E4%BA%AE.png"><img src="/2020/12/nginx-vim%E8%AF%AD%E6%B3%95%E9%AB%98%E4%BA%AE.png"></a></p>
<p>出于可读性考虑，你或许会将include文件放在其他路径下，此时再用vim打开这些子配置文件，可能没有语法高亮效果。这是因为contrib/vim/ftdetect/nginx.vim文件定义了仅对4类配置文件使用语法高亮规则：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">//对所有.nginx后缀的配置文件语法高亮</span><br><span class="line">au BufRead,BufNewFile *.nginx <span class="built_in">set</span> ft=nginx</span><br><span class="line"></span><br><span class="line">//对/etc/nginx/目录下的配置文件语法高亮</span><br><span class="line">au BufRead,BufNewFile */etc/nginx/* <span class="built_in">set</span> ft=nginx</span><br><span class="line"></span><br><span class="line">//对/usr/<span class="built_in">local</span>/nginx/conf/目录下的配置文件语法高亮</span><br><span class="line">au BufRead,BufNewFile */usr/<span class="built_in">local</span>/nginx/conf/* <span class="built_in">set</span> ft=nginx</span><br><span class="line"></span><br><span class="line">//对任意路径下，名为nginx.conf的文件语法高亮</span><br><span class="line">au BufRead,BufNewFile nginx.conf <span class="built_in">set</span> ft=nginx</span><br></pre></td></tr></table></figure>

<p>因此，你可以将这类文件的后缀名改为.nginx，或者将它们移入/etc/nginx/、/usr/local/nginx/conf/目录即可。当然，你也可以向ftdetect/nginx.vim添加新的识别目录。</p>
<p>即使拥有语法高亮功能，对于生产环境中长达数百、上千行的nginx.conf，仍然难以避免出现配置错误。这时可以通过nginx -t或者nginx -T命令，检查配置语法是否正确。出现错误时，<strong>Nginx会在屏幕上给出错误级别、原因描述以及到底是哪一行配置出现了错误</strong>。例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nginx -t</span></span><br><span class="line">nginx: [emerg] directive <span class="string">&quot;location&quot;</span> has no opening <span class="string">&quot;&#123;&quot;</span> <span class="keyword">in</span> /usr/<span class="built_in">local</span>/nginx/conf/notflowlocation.conf:1281</span><br><span class="line">nginx: configuration file /usr/<span class="built_in">local</span>/nginx/conf/nginx.conf <span class="built_in">test</span> failed</span><br></pre></td></tr></table></figure>

<p>从上面的错误信息中，我们知道Nginx解析配置文件失败，错误发生在include的子配置文件/usr/local/nginx/conf/notflowlocation.conf的第1281行，从描述上推断是location块的配置出现了错误，可能是缺失了大括号，或者未转义的字符导致无法识别出大括号。</p>
<p>当你修改完配置文件后，可以通过nginx -s reload命令重新载入指令。这一过程不会影响正在服务的TCP连接，在描述Nginx进程架构的文章中，我会详细解释其原因。</p>
<h2 id="搭建静态资源服务，root与alias有何不同？"><a href="#搭建静态资源服务，root与alias有何不同？" class="headerlink" title="搭建静态资源服务，root与alias有何不同？"></a>搭建静态资源服务，root与alias有何不同？</h2><p>接下来我们以root和alias指令为例，看看如何掌握配置指令的使用方法。</p>
<p><strong>配置指令的说明，被放置在它所属Nginx模块的帮助文档中</strong>。因此，如果你对某个指令不熟悉，要先找到所属模块的说明文档。对于官方模块，你可以进入nginx.org站点查找。搭建静态资源服务的root/alias指令是由ngx_http_core_module模块实现的，因此，我们可以进入<a href="http://nginx.org/en/docs/http/ngx_http_core_module.html">http://nginx.org/en/docs/http/ngx_http_core_module.html</a>页面寻找指令介绍，比如root指令的介绍如下所示：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:root path;</span><br><span class="line">Default: root html;</span><br><span class="line">Context:http, server, location, if in location</span><br></pre></td></tr></table></figure>

<p>这里Syntax、Default、Context 3个关键信息，是所有Nginx配置指令共有的，下面解释下其含义：</p>
<ul>
<li>  Syntax：表示指令语法，包括可以跟几个选项，每个选项的单位、分隔符等。root path指令，可以将URL映射为磁盘访问路径path+URI，比如URL为/img/a.jpg时，磁盘访问路径就是html/img/a.jpg。</li>
</ul>
<p>注意，这里path既可以是相对路径，也可以是绝对路径。作为相对路径，path的前缀路径是由configure –prefix指定，也可以在运行时由nginx -p path指定。</p>
<ul>
<li>  Default：表示选项的默认值，也就是说，即使你没有在nginx.conf中写入root指令，也相当于配置了root html;</li>
<li>  Context：表示指令允许出现在哪些配置块中。比如root可以出现在server{}中，而alias则只能出现在location{}中。为什么root指令的Context，允许其出现在http{ }、server{ }、location { }、if { }等多个配置块中呢?</li>
</ul>
<p>这是因为，Nginx允许多个配置块互相嵌套时，相同指令可以向上继承选项值。例如下面两个配置文件是完全等价的：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">  <span class="attribute">root</span> html;</span><br><span class="line">    <span class="attribute">location</span> / &#123;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server&#123;</span><br><span class="line">  <span class="attribute">root</span> html;</span><br><span class="line">  <span class="attribute">location</span> / &#123;</span><br><span class="line">    <span class="attribute">root</span> html;</span><br><span class="line">  &#125;</span><br><span class="line">｝</span><br></pre></td></tr></table></figure>

<p>这种向上承继机制，可以简化Nginx配置文件。因此，使用root指令后，不用为每个location块重复写入root指令。相反，alias指令仅能放置在location块中，这与它的使用方式有关：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Syntax:alias path;</span><br><span class="line">Default:—</span><br><span class="line">Context:location</span><br></pre></td></tr></table></figure>

<p>alias的映射关系与其所属的location中匹配的URI前缀有关，比如当HTTP请求的URI为/a/b/c.html时，在如下配置中，实际访问的磁盘路径为/d/b/c.html：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">location</span> /a &#123;</span><br><span class="line">  <span class="attribute">alias</span> /d;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因此，<strong>当URI中含有磁盘路径以外的前缀时，适合使用alias指令。反之，若完整的URI都是磁盘路径的一部分时，则不妨使用root指令</strong>。学习其他指令时，如果你不清楚它属于哪一个模块，还可以<strong>查看以字母表排序的指令索引</strong><a href="http://nginx.org/en/docs/dirindex.html">http://nginx.org/en/docs/dirindex.html</a>页面，点击后会进入所属模块的指令介绍页面。</p>
<p>如果是第三方模块，通常在README文件中会有相应的指令介绍。比如OpenResty模块的指令会放在GitHub项目首页的README文件中：</p>
<p><a href="http://www.taohui.pub/2020/12/23/%e4%bb%8e%e9%80%9a%e7%94%a8%e8%a7%84%e5%88%99%e4%b8%ad%e5%ad%a6%e4%b9%a0nginx%e6%a8%a1%e5%9d%97%e7%9a%84%e5%ae%9a%e5%88%b6%e6%8c%87%e4%bb%a4/%e7%ac%ac%e4%b8%89%e6%96%b9%e6%a8%a1%e5%9d%97%e8%af%b4%e6%98%8e%e6%96%87%e6%a1%a3/"><img src="/2020/12/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.png"></a></p>
<p>而TEngine模块的指令介绍则会放在tengine.taobao.org网站上：</p>
<p><a href="/2020/12/tengine%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.png"><img src="/2020/12/tengine%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.png"></a></p>
<p>从这两张截图中可以看到，第三方模块在解释指令的用法时，同样遵循着上文介绍过的方式。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文介绍了Nginx配置文件的使用方法。</p>
<p>学习Nginx的通用语法时，要先掌握Nginx框架解析配置文件的5条基本规则，这样就能读懂nginx.conf的整体结构。其次，当模块指令包含时间、空间单位时，会使用Nginx框架提供的通用解析工具，熟悉这些时、空单位会降低你学习新指令的成本。</p>
<p>配置文件的位置，可以由编译期configure脚本的—prefix、–conf-path选项指定，也可以由运行时的-p选项指定。复杂的配置文件很容易出错，通过nginx -t/T命令可以检测出错误，同时屏幕上会显示出错的文件、行号以及原因，方便你修复Bug。</p>
<p>用vim工具编辑配置文件时，将Nginx源码中contrib/vim/目录复制到~/.vim/目录，就可以打开语法高亮功能。对于子配置文件，只有放置在/etc/nginx或者/usr/local/nginx/conf目录中，或者后缀为.nginx时，才会高亮显示语法。当然，你可以通过ftdetect/nginx.vim文件修改这一规则。</p>
<p>学习模块指令时，要从它的帮助文档中找到指令的语法、默认值、上下文和描述信息。比如，root和alias的语法相似，但alias没有默认值，仅允许出现在location上下文中，这实际上与它必须结合URI前缀来映射磁盘路径有关。</p>
<p><strong>由于每个Nginx模块都能定义独特的指令，这让nginx.conf变成了复杂的运维界面。在掌握了基本的配置语法，以及第三方模块定义指令时遵循的潜规则后，你就能游刃有余地编写Nginx配置文件。</strong></p>
]]></content>
      <categories>
        <category>web</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>时间单位</tag>
        <tag>空间单位</tag>
        <tag>配置语法</tag>
      </tags>
  </entry>
  <entry>
    <title>公开课：用nginx搭建waf防火墙的实践</title>
    <url>/2021/05/19/nginx/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B%EF%BC%9A%E7%94%A8nginx%E6%90%AD%E5%BB%BAwaf%E9%98%B2%E7%81%AB%E5%A2%99%E7%9A%84%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>WAF全称为Web Application Firewall，因此作为七层负载均衡的Nginx很适合实现Web应用层防火墙。许多C、Lua模块都在rewrite、access等处理阶段截获HTTP请求，基于可配置的规则过滤内容并判断安全后，再放行给content阶段的反向代理模块转发到上游服务。本次4节课我将从Web攻击方式讲起，看看Nginx是如何用作反向代理型WAF的。<br><img src="/images/waf/WAF%E9%98%B2%E7%81%AB%E5%A2%99.png"></p>
<span id="more"></span>


<h1 id="12月03日：waf应用层攻击对抗详解"><a href="#12月03日：waf应用层攻击对抗详解" class="headerlink" title="12月03日：waf应用层攻击对抗详解"></a>12月03日：waf应用层攻击对抗详解</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=885856066&bvid=BV19K4y1V7mH&cid=272041997&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="12月10日：恶意http请求的甄别"><a href="#12月10日：恶意http请求的甄别" class="headerlink" title="12月10日：恶意http请求的甄别"></a>12月10日：恶意http请求的甄别</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=330753616&bvid=BV1rA411s76B&cid=272047326&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="12月17日：恶意客户端的防御控制"><a href="#12月17日：恶意客户端的防御控制" class="headerlink" title="12月17日：恶意客户端的防御控制"></a>12月17日：恶意客户端的防御控制</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=885781481&bvid=BV1AK4y1j7LY&cid=272047993&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="12月24日：降低waf防火墙的性能损耗"><a href="#12月24日：降低waf防火墙的性能损耗" class="headerlink" title="12月24日：降低waf防火墙的性能损耗"></a>12月24日：降低waf防火墙的性能损耗</h1>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
<iframe src="//player.bilibili.com/player.html?aid=203273208&bvid=BV17h411f79U&cid=272053712&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</div>


<h1 id="课件下载"><a href="#课件下载" class="headerlink" title="课件下载"></a>课件下载</h1><p>这四次课程的PPT在这里：<a href="/pdf/%E7%AC%AC%E4%B8%83%E5%AD%A3.-%E7%94%A8nginx%E6%90%AD%E5%BB%BAwaf%E9%98%B2%E7%81%AB%E5%A2%99%E7%9A%84%E5%AE%9E%E8%B7%B5.pdf" title="第七季.-用nginx搭建waf防火墙的实践">点击下载</a> 。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>waf</tag>
        <tag>ddos</tag>
        <tag>限流限速</tag>
        <tag>CSRF</tag>
        <tag>XXE</tag>
        <tag>XXS</tag>
        <tag>点击劫持</tag>
        <tag>CRLF攻击</tag>
      </tags>
  </entry>
  <entry>
    <title>在这里，NGINX 创始人 Igor Sysoev 将亲述 NGINX 的诞生史</title>
    <url>/2020/04/30/nginx/%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%8Cnginx-%E5%88%9B%E5%A7%8B%E4%BA%BA-igor-sysoev-%E5%B0%86%E4%BA%B2%E8%BF%B0-nginx-%E7%9A%84%E8%AF%9E%E7%94%9F%E5%8F%B2/</url>
    <content><![CDATA[<blockquote>
<p>2020 年 5 月 20 日，一场 NGINX 在国内的盛会、一个所有 NGINX 用户 &amp; 爱好者朝圣的最佳场所，F5 线上技术峰会 - NGINX 专场将以线上直播的形式面向所有开发者召开。届时各位 NGINX 开发者心目中的偶像 NGINX 创始人 Igor Sysoev 以及国内 NGINX 技术专家陶辉老师将空降大会现场，从 NGXIN 创始人的成长经历出发，帮助每一位开发者来重新理解 NGINX 的前世今生。  </p>
</blockquote>
<p>如果想让产品在支持高并发请求的同时保持高效的服务，NGINX 可能是最好的选择。这并非一句玩笑话，而是经过全球技术人多年来技术实践后所得出的结论。NGINX 就像一个万能药，在任何存在性能需求的场合都能找到它的身影，它可以在百万并发链接中实现高吞吐量的 Web 服务。然而即便是这样，NGINX 却至今缺少一个能够将所有 NGINX 用户聚集起来的官方场所，这对于像这样一个如此受欢迎的开源产品来说是很不常见的，而这也是此次大会之下的重头戏之一。扫描下图二维码或点击阅读原文链接即可免费报名！</p>
<span id="more"></span>
<p><a href="/2020/04/30/%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%8Cnginx-%E5%88%9B%E5%A7%8B%E4%BA%BA-igor-sysoev-%E5%B0%86%E4%BA%B2%E8%BF%B0-nginx-%E7%9A%84%E8%AF%9E%E7%94%9F%E5%8F%B2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200430083818/"><img src="/2020/04/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200430083818.jpg"></a>NGINX 现在已经成为了众多企业后台架构的核心，许多企业都将 NGINX 用作承担所有来自 Web 服务的业务流量负载，也将其用作全球数百万台服务  器上的反向代理，能够支撑业务数以百万级别的高并发。这样一款自由的、开源的、高性能的 HTTP 服务器和反向代理软件，在企业“数字化转型概念”大行其道的今天，NGINX 能力给企业的后台架构带来了极大的稳定性，更是成为企业实现数字转型的必备利器。</p>
<h1 id="1对于企业来说，NGINX-是实现数字转型的有效途径"><a href="#1对于企业来说，NGINX-是实现数字转型的有效途径" class="headerlink" title="1对于企业来说，NGINX 是实现数字转型的有效途径"></a>1对于企业来说，NGINX 是实现数字转型的有效途径</h1><blockquote>
<p>NGINX 是实现技术突破的必要工具。</p>
</blockquote>
<p>随着 2020 年的魔幻开局，国内众多行业都受到了不小的冲击，疫情期间人人自危，企业复工困难，上下游供应链有一端没有恢复就不能真的恢复业务；像疫情这种黑天鹅事件是完全不可预测的。对于企业而言现在正处于一个模糊的、不确定的、快速变化的时代，在这种 VUCA 时代特征下出现这种状况可以说既是意外又不是意外。对于企业的影响一方面取决于该行业的特点，另外一方面企业所做出反应状况的不同也会形成不一样的结果。 随之而来的就是许多线下业务被迫转移线上，然而看起来只是一场非常简单的业务迁移，但在后台架构看来，却是一场对企业自身、以及企业后台面对流量、并发与架构稳定性的挑战。 首先是业务场景的变换。从线下切换至线上，不只是业务呈现形式的变更，其更涉及到企业内部更深处的平台建设、流程规划、人员培训等一系列内容。 其次是现有的技术能力难以支撑。随着线下业务的大量取消，越来越多的用户开始涌入线上平台，这对企业的后端架构能力提出了更高的要求，要在能够稳定承受流量高并发的同时还能兼顾后台性能的稳定性。然而这对众多专注在线下业务的企业来说，要在短时间内把线上平台打造为这样一款高性能的平台，的确有点难为他们。 这也显示出当下的一个痛点，场景的突然转变驱使着企业去选择具备更加高性能、更加高效的处理平台，而对于企业的现实情况来说，线上的高并发表示其急需平台下的高性能 web 服务。 而这，恰好是 NGINX 的长处。为什么这么说？因为相较于传统 ADC，NGINX 具有以下几点优势：</p>
<p>1、采用事件驱动的异步框架</p>
<p>基于异步及非阻塞的事件驱动模型，可以说是 NGINX 得以获得高并发、高性能的关键因素。因为一个 HTTP/HTTPS 请求包括多个阶段，每一个阶段在什么时候发生是不确定的，这就造成了异步性。每一个阶段的发生都会触发事件驱动框架，然后交由事件消费者处理，也就是说一个事件消费者仅仅是处理了一个请求中的一小部分。NGINX 采用事件驱动的设计来减少进程休眠的几率，从而实现提高网络性能、减少请求延时以及支撑高并发的能力。</p>
<p>2、反向代理</p>
<p>有正向代理自然就存在反向代理。正向代理是指以请求端也就是客户端的角度为正向，用户发出请求经过的代理，称为“正向代理”。反向代理则恰恰相反，是由代理选择服务端节点。存在即合理，反向代理的存在也表明其拥有着不可替代优势：</p>
<ul>
<li>  首先能够通过隐藏服务节点的 IP 来保护服务安全，此外也可以通过将服务节点置于防火墙之后来确保业务节点服务器不会被直接攻击到。</li>
<li>  其次反向代理可以让服务节点更加专注于业务，一些 HTTPS、压缩等于业务无关的能力可以交由反向代理服务器去实现，从而避免浪费业务服务节点处理请求的能力。</li>
<li>  最后反向代理服务器能够提供额外的缓存机制，将一些短时间内不会变化的动态内容储存在缓存中，降低业务服务器的请求量；</li>
</ul>
<p>正是由于 NGINX 引入了反向代理的特性，让请求和响应都要经过 NGINX，因此也给 NGINX 带来了诸如负载均衡、HTTP 缓存等能力。</p>
<p>3、负载均衡</p>
<p>“准备超越当前 ADC 的功能了吗？”这是在 NGINX 官网负载均衡功能介绍页面非常醒目的一句话，这无疑显示了 NGINX 在这方面的雄厚实力与决心。负载均衡就是将请求“均衡”地分配到多台业务节点服务器上。这里的“均衡”是依据实际场景和业务需要而定的。对于 NGINX 来说，请求到达 NGINX，NGINX 作为反向代理服务器，有绝对的决策权，可以按照规则将请求分配给它知道的节点中的一个，通过这种分配，使得所有节点需要处理的请求量处于相对平均的状态，从而实现负载均衡。</p>
<p>4、HTTP 缓存</p>
<p>浏览器缓存是前端开发中经常遇到的问题，它是提升性能同时减少服务器压力的有效手段之一。NGINX 可以作为静态页面的 web 服务器，同时还支持 CGI 协议的动态语言，比如 perl、PHP 等。 而综合上述总结的几点 NGINX 优势，NGINX 无疑是最合适的那个打造高性能平台的工具。然而虽然它很火，但往往流行程度和开发者的掌握程度是不相等的。尤其是在众多业务转型线上，越来越多的企业认识到 NGINX 对于业务支撑的重要性，作为开发者，掌握 NGINX 开发能力似乎已经成为了“必修课”。 然而开发者在应用 NGINX 的过程中往往会遇到各种问题，国内 NGINX 技术专家陶辉曾经总结过，大多数人使用 NGINX 都停留在这几个级别：</p>
<ul>
<li>  第一种：使用 NGINX 配置最简单的反向代理服务或者静态资源服务，当扩展功能时发现新增的指令 NGINX 不支持，但又不懂如何增加 NGINX 模块，如何分析 access 日志。</li>
<li>  第二种：可以根据源码定制安装 NGINX，对网上流传的大众配置做一些个性化的修改，但遇到修改 proxy_pass 后的 URL 上游服务不正常等问题时就束手无策，不清楚 NGINX 各个目录的意义，也不清楚 NGINX 的进程结构。</li>
<li>  第三种：能够顺畅地使用 NGINX 的常用功能，但不清楚第三方模块发生冲突时的解决方案、stale 过期缓存的用法、NGINX 诸多变量是如何被赋值的、听说 if 指令是邪恶的却不知道它的设计理念及正确用法等等。</li>
<li>  第四种：可以正确地使用 NGINX 的功能及第三方模块，并按照网络上常见的优化参数优化性能，但对如何系统化地优化性能没有头绪，对于 NGINX、Linux 提供的内存缓冲区、网络类等诸多指令和参数的优化没有头绪。</li>
<li>  第五种：可以熟练使用 NGINX，但对各第三方功能模块如何与 NGINX 结合使用以及对 NGINX 性能影响不太清楚，对 NGINX 源码的理解没有达到由点到面的程度。</li>
</ul>
<p>但这还只是冰山一角，NGINX 技术所涵盖的范围之广超出我们每一个人的想象。作为一款全球最受欢迎的开源产品之一，NGINX 的一举一动都受到了来自全球开发者的重点关注。</p>
<h1 id="2NGINX-在中国又有大动作了"><a href="#2NGINX-在中国又有大动作了" class="headerlink" title="2NGINX 在中国又有大动作了"></a>2NGINX 在中国又有大动作了</h1><p>2020 年 5 月 20 日（星期三），F5 以线上峰会的形式召开 F5 Code to Customer 2020 代码到用户暨 F5 中国 20 周年纪念庆典。届时，各位 NGINX 开发者心目中的偶像 NGINX 创始人 Igor Sysoev 以及国内 NGINX 技术专家陶辉老师将空降大会现场，从 NGXIN 创始人的成长经历出发，帮助每一位开发者来重新理解 NGINX 的前世今生。 另外备受开发者关注的 NGXIN 开源社区也将在大会现场正式成立，至此，NGINX 开发者终于有一个官方的“家”。此外本次大会更设有 5 大技术专题论坛、30+ 技术内容深度解读以及 100+ 解决方案，足以满足你对数字转型技术趋势的渴望。</p>
<h1 id="3关于-NGINX-中国开源社区"><a href="#3关于-NGINX-中国开源社区" class="headerlink" title="3关于 NGINX 中国开源社区"></a>3关于 NGINX 中国开源社区</h1><p>NGINX 开源社区是 F5/NGINX 面向所有 NGINX 用户的官方社区。我们秉持“开放，包容，沟通，贡献“ （open，inclusive，connect，contribution） 之宗旨，与业界共建开放、包容、活跃的“NGINX 用户之家“；秉承开源的精神，在社区治理上高度开放，为所有 NGINX 的用户，开发者和技术爱好者，提供一个方便学习、讨论的场所。也期待您成为此社区中活跃的一员，贡献您的文章，博客，代码，踊跃讨论与回答问题，打造您个人品牌和影响力。 2019 年 3 月，云计算和安全应用服务公司 F5 Networks Inc 宣布收购 NGINX，NGINX 是应用交付领域的开源领导者。 <a href="/2020/04/30/%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%8Cnginx-%E5%88%9B%E5%A7%8B%E4%BA%BA-igor-sysoev-%E5%B0%86%E4%BA%B2%E8%BF%B0-nginx-%E7%9A%84%E8%AF%9E%E7%94%9F%E5%8F%B2/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200430083814/"><img src="/2020/04/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200430083814.jpg"></a></p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>F5</tag>
        <tag>Igor Sysoev</tag>
      </tags>
  </entry>
  <entry>
    <title>如何configure定制出属于你的Nginx？</title>
    <url>/2020/12/22/nginx/%E5%A6%82%E4%BD%95configure%E5%AE%9A%E5%88%B6%E5%87%BA%E5%B1%9E%E4%BA%8E%E4%BD%A0%E7%9A%84nginx%EF%BC%9F/</url>
    <content><![CDATA[<p>上一篇<a href="https://www.taohui.pub/2020/12/17/10%e5%88%86%e9%92%9f%e5%bf%ab%e9%80%9f%e8%ae%a4%e8%af%86nginx/">文章</a>中，我介绍了Nginx的特性，如何获取Nginx源代码，以及源代码中各目录的含义。本文将介绍如何定制化编译、安装、运行Nginx。 </p>
<p>当你用yum或者apt-get命令安装、启动Nginx后，通过nginx -t命令你会发现，nginx.conf配置文件可能在/etc/目录中。而运行基于源码安装的Nginx时，nginx.conf文件又可能位于/usr/local/nginx/conf/目录，运行OpenResty时， nginx.conf又被放在了/usr/local/openresty/nginx/conf/目录。<strong>这些奇怪的现象都源于编译Nginx前，configure脚本设置的–prefix或者–conf-path选项</strong>。 </p>
<span id="more"></span>
<p>Nginx的所有功能都来自于官方及第三方模块，<strong>如果你不知道如何使用configure添加需要的模块，相当于放弃了Nginx诞生16年来累积出的丰富生态</strong>。而且，很多高性能特性默认是关闭的，如果你习惯于使用应用市场中编译好的二进制文件，也无法获得性能最优化的Nginx。 本文将会介绍定制Nginx过程中，configure脚本的用法。其中对于定制模块的选项，会从模块的分类讲起，带你系统的掌握如何添加Nginx模块。同时，也会介绍configure执行后生成的objs目录，以及Makefile文件的用法。这也是Nginx开源社区基础培训系列课程第一季，即6月11日晚第2次视频直播课前半部分的文字总结。  </p>
<h2 id="configure脚本有哪些选项？"><a href="#configure脚本有哪些选项？" class="headerlink" title="configure脚本有哪些选项？"></a>configure脚本有哪些选项？</h2><p>在Linux系统（包括各种类Unix操作系统）下，编译复杂的C语言软件工程是由Makefile文件完成的。<strong>你一定注意到Nginx源码中并没有Makefile文件，这是因为Makefile是由configure脚本即时生成的</strong>。接下来我们看看，configure脚本悄悄的做了哪些事，这些工作又会对Nginx产生哪些影响。   configure脚本支持很多选项，掌握它们就可以灵活的定制Nginx。为了方便理解，从功能上我把它们分为5类：</p>
<ul>
<li>  <strong>改变Nginx编译、运行时各类资源的默认存取路径</strong></li>
</ul>
<p>configure既可以设置Nginx运行时各类资源的默认访问路径，也可以设置编译期生成的临时文件存放路径。比如：</p>
<ul>
<li>  --error-log-path=定义了运行期出现错误信息时写入log日志文件的路径。</li>
<li>  --http-log-path=定义了运行期处理完HTTP请求后，将执行结果写入log日志文件的路径。</li>
<li>  --http-client-body-temp-path=定义了运行期Nginx接收客户端的HTTP请求时，存放包体的磁盘路径。</li>
<li>  --http-proxy-temp-path=定义了运行期负载均衡使用的Nginx，临时存放上游返回HTTP包体的磁盘路径。</li>
<li>  --builddir=定义了编译期生成的脚本、源代码、目标文件存放的路径。</li>
</ul>
<p>等等。 对于已经编译好的Nginx，可以通过nginx -V命令查看设置的路径。<strong>如果没有显式的设置选项，Nginx便会使用默认值，例如官方Nginx将–prefix的默认值设为/usr/local/nginx，而OpenResty的configure脚本则将–prefix的默认值设为/usr/local/openresty/nginx</strong>。  </p>
<ul>
<li>  <strong>改变编译器选项</strong></li>
</ul>
<p>Nginx由C语言开发，因此默认使用的C编译器，由于C++向前兼容C语言，如果你使用了C++编写的Nginx模块，可以通过–cc-opt等选项，将C编译器修改为C++编译器，这就可以支持C++语言了。 Nginx编译时使用的优化选项是-O，如果你觉得这样优化还不够，可以调大优化级别，比如OpenResty就将gcc的优化调整为-O2。当某些模块依赖其他软件库才能实现需求时，也可以通过–with-ld-opt选项链接其他库文件。  </p>
<ul>
<li>  <strong>修改编译时依赖的中间件</strong></li>
</ul>
<p>Nginx执行时，会依赖pcre、openssl、zlib等中间件，实现诸如正则表达式解析、TLS/SSL协议处理、解压缩等功能。通常，编译器会自动寻找系统默认路径中的软件库，但当系统中含有多个版本的中间件时，就可以人为地通过路径来指定版本。比如当我们需要使用最新的TLS1.3时，可以下载最新的openssl源码包，再通过–with-openssl=选项指定源码目录，让Makefile使用它去编译Nginx。  </p>
<ul>
<li>  <strong>选择编译进Nginx的模块</strong></li>
</ul>
<p><strong>Nginx是由少量的框架代码、大量的C语言模块构成的</strong>。当你根据业务需求，需要通过某个模块实现相应的功能时，必须先通过configure脚本将它编译进Nginx（Nginx被设计为按需添加模块的架构），之后你才能在nginx.conf配置文件中启用它们。下一小节我会详细介绍这部分内容。  </p>
<ul>
<li>  <strong>其他选项</strong></li>
</ul>
<p>还有些不属于上述4个类别的选项，包括：</p>
<ul>
<li>  定位问题时，最方便的是通过log查看DEBUG级别日志，而打开调试日志的前提，是在configure时加入–with-debug选项。</li>
<li>  HTTP服务是默认打开的，如果你想禁用HTTP或者HTTP缓存服务，可以使用–without-http和–without-http-cache选项。</li>
<li>  大文件读写磁盘时，并不适宜使用正常的read/write系统调用，因为文件内容会写入PageCache磁盘高速缓存。由于PageCache空间有限，而大文件会迅速将可能高频命中缓存的小文件淘汰出PageCache，同时大文件自身又很难享受到缓存的好处。因此，在Linux系统中，可以通过异步IO、直接IO来处理文件。但开启Linux原生异步IO的前提，是在configure时加入–with-file-aio选项。</li>
<li>  开启IPv6功能时，需要加入–with-ipv6选项。</li>
<li>  生产环境中，需要使用master/worker多进程模式运行Nginx。master是权限更高的管理进程，而worker则是处理请求的工作线程，它的权限相对较低。通过–user=和–group=选项可以指定worker进程所属的用户及用户组，当然，你也可以在conf中通过user和group指令修改它。</li>
</ul>
<p>  在大致了解configure提供的选项后，下面我们重点看下如何定制Nginx模块。</p>
<h2 id="如何添加Nginx模块？"><a href="#如何添加Nginx模块？" class="headerlink" title="如何添加Nginx模块？"></a>如何添加Nginx模块？</h2><p>编译Nginx前，我们需要决定添加哪些模块。<strong>在定制化模块前，只有分清了模块的类别才能系统的掌握它们</strong>。Nginx通常可以分为6类模块，包括：</p>
<ul>
<li>  核心模块：有限的7个模块定义了Nginx最基本的功能。需要注意，<strong>核心模块并不是默认一定编译进Nginx</strong>，例如只有在configure时加入–with-http_ssl_module或者–with-stream_ssl_modul选项时，ngx_openssl_module核心模块才会编译进Nginx。</li>
<li>  配置模块：仅包括ngx_conf_module这一个模块，负责解析conf配置文件。</li>
<li>  事件模块：Nginx采用事件驱动的异步框架来处理网络报文，它支持epoll、poll、select等多种事件驱动方式。目前，epoll是主流的事件驱动方式，选择事件驱动针对的是古董操作系统。</li>
<li>  HTTP模块：作为Web服务器及七层负载均衡，Nginx最复杂的功能都由HTTP模块实现，稍后我们再来看如何定制HTTP模块。</li>
<li>  STREAM模块：负责实现四层负载功能，默认不会编译进Nginx。你可以通过–with-stream启用STREAM模块。</li>
<li>  MAIL模块：Nginx也可以作为邮件服务器的负载均衡，通过–with-mail选项启用。</li>
</ul>
<p><a href="/2020/12/22/%E5%A6%82%E4%BD%95configure%E5%AE%9A%E5%88%B6%E5%87%BA%E5%B1%9E%E4%BA%8E%E4%BD%A0%E7%9A%84nginx%EF%BC%9F/nginx%E6%A8%A1%E5%9D%97%E5%8C%96/"><img src="/2020/12/Nginx%E6%A8%A1%E5%9D%97%E5%8C%96.png"></a> 在上图中，HTTP模块又可以再次细分为3类模块：</p>
<ul>
<li>  请求处理模块：Nginx接收、解析完HTTP报文后，会将请求交给各个HTTP模块处理。比如读取磁盘文件并发送到客户端的静态资源功能，就是由ngx_http_static_module模块实现的。为了方便各模块间协同配合，Nginx将HTTP请求的处理过程分为11个阶段，如下图所示：</li>
</ul>
<p><a href="/2020/12/22/%E5%A6%82%E4%BD%95configure%E5%AE%9A%E5%88%B6%E5%87%BA%E5%B1%9E%E4%BA%8E%E4%BD%A0%E7%9A%84nginx%EF%BC%9F/11%E4%B8%AAhttp%E9%98%B6%E6%AE%B5%E8%A1%A8/"><img src="/2020/12/11%E4%B8%AAHTTP%E9%98%B6%E6%AE%B5%E8%A1%A8.png"></a></p>
<ul>
<li>  响应过滤模块：当上面的请求处理模块生成合法的HTTP响应后，将会由各个响应过滤模块依次对HTTP头部、包体做加工处理。比如返回HTML、JS、CSS等文本文件时，若配置了gzip on;指令，就可以添加content-encoding: gzip头部，并使用zlib库压缩包体。</li>
<li>  upstream负载均衡模块：当Nginx作为反向代理连接上游服务时，允许各类upstream模块提供不同的路由策略，比如ngx_http_upstream_hash_module模块提供了哈希路由，而ngx_http_upstream_keepalive_module模块则允许复用TCP连接，降低握手、慢启动等动作提升的网络时延。</li>
</ul>
<p>  对于这3类模块，你可以从模块名中识别，比如模块中出现filter和http字样，通常就是过滤模块，比如ngx_http_gzip_filter_module。如果模块中出现upstream和http字样，就是负载均衡模块。 我们可以使用–with-模块名，将其编译进Nginx，也可以通–without-模块名，从Nginx中移出该模块。需要注意的是，当你通过configure –help帮助中看到–with-打头的选项，都是默认不编译进Nginx的模块，反之，–without-打头的选项，则是默认就编译进Nginx的模块。 还有一些HTTP模块并不属于上述3个类别，比如–with-http_v2_module是加入支持HTTP2协议的模块。<strong>当你需要添加第三方模块时，则可以通过–add-module=或者–add-dynamic-module=（动态模块将在后续文章中再介绍）选项指定模块源码目录，这样就可以将它编译进Nginx</strong>。  </p>
<h2 id="如何安装并运行Nginx？"><a href="#如何安装并运行Nginx？" class="headerlink" title="如何安装并运行Nginx？"></a>如何安装并运行Nginx？</h2><p>当configure脚本根据指定的选项执行时，会自动检测体系架构、系统特性、编译器、依赖软件等环境信息，并基于它们生成编译Nginx工程的Makefile文件。同时，还会生成objs目录，我们先来看看objs目录中有些什么：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">objs</span><br><span class="line">-- autoconf.err            <span class="comment">#configure自动检测环境时的执行纪录</span></span><br><span class="line">-- Makefile                 <span class="comment">#编译C代码用到的脚本</span></span><br><span class="line">-- ngx_auto_config.h   <span class="comment">#以宏的方式，存放configure指定的配置，供安装时使用</span></span><br><span class="line">-- ngx_auto_headers.h<span class="comment">#存放编译时包含的头文件中默认生成的宏</span></span><br><span class="line">-- ngx_modules.c        <span class="comment">#根据configure时加入的模块，生成ngx_modules数组</span></span><br><span class="line">`-- src                          <span class="comment">#存放编译时的目标文件</span></span><br><span class="line">    -- core                <span class="comment">#存放核心模块及框架代码生成的目标文件</span></span><br><span class="line">    -- event               <span class="comment">#存放事件模块生成的目标文件</span></span><br><span class="line">    -- http                 <span class="comment">#存放HTTP模块生成的目标文件</span></span><br><span class="line">    -- mail                 <span class="comment">#存放MAIL模块生成的目标文件</span></span><br><span class="line">    -- misc                <span class="comment">#存放ngx_google_perftools_module模块生成的目标文件</span></span><br><span class="line">    -- os                   <span class="comment">#存放与操作系统关联的源代码生成的目标文件</span></span><br><span class="line">    `-- stream             <span class="comment">#存放STREAM模块生成的目标文件</span></span><br></pre></td></tr></table></figure>

<p>接着，执行make命令就可以基于Makefile文件编译Nginx了。make命令可以携带4种参数：</p>
<ul>
<li>  build：编译Nginx，这也是make不携带参数时的默认动作。它会在objs目录中生成可执行的二进制文件nginx。</li>
<li>  clean：通过删除Makefile文件和objs目录，将configure、make的执行结果清除，方便重新编译。</li>
<li>  install：将Nginx安装到configure时指定的路径中，注意install只针对从头安装Nginx，如果是升级正在运行的服务，请使用upgrade参数。</li>
<li>  upgrade：替换可执行文件nginx，同时热升级运行中的Nginx进程。</li>
</ul>
<p>因此，当我们首次安装Nginx时，只需要先执行make命令编译出可执行文件，再执行make install安装到目标路径即可。 启动Nginx也很简单，进入Nginx目录后（比如/usr/local/nginx），在sbin目录下执行nginx程序即可，Nginx默认会启用Daemon守护者模式（参见daemon on;指令），这样shell命令行不会被nginx程序阻塞。 至此，Nginx已经编译、安装完成，并成功运行。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最后做个小结，本文介绍了定制化编译、安装及运行Nginx的方法。   </p>
<p>如果你想定制符合自己业务特点的Nginx，那就必须学会使用configure脚本，它会根据输入选项、系统环境生成差异化的编译环境，最终编译出功能、性能都不一样的Nginx。configure支持的选项分为5类，它允许用户修改资源路径、编译参数、依赖软件等，最重要的是可以选择加入哪些官方及第三方模块。 定制模块前，先要掌握模块的类别。</p>
<p>Nginx模块分为6类，作为Web服务器使用时，其中最复杂、强大的自然就是HTTP模块，它又可以再次细分为3小类：请求处理模块、响应过滤模块、负载均衡模块。我们可以使用–with或者–without选项增删官方模块，也可以通过–add-module或者–add-dynamic-module添加第三方模块。 configure会生成源代码、脚本、存放目标文件的临时目录，以及编译C工程的Makefile文件。其中，Makefile支持4个选项，允许我们编译、安装、升级Nginx。由于Nginx支持Daemon模式，启动它时直接运行程序即可。   </p>
<p><a href="/2020/12/23/%E4%BB%8E%E9%80%9A%E7%94%A8%E8%A7%84%E5%88%99%E4%B8%AD%E5%AD%A6%E4%B9%A0nginx%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%9A%E5%88%B6%E6%8C%87%E4%BB%A4/">下一篇</a>将会介绍nginx.conf的配置语法，以及使用命令行或者免费的可视化工具分析access.log日志文件的方法</p>
]]></content>
      <categories>
        <category>web</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>configure</tag>
        <tag>模块化</tag>
        <tag>module</tag>
      </tags>
  </entry>
  <entry>
    <title>深圳《运维世界大会》中《从代码看Nginx运维本质》演讲PPT分享</title>
    <url>/2017/01/27/nginx/%E6%B7%B1%E5%9C%B3%E3%80%8A%E8%BF%90%E7%BB%B4%E4%B8%96%E7%95%8C%E5%A4%A7%E4%BC%9A%E3%80%8B%E4%B8%AD%E3%80%8A%E4%BB%8E%E4%BB%A3%E7%A0%81%E7%9C%8Bnginx%E8%BF%90%E7%BB%B4%E6%9C%AC%E8%B4%A8%E3%80%8B/</url>
    <content><![CDATA[<p><img src="/2017/01/9ad22f2511b9e03464dee1f37861b58f_-300x225.jpg"><br>2016年12月3日赴深圳参加OpsWorld运维世界大会，作为嘉宾讲师向中国的一线运维研发工程师分享Nginx的使用技巧，大会由运维帮、云技术、Linux中国联合举办，三大社区汇聚了大量的技术精英和行业领袖，微信订阅号粉丝达到20多万人，技术内容覆盖整个互联网技术圈。特将PPT放在这里，希望能够帮助到大家！<br><img src="/2017/01/62671066407125606-300x225.jpg"> <img src="/2017/01/341961657994339271-300x225.jpg"> <a href="/ppt/Nginx%E8%BF%90%E7%BB%B4.pptx">从代码看Nginx运维</a></p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>南非蜘蛛</tag>
        <tag>运维世界大会</tag>
        <tag>运维帮</tag>
      </tags>
  </entry>
  <entry>
    <title>巧用 Nginx 实现大规模分布式集群的高可用性</title>
    <url>/2019/08/09/nginx/%E5%B7%A7%E7%94%A8-nginx-%E5%AE%9E%E7%8E%B0%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7/</url>
    <content><![CDATA[<p>本文是我对2019年GOPS深圳站演讲的文字整理。这里我希望带给各位读者的是，如何站在整个互联网背景下系统化地理解Nginx，因为这样才能解决好大流量分布式网络所面临的高可用问题。</p>
<span id="more"></span>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E7%9B%AE%E5%BD%95.jpg"></p>
<p>标题里有“巧用”二字，何谓巧用？同一个问题会有很多种解决方案，但是，各自的约束性条件却大不相同。巧用就是找出最简单、最适合的方案，而做到这一点的前提就是必须系统化的理解Nginx！本文分四个部分讲清楚如何达到这一目的：</p>
<ol>
<li> 首先要搞清楚我们面对的是什么问题。这里会谈下我对大规模分布式集群的理解；</li>
<li> Nginx如何帮助集群实现可伸缩性；</li>
<li> Nginx如何提高服务的性能；</li>
<li> 从Nginx的设计思路上学习如何用好它。</li>
</ol>
<h2 id="1-大规模分布式集群的特点"><a href="#1-大规模分布式集群的特点" class="headerlink" title="1. 大规模分布式集群的特点"></a>1. 大规模分布式集群的特点</h2><p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%874.jpg"></p>
<p>互联网是一个巨大的分布式网络，它有以下特点：</p>
<ul>
<li>  多样化的客户端。网络中现存各种不同厂商、不同版本的浏览器，甚至有些用户还在使用非常古老的浏览器，而我们没有办法强制用户升级；</li>
<li>  多层代理。我们不知道用户发来的请求是不是通过代理翻墙过来的；</li>
<li>  多级缓存。请求链路上有很多级缓存，浏览器、正反向代理、CDN等都有缓存，怎么控制多级缓存？RFC规范中有明确的定义，但是有些Server并不完全遵守；</li>
<li>  不可控的流量风暴。不知道用户来自于哪些地区，不知道他们会在哪个时间点集中访问，不知道什么事件会触发流量风暴；</li>
<li>  网络安全的高要求：信息安全问题要求通信数据必须加密；</li>
<li>  快速迭代的业务需求：BS架构使软件开发方式发生了巨大变化，我们可以通过快速迭代、发布来快速验证、试错。</li>
</ul>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%875.jpg"></p>
<p>上图是典型的REST架构，图中包括客户端、正反向代理、源服务器，$符号代表缓存可以服务于上游，也可以服务于下游。</p>
<p>通过IP地址标识主机，通过域名系统简化使用，URI则指向具体资源，每种资源有许多种表述，而服务器通过HTTP协议将表述转移至客户端上展示。这便是REST名为表述性状态转移的缘由，我在极客时间《Web协议详解与抓包实战》课程第7、8节课中对此有详细的介绍。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%876.jpg"></p>
<p>设计架构时有许多关注点，与本文主题相关的有4个要点：</p>
<ul>
<li>  可伸缩性。核心点在于如何有效的、动态的、灰度的均衡负载。</li>
<li>  可扩展性指功能组件的独立进化。可以理解为某个Nginx模块独立升级后，并不影响Nginx整体服务的属性。</li>
<li>  网络效率，也就是如何提升信息传输的效率。</li>
<li>  HTTP协议功能的全面支持。HTTP1的RFC规范非常多，毕竟它经历了20多年的变迁，而这20多年里互联网的巨大变化是HTTP1的设计者无法预料到的，这些规范也并不被所有Server、Client支持。 当然HTTP2和HTTP3相对情况会好很多。</li>
</ul>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%877.jpg"></p>
<ul>
<li>Nginx有优秀的可插拔模块化设计，它基于统一管道架构。<ul>
<li>  其中有一类模块我称它为upstream负载均衡模块，官方Nginx便提供了最小连接、RoundRobin、基于变量控制的hash、一致性hash等负载均衡策略，而大量的第三方模块更提供了许多定制化的负载均衡算法。</li>
<li>  基于Lua语言的Openresty有自己的生态，这些Lua模块也提供了更灵活的实现方式。</li>
</ul>
</li>
<li>  Nginx在性能优化上做得非常极致，大家知道最近F5收购了Nginx公司，为什么要收购？因为Nginx的性能可以与基于硬件的、价格昂贵的F5媲美！</li>
<li>  Nginx对HTTP协议的支持是比较全面的，当我们使用一些小众的替代解决方案时，一定要明确自己在HTTP协议有哪些独特需求。</li>
<li>  优秀的可配置性，在nginx.conf配置文件里我们可以使用脚本指令与变量实现复杂的功能。</li>
</ul>
<h2 id="2-Nginx与scalability"><a href="#2-Nginx与scalability" class="headerlink" title="2. Nginx与scalability"></a>2. Nginx与scalability</h2><p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%879.jpg"></p>
<p>在讨论Nginx的负载均衡策略前，我们先来了解AKF扩展立方体，它能使我们对此建立整体思维。AKF扩展立方体有X、Y、Z轴，这三个轴意味着可以从3个角度实现可伸缩性：</p>
<ul>
<li>  X轴指只需要增加应用进程，不用改代码就能水平的扩展。虽然最方便 ，但它解决不了数据不断增长的问题。</li>
<li>  Y轴按功能切分应用，它能解决数据增长的问题，但是，切分功能意味着重构代码，它引入了复杂性，成本很高。</li>
<li>  Z轴基于用户的属性扩展服务，运维Nginx时这招我们最常用，通常我们基于变量取到用户的IP地址、URL或者其他参数来执行负载均衡。</li>
</ul>
<p>当然，这三个轴可以任意组合以应对现实中的复杂问题。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8710.jpg"></p>
<p>当然，要想解决可伸缩性问题，还必须在功能上支持足够多的协议。面向下游客户端主要是HTTP协议，当然Nginx也支持OSI传输层的UDP协议和TCP协议。受益于Nginx优秀的模块化设计，对上游服务器Nginx支持非常多的应用层协议，如grpc、uwsgi等。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8711.jpg"></p>
<p>上图是Nginx执行反向代理的流程图，红色是负载均衡模块，任何一个独立的开发者都可以通过开发模块来添加新的LB策略。</p>
<p>Nginx必须解决无状态HTTP协议带来的信息冗余及性能低下问题，而Cache缓存是最重要的解决手段，我们需要对Cache在反向代理流程中的作用有所了解。当下游是公网带宽并不稳定，且单用户信道较小时，通常Nginx应缓存请求body，延迟对上游应用服务建立连接的时间；反之，若上游服务的带宽不稳定，则应缓存响应body。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8712.jpg"></p>
<p>理解nginx配置文件的3个关键点是：</p>
<ol>
<li> 多级指令配置。通过大括号{}，我们可以层层嵌套指令，借用父子关系来模块化的配置代码。</li>
<li> 变量，这是我们实现复杂功能，且不影响Nginx模块化设计的关键。变量是不同模块间低耦合交互的最有效方式！</li>
<li> 脚本引擎。脚本指令可以提供应用编程功能。很多人说Nginx的if指令是邪恶的，比如上图中的代码，其实我们只有理解if指令是如何影响父子嵌套关系后，才能正确的使用if。在《Nginx核心知识150讲》第141课我有详细介绍。</li>
</ol>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8713.jpg"></p>
<p>Nginx官方迭代速度很快，在前两年差不多是两周一个版本，现在是一个月一个版本。频繁的更新解决了Bug也推出了新功能。但我们更新Nginx时却不能像更新其他服务一样，因为Nginx上任一时刻处理的TCP连接都太多了，如果升级Nginx时不能很好的应对就会出现大规模的用户体验问题。</p>
<p>Nginx采用多进程结构来解决升级问题。它的master进程是管理进程，为所有worker进程保留住Syn半连接队列，所以升级Nginx时不会导致大规模三次握手失败。相反，单进程的HAProxy升级时就会出现连接建立失败问题。</p>
<h2 id="3-Nginx与集群performance"><a href="#3-Nginx与集群performance" class="headerlink" title="3. Nginx与集群performance"></a>3. Nginx与集群performance</h2><p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8715.jpg"></p>
<p>缓存有两个实现维度：时间与空间。基于空间的缓存需要基于信息来预测，提前把用户可能请求的字节流准备好。而基于时间的缓存如上图所示，蓝色线条的请求触发了缓存（public share cache），这样红色线条的第二次请求可以直接命中缓存。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8716.jpg"></p>
<p>浏览器中的是私有缓存，私有缓存只为一个用户服务。Nginx上实现了共享缓存，同时Nginx也可以控制浏览器中私有缓存的有效时间。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8717.jpg"></p>
<p>RFC规范定义了许多缓存相关的头部，如果我们忽略了这些规则会很难理解Nginx如何基于下游的请求、上游的响应控制私有缓存及共享缓存，而且不了解这些规则其实不容易读懂nginx.conf中缓存相关指令的说明文档。在《Web协议详解与抓包实战》课程第29到32课我详细的介绍了缓存相关的规则。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8718.jpg"></p>
<p>有些同学会问我，为什么部署Nginx之后没有看到上图中的Cache Loader和Cache Manger进程呢？因为我们没有启用Nginx的缓存。当然，即使我们开启缓存后，Cache Loader进程可能还是看不到的。</p>
<p>为什么呢？因为Nginx为了高性能做了很多工作。当重启Nginx时，之前保存在磁盘上的缓存文件需要读入内存建立索引，但读文件的IO速度是很慢的，读缓存文件（文件很大很多）这一步骤可能耗时非常久，对服务器的负载很大，这会影响worker进程服务用户请求的能力。CL进程负责每次只读一小部分内容到共享内存中，这大大缓解了读IO慢的问题。CM进程负责淘汰过期缓存。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8719.jpg"></p>
<p>当下游有一份过期资源时，它会来询问Nginx时：此资源还能用吗？能用的话，通过304告诉我，不要返回响应body（可能很大！）了。</p>
<p>当Nginx缓存的资源可能过期时，它也可以问上游的web应用服务器：缓存还能用吗？能用的话通过304告诉我，我来更新缓存Age。</p>
<p>RFC7033文档详细定义了这一过程，我在《Web协议详解与抓包实战》第28课有详细介绍。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8720.jpg"></p>
<p>Nginx的not_modified过滤模块便负责执行这一功能。我在《Nginx核心知识150讲》课程第97、98课对此有详细介绍。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8721.jpg"></p>
<p>如果我们突然发布了一个热点资源，许多用户请求瞬间抵达访问该资源，可是该资源可能是一个视频文件尺寸很大，Nginx上还没有建立起它的缓存，如果Nginx放任这些请求直达上游应用服务器（比如可能是Tomcat），非常可能直接把上游服务器打挂了。因为上游应用服务器为了便于功能的快速迭代开发，性能上是不能与Nginx相提并论的。这就需要合并回源请求。</p>
<p>怎么合并回源请求呢？第一个请求过来了，放行！第二个请求也到了，但因为第1个请求还没有完成，所以上图中的请求2、4、5都不放行，直到第6步第1个请求的响应返回后，再把缓存的内容作为响应在第8、9、10中返回。这样就能缓解上游服务的压力。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8722.jpg"></p>
<p>减少回源请求是一个解决方案，但如果Nginx上有过期的响应，能不能先将就着发给用户？当然，同时也会通过条件请求去上游应用那里获取最新的缓存。我们经常提到的互联网柔性、分级服务的原理与此是相同的。既然最新内容暂时由于带宽、性能等因素不能提供，不如先提供过期的内容，当然前提是不对业务产生严重影响。</p>
<p>Nginx中的proxy_cache_use_stale指令允许使用stale过期缓存，上图中第1个请求放行了，第2、3请求使用旧缓存。从这里可以看出Nginx应对大流量有许多成熟的方案。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8723.jpg"></p>
<p>我们在网页上会使用播放条拖动着看视频，这可以基于Http Range协议实现。但是，如果不启用Slice模块Nginx就会出现性能问题，比如现在浏览器要访问一个视频文件的第150-249字节，由于满足了缓存条件，Nginx试图先把文件拉取过来缓存，再返回响应。然而，Nginx会拉取完整的文件缓存！这是很慢的。</p>
<p>怎么解决这个问题呢？使用Nginx的slice模块即可，如果配置100字节作为基础块大小，Nginx会基于100-199、200-299产生2个请求，这2个请求的应用返回并存入缓存后再构造出150-249字节的响应返回给用户。这样效率就高很多！通常，Nginx作为CDN使用时都会打开这一功能。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8724.jpg"></p>
<p>互联网解决信息安全的方案是TLS/SSL协议，Nginx对其有很好的支持。比如，Nginx把下游公网发来的TLS流量卸载掉TLS层，再转发给上游；同时，它也可以把下游传输来的HTTP流量 ，根据配置的证书转换为HTTPS流量。在验证证书时，在nginx.conf中我们可以通过变量实现证书或者域名验证。</p>
<p>虽然TLS工作在OSI模型的表示层，但Nginx作为四层负载均衡时仍然可以执行同样的增、删TLS层功能。Nginx的Stream模块也允许在nginx.conf中通过变量验证证书。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8725.jpg"></p>
<p>Nginx处理TLS层性能非常好，这得益于2点：</p>
<ul>
<li>  Nginx本身的代码很高效，这既因为它基于C语言，也由于它具备优秀的设计。</li>
<li>减少TLS握手次数，包括：<ul>
<li>  session缓存。减少TLS1.2握手中1次RTT的时间，当然它对集群的支持并不好，而且比较消耗内存。</li>
<li>  Ticket票据。Ticket票据可应用于集群，且并不占用内存。</li>
</ul>
</li>
</ul>
<p>当然，减少TLS握手的这2个策略都面临着重放攻击的危险，更好的方式是升级到TLS1.3。我在《Web协议详解与抓包实战》第80课有详细介绍。</p>
<h2 id="4-巧用Nginx"><a href="#4-巧用Nginx" class="headerlink" title="4. 巧用Nginx"></a>4. 巧用Nginx</h2><p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8727.jpg"></p>
<p>Nginx模块众多，我个人把它分为四类，这四类模块各自有其不同的设计原则。</p>
<ul>
<li>  请求处理模块。负责生成响应或者影响后续的处理模块，请求处理模块遵循请求阶段设计，在同阶段内按序处理。</li>
<li>  过滤模块。生成了HTTP响应后，此类模块可以对响应做再加工。</li>
<li>  仅影响变量的模块。这类模块为其他模块的指令赋能，它们提供新的变量或者修改已有的变量。</li>
<li>  负载均衡模块。它们提供选择上游服务器的负载均衡算法，并可以管理上游连接。</li>
</ul>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8728.jpg"></p>
<p>请求处理模块、过滤模块、负载均衡模块均遵循unitform pipe and filter架构，每个模块以统一的接口处理输入，并以同样的接口产生输出，这些模块串联在一起提供复杂的功能。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8729.jpg"></p>
<p>Nginx把请求处理流程分为11个阶段，所有请求处理模块必须隶属于某个阶段，或者同时在多个阶段中工作。每个处理阶段必须依次向后执行，不可跳跃阶段执行。</p>
<p>同阶段内允许存在多个模块同时生效，这些模块串联在一起有序执行。当然，先执行的模块还有个特权，它可以决定忽略本阶段后续模块的执行，直接跳跃到下一个阶段中的第1个模块执行。</p>
<p>每个阶段的功能单一，每个模块的功能也很简单，因此该设计扩展性很好。上图中的灰色模块Nginx框架中的请求处理模块。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8730.jpg"></p>
<p>上图中右边是Openresty默认编译进Nginx的过滤模块，它们是按序执行的。图中用红色框出的是关键模块，它们是必须存在的，而且它们也将其他模块分为三组，开发第三方过滤模块时必须先决定自己应在哪一组，再决定自己应在组内的什么位置。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8731.jpg"></p>
<p>Nginx中的变量分为：提供变量的模块和使用变量的模块。其含义我在《Nginx核心知识150讲》第72课有介绍，关于框架提供的变量在第73、74课中有介绍。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8732.jpg"></p>
<p>无论我们使用了哪些模块，Nginx框架中的变量一定是默认提供的，它为我们提供了基础功能，理解好它们是我们使用好Nginx变量的关键。</p>
<p>框架变量分为5类：</p>
<ul>
<li>  HTTP 请求相关的变量</li>
<li>  TCP 连接相关的变量</li>
<li>  Nginx 处理请求过程中产生的变量</li>
<li>  发送 HTTP 响应时相关的变量</li>
<li>  Nginx 系统变量</li>
</ul>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8733.jpg"></p>
<p>最后我们来谈谈Openresty，它其实是Nginx中的一系列模块构成的，但它由于集成了Lua引擎，又延伸出Lua模块并构成了新的生态。看看Openresty由哪些部分组成：</p>
<ul>
<li>  Nginx，这里指的是Nginx的框架代码。</li>
<li>  Nginx官方模块，以及各类第三方（非Openresty系列）C模块。</li>
<li>  Openresty生态模块，它包括直接在Nginx中执行的C模块，例如上图中的绿色模块，也包括必须运行在ngx_http_lua_module模块之上的Lua语言模块。</li>
<li>  当然，Openresty也提供了一些方便使用的脚本工具。</li>
</ul>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8734.jpg"></p>
<p>Openresty中的Lua代码并不用考虑异步，它是怎么在Nginx的异步C代码框架中执行的呢？</p>
<p>我们知道，Nginx框架由事件驱动系统、HTTP框架和STREAM框架组成。而Openresty中的ngx_http_lua_module和ngx_stream_lua_module模块给Lua语言提供了编程接口，Lua语言通过它们编译为C代码在Nginx中执行。</p>
<p>我们在nginx.conf文件中嵌入Lua代码，而Lua代码也可以调用上述两个模块提供的SDK调动Nginx的功能。</p>
<p><img src="/2019/08/%E5%B7%A7%E7%94%A8Nginx-%E5%B9%BB%E7%81%AF%E7%89%8735.jpg"></p>
<p>Openresty的SDK功能强大，我个人把它分为以下8大类：</p>
<ul>
<li>  Cosocket提供了类似协程的网络通讯功能，它的性能优化很到位，许多其他Lua模块都是基于它实现的。</li>
<li>  基于共享内存的字典，它支持多进程使用，所有worker进程间同步通常通过Shared.DICT。</li>
<li>  定时器。</li>
<li>  基于协程的并发编程。</li>
<li>  获取客户端请求与响应的信息</li>
<li>  修改客户端请求与响应，包括发送响应</li>
<li>  子请求，官方Nginx就提供了树状的子请求，用于实现复杂功能，Openresty用比C简单的多的Lua语言又实现了一遍。</li>
<li>工具类，大致包含以下5类：<ul>
<li>  正则表达式</li>
<li>  日志</li>
<li>  系统配置</li>
<li>  编解码</li>
<li>  时间类</li>
</ul>
</li>
</ul>
<p> </p>
<p>最后做个总结。在恰当的时间做恰当的事，听起来很美好，但需要我们有大局观。我们要清楚大规模分布式网络通常存在哪些问题，也要清楚分布式网络的常用解决方案，然后才能谈如何用Nginx解决上述问题。而用好Nginx，必须系统的掌握Nginx的架构与设计原理，理解模块化设计、阶段式设计，清楚Nginx的核心流程，这样我们才能恰到好处地用Nginx解决掉问题。</p>
]]></content>
      <categories>
        <category>web</category>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>负载均衡</tag>
        <tag>http2</tag>
        <tag>tls</tag>
        <tag>F5</tag>
        <tag>AKF</tag>
        <tag>CDN</tag>
        <tag>http</tag>
        <tag>http3</tag>
        <tag>Lua</tag>
        <tag>Nginx核心知识150讲</tag>
        <tag>Nginx模块</tag>
        <tag>openresty</tag>
        <tag>rest</tag>
        <tag>RFC规范</tag>
        <tag>slice</tag>
        <tag>Web协议详解与抓包实战</tag>
        <tag>共享缓存</tag>
        <tag>反向代理</tag>
        <tag>合并回源</tag>
        <tag>条件请求</tag>
        <tag>正向代理</tag>
        <tag>流量风暴</tag>
        <tag>网络效率</tag>
        <tag>脚本引擎</tag>
        <tag>过滤模块</tag>
      </tags>
  </entry>
  <entry>
    <title>进阶 Nginx 高手必须跨越的 5 座大山</title>
    <url>/2018/12/25/nginx/%E8%BF%9B%E9%98%B6-nginx-%E9%AB%98%E6%89%8B%E5%BF%85%E9%A1%BB%E8%B7%A8%E8%B6%8A%E7%9A%84-5-%E5%BA%A7%E5%A4%A7%E5%B1%B1/</url>
    <content><![CDATA[<p>图片较多，摘要中不再显示！</p>
<span id="more"></span>
<p><a href="https://time.geekbang.org/column/article/74528"><img src="/2018/12/1.jpg"></a></p>
<p> <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B12.jpg"></a></p>
<h1 id="点击查看知识图谱的高清大图"><a href="#点击查看知识图谱的高清大图" class="headerlink" title="点击查看知识图谱的高清大图"></a>点击查看知识图谱的<a href="https://time.geekbang.org/column/article/74506"><strong>高清大图</strong></a></h1><p><a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B13-1.jpg"></a> <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B14.jpg"></a> <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B15.jpg"></a> <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B16.jpg"></a> <a href="https://time.geekbang.org/course/intro/138"><img src="/2018/12/nginx%E4%BA%94%E5%BA%A7%E5%A4%A7%E5%B1%B17.jpg"></a> <a href="http://www.taohui.pub/2018/12/27/nginx%e6%a0%b8%e5%bf%83%e7%9f%a5%e8%af%86100%e8%ae%b2%e8%af%be%e4%bb%b6/poster/"><img src="/2018/12/poster.jpg"></a></p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>极客时间</tag>
        <tag>进阶</tag>
        <tag>高手</tag>
      </tags>
  </entry>
  <entry>
    <title>深入剖析Nginx负载均衡算法</title>
    <url>/2021/02/08/nginx/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>负载均衡是Nginx的核心应用场景，本文将介绍官方提供的5种负载均衡算法及其实现细节。</p>
<p>Nginx提供的Scalability，主要由复制扩展（AKF X轴）和用户数据扩展（AKF Z轴）组成。所谓复制扩展，是指上游Server进程是完全相同的，因此可以采用最少连接数、Round Robin轮询、随机选择等算法来分发流量。所谓用户数据扩展，是指每个上游Server只处理特定用户的请求，对这种场景Nginx提供了支持权重的哈希算法，以及支持虚拟节点的一致性哈希算法。</p>
<span id="more"></span>
<p>当上游集群规模巨大时，<strong>我们必须了解这些算法的细节，才能有效地均衡负载</strong>。比如，当上游server出错时，Weight权重会动态调整吗？调整策略又是什么？如果算法选出的上游server达到了max_fails限制的失败次数，或者max_conns限制的最大并发连接数，那么又该如何重新选择新路由呢？</p>
<p>再比如，为了减少宕机、扩容时受影响的Key规模，同时让CRC32哈希值分布更均衡，Nginx为每个Weight权重配置了160个虚拟节点，为什么是这个数字？一致性哈希算法执行的时间复杂度又是多少呢？ </p>
<p>这一讲我将深入分析Nginx的负载均衡算法，同时围绕ngx_http_upstream_rr_peer_s这个核心数据结构，探讨这些HTTP负载均衡模块到底是怎样工作的。同时，本文也是Nginx开源社区基础培训系列课程第二季，即7月16日晚第2次直播课的文字总结。</p>
<h1 id="RoundRobin权重的实现算法"><a href="#RoundRobin权重的实现算法" class="headerlink" title="RoundRobin权重的实现算法"></a>RoundRobin权重的实现算法</h1><p>在Nginx中，上游服务可以通过server指令声明其IP地址或者域名，并通过upstream块指令定义为一组。这一组server中，将使用同一种负载均衡算法，从请求信息（比如HTTP Header或者IP Header）或者上游服务状态（比如TCP并发连接数）中计算出请求的路由：<br><img src="/images/nginx/Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95.png"><br>如果上游服务器是异构的，例如上图中server 1、3、4、5都是2核4G的服务器，而server 2则是8核16G，那么既可以在server 2上部署多个不同的服务，并把它配置到多个usptream组中，也可以通过server指令后的weight选项，设置算法权重：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">upstream</span> rrBackend &#123;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8001</span> weight=<span class="number">1</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8002</span> weight=<span class="number">2</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8003</span> weight=<span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="attribute">location</span> /rr &#123;</span><br><span class="line">                <span class="attribute">proxy_pass</span> http://rrBackend;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面这段配置指令中，并没有显式指定负载均衡算法，此时将使用Nginx框架唯一自带的RoundRobin轮询算法。顾名思义，它将按照server在upstream配置块中的位置，有序访问上游服务。需要注意，加入weight权重后，Nginx并不会依照字面次序访问上游服务。仍然以上述配置为例，你可能认为Nginx应当这么访问：8001、8002、8002、8003、8003、8003（我在本机上启动了这3个HTTP端口，充当上游server，这样验证成本更低），但事实上，Nginx却是按照这个顺序访问的：8003、8002、8003、8001、8002、8003，为什么会这样呢？<strong>实际上这是为了动态权重的实现而设计的</strong>。我们先从实现层面谈起。</p>
<p>Nginx为每个server设置了2个访问状态：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ngx_http_upstream_rr_peer_s</span> &#123;</span></span><br><span class="line">	... </span><br><span class="line">    <span class="keyword">ngx_int_t</span>                       current_weight;</span><br><span class="line">    <span class="keyword">ngx_int_t</span>                       effective_weight;</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中current_weight初始化为0，而effective_weight就是动态权重，它被初始化为server指令后的weight权重。我们先忽略转发失败的场景，此时RoundRobin算法可以简化为4步：</p>
<ol>
<li>   遍历upstream组中的所有server，将current_weight的值增加effective_weight；</li>
<li>   将全部的权重值相加得到total；</li>
<li>   选择current_weight最大的server；</li>
<li>   将这个选中server的current_weight减去total值。</li>
</ol>
<p>这样，前6次的运算结果就如下表所示：</p>
<table>
<thead>
<tr>
<th>current_weight</th>
<th>current_weight加effective_weight</th>
<th>total</th>
<th>选中server</th>
<th>current_weight</th>
</tr>
</thead>
<tbody><tr>
<td>[0,0,0]</td>
<td>[1,2,3]</td>
<td>6</td>
<td>8003</td>
<td>[1,2,-3]</td>
</tr>
<tr>
<td>[1,2,-3]</td>
<td>[2,4,0]</td>
<td>6</td>
<td>8002</td>
<td>[2,-2,0]</td>
</tr>
<tr>
<td>[2,-2,0]</td>
<td>[3,0,3]</td>
<td>6</td>
<td>8003</td>
<td>[3,0,-3]</td>
</tr>
<tr>
<td>[3,0,-3]</td>
<td>[4,2,0]</td>
<td>6</td>
<td>8001</td>
<td>[-2,2,0]</td>
</tr>
<tr>
<td>[-2,2,0]</td>
<td>[-1,4,3]</td>
<td>6</td>
<td>8002</td>
<td>[-1,-2,3]</td>
</tr>
<tr>
<td>[-1,-2,3]</td>
<td>[0,0,6]</td>
<td>6</td>
<td>8003</td>
<td>[0,0,0]</td>
</tr>
<tr>
<td>[0,0,0]</td>
<td>[1,2,3]</td>
<td>6</td>
<td>8003</td>
<td>[1,2,-3]</td>
</tr>
</tbody></table>
<p>由于总权重为6（1+2+3），所以每6次转发后就是一个新的轮回。我再把简化的RoundRobin源代码列在下方，你可以对照理解：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">ngx_http_upstream_rr_peer_t</span>* best = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">ngx_int_t</span>  total = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (peer = rrp-&gt;peers-&gt;peer, i = <span class="number">0</span>;</span><br><span class="line">         peer;</span><br><span class="line">         peer = peer-&gt;next, i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//在每一轮计算中，current_weight要加上effective_weight</span></span><br><span class="line">peer-&gt;current_weight += peer-&gt;effective_weight; </span><br><span class="line"><span class="comment">//total值是所有effective_weight的累加和</span></span><br><span class="line">        total += peer-&gt;effective_weight;</span><br><span class="line">        <span class="keyword">if</span> (best == <span class="literal">NULL</span> || peer-&gt;current_weight &gt; best-&gt;current_weight) &#123;</span><br><span class="line">            <span class="comment">//每一轮找出current_weight最大的那个server</span></span><br><span class="line">best = peer;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//选出server后，要将最大的</span></span><br><span class="line">    best-&gt;current_weight -= total;</span><br><span class="line">    <span class="keyword">return</span> best;</span><br></pre></td></tr></table></figure>
<p>可以看到，这段代码只做一遍循环就完成了server选择，执行效率很高。</p>
<h1 id="网络错误该如何处理？"><a href="#网络错误该如何处理？" class="headerlink" title="网络错误该如何处理？"></a>网络错误该如何处理？</h1><p>在上例中我们假定不会转发失败，所以effective_weight是不变的。但现实中分布式系统出错才是常态，接下来我们看看RoundRobin算法是怎样处理错误的。</p>
<p>在server指令后，可以加入max_fails和fail_timeout选项，它们共同对转发失败的次数加以限制：</p>
<ol>
<li>   在fail_timeout秒内（默认为10秒），<strong>每当转发失败，server的权重都会适当调低（通过effective_weight实现）</strong>；</li>
<li>   如果转发失败次数达到了max_fails次，则接下来的fail_timeout秒内不再向该server转发任何请求；</li>
<li>   在等待fail_timeout秒的空窗期后，server将会基于最低权重执行算法，尝试转发请求；</li>
<li>   <strong>每成功转发1次权重加1，直到恢复至weight配置</strong>。</li>
</ol>
<p><strong>这就是动态权重发挥作用的机制，它不只对RoundRobin算法有效，对于最少连接数、一致性哈希算法同样有效</strong>。接下来我们再从实现层面上回顾下这一流程，加深你对动态权重的理解。Nginx为这一功能准备了6个状态变量：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ngx_http_upstream_rr_peer_s</span> &#123;</span></span><br><span class="line">...</span><br><span class="line">    <span class="keyword">ngx_int_t</span>                       weight;</span><br><span class="line">    <span class="keyword">time_t</span>                          accessed;</span><br><span class="line">    <span class="keyword">ngx_uint_t</span>                      max_fails;</span><br><span class="line">    <span class="keyword">ngx_uint_t</span>                      fails;</span><br><span class="line">    <span class="keyword">time_t</span>                          checked;</span><br><span class="line">    <span class="keyword">time_t</span>                          fail_timeout;</span><br><span class="line">...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中，weight、max_fails、fail_timeout都是server指令后的选项，它们是固定不变的。fails是窗口期的转发失败次数，accessed表示最近一次转发失败时间，而checked则是最近一次转发时间（无论成功或者失败）。</p>
<p>这样，当访问上游server失败时，将会把accessed和checked置为当前时间，并将fails次数加1：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">peer-&gt;fails++;</span><br><span class="line">peer-&gt;accessed = now;</span><br><span class="line">peer-&gt;checked = now;</span><br></pre></td></tr></table></figure>
<p>如果max_fails功能没有关闭（0表示关闭，默认值是1），就会通过effective_weight适当降低权重：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (peer-&gt;max_fails) &#123;</span><br><span class="line">    peer-&gt;effective_weight -= peer-&gt;weight / peer-&gt;max_fails;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当执行负载均衡算法时，如果在fail_timeout秒内连续失败了max_fails次，则不再访问该server：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (peer-&gt;max_fails</span><br><span class="line">    &amp;&amp; peer-&gt;fails &gt;= peer-&gt;max_fails</span><br><span class="line">    &amp;&amp; now - peer-&gt;checked &lt;= peer-&gt;fail_timeout)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在过了fail_timeout秒的空窗期后，一旦算法再次选择了该server，就会将checked重置为当前时间：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (now - best-&gt;checked &gt; best-&gt;fail_timeout) &#123;</span><br><span class="line">    best-&gt;checked = now;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一旦最终转发请求成功，就会通过accessed将fails失败次数清零：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (peer-&gt;accessed &lt; peer-&gt;checked) &#123;</span><br><span class="line">    peer-&gt;fails = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，此时effective_weight还需要通过不断的成功来缓慢恢复权重：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (peer-&gt;effective_weight &lt; peer-&gt;weight) &#123;</span><br><span class="line">    peer-&gt;effective_weight++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RoundRobin算法还能控制并发连接数，你可以通过server指令后的max_conns选项设置（默认为0表示不加限制）。它的实现原理非常简单，这里不再介绍。</p>
<p>可见，RoundRobin算法可以柔性恢复转发错误。如果上游Server进程是复制扩展的（处理的数据相同），那么RoundRobin就是最简单有效的负载均衡算法。</p>
<h1 id="最少连接数与随机选择算法"><a href="#最少连接数与随机选择算法" class="headerlink" title="最少连接数与随机选择算法"></a>最少连接数与随机选择算法</h1><p>前文之所以要详尽的介绍RoundRobin权重、错误恢复、并发连接限制等功能，是因为Nginx中几乎所有负载均衡算法，都在一定程度上继承了上述机制。接下来我们分析与RoundRobin极为相似的Least Conn和Random算法，它们皆处理沿AKF X轴扩展的场景。</p>
<p>首先来看Least Conn最少连接数算法。多数场景下，并发TCP连接最少的服务器负载最轻，因此ngx_http_upstream_least_conn_module模块会选择连接最少的server转发请求。只需要在upstream中加入least_conn指令，就可以开启最少连接数算法：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">upstream</span> &#123;</span><br><span class="line">	<span class="attribute">server</span> localhost:<span class="number">8001</span> weight=<span class="number">1</span>;</span><br><span class="line">	<span class="attribute">server</span> localhost:<span class="number">8002</span> weight=<span class="number">2</span>;</span><br><span class="line">	least_conn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它的实现非常简单，在符合max_fails、fail_timeout失败次数约束、max_conns并发连接数约束下，取当前并发连接数与权重相乘后最小的server即可：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">     <span class="keyword">if</span> (best == <span class="literal">NULL</span></span><br><span class="line">         || peer-&gt;conns * best-&gt;weight &lt; best-&gt;conns * peer-&gt;weight)</span><br><span class="line">     &#123;</span><br><span class="line">         best = peer;</span><br><span class="line">         many = <span class="number">0</span>;</span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (peer-&gt;conns * best-&gt;weight == best-&gt;conns * peer-&gt;weight) &#123;</span><br><span class="line"><span class="comment">// many表示存在多个最少连接服务器</span></span><br><span class="line">         many = <span class="number">1</span>;</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<p>如果存在不只1个的最少连接server，将对这些上游server继续执行RoundRobin算法。</p>
<p>其次，我们再来看Random随机选择算法。如前文所述，RoundRobin轮询算法是有规律的，当我们需要完全随机的访问上游server时，就可以选择Random算法，它的开启方式非常简单，在upstream中加入random指令即可：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">upstream</span> rrBackend &#123;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8001</span> weight=<span class="number">1</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8002</span> weight=<span class="number">2</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8003</span> weight=<span class="number">3</span>;</span><br><span class="line">				random;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时，Nginx会建立含有3个元素的有序数组，分别对应3个server，其值为权重的累加值，如下所示：<br>1：server1 | 3(1+2)：server2 | 6(1+2+3)：server3<br>——- | ——- | ——-</p>
<p>执行随机算法时，首先取小于total_weight（即6）的随机数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ngx_uint_t</span>  x = ngx_random() % peers-&gt;total_weight; </span><br></pre></td></tr></table></figure>
<p>接着，基于二分法遍历有序数组，找到下标x对应的上游server：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">ngx_uint_t</span>  i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">ngx_uint_t</span>  j = peers-&gt;number; <span class="comment">//number是upstream下的server个数</span></span><br><span class="line"><span class="keyword">while</span> (j - i &gt; <span class="number">1</span>) &#123;  <span class="comment">//如果存在超过2个server，才需要执行随机选择</span></span><br><span class="line">        <span class="keyword">ngx_uint_t</span>  k = (i + j) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (x &lt; rp-&gt;conf-&gt;ranges[k].range) &#123;</span><br><span class="line">            j = k;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            i = k;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">return</span> i;  <span class="comment">//返回选中server对应的序号</span></span><br></pre></td></tr></table></figure>
<p>注意，随机选择出的server很有可能并不满足max_fails、fail_timeout失败次数的约束，或者不满足max_conns并发连接数约束。<strong>对于同一个请求，如果连续20次的随机选择都没有找到合适的server，那么Random算法将会退化为RoundRobin算法选择server</strong>。</p>
<p>事实上，Random算法还有一个功能，你可以在random指令后添加two least_conn选项，这样算法将会随机找出2个server，再选择并发连接数最少的那1个：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">upstream</span> rrBackend &#123;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8001</span> weight=<span class="number">1</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8002</span> weight=<span class="number">2</span>;</span><br><span class="line">                <span class="attribute">server</span> localhost:<span class="number">8003</span> weight=<span class="number">3</span>;</span><br><span class="line">				<span class="attribute">random</span> two least_conn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>官方提供的RoundRobin、最少连接数、随机选择这3个算法，只适用于无差别的上游服务。当上游server只处理特定范围的请求时，可以使用ip_hash、hash以及hash consistent这三种算法。</p>
<h1 id="哈希算法的问题"><a href="#哈希算法的问题" class="headerlink" title="哈希算法的问题"></a>哈希算法的问题</h1><p>复制扩展无法解决数据增长问题，这样当业务增长到某一阶段，以致上游server无法将高频访问数据全部放于内存中时，性能便会一落千丈。Nginx通过ngx_http_upstream_ip_hash_module、ngx_http_upstream_hash_module这两个模块，实现了哈希与一致性哈希算法，它们可以限制每个上游server处理的数据量，以此提升上游server的性能。我们先来看ip_hash算法。</p>
<p>每个IP报文头部都含有源IP地址，它标识了唯一的客户端。因此，将IP地址依据字符串哈希函数转换为32位的整数，再对server总数取模，就可以将客户端与上游server的访问关系固定下来。</p>
<p>它的实现非常简单，包括以下3步：</p>
<ol>
<li><p>将IP地址这个字符串转化为哈希值，代码如下所示：</p>
<pre><code> ngx_uint_t    hash = 89;
 for (i = 0; i &lt; (ngx_uint_t) iphp-&gt;addrlen; i++) &#123;
     hash = (hash * 113 + iphp-&gt;addr[i]) % 6271;
 &#125;
</code></pre>
</li>
<li><p>接着，基于所有上游server的权重和，缩小哈希值范围：<br>ngx_uint_t  w = hash % iphp-&gt;rrp.peers-&gt;total_weight;</p>
</li>
<li><p>最后，通过遍历所有server的权重，选取上游server：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (w &gt;= peer-&gt;weight) &#123;</span><br><span class="line">    w -= peer-&gt;weight;</span><br><span class="line">    peer = peer-&gt;next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见，<strong>相对于采用二分查找的Random算法，古老的ip_hash性能有所下降（时间复杂度从O(logN)降到O(N)），在server非常多时性能不够理想</strong>。</p>
</li>
</ol>
<p>实际上，ip_hash还有一个很糟糕的问题，就是对于IPv4地址，它会忽略最后1个字节的值。比如若IP地址为AAA.BBB.CCC.DDD，那么ip_hash只会使用AAA.BBB.CCC来求取哈希值，相关代码如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> AF_INET:</span><br><span class="line">    <span class="built_in">sin</span> = (struct sockaddr_in *) r-&gt;connection-&gt;sockaddr;</span><br><span class="line">    iphp-&gt;addr = (u_char *) &amp;<span class="built_in">sin</span>-&gt;sin_addr.s_addr;</span><br><span class="line">    iphp-&gt;addrlen = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure>
<p>对于后出现的IPv6地址，将会使用全部16个字节的地址。为了向前兼容，ip_hash模块很难修改掉IPv4地址的这个Bug。此时，你可以使用更新的hash指令来解决，它可以对Nginx变量（也接受变量与字符串的组合）取哈希值：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">upstream</span> &#123;</span><br><span class="line">	<span class="attribute">server</span> A;</span><br><span class="line">	<span class="attribute">server</span> B;</span><br><span class="line">	<span class="attribute">hash</span> $remote_addr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>hash模块会使用CRC32函数，对变量求出32位的哈希值，之后执行与ip_hash相同的算法。</p>
<p><strong>哈希算法最大的问题在于，当server数量、权重发生变化时，映射函数就会变化，很容易导致映射关系大幅变动</strong>。比如，当上游server数量为5时，关键字与上游server的映射如下所示：<br> <img src="/images/nginx/LB%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E6%9C%AA%E5%8F%98%E5%8A%A8.png"></p>
<p>一旦server4宕机，这5个关键字的映射关系就会全部变动：<br><img src="/images/nginx/LB%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E5%8F%98%E5%8A%A8.png"></p>
<p>如果上游server为数据建立了缓存，那么此时会导致这5个关键字对应的缓存全部失效。</p>
<h1 id="一致性哈希算法是怎样实现的？"><a href="#一致性哈希算法是怎样实现的？" class="headerlink" title="一致性哈希算法是怎样实现的？"></a>一致性哈希算法是怎样实现的？</h1><p><strong>一致性哈希算法将哈希算法中的函数映射，改为32位数字构成的环映射，大幅降低了server变动时受影响的关键字数量</strong>。如下图所示，Nginx将关键字（hash指令后的变量）基于CRC32函数转换为无符号的32位整数，其中232与0相接构成了一个环：<br><img src="/images/nginx/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%8E%AF.png"> </p>
<p>这样，3个server将会基于weight权重，各自负责环中的一段弧线，划分了处理关键字的范围。当扩容或者宕机时，只会影响相邻server节点上的关键字。</p>
<p>当然，这样还是有2个问题：</p>
<ol>
<li>   当节点1宕机时，它负责的所有请求都被映射到了节点2，这样节点2可能会抗不住压力继续宕机，进而引发雪崩效应。扩容时也一样，当增加节点3时，只是分流了节点2上的请求，这对节点0、节点1完全没有帮助。</li>
<li>   如果server只是基于权重划分哈希环，那么很难保证全部关键字均衡地落进每个server上。</li>
</ol>
<p>解决这2个问题的方案，就是在哈希环上，增加一层二次映射的虚拟节点环。这样，二次哈希既可以让数据分布更均衡，也可以由全体server共同分担宕机压力，享受扩容带来的收益。</p>
<p>虚拟节点数量越多，分布会越均衡。然而，在有序的哈希环上选择server，最快的方法也只是二分查找法，它的时间复杂度是O(logN)，因此，虚拟节点数还是得控制在一个范围内。通常，每个真实节点对应的虚拟节点数在100到200之间，而Nginx选择为每个权重分配160个虚拟节点。</p>
<p>下面我们看下Nginx是如何实现一致性哈希算法的。对于哈希环上的每个虚拟节点，Nginx都会分配1个ngx_http_upstream_chash_point_t结构体表示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span>                            hash;</span><br><span class="line">    <span class="keyword">ngx_str_t</span>                          *server;</span><br><span class="line">&#125; <span class="keyword">ngx_http_upstream_chash_point_t</span>;</span><br></pre></td></tr></table></figure>
<p>其中，hash是二次哈希映射后的值，server则指向真实的上游服务。这些虚拟节点环会以数组的形式放在ngx_http_upstream_chash_points_t结构体中：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">ngx_uint_t</span>                          number;</span><br><span class="line">    <span class="keyword">ngx_http_upstream_chash_point_t</span>     point[<span class="number">1</span>];</span><br><span class="line">&#125; <span class="keyword">ngx_http_upstream_chash_points_t</span>;</span><br></pre></td></tr></table></figure>
<p>其中，number成员保存了虚拟节点的总数量，而point则是虚拟节点环的首地址。</p>
<p>构建虚拟节点环的初始化代码如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">     <span class="keyword">ngx_uint_t</span>	npoints = peer-&gt;weight * <span class="number">160</span>; <span class="comment">//每个权重赋予160个虚拟节点</span></span><br><span class="line">     <span class="keyword">for</span> (<span class="keyword">ngx_uint_t</span> j = <span class="number">0</span>; j &lt; npoints; j++) &#123;</span><br><span class="line">         hash = base_hash; <span class="comment">//基于上游server的IP、端口进行首次哈希</span></span><br><span class="line"><span class="comment">//基于相同的算法执行二次哈希</span></span><br><span class="line">         ngx_crc32_update(&amp;hash, prev_hash.byte, <span class="number">4</span>);</span><br><span class="line">         ngx_crc32_final(hash);</span><br><span class="line"><span class="comment">//将二次哈希值放入ngx_http_upstream_chash_point_t环中</span></span><br><span class="line">         points-&gt;point[points-&gt;number].hash = hash;</span><br><span class="line">         points-&gt;point[points-&gt;number].server = server;</span><br><span class="line">         points-&gt;number++;</span><br><span class="line">         prev_hash.value = hash;</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<p>当用户请求到达时，会首先基于Nginx变量生成CRC32哈希值，接着采用二分查找法，在O(logN)时间复杂度下找到对应的真实server：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ngx_http_upstream_chash_point_t</span>  * point = &amp;points-&gt;point[<span class="number">0</span>]; <span class="comment">//环上第1个虚拟节点</span></span><br><span class="line"><span class="keyword">ngx_uint_t</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">ngx_uint_t</span> j = points-&gt;number;</span><br><span class="line"><span class="keyword">while</span> (i &lt; j) &#123;    <span class="comment">//以二分法检索虚拟节点</span></span><br><span class="line">    <span class="keyword">ngx_uint_t</span> k = (i + j) / <span class="number">2</span>;   </span><br><span class="line">    <span class="keyword">if</span> (hash &gt; point[k].hash) &#123;</span><br><span class="line">        i = k + <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (hash &lt; point[k].hash) &#123;</span><br><span class="line">        j = k;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> k;	<span class="comment">//返回哈希环中对应虚拟节点的下标</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> i;</span><br></pre></td></tr></table></figure>
<p>如果选出的server由于失败次数、并发连接数达到限制后，将会采用闭散列函数的方案，尝试选择相邻哈希桶上的server。另外，<strong>如果连续选出的20个server都不能使用，一致性哈希算法将会回退到RoundRobin算法</strong>。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>最后对本文内容做个总结。</p>
<p>为异构服务器设置Weight权重后，Nginx还为转发失败提供了动态权重功能。其中，每失败1次，动态权重会下降weight/max_fails，在fail_timeout时间窗口内失败次数达到max_fails后，server将会冷却fail_timeout秒，之后权重会缓慢恢复。动态权重对于RoundRobin、一致性哈希、最少连接数算法都有效。</p>
<p>当哈希、随机选择算法连续20次计算出的server都不可用，它们会退化为RoundRobin算法。当一致性哈希算法计算出的server不可用时，则会顺序向后寻找相邻哈希桶上的server。同样连续20次失败后，也会退化为RoundRobin算法。因此，理解Nginx框架自带的RoundRobin算法，对于学习负载均衡算法至关重要。</p>
<p>Nginx为一致性哈希算法上的每个权重分配了160个虚拟节点，这个数字既照顾到了分布均衡性及流量压力的分散，也照顾到了算法的执行效率，毕竟二分查找法的时间复杂度是O(logN)。 </p>
<p>下一篇，我们将讨论Nginx如何向客户端隐藏应用层错误。</p>
]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>负载均衡</tag>
        <tag>AKF</tag>
        <tag>RoundRobin</tag>
        <tag>最少连接数</tag>
        <tag>一致性哈希算法</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式在C语言中的应用--读nginx源码</title>
    <url>/2013/01/27/nginx/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9C%A8c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8-%E8%AF%BBnginx%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<p>市面上的“设计模式“书籍文章，皆针对<a href="http://lib.csdn.net/base/javase" title="Java SE知识库">Java</a>/C++/C#等面向对象语言，似乎离开了面向对象的种种特性，设计模式就无法实现，没有用武之地了。 </p>
<p>是这样吗？设计模式的概念是从建筑领域引入的，本身从没歧视过面向过程编程语言，它只是对一类问题的普遍解决方案而已。面向对象语言因为有类、多态等特点，使得开发者们容易达到：隐藏细节、封装变化，而这与设计模式的目的比较一致，所以大师们爱把设计模式与面向对象语言二位一体的使用。然而，存在即合理，<a href="http://lib.csdn.net/base/c" title="C语言知识库">C语言</a>直到今日仍然在大型软件工程中担纲主角，其种种设计方法其实与我们通常见到的设计模式本质是相同的。例如nginx这个纯C语言写就的的高性能WEB服务器，就有许多地方使用到了市面书籍提到的设计模式。下面通过nginx源码来看看C语言是怎么做的。当然，UML图都是我根据代码意图所画，并不准确（C语言真没法画UML），只用于方便理解，呵呵。 </p>
<span id="more"></span>
<h1 id="strategy模式："><a href="#strategy模式：" class="headerlink" title="strategy模式："></a>strategy模式：</h1><p>该模式用于客户代码在“无知”状态下，可以使用种种不同的实现。下面我们以nginx对网络IO操作的封装部分来看看C语言的实现吧。 </p>
<p>设计模式就是通过封装变化来解耦，所以，我们先要找出网络IO操作的变化点来。nginx是跨平台的，它会支持<a href="http://lib.csdn.net/base/linux" title="Linux知识库">Linux</a>、freebsd、solaris等<a href="http://lib.csdn.net/base/operatingsystem" title="操作系统知识库">操作系统</a>，而每个操作系统的网络IO操作是不同的，这就是变化点了。 </p>
<p>所以，nginx首先定义了ngx_os_io_t来封装这些变化。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span>  </span><br><span class="line">    ngx_recv_pt        recv;  </span><br><span class="line">    ngx_recv_chain_pt  recv_chain;  </span><br><span class="line">    ngx_recv_pt        udp_recv;  </span><br><span class="line">    ngx_send_pt        send;  </span><br><span class="line">    ngx_send_chain_pt  send_chain;  </span><br><span class="line">    <span class="keyword">ngx_uint_t</span>         flags;  </span><br><span class="line">&#125; <span class="keyword">ngx_os_io_t</span>;  </span><br></pre></td></tr></table></figure>

<p>这里有五个函数指针（*_pt都是函数指针）和一个变量，用于收发网络数据，我把它理解为OO中的abstract class（每个ngx_os_io_t定义的变量都会重新实现这五个函数）。 </p>
<p>拥有函数指针的struct，我通常认为它们是OO中的abstract class，实现它们的文件（一堆函数）要对应到OO上，我则喜欢把它们当做子类来看。对于void*这样的成员，要根据意图来看了，通常我会转换成聚合加继承的关系。 <img src="/2017/01/0_1328087269KWms-1-1.png"> ngx_io会在相应的ngx_os_specific_init方法中，来策略性的选择到底使用哪个实现。客户代码只需要简单的调用ngx_io中的方法即可。 </p>
<h1 id="adapter模式："><a href="#adapter模式：" class="headerlink" title="adapter模式："></a>adapter模式：</h1><p>这个模式用以适配接口，通常都是我们已经定义好一种接口了，有一个新的实现却有着不同的接口，接下来adapter就开始发力了。下面我们仍然以nginx对网络IO操作的封装部分来看。 </p>
<p>linux平台下可能存在普通的IO或者异步IO方式。我们在最初已经封装好ngx_os_io_t接口了，客户代码都是这么直接使用的。现在linux实现了异步IO，而它的调用方式与普通的读写IO接口完全不同，所以，如果要支持aoi就需要一层adapter来适配ngx_os_io_t，这就是adapter方式了。 <img src="/2013/01/adapter.png"> </p>
<p>上图中，ngx_os_aio适配了原生的异步IO接口，这样，用户代码仍然像以前一样，只要直接使用ngx_io中的五个接口方法，当nginx的IO部分支持linux aio后，用户代码不需要修改。 </p>
<h1 id="bridge桥模式："><a href="#bridge桥模式：" class="headerlink" title="bridge桥模式："></a>bridge桥模式：</h1><p>桥模式用于将抽象和实现分离，各自都能独立的变化。下面以nginx的核心概念module举例，虽然有些牵强，因为nginx的代码从来没这么用过：通常都是一个抽象module context只对应着一个实现module来用，但是，毕竟这种结构下还是可以达到抽象与实现分离的目的，桥模式只好对应到这上面了。 </p>
<p>nginx是以module的概念贯穿始终的。它有一个基本的抽象层ngx_core_module_t（从意图上判断，context有抽象接口的功能，虽然简单从语法上看不出）。然后，nginx module有三个基本类型，分别是event（处理各种事件模型，如epoll/select等），http（处理各种http协议的事件），mail（处理mail相关的事件）。针对每种类型的module，都有许多个实现，比如event module就有9个实现，这里的每个实现其实也是个子类。 </p>
<p>但是，在我们理解桥模式时，这些子类暂时要被看成是event module的实例。代码中看，像ngx_epoll_module这样的子类中，还是把一些通用的细节隐藏给ngx_event_core_module来做（管理这个词更合适）了。从这个角度可以认为，通过context接口，把三个基本module实现分开了。来看看类图： <img src="/2013/01/bridge%E6%A8%A1%E5%BC%8F.png"> </p>
<p>nginx自己用时，是以ngx_module_t中的type成员来决定使用哪个实现的。目前的nginx代码中，如果用了一种接口就一定会指定相应的type。可是实际上，这也可以用来展示桥模式。以事件module为例来看看： <img src="/2013/01/bridge2.png"> </p>
<p>由于UML本就是针对OO语言的，所以以上我画的类图都比较牵强，什么是继承？什么是聚合？在C语言中，往往都是通过几个函数指针，或者void*指针实现各种封装和多态。没有什么语法上的关联，我就只能从代码意图中来判断了。而代码意图这个比较虚，因为不同的角度理解出来都不一样，所以这个确实不好画。太灵活了点，我只能从一个便于说明的角度来看，例如：上面的ngx_devpoll_module其实就是一个ngx_module_t，呵呵，但是，实际上它最关心的是ngx_event_actions_t的实现，如果完全根据语法来看，根本说不通的。但从代码意图中看，这些module并不关心ngx_module_t，所以我认为，它们只是在实现ngx_event_module_t了。 </p>
<p>当然以上只是一家之言，不必当真，如果对nginx源码有研究的话，欢迎各位拍砖。<br>客观的说，C语言确实在封装上很差，就像nginx，如果我们要开发一个处理http协议的module嵌入进nginx进程，必须了解ngx_http_module里到底做了什么，真没隐藏啥细节，module开发者们表示很郁闷。上面的这些设计模式，只是做到了代码上的解藕。如果nginx用C++写的话，我相信，现在第三方module都能数以万计了。</p>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>adapter模式</tag>
        <tag>strategy模式</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>《见识》读书笔记：大家智慧</title>
    <url>/2018/04/07/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E3%80%8A%E8%A7%81%E8%AF%86%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A4%A7%E5%AE%B6%E6%99%BA%E6%85%A7/</url>
    <content><![CDATA[<p>周末抽空在读吴军老师的《见识》，今天在读“大家智慧”章节时对商业的一些看法有所感，在此记录一二。 吴军提到拉里佩奇的商业智慧是从本质中寻找商业模式。这个本质就是将有用的信息带给用户，想做到这一点其实挺难的。比如百度，你想搜索对你有用的信息，比起google来需要更多的技巧，添加更多的关键字。为什么呢？</p>
<span id="more"></span>
<p>产品的商业价值在影响着这一点，百度的竞价排名里认为你需要综合考虑百度的利益，所以结果展示不会以对你有用的信息传达给你为首要价值。说到这里，对当年google离开中国又多了一些理解，因为中国监管对搜索结果展示的要求确实违背了google的核心价值。当然，展示有用的信息也需要高超的技术才能实现。 有用的信息不一定要属于你，但是只要你能把它送达用户，这就是核心的价值。因为你把信息与用户连接在了一起。我们团队正在做的产品就是在试图连接物联网与人，其实本质上也是把最有用的信息送达用户。如果用户觉得不好用，或者这个信息没有价值，哪怕通过其他手段强制用户使用产品，就像一个小伙在追求姑娘不断献殷勤但姑娘很反感一样，用户都会有一种强买强卖的感觉。坚持送达最有用的信息给用户，是需要做为第一准则的，因为有太多的其他因素在诱惑你的团队：技术难度、推广速度都会影响我们的决断，而互联网产品本来就不是静态的，它需要反复迭代，在迭代过程中的疲惫里，如果不能坚持这一点，很难想象产品可以做大。我们公司的名字是“智链达”，其意义就在于用智能的技术把有用的信息送达用户。 何谓有用的信息呢？其实这个并不容易判断，我们基于自己的常识判断某类信息是对用户有用的，可是，如果我们与用户是一类人，那么可以通过站在对方的角度思考这类信息，但是中国社会在几十年内的快速变化，虽然貌似大家通过免费的互联网可以获取到同等的信息，实则受制于见识与格局，中国人在见识层面上的分层还是比较明显的。每个人都有过这种感觉吧：非常明显的道理跟某些人却怎么也讲不通。如果我们的用户与我们不是一类人，那么如何知道信息是对用户有用的呢？深入用户中调研吧。可是，并不是什么人都能做到，只有见识和经历达到一定阶段的人才能做得好。所以，好的企业掌舵人都是产品、销售、运营出身，就在于他能更准确的判断。 拉里佩奇还有个智慧是“把产品做成牙刷”，就是让用户每天都会用那么一小会。所以，你的app其实需要的是，用户每天打开都能发现价值。如果不能做到每天，用户就会遗忘，可能会好几天才想起来用一下，这样效果就差了很多。宝洁的产品这么成功，还在经常打广告，google这么常用，也时不时冒出个新的应用点，许多app都会有社区在运营且经常搞点引爆话题类的线上线下活动，这都是因为：牙刷经常在用，但需要用爆点吸引用户的注意力。否则，用户还是容易遗忘的。比如intel虽然其x86 cpu架构不如其他公司，但它是18个月更新一次产品，其竞争对手们在产品性能上并不输入intel但却是36个月更新一次产品，虽然intel因为迭代速度快团队规模更大管理要求更高，但它始终能引起用户的关注，所以intel成功了。 吴军老师分享了其好友与巴菲特一餐饭中的所得，最重要的就是不做自己不懂的事。其实能把这一点做得比较好的人是很少的，对于企业或者个来看似乎都意味着放弃了许多唾手可得的利润。仿佛这个产品不需要采购，完全可以自研；好像成立一个部门做这件事，能大大提高效率，提升公司的价值，还能节约运营成本；似乎这支股票在这波涨势下买来是十拿九稳的赚钱。吴军好友在拿下央视标王对其公司下属纷纷要求成立广告公司时说：<strong>我确实不知道为什么我们不可能办好，但是我知道一定会是一个失败的结果。因为如果你们的逻辑成立的话，今天世界上最大的广告公司应该是可口可乐广告公司或者宝洁广告公司，但是结果却不是，这里面必然有它的原因。</strong>对个人来说，少花点时间在自己不擅长的事上，多花点时间在自己的职业生涯里，做自己最擅长的事，这才是收益最大的选择。 吴军举了他的好友摩拜单车CEO王晓峰的例子。王晓峰在创业前就是金牌销售，他有3个智慧分享： 1、销售的本质是把钱收回来，而不是把东西卖出去。之前做技术专家时我就从未想过，在中国的传统行业里其实把钱收回来是非常困难的。因为互联网产品其实对这一点相对容易些，特别是如果我们在设计产品时就能考虑到这一点，其销售方式、技术手段、运营模式都在最初就考虑如何把钱收回来。 2、一定要用户把买的东西最快的用掉。比如许多理发店就通过充值赠送、办会员卡打折的方式来吸引用户，但用户花钱买的卡却大都需要很久才能用掉。这样产品设计就有问题了。现在如阿里云、腾讯云、华为云等也有类似的活动，但他们一直在不断的推出更多的PAAS产品，在业务上总是能解决更多的痛点，总在吸引用户把充值卡里的钱尽快的用掉。 3、商品和服务要让消费者有面子。其实现在许多高端手机其设计上都是为了让用户拿出来感觉有面子。罗胖在2018年跨年演讲时就说过，他们不敢做让“得到”用户感觉没面子的事。以前自行车总给人低端的印象，而共享单车们为了让用户感觉有面子，才会把共享单车都设计得挺酷。我们运营总监这点也跟我强调过，一定要让用户感觉用了我们的产品倍有面子，而不是一听名字一看界面就感觉很乡土。当然，有面子并不是说就不接地气，这两点并不矛盾。能把这两点结合好，才能变成一个优秀的产品。</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
  </entry>
  <entry>
    <title>《风起陇西》：杰出的三国谍战小说</title>
    <url>/2018/07/11/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E3%80%8A%E9%A3%8E%E8%B5%B7%E9%99%87%E8%A5%BF%E3%80%8B%EF%BC%9A%E6%9D%B0%E5%87%BA%E7%9A%84%E4%B8%89%E5%9B%BD%E8%B0%8D%E6%88%98%E5%B0%8F%E8%AF%B4/</url>
    <content><![CDATA[<p>花了近一个月，在喜马拉雅听完了马亲王的这本《风起陇西》(之所以听了这么久，主要我对这种休闲小说都是放在晚上睡前听的。)。书不长，但情节精彩异常，对三国谜来说给了完全不同的视角。</p>
<span id="more"></span>
<p>为什么喜欢三国呢？其实我的阅读入门读物就是《三国演义》，那是在初一时开始读的。在这之前，主要都是在读小人书、故事会之类的读物，呵。入门读物都是对人生影响巨大的，至少会激活基因中的很多隐藏因素：-）每次读三国，前半部分总是读的激情澎湃，反复读过10遍以上有么有，但是到白帝城刘备死后就跳跃式快进了。而这本《风起陇西》其实说得是诸葛亮二出祁山到四出祁山之间的故事，用了非常西式的写作方法，人物的对话可能会有代出感，但这不重要，因为情节太精彩了！ <a href="/2018/07/unnamed-file-1-2.jpg"><img src="/2018/07/unnamed-file-1-2.jpg"></a> 喜欢它的原因都列在上面这张思维脑图上了。特别想提以下三点： </p>
<ol>
<li>“为了汉室”，一群执着的蜀汉精英，但缺乏个人思考，注定悲剧的英雄们更感人！ </li>
<li>荀诩这个正面的形象很喜欢，做事情一往无前，有激情、有担当，是我辈学习的楷模！ </li>
<li>诸葛亮，鲁讯说三国演义里的他多智近妖，更多的书里把他写成一个平庸的管理者、杰出的政治家、弱爆的军事家，而这本书里把他描述成一个了不起的谍战顶层设计者、政治权谋老手！很喜欢这种有料的观点。就像看电视剧《军师联盟》里的曹操一样，感觉非常爽！</li>
</ol>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>三国演义</tag>
        <tag>诸葛亮</tag>
        <tag>谍战</tag>
        <tag>风起陇西</tag>
        <tag>马伯庸</tag>
      </tags>
  </entry>
  <entry>
    <title>都是事件驱动，为什么Nginx的性能远高于Redis？</title>
    <url>/2020/12/14/nginx/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/</url>
    <content><![CDATA[<p>谈到Redis缓存，我们描述其性能时会这么说：支持1万并发连接，几万QPS。而我们描述Nginx的高性能时，则会宣示：支持C10M（1千万并发连接），百万级QPS。Redis与Nginx同样使用了事件驱动、异步调用、Epoll这些机制，为什么Nginx的并发连接会高出那么多呢？（本文不讨论Redis分布式集群） 这其实是由<strong>进程架构</strong>决定的。为了让进程占用CPU的全部计算力，Nginx充分利用了分时操作系统的特点，比如增加CPU时间片、提高CPU二级缓存命中率、用异步IO和线程池的方式回避磁盘的阻塞读操作等等，只有清楚了Nginx的这些招数，你才能将Nginx的性能最大化发挥出来。 为了维持Worker进程间的负载均衡，在1.9.1版本前Nginx使用互斥锁，基于八分之七这个阈值维持了简单、高效的基本均衡。而在此之后，使用操作系统提供的多ACCEPT队列，Nginx可以获得更高的吞吐量。 本文将会沿着高性能这条主线介绍Nginx的Master/Worker进程架构，包括进程间是如何分担流量的，以及默认关闭的多线程模式又是如何工作的。同时，本文也是Nginx开源社区基础培训系列课程第一季，即6月18日晚第3次直播课的部分文字总结。  </p>
<span id="more"></span>

<h2 id="如何充分使用多核CPU？"><a href="#如何充分使用多核CPU？" class="headerlink" title="如何充分使用多核CPU？"></a>如何充分使用多核CPU？</h2><p><strong>由于散热问题，CPU频率已经十多年没有增长了</strong>。如下图统计了1970年到2018年间CPU性能的变化，可以看到表示频率的绿色线从2005年后就不再升高，服务器多数都在使用能耗比更经济的2.x GHz CPU： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/42%E5%B9%B4cpu-trend-data/"><img src="/2020/12/42%E5%B9%B4cpu-trend-data.png"></a> （图片来源：<a href="https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/%EF%BC%89">https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/）</a> 我们知道，<strong>CPU频率决定了它的指令执行速度，当频率增长陷入瓶颈，这意味着所有单进程、单线程的软件性能都无法从CPU的升级上获得提升</strong>，包括本文开头介绍的Redis服务就是如此。如果你熟悉JavaScript语言，可能使用过NodeJS这个Web服务，虽然它也是高并发服务的代表，但同样受制于单进程、单线程架构，无法充分CPU资源。 CPU厂商对这一问题的解决方案是横向往多核心发展，因此上图中表示核心数的黑色线至2005年后快速上升。由于操作系统使用CPU核心的最小单位是线程，要想同时使用CPU的所有核心，软件必须支持多线程才行。当然，进程是比线程更大的调度粒度，所以多进程软件也是可以的，比如Nginx。 下图是Nginx的进程架构图，可以看到它含有4类进程：1个Master管理进程、多个Worker工作进程、1个Cache Loader缓存载入进程和1个Cache Manager缓存淘汰进程。 <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx%E8%BF%9B%E7%A8%8B%E6%9E%B6%E6%9E%84-2/"><img src="/2020/12/nginx%E8%BF%9B%E7%A8%8B%E6%9E%B6%E6%9E%84.png"></a> 其中，Master是管理进程，它长期处于Sleep状态，并不参与请求的处理，因此几乎不消耗服务器的IT资源。另外，只有在开启HTTP缓存后，Cache Loader和Cache Manager进程才存在，其中，当Nginx启动时加载完磁盘上的缓存文件后，Cache Loader进程也会自动退出。关于这两个 Cache进程，我会在后续介绍Nginx缓存时中再详细说明。   负责处理用户请求的是Worker进程，只有Worker进程能够充分的使用多核CPU，Nginx的QPS才能达到最大值。因此，<strong>Worker进程的数量必须等于或者大于CPU核心的数量</strong>。由于Nginx采用了事件驱动的非阻塞架构，繁忙时Worker进程会一直处于Running状态，<strong>因此1个Worker进程就能够完全占用1个CPU核心的全部计算力</strong>，如果Worker进程数超过了CPU核心数，反而会造成一些Worker进程因为抢不到CPU而进入Sleep状态休眠。所以，Nginx会通过下面这行代码自动获取到CPU核心数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">ngx_ncpu = sysconf(_SC_NPROCESSORS_ONLN);</span><br></pre></td></tr></table></figure>

<p>如果你在nginx.conf文件中加入下面这行配置：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">worker_processes</span> auto;</span><br></pre></td></tr></table></figure>

<p>Nginx就会自动地将Worker进程数设置为CPU核心数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (ngx_strcmp(value[<span class="number">1</span>].data, <span class="string">&quot;auto&quot;</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    ccf-&gt;worker_processes = ngx_ncpu;</span><br><span class="line">    <span class="keyword">return</span> NGX_CONF_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>为了防止服务器上的其他进程占用过多的CPU，你还可以给Worker进程赋予更高的静态优先级</strong>。Linux作为分时操作系统，会将CPU的执行时间分为许多碎片，交由所有进程轮番执行。这些时间片有长有短，从5毫秒到800毫秒不等，内核分配其长短时，会依据静态优先级和动态优先级。其中，动态优先级由内核根据进程类型自动决定，比如CPU型进程就能比IO型进程获得更长的时间片，而静态优先级可以通过setpriority函数设置。 在Linux中，静态优先级共包含40级，从-20到+19不等，其中-20表示最高优先级。进程的默认优先级是0，所以你可以通过调级优先级，让Worker进程获得更多的CPU资源。在nginx.conf文件中，worker_priority配置就能设置静态优先级，比如：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">worker_priority</span> -<span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<p>由于每个CPU核心都拥有一级、二级缓存（Intel的Smart Cache三级缓存是所有核心共享的），为了提高这两级缓存的命中率，还可以将Worker进程与CPU核心绑定在一起。<strong>CPU缓存由于离计算单元更近，而且使用了更快的存储介质，所以二级缓存的访问速度不超过10纳秒，相对应的，主存存取速度至少在60纳秒以上，因此频繁命中CPU缓存，可以提升Nginx指令的执行速度</strong>。在nginx.conf中你可以通过下面这行配置绑定CPU：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">worker_cpu_affinity</span> auto;</span><br></pre></td></tr></table></figure>

<p>Nginx的多进程架构已经能够支持C10M级别的高并发了，那么Nginx中的多线程又是怎么回事呢？这要从Linux文件系统的非阻塞调用说起。   Worker进程上含有数万个并发连接，在处理连接的过程中会产生大量的上下文切换。由于内核做一次切换的成本大约有5微秒，随着并发连接数的增多，这一成本是以指数级增长的。因此，<strong>只有在用户态完成绝大部分的切换，才有可能实现高并发</strong>。想做到这一点，只有完全使用非阻塞的系统调用。对于网络消息的传输，non-block socket可以完美实现。然而，Linux上磁盘文件的读取却是个大问题。 我们知道，机械硬盘上定位文件很耗时，由于磁盘转速难以提高（服务器磁盘的转速也只有10000转/秒），所以定位操作需要8毫秒左右，这是一个很高的数字。写文件时还可以通过Page Cache磁盘高速缓存的write back功能，先写入内存再异步回盘，读文件时则没有好办法。虽然Linux提供了原生异步IO系统调用，但在内存紧张时，异步AIO会回退到阻塞API（FreeBSD操作系统上的AIO没有这个问题）。 所以，为了缩小阻塞API的影响范围，Nginx允许将读文件操作放在独立的线程池中执行。比如，你可以通过下面这2条配置，为HTTP静态资源服务开启线程池：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">thread_pool</span> name threads=number [max_queue=number];</span><br><span class="line"><span class="attribute">aio</span> threads[=pool];</span><br></pre></td></tr></table></figure>

<p>这个线程池是运行在Worker进程中的，并通过一个任务队列（max_queue设置了队列的最大长度），以生产者/消费者模型与主线程交换数据，如下图所示： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx%E7%BA%BF%E7%A8%8B%E6%B1%A0/"><img src="/2020/12/nginx%E7%BA%BF%E7%A8%8B%E6%B1%A0.png"></a> 在极端场景下（活跃数据占满了内存），线程池可以将静态资源服务的性能提升9倍，具体测试可以参见这篇文章：<a href="https://www.nginx.com/blog/thread-pools-boost-performance-9x/">https://www.nginx.com/blog/thread-pools-boost-performance-9x/</a>。   到这里你可能有个疑问：又是多进程，又是多线程，为什么Nginx不索性简单点，全部使用多线程呢？这主要由2个原因决定：</p>
<ul>
<li>  首先，作为高性能负载均衡，稳定性非常重要。由于多线程共享同一地址空间，一旦出现内存错误，所有线程都会被内核强行终止，这会降低系统的可用性；</li>
<li>  其次，Nginx的模块化设计允许第三方代码嵌入到核心流程中执行，这虽然大大丰富了Nginx生态，却也引入了风险。</li>
</ul>
<p>因此，Nginx宁肯选用多进程模式使用多核CPU，而只以多线程作为补充。  </p>
<h2 id="Worker进程间是如何协同处理请求的？"><a href="#Worker进程间是如何协同处理请求的？" class="headerlink" title="Worker进程间是如何协同处理请求的？"></a>Worker进程间是如何协同处理请求的？</h2><p>当一个进程监听了80端口后，其他进程绑定该端口时会失败，通常你会看到“Address already in use”的提示。那么，所有Worker进程同时监听80或者443端口，又是怎样做到的呢？ 如果你用netstat命令，可以看到只有进程ID为2758的Master进程监听了端口： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx%E8%BF%9B%E7%A8%8B1/"><img src="/2020/12/nginx%E8%BF%9B%E7%A8%8B1.png"></a> </p>
<p>Worker进程是Master的子进程，用ps命令可以从下图中看到，2758有2个Worker子进程，ID分别为3188和3189： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx%E8%BF%9B%E7%A8%8B2/"><img src="/2020/12/nginx%E8%BF%9B%E7%A8%8B2.png"></a> </p>
<p>由于子进程自然继承了父进程已经打开的端口，所以Worker进程也在监听80和443端口，你可以用lsof命令看到这一点： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx%E8%BF%9B%E7%A8%8B3/"><img src="/2020/12/nginx%E8%BF%9B%E7%A8%8B3.png"></a> </p>
<p>我们知道，TCP的三次握手是由操作系统完成的。其中，成功建立连接的socket会放入ACCEPT队列，如下图所示： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%8C%E6%88%90%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"><img src="/2020/12/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%8C%E6%88%90%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png"></a> </p>
<p>这样，当Worker进程通过epoll_wait的读事件（Master进程不会执行epoll_wait函数）获取新连接时，就由内核挑选1个Worker进程处理新连接。早期Linux内核的挑选算法很糟糕，特别是1个新连接建立完成时，内核会唤醒所有阻塞在epoll_wait函数上的Worker进程，然而，只有1个Worker进程，可以通过accept函数获取到新连接，其他进程获取失败后重新休眠，这就是曾经广为人知的“惊群”现象。同时，这也很容易造成Worker进程间负载不均衡，由于每个Worker进程绑定1个CPU核心，当部分Worker进程中的并发TCP连接过少时，意味着CPU的计算力被闲置了，所以这也降低了系统的吞吐量。   Nginx早期解决这一问题，在通过应用层accept_mutex锁完成的，在1.11.3版本前它是默认开启的：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">accept_mutex</span> <span class="literal">on</span>;</span><br></pre></td></tr></table></figure>

<p>这把锁的工作原理是这样的：同一时间，通过抢夺accept_mutex锁，只有唯一1个持有锁的Worker进程才能将监听socket添加到epoll中：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (ngx_shmtx_trylock(&amp;ngx_accept_mutex)) &#123;</span><br><span class="line">    <span class="keyword">ngx_listening_t</span>   * ls = cycle-&gt;listening.elts;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">ngx_uint_t</span>  i = <span class="number">0</span>; i &lt; cycle-&gt;listening.nelts; i++) &#123;</span><br><span class="line">        <span class="keyword">ngx_connection_t</span> * c = ls[i].connection;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (ngx_add_event(c-&gt;read, NGX_READ_EVENT, <span class="number">0</span>) == NGX_ERROR) &#123;</span><br><span class="line">            <span class="keyword">return</span> NGX_ERROR;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>这就解决了“惊群”问题，我们再来看负载均衡功能是怎么实现的</strong>。在nginx.conf中可以通过下面这行配置，设定每个Worker进程能够处理的最大并发连接数：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">worker_connections</span> number;</span><br></pre></td></tr></table></figure>

<p>当空闲连接数不足总数的八分之一时，Worker进程会大幅度降低获取accept_mutex锁的概率：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ngx_int_t</span>  ngx_accept_disabled = ngx_cycle-&gt;connection_n / <span class="number">8</span> - ngx_cycle-&gt;free_connection_n;</span><br><span class="line"><span class="keyword">if</span> (ngx_accept_disabled &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    ngx_accept_disabled--;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们还可以通过accept_mutex_delay配置控制负载均衡的执行频率，它的默认值是500毫秒，也就是最多500毫秒后，并发连接数较少的Worker进程会尝试处理新连接：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">accept_mutex_delay</span> <span class="number">500ms</span>;</span><br></pre></td></tr></table></figure>

<p>当然，在1.11.3版本后，Nginx默认关闭了accept_mutex锁，这是因为操作系统提供了reuseport（Linux3.9版本后才提供这一功能）这个更好的解决方案。我们先来看一下处理新连接的性能对比图： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx-reuseport/"><img src="/2020/12/nginx-reuseport.png"></a> </p>
<p>上图中，横轴中的default项开启了accept_mutex锁。可以看到，使用reuseport后，QPS吞吐量有了3倍的提高，同时处理时延有明显的下降，特别是时延的波动（蓝色的标准差线）有大幅度的下降。 reuseport能够做到这么高的性能，是因为内核为每个Worker进程都建立了独立的ACCEPT队列，由内核将建立好的连接按负载分发到各队列中，如下图所示： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/reuseport%E5%8E%9F%E7%90%86/"><img src="/2020/12/reuseport%E5%8E%9F%E7%90%86.png"></a> </p>
<p>这样，Worker进程的执行效率就高了很多！如果你想开启reuseport功能，只需要在listen指令后添加reuseport选项即可： <a href="/2020/12/14/%E9%83%BD%E6%98%AF%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88nginx%E7%9A%84%E6%80%A7%E8%83%BD%E8%BF%9C%E9%AB%98%E4%BA%8Eredis%EF%BC%9F/nginx-conf-reuseport/"><img src="/2020/12/nginx-conf-reuseport.png"></a> </p>
<p>当然，Master/Worker进程架构带来的好处还有热加载与热升级。在<a href="https://www.nginx-cn.net/article/70">https://www.nginx-cn.net/article/70</a>这篇文章中，我对这一流程有详细的介绍。  </p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>  最后对本文的内容做个总结。 材料、散热这些基础科技没有获得重大突破前，CPU频率很难增长，类似Redis、NodeJS这样的单进程、单线程高并发服务，只能向分布式集群方向发展，才能继续提升性能。Nginx通过Master/Worker多进程架构，可以充分使用服务器上百个CPU核心，实现C10M。 </p>
<p>为了榨干多核CPU的价值，Nginx无所不用其极：通过绑定CPU提升二级缓存的命中率，通过静态优先级扩大时间片，通过多种手段均衡Worker进程之间的负载，在独立线程池中隔离阻塞的IO操作，等等。可见，高性能既来自于架构，更来自于细节。</p>
]]></content>
      <categories>
        <category>web</category>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>C10M</tag>
        <tag>cpu绑定</tag>
        <tag>redis</tag>
        <tag>reuseport</tag>
      </tags>
  </entry>
  <entry>
    <title>两种战争</title>
    <url>/2015/01/25/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E4%B8%A4%E7%A7%8D%E6%88%98%E4%BA%89/</url>
    <content><![CDATA[<p>有一种国家，越打仗越有钱，例如英国，曾经的日不落帝国，又比如美国以色列等等。还有一种国家，特别是中世纪以前的国家，越打仗越穷，例如大家熟悉的汉武帝，打完匈奴国力大损。</p>
<p>为什么会有这两种截然相反的现象呢？因为利益诉求不明确，但最大原因是利益分配不公！</p>
<span id="more"></span>
<p>打仗，必然是为了利益，要么是防止别人抢自己的利益，无论是土地还是财富，要么是抢原本不是自己的利益，这是事实。</p>
<p>打仗的主体是国家的全体人民，穷人出人，富人出钱，打仗通常带来通货膨胀，所以即使不加税不捐款你也要出力的。</p>
<p>由以上前提可以得出，国家越打仗越有钱，是因为打仗保护的利益或者抢来的利益都归为打仗的主体了，例如英国的商人、企业家，他们获得了廉价的原材料，例如水手士兵，他们的财富提高了，例如本土的工人，他们所在企业更加盈利从而工人的薪水水涨船高。</p>
<p>有的国家越打仗越没钱，因为利益分配的主体是少数官员或者官商，例如抢来的金银之物献给皇宫、将士，企业家没有拿到好处，少数的官商拿到好处后必须献给挺他们的官员，而不是员工，因此全国出力的大部分人没有拿到好处，但战争却消耗了他们的实力，这种恶性循环下国家就会越打越穷。</p>
<p>所以，打仗必须要思考：是为了保护利益？还是为了争夺利益？如果是保护了利益，那么保护了谁的利益？如果是争夺利益，那么新争夺到的利益最终如何分配？例如，打下海上油气田，是否油价能够下降？由原材料价格的下降，是否能够完全的传导到战争中受损最大的民众？如果不能完全传导，那么落到人民身上的好处到底有多少？战争胜利后，油价仅仅回落到原先的水平吗？</p>
<p>希望嚷嚷着对日开战的人们认真想想这个问题先。</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
  </entry>
  <entry>
    <title>从码农到工程师：只要做到这6点</title>
    <url>/2018/04/21/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E4%BB%8E%E7%A0%81%E5%86%9C%E5%88%B0%E5%B7%A5%E7%A8%8B%E5%B8%88%EF%BC%9A%E5%8F%AA%E8%A6%81%E5%81%9A%E5%88%B0%E8%BF%996%E7%82%B9/</url>
    <content><![CDATA[<p>许多程序员自称码农，因为每天事情总也做不完，而这些工作也没有给自己带来职业上的提升，总在原地打转，自己的工作似乎随时可被新人替换，可有可无。于是，年轻些的考虑着转管理或者转行，年纪大些的则被所谓的40岁危机困扰焦虑着。另一方面，有些程序员工作高效，能力出众，每当机会来临时总能获得职位上升，收入迅速的提高，个人价值的提升又从精神上给自己带来满足感，常常斗志昂扬，而这样能解决复杂问题的程序员才叫工程师。本文中笔者将根据自己10多年从业经历谈谈如何从码农升级到工程师。 </p>
<span id="more"></span>
<p>事实上，互联网行业的项目需求从来不是静态的，项目是动态的、永远在不停迭代，所以即使你能力再好效率再高，也不可能让你处在空档期，所以，相比其他行业程序员们总是很容易处于忙忙碌碌的状态中。另一方面，项目里哪怕没有新功能了程序员自身也有很大的欲望去优化、重构代码，还是忙忙碌碌。但是，到底<strong>客户的问题、行业的痛点有没有真正解决</strong>？项目给公司带来多少收益？我手头的工作对公司下一步的发展有何意义？这些通常不在程序员们的思考范围：这与我何干？我是专业写代码的，这些应该由老板、产品经理、运营、销售、其他业务部门去考虑，我只需要精益求精把代码写好写稳定就可以了，我预留了许多扩展接口，到时公司需要的话去扩展模块就行了，我何必要知道与我工作无关的事？这个想法其实是让许多程序员始终停留在码农阶段，与那些卓越的工程师同等辛苦，但待遇层次总是相差甚远的罪魁祸首。 </p>
<p>吴军老师在《见识》一书中把工程师定义为5个等级，相邻的等级间会有10倍的差距，而第五级工程师以下其实就是码农。 <img src="/2018/04/8a7f9a0f01c0b934decba63aca9098f7-1.jpg"> 实际上，能够到达第五级，就已经从码农提升为工程师了。比如，现在有一个任务需要实现一个功能子系统，一个第五级工程师能够与产品经理深入挖掘需求及其到底是否解决了问题，能够用算法建模解决现实中的问题，能够独立跨部门沟通获取所需的资源及协调其他工程师的帮助，能够正确的使用各种开源组件保质保量不重复造轮子，能够解决开发过程中出现的各种坑，按时交付出高质量的产品，这才是一个<strong>合格的第五级工程师</strong>了。码农离第五级工程师到底有多远呢？大家可以观察下身周，码农往往沟通技巧欠缺，不愿深入理解需求的意义，不愿深入研究某个技术或者框架的意义，或者只是深入研究某些语法糖却不考虑维护代价，喜欢造轮子，只要接手别人的工作先不愿精读代码而是想着按自己最熟悉的方式重构，做到一半时各种困难下开始退缩求助，于是交付时不断的延期再延期。。。 </p>
<p>成为一个合格的第五级工程师，需要哪些条件呢？ </p>
<h1 id="要有欲望成为高阶工程师！"><a href="#要有欲望成为高阶工程师！" class="headerlink" title="要有欲望成为高阶工程师！"></a>要有欲望成为高阶工程师！</h1><p>无欲则刚，如果内心就不大想成为一个高级工程师，那么肯定不愿付出更多的努力，肯定<strong>不会主动的加班</strong>，也不会在不加班的时候脑袋里还在想着问题和项目上的事，而加班或者正常上班时敷衍的时间比例很高。从低一级迈向高一级时，若不愿意付出比同级人更多的努力，又谈何升级呢？在任何领域，努力一定是成功的必要条件。 </p>
<h1 id="懂得做减法的学问。"><a href="#懂得做减法的学问。" class="headerlink" title="懂得做减法的学问。"></a>懂得做减法的学问。</h1><p>事务性的工作总是非常多的，同时也会接到很多需求功能以及测试提交的bug，还有兴趣爱好呢？！很多想看的演唱会、连续剧、电影等着你，还有许多朋友聚会应酬要参加，还有朋友圈要刷刷，微博大V们的文章要读读，股票要炒炒，理财要学学，游戏要玩玩，所以，忙忙碌碌里职业技能没有得到一点增长。 或者你效率奇高，但你要做的事太多了，效率不等于效能，效能是指<strong>完成的</strong>事情*事情的意义。事情要做到100%完成，而且必须是重要的事。既然你想成为高阶工程师，那么请把不重要的事从你一天的计划中移除吧。就像上图中吴军老师所说的，每升级到下一级，你的收入都将呈现10倍上涨的趋势，这收益远远大于你去做自己并不擅长的炒股所获取的收益（长期来看）。而所谓的应酬、各类资讯、个人爱好，并不是只要清楚的认识到自己想要什么就能够正确的做减法，这需要你的认知升级。 而在leader分配下来的任务里，也需要你准确的判断出优先级，一定要先把最重要的事百分百的完成。这需要你与leader间密切沟通，因为技术管理者所掌握的信息量远大于你，而且信息在时刻变化着，他那里的信息及时度也超过你，唯有从你的上级那里才能快速的了解到工作的优先级。这也需要与产品经理、上下游部门间密切沟通，这样你才能准确的了解到你的工作对别人的意义，这也有助于你判断优先级。 总之，做减法是一门学问。 </p>
<h1 id="有效的做到10000小时定律。"><a href="#有效的做到10000小时定律。" class="headerlink" title="有效的做到10000小时定律。"></a>有效的做到10000小时定律。</h1><p>一万小时定律是作家格拉德威尔在《异类》一书中指出的定律。“人们眼中的天才之所以卓越非凡，并非天资超人一等，而是付出了持续不断的努力。1万小时的锤炼是任何人从平凡变成世界级大师的必要条件。”他将此称为“一万小时定律”。要成为某个领域的专家，需要10000小时，按比例计算就是：如果每天工作八个小时，一周工作五天，那么成为一个领域的专家至少需要五年。这就是一万小时定律。 显然，并不是任何人在一个领域工作五年就能成为大师的。有效的做到这一万小时的关键是，<strong>这一次的努力请最大程度的复用上一次努力的结果</strong>！例如当下许多互联网从业者一年就跳槽一次，先不谈是不是应该跳槽（如果只是想通过跳槽涨薪，而不是原公司没有新的位置带给自己职业发展，那就有问题了），首先你能感觉到跳槽之后是在最大程度的复用上一家公司里自己的努力吗？如果一切是在从头开始，包括新的开发工具、新的技术栈、新的业务场景、新的产业链、新的合作关系、新的同事圈子等，那么很显然十万小时也不够成为专家的。 或者从另一个角度，有些人经常换工具、框架、编程语言，如果你能够在学新技术时，始终感觉到与自己熟悉的技术一一对应，基于此能够轻易的举一反三，那么这就是在高效的复用上一次的努力。反之，或者你上一个技术还学得不到家，换了新技术后很难敏感的发现共通性，这就很糟糕。 </p>
<h1 id="抓住关键节点。"><a href="#抓住关键节点。" class="headerlink" title="抓住关键节点。"></a>抓住关键节点。</h1><p>当我们手头有许多小功能，或者与许多团队有交互时，往往经常被开会、被沟通，事情也又杂又多。此时，务必把手头上的事在分好优先级的基础上，确认每件工作的几个关键节点：完成时间点，中期交付或者需要他人交付产品、文档给你的时间点，需要协调其他人启动的时间点等等。抓住了这些时间点，往往一头乱麻的事就自然理清了。当我们的时间非常碎片化时，一定要尽力抽出大块整块的时间，这能让我们有时间思考，而且减少了任务切换的成本，而这依赖于很好的抓住关键节点。 </p>
<h1 id="常识的重要性。"><a href="#常识的重要性。" class="headerlink" title="常识的重要性。"></a>常识的重要性。</h1><p>一个有志向的农民和一个航空航天专业的毕业生都在做飞机，其最大的不同在于常识。对于不同的程序员来说，常识并不相同。我有一些同事本不是计算机专业，有些还是先做了几年其他行业再转过来做前端程序员。这样，如算法复杂度、网络模型等计算机科学体系里的基础知识对于他们就不再是常识，而常识通常是将事情做到50%程度的关键。常识的缺失会导致与同级程序员相比做事情事倍功半，这从长期来看一定会让你早早的触及职业天花板，而补足常识的缺失相较起来还是比较容易的（毕竟这本不是什么尖端知识），但许多人长年不愿在此下功夫。 </p>
<h1 id="有后劲儿。"><a href="#有后劲儿。" class="headerlink" title="有后劲儿。"></a>有后劲儿。</h1><p>有些人工作年限越久，竞争力越强，职业上升空间很大，反例其实更多，而这种有无“后劲”在我看来其实关键在于有没有科学的职场做事方法。比如习惯做乙方的外包程序员，转到甲方开始做产品时，还是习惯于把产品当成别人家的孩子，缺乏一种主人翁的精神，而在任何公司做任何产品，如果没有一种把自己的产品当孩子的感觉，就很容易向其他人表现出<strong>喜欢推诿、不肯担责任</strong>的特点，而缺乏主动精神往往导致项目前期准备工作不足，后期疲于奔命。没有主人翁精神，往往对整个研发链条自己这块以外的部分不愿意了解，这样没有办法管理好你的上游和下游，最终导致自己的工作困难重重，难出成绩。 对自己的产品有主人翁精神，会让自己保有一种使命感，进而相对更敬业、更有激情，而这对团队是有正向激励作用的。而且，有这种精神后，往往会想办法把工作流程标准化，把知识分享给团队同事以提升团队的作战能力，进而让产品更优秀。自己的工作有一点提升，与同时带动其他同事有一点提升，这是有<strong>量级差别</strong>的。当有晋升机会时，主管们自然更偏爱把机会给这样的同事。   </p>
<p>结语：职业发展的天花板在哪？许多人说是需要认知升级，但这太抽象了。在我看来，能做到以上6点，从码农上升为优秀的工程师（在所有互联网公司都极受欢迎）并不在话下。</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>10000小时</tag>
        <tag>工程师</tag>
        <tag>码农</tag>
        <tag>认识</tag>
      </tags>
  </entry>
  <entry>
    <title>前端程序员如何快速转型全栈工程师（基础版）</title>
    <url>/2018/09/03/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E5%89%8D%E7%AB%AF%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E8%BD%AC%E5%9E%8B%E5%85%A8%E6%A0%88%E5%B7%A5%E7%A8%8B%E5%B8%88%EF%BC%88%E5%9F%BA%E7%A1%80%E7%89%88%EF%BC%89/</url>
    <content><![CDATA[<p>前端与后端的思维专注点很不相同，前端聚焦在如何把内容以可视化的方式展现给用户，后端聚焦在如何利用IT基础设施实现业务逻辑。所以前端参与后端开发时（全栈工程师必备！）首先需要理解后端会做哪些事，其次才是如何才能做好这些事。 所谓“利用IT基础设施实现业务逻辑”，意味着以下几个概念：</p>
<span id="more"></span>
<h1 id="IT基础设施有哪些？"><a href="#IT基础设施有哪些？" class="headerlink" title="IT基础设施有哪些？"></a>IT基础设施有哪些？</h1><p>数据库一定是最重要的，这里特指关系数据库，例如mysql。因为前端所用的数据库往往非常简单，浏览器或者APP毕竟只服务于一位用户，而后端的数据库需要服务于全部用户，这不是一个量级。在现实世界中，一旦量级发生改变，需要用到的技术就完全不一样了。数据库的基本操作ACID、事务、关联查询、索引都是完成业务逻辑的必备品。 <img src="/2018/09/mysql%E5%AE%A2%E6%88%B7%E7%AB%AF-3.jpg"> 缓存也是前端必须理解的概念。后端可以直接操作SATA磁盘，SSD磁盘，内存等不同的存储介质，而这些介质的存取速度差异巨大。CPU操作L1和L2缓存只有3个纳秒以内，到了L3缓存（可以以MB为单位计量了）就得10纳秒以上了，而到了内存就得100纳秒以上，通过网卡访问远端则需要数百微秒，访问机械硬盘则要几十毫秒。为了能够让用户的请求尽快获得响应，必须使用缓存。很少的场景下才会直接编写缓存，通常后端都在使用的缓存服务包括redis、memcached等，其中前者使用更多。</p>
<h1 id="如何正确的分析业务逻辑？"><a href="#如何正确的分析业务逻辑？" class="headerlink" title="如何正确的分析业务逻辑？"></a>如何正确的分析业务逻辑？</h1><p>UML图是一个非常好的手段！类图、时序图、状态图可以帮助后端理清先做什么、再做什么、不会漏掉什么。这是因为后端的程序需要整年的运行不能宕机，而前端是没有这种要求的。因此，后端必须全面的考虑各种异常情况，防止一个用户（请求）引起的意外把整个服务宕机，影响了全部用户。 <img src="/2018/09/UML%E7%A4%BA%E4%BE%8B-1.jpg"></p>
<h1 id="业务逻辑如何与IT设施结合？"><a href="#业务逻辑如何与IT设施结合？" class="headerlink" title="业务逻辑如何与IT设施结合？"></a>业务逻辑如何与IT设施结合？</h1><p>了解MVC模型！前端有许多模型，例如MVVM等，这些名词不重要，因为它们的关注点各不相同。对于后端，通常M意味着关系数据库，所以后端的WEB框架一定围绕着M进行。我们分析任何一个WEB框架，一定先要看它的数据库模型，即如何将数据库中的表、行映射到编程语言中。另一方面，HTTP协议有许多特性，它会导致MVC框架试图以此解耦，将URL的配置与业务处理代码分开。最后，WEB框架由于处理场景的复杂，通常以可插拔的方式将许多插件串行的组合起来处理一个请求。前端在学习WEB框架时，把握这三点即可快速掌握。 <img src="/2018/09/iis%E4%B8%BE%E4%BE%8Bmvc-1.jpg"> 前端做后端时最容易犯2个错误：</p>
<h1 id="日志打得很少"><a href="#日志打得很少" class="headerlink" title="日志打得很少"></a>日志打得很少</h1><p>后端的复杂场景会导致bug难以复现（相比前端更难），且一个应用服务可能跑在多个服务器上，所以error、info、debug等级日志的输出显得尤为重要！没有日志，问题很难定位！</p>
<h1 id="资源没有即用即放！"><a href="#资源没有即用即放！" class="headerlink" title="资源没有即用即放！"></a>资源没有即用即放！</h1><p>因为服务是7*24小时运行的，所以一点点资源泄露（如打开了句柄却未关闭）都会被时间放大！最后导致严重后果。   后端的代码如何更高效？答案一定是算法！ 好的算法在我看来就是3点：</p>
<ol>
<li> 不做重复的事；</li>
<li> 充分利用已知信息或者中间计算结果；</li>
<li> 充分利用IT基础设施的特性。比如多核、CPU亲和性、存储介质的性价比、网络报文的收发等。</li>
</ol>
<p>为了达到这一点，我们必须学习：</p>
<ol>
<li> 算法复杂度；</li>
<li> 分而治之的思想，这可能是所有算法思想中最有用的了；</li>
<li> 计算机体系的特点，如CPU架构、网络通讯成本等；</li>
<li> 常用数据结构，如树、哈希表、图等。</li>
</ol>
<p>本文出现的原因是团队中有前端同事想在后端试试水，我当然非常欢迎，于是尽量从我对前端的理解上阐述后端开发的要点，或者更准确的说，是后端WEB应用开发工程师的开发要点。全栈工程师的要求高得多，这里虽然有些标题党嫌疑，但好在标明了基础版，进阶版在好好谈谈前端转全栈工程师的其他要求。</p>
]]></content>
      <categories>
        <category>web</category>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>全栈</tag>
        <tag>前端</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>产品思维的修炼：技术的必修课</title>
    <url>/2018/07/24/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%E7%9A%84%E4%BF%AE%E7%82%BC-%E6%8A%80%E6%9C%AF%E7%9A%84%E5%BF%85%E4%BF%AE%E8%AF%BE/</url>
    <content><![CDATA[<p>作为写了十多年代码的技术表示：产品思维比程序员们想象中重要得多！掌握了产品思维的程序员能力可以double！我把产品思维的养成要点，从我的认知上提炼了下，供大家参考。 理解产品思维前，首先需要了解产品经理是一群什么样的人；其次我们再来看产品思维的本质；再次看看程序员们的技术思维有什么特点；最后谈谈技术人员如何具备产品思维。</p>
<span id="more"></span>
<h1 id="1、产品经理是一群什么样的人？"><a href="#1、产品经理是一群什么样的人？" class="headerlink" title="1、产品经理是一群什么样的人？"></a>1、产品经理是一群什么样的人？</h1><h2 id="1）产品经理必须能保护技术人员！"><a href="#1）产品经理必须能保护技术人员！" class="headerlink" title="1）产品经理必须能保护技术人员！"></a>1）产品经理必须能保护技术人员！</h2><p>需求是混乱无序的，需求有来自管理层关于公司长期目标的、有来自合作伙伴的诉求、有来自销售和市场对新客户的功能代言、有来自运营对存量用户使用体验的代言、有来自品牌对活动运营的诉求，还有来自所谓“用户”由产品经理代言的需求，因为用户种类很多，且随着时间而变化，所以最后这个代言非常难。如果让这些需求直接砸到技术，那么技术是没办法设计、开发、按时交付产品的。产品经理需要把混乱的需求<strong>翻译</strong>成技术可以看得懂、可以执行的产品需求、可以迭代的版本！所以，如果一个产品经理不能够保护技术直面混乱的需求，那么这不是一个好产品经理！产品经理通常会很在意自己的“<strong>人品值</strong>”，每当他们没有保护好技术，使得技术在多个版本里返工，推倒原先的代码和功能实现，这就在消耗他们的人品。当技术对产品经理完全不信任时，这个产品也就该走人了。</p>
<h2 id="2）产品经理是解决问题、而不是提出问题的人！"><a href="#2）产品经理是解决问题、而不是提出问题的人！" class="headerlink" title="2）产品经理是解决问题、而不是提出问题的人！"></a>2）产品经理是解决问题、而不是提出问题的人！</h2><p>如果在产品评审会，产品经理抛出了许多没有解决方案的问题，那么他不是一个优秀的产品经理。所有人都有无数的idea，每个人都可以很挑剔，提问题的人应当是产品经理以外的所有人！产品经理的核心职责是解决问题，给出问题的解决方案（当然，产品经理可以私下与专家讨论，汇聚想法，而不是在需求评审会里提问题）！</p>
<h2 id="3）比技术更懂运营的人！"><a href="#3）比技术更懂运营的人！" class="headerlink" title="3）比技术更懂运营的人！"></a>3）比技术更懂运营的人！</h2><p>互联网行业与传统的IT行业最大的差别在于，前者提供的是服务，是<strong>持续交付</strong>的，而后者提供的是软件，是一次性交付的！因此，互联网产品非常需要运营，它与产品是共生的！而运营需要考虑行业蓝图，谁是敌人？谁是友军？公司的资源在哪？我处在供应链的哪个环节？谁是惹不起的？BAT哪家有红利可以使用？哪里投入产出比最高？产品现在是早期、增长期还是成熟期？是应该不计成本的投入给种子用户，还是该规模化拉大众用户进场了？这些离研发似乎有些远，但确是产品经理得懂的必知必会。</p>
<h2 id="4）与逻辑较真，但也能与天马行空的设计师、不专业的用户、不关注细节的老板、目标导向侵入性强的销售、思维严谨保守的技术聊得嗨！"><a href="#4）与逻辑较真，但也能与天马行空的设计师、不专业的用户、不关注细节的老板、目标导向侵入性强的销售、思维严谨保守的技术聊得嗨！" class="headerlink" title="4）与逻辑较真，但也能与天马行空的设计师、不专业的用户、不关注细节的老板、目标导向侵入性强的销售、思维严谨保守的技术聊得嗨！"></a>4）与逻辑较真，但也能与天马行空的设计师、不专业的用户、不关注细节的老板、目标导向侵入性强的销售、思维严谨保守的技术聊得嗨！</h2><p>产品经理非常需要严谨的逻辑，因为他需要<strong>设计流程</strong>，而流程是不能容忍“例外”的！同时，他还需要与各种角色沟通，并能够从沟通中获取到自己需要的信息，同时准确、讲究方式方法的把信息传达给目标角色。</p>
<h2 id="5）产品经理是用户代言人！"><a href="#5）产品经理是用户代言人！" class="headerlink" title="5）产品经理是用户代言人！"></a>5）产品经理是用户代言人！</h2><p>对互联网产品来说，每个人都是用户！但用户作为群体是没办法发声的，产品经理必须为用户群体发声！当然，这需要强大的能力，包括用户调研、前端埋点、数据分析等各种招数。 简单的聊完产品经理，我们再看看产品思维是什么。</p>
<h1 id="2、产品思维是什么？"><a href="#2、产品思维是什么？" class="headerlink" title="2、产品思维是什么？"></a>2、产品思维是什么？</h1><h2 id="1）大局观：操盘思维"><a href="#1）大局观：操盘思维" class="headerlink" title="1）大局观：操盘思维"></a>1）大局观：操盘思维</h2><p>首先要把自己放在产品的操盘手位置上去思考。例如下面的金牛瘦狗图，横坐标是市场占有率，市场占有率高（左边）当然最好！ <img src="http://www.taohui.pub/wp-content/uploads/2018/07/unnamed-file-2-3.jpg"> 纵轴表示需求增长率，上方表示需求增长很快，这表示我们必须花更多的资源才能满足用户。所以，左上角就是明星产品，它值得花大力气去研发，而下方的金牛则是可以考虑变现，潜力不足但市场占有率很高。对于右上角市场占有率低且需求增长很快，则明显是个“鸡肋”，这种问题产品应该尽快放弃掉。 能像以上这样思考问题，就有了行业视角、老板视角，这样的大局观是高级产品经理必须具备的。或者使用下面的SWOT态势分析法，从战略层面上定位自己的产品。 <img src="/2018/07/SWOT-2.jpg"> 现在我们再来看很多问题就一目了然。比如，互联网的商业模式要么是to C从用户那里收费，这要求我们的用户体验必须是第一流的，就像腾讯！ 要么是to B从服务的企业那里收费，这要求我们的技术能力必然远强于企业客户，所以我们要在技术能力上下大功夫，就像百度； 要么是在B to C商家向用户出售产品的过程中收取服务佣金，这要求我们的运营能力必须非常强，能够整合商家到平台上，吸引用户消费，就像阿里。 所以，你的产品的商业模式到底是什么？最大的成本花在哪里了？</p>
<h2 id="2）用户体验思维"><a href="#2）用户体验思维" class="headerlink" title="2）用户体验思维"></a>2）用户体验思维</h2><p>本质上，互联网产品需要取悦用户，由用户的微笑价值进而才能产生商业价值。 <img src="http://www.taohui.pub/wp-content/uploads/2018/07/unnamed-file-3-2.jpg"> 这要求我们必须具备从用户体验出发的设计思维，就像下面这张图，从用户体验的5个层面上思考产品的设计： <img src="/2018/07/unnamed-file-4-3.jpg"> 界面好看不好看，从来不是决定一个产品成功或者失败的关键因素！所以，上面这张图越是下面的层次越是重要！</p>
<h2 id="3）互联网式的产品迭代思维"><a href="#3）互联网式的产品迭代思维" class="headerlink" title="3）互联网式的产品迭代思维"></a>3）互联网式的产品迭代思维</h2><p>互联网行业最擅长快速迭代的交付产品，这是有原因的： 1、快速交付产品可以减少版本风险！时间跨度越长，交付的产品与我们的预期差距越大，版本风险越大！ 2、互联网产品有许多都是从0到1的突破性产品，而不是从1到N！这样，在探索期内，降低试错成本非常重要，产品必须灵活的快速尝试简单、实现迅速的功能，由种子用户的运营中反馈到版本迭代中去，进而修正产品，这样最有效。 而快速迭代也不能乱来，就像下图中的<strong>MVP最小化可实行产品</strong>设计。当我们想造一辆汽车，不能第1个版本先迭代造出轮子，第2个版本选出车身，第3个版本集成，这可以是快速迭代，但它不是MVP。 <img src="/2018/07/MVP%E6%9C%80%E5%B0%8F%E5%8C%96%E5%8F%AF%E5%AE%9E%E8%A1%8C%E4%BA%A7%E5%93%81-2.png"> 以滑板车、自行车、摩托车、汽车的方式迭代，这才是MVP，才能给用户提供微笑价值！</p>
<h2 id="5）有运营视角"><a href="#5）有运营视角" class="headerlink" title="5）有运营视角"></a>5）有运营视角</h2><p>产品经理需要有运营视角，因为需要从迭代中要数据，从数据中去迭代。在产品的不同发展周期，用户群体也是不同的，如下图所示。 <img src="/2018/07/unnamed-file-7.png"> 产品早期愿意尝鲜的用户是创新者，他们是不走寻常路的，广告投放对他们无效。而对他们则应该增加投入成本，找到可以解决用户痛点的引爆点，从而使用户增长斜率从小于1到大于1！而且这些用户就像恋爱理论里的18岁红颜（“我要我要我就要”），“懒惰而贪婪”，是产品经理（“我给我给我全给”）<strong>最理想的用户</strong>，从他们身上可以最快速的试错。而这些用户最不吝于用口碑去宣传产品，只要产品能给他们惊喜！一定要珍惜这样的用户，千万不能让他们跑了！！ 在增长期才应该在媒体上投放广告轰炸，给大众用户以“大家都在用XXX”的感觉，大众用户走的是群体思维，爱从众。   下面再来看看技术思维的不同之处。</p>
<h1 id="3、技术思维有什么特点？"><a href="#3、技术思维有什么特点？" class="headerlink" title="3、技术思维有什么特点？"></a>3、技术思维有什么特点？</h1><h2 id="1）讨厌不确定性！"><a href="#1）讨厌不确定性！" class="headerlink" title="1）讨厌不确定性！"></a>1）讨厌不确定性！</h2><p>技术人最讨厌的就是不确定性。如果产品经理在跟技术阐明需求时，表达出各种不确定性。特别是，即使某个需求点可能有变化，但变化的趋势也完全不确定时，技术就要抓狂了！</p>
<h2 id="2）严谨的工程师思维！"><a href="#2）严谨的工程师思维！" class="headerlink" title="2）严谨的工程师思维！"></a>2）严谨的工程师思维！</h2><p>产品经理讲述概念、场景时最喜欢类比，因为讲故事这个能力产品经理很擅长！但是请记住，工程师不吃这套！比如产品经理为了说明需求，可以拿一个完全不同的故事来说事，因为这两件事有共同点，这样表述重点突出也更性感生动（在产品经理看来）。但工程师的思维很严谨，他的潜意识会优先判断这两件事有没有可类比性！通常，产品经理只是为了让故事服务于他的观点，而所有的“故事”都是不严谨的，所以产品经理一旦想拿“故事”与工程师沟通，首先就会遭遇“<strong>穷举法</strong>”的为难，找例外嘛，这是程序员非常擅长的事！当然，程序员的招还有很多，因为所有的设计模式准则都能套用在现实世界。所以，如果产品经理理论功底欠缺，或者拿与其他角色沟通的方式与程序员交流，就会陷入困境。</p>
<h2 id="3）重视数据与逻辑！"><a href="#3）重视数据与逻辑！" class="headerlink" title="3）重视数据与逻辑！"></a>3）重视数据与逻辑！</h2><p>技术人员非常讲究逻辑、数据、方法，包括在很感性的人际交往中。而产品经理遭遇的局面往往错综复杂，在信息不足时非常需要产品经理基于经验和方法论的主观判断能力。这时，由于产品经理拿不出论据，在与技术沟通时就会非常吃力。</p>
<h2 id="4）聚焦在实现上"><a href="#4）聚焦在实现上" class="headerlink" title="4）聚焦在实现上"></a>4）聚焦在实现上</h2><p>技术人员谈需求时下意识的就会讨论各种实现方案的成本与优劣！所以，技术人员很容易陷入在局部细节中，而忽视了总体目标与整体结构，缺乏计划性。</p>
<h2 id="5）完美主义"><a href="#5）完美主义" class="headerlink" title="5）完美主义"></a>5）完美主义</h2><p>技术人员非常在意自己的代码是否优美，可扩展性好不好，像不像一件艺术品。通常又懒于关注他人，于是特别喜欢<strong>重构</strong>新接手的他人代码，当然自己的代码也超爱重构！完美主义极易导致设计过度，忽视了项目的成本和进度。   技术人员在具备了产品思维后，就可以直接对自己的产品负责，进而同时为产品设计、测试、运营赋能。而且可以从任务导向转为目标导向，大幅提升效能，优化产品的招数套路也会更多！下面我们来看看如何具备产品思维。</p>
<h1 id="4、技术人员如何具备产品思维？"><a href="#4、技术人员如何具备产品思维？" class="headerlink" title="4、技术人员如何具备产品思维？"></a>4、技术人员如何具备产品思维？</h1><h2 id="1）调整视角，目标导向"><a href="#1）调整视角，目标导向" class="headerlink" title="1）调整视角，目标导向"></a>1）调整视角，目标导向</h2><p>把任务导向调整为目标导向，不再仅仅去看产品经理PRD文档上的需求，而是去看产品的生命周期与发展，关注行业、公司、部门、团队的总体目标，这样就能理解产品思维。当然，屁股决定脑袋，因为职位与职责所以不用为决策（如果有的话）的后果负责（通常，互联网公司都不会让技术对失败的产品负责），所以技术尤其不应当<strong>固执</strong>（！！！），保持头脑的极度开放，从长远目标看任务。</p>
<h2 id="2）培养用户体验导向的思维"><a href="#2）培养用户体验导向的思维" class="headerlink" title="2）培养用户体验导向的思维"></a>2）培养用户体验导向的思维</h2><p>这是互联网服务下必修的技能，网上各种文章，不再赘述。</p>
<h2 id="3）了解点基因、神经科学、心理学"><a href="#3）了解点基因、神经科学、心理学" class="headerlink" title="3）了解点基因、神经科学、心理学"></a>3）了解点基因、神经科学、心理学</h2><p>程序员非常需要学点心理学知识并践行，比起机器来人性很复杂，无论是了解产品用户还是与同事协作，都需要食点人间烟火。而学习心理学上的很多系统性理论能够降低<strong>未知恐惧</strong>感，特别是近来非常流行的基因、神经科学与心理学的交叉理论知识。</p>
<h2 id="4）广泛了解各类互联网产品"><a href="#4）广泛了解各类互联网产品" class="headerlink" title="4）广泛了解各类互联网产品"></a>4）广泛了解各类互联网产品</h2><p>不能因自己的喜好就抗拒使用新类型的互联网产品，好奇心是掌握产品思维的必要条件！   技术人员天天爱看的文章、视频都是关于数据库、分布式框架、消息系统、算法、神经网络、爬虫这样的纯技术知识，当然，如果你有非常紧迫的任务，可以立刻提升工作效率那另说。从长远看，沉下心学学与技术不那么相关的产品知识，其实对我们的未来发展更好！就像产品经常说的两点之间曲线最快（<strong>最速曲线</strong>，如下图），我们的职业生涯也是一样，下面这条红色的曲线和蓝色的直线，小球沿线下落时红线是最快的。 <img src="http://www.taohui.pub/wp-content/uploads/2018/07/unnamed-file-1.gif"> 这其实要求我们多蓄点势能再出发，到达终点的时间会更短些！ 本文其实是笔者最近看完后显慧的《产品的视角：从热门到门道》一书有感而作。笔者从资深后端架构师，跨度为创业公司的联合创始人，翻完这本薄薄的小书后，豁然发现这两年自己踩了无数的坑，于是写下本文给团队的研发小伙伴们看看，如何快速提升自己的产品思维，也希望能给广大的互联网从业者们以启发。最后附上我的读书笔记思维导图供大家快速查阅。特别欣赏这本书序言里的一句话：你所做的一切，都是为了明天的某个时刻做准备！所以，程序员们，学点与技术无关的知识吧！ <img src="/2018/07/unnamed-file-5-2.jpg"></p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>MVP</tag>
        <tag>SWOT</tag>
        <tag>三堂课</tag>
        <tag>产品思维</tag>
        <tag>产品经理</tag>
        <tag>微笑价值</tag>
        <tag>用户体验</tag>
        <tag>瘦狗金牛</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈哲学和人性</title>
    <url>/2011/01/25/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E8%B0%88%E8%B0%88%E5%93%B2%E5%AD%A6%E5%92%8C%E4%BA%BA%E6%80%A7/</url>
    <content><![CDATA[<p>哲学是什么？学校里的哲学定义我不认同。哲学不是一种知识，是无法“学”到的，大学里的哲学专业和哲学课，只是去研究别人的某些抽象总结出的哲学观点，更象考古学，而我的理解不同：哲学一定是针对自己的，仅可以从别人那里了解一些观点事例，它们可能会较深程度的融入自己的思想中，形成自己的新的哲学思想。­</p>
<span id="more"></span>
<p>我的观点，哲学就是自己人生中所有阅历经验思想的总和。总和又是什么？总和包括两部分动作，整理和规则提取：把共性的人生经历模糊的归并，非重要经历丢到记忆死角，重要记忆加入大脑热点记忆中，每当共性归并记忆到达临界点后，就对这批相似的记忆提取出一些不同重要级别的规则。这种种不同级别的规则，各种不同重要级别的阅历记忆，就是哲学！哲学会指导自己的所有行为，任何新事态出现时，哲学会给出共有哪些选择项，规则和热点记忆会给出自己最可能做出的选择，当然，人类的进化规则和你的人性会做出此时是否需要突变的做出另类选择（任性一把？莫名其妙的做了奇怪的选择？情绪化？感性？或者这些都有吧。），总之，哲学最终指导你做出选择。­ </p>
<p>人性是什么？我认为，就是人作为一种生物在进化过程中产生的属性。有种观点认为，一个人做的任何决定，都是他在当时的情形下，以他当时的信息量、当时的价值观中，做出的最好选择。我基本认同这个观点，但是这里忽略了生物在进化过程中的突变行为，突变行为一定不是当时的最优决定，但是根据DNA决定了此时有必要做出这种虽然不是最优决定，但可用于探索新的更优决定。就像遗传<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">算法</a>中的基因突变，或者蚁群算法中少量蚂蚁的探索行为。所以，一个人的决定大都是当时他所能做出的最好决定，少量可能不是的最好的，但是依照其人性是有必要的探索性决定。­</p>
<p>所以，人类作为群体进化到现阶段，宏观上个性上的差异并不明显，就是说，大家的人性差不太多。微观上，每个人之间的DNA不同，即使是新生婴儿，有的婴儿生来就更喜欢冒险，可能每五次或者每十次决定中，就有一次是非最优决定。有的婴儿可能生来保守，一百次决定中才有一次轻度的非常规试探。后天也会对人性产生影响。生来喜欢冒险的婴儿，如果每次冒险得到的结果都优于之前的结果，就会强化他的冒险精神，反之他会变得更保守。­同样，有人可能经历过一千次相似经历后才会去整理提取规则，有人可能一百次就会去做，如果提取出的规则总是有好的正效果，就会强化这一趋势。我发现最近两年到合肥闲了后，是越来越爱干这事了，当然是非被动式的整理。</p>
<p>哲学形成中是靠着人性来指导的，当然哲学也会反过来影响人性。哲学形成中的归并，整理记忆，提取规则，都是人性在起作用。人性很复杂，所以机器人、<a href="http://lib.csdn.net/base/ai" title="人工智能知识库">人工智能</a>技术到现在与人相比还相差很远，毕竟是久远的进化。人性强调比较，没有什么绝对化的东西，一切因素都有权重，以及修正权重的规则。人的记忆在不停的通过五官来记录新东西，但人性在左右这些记忆，会删除一些，把一些记忆放到大箱子里，把相仿的放在一起，只记录有代表性的几个，把一些权重高的放到最容易访问的记忆里。使用记忆时，会自动的在速度和正确率上取最优解。在现实与自身不协调时，会适应现实，并在这个过程中缓慢的调整记忆和规则，所以，越不协调时越容易自我产生催眠效果。­ 哲学和人性，是唯一指导我们思想、决定的两个因素。­</p>
<p>让我们从股市中去验证这个观点。哲学上人们大不同，因为哲学主要受制于阅历，但是人性差异却没有那么大，因为人性主要来自于亿万年的进化，进化过程中产生的自动趋利避害，自动获取最优，将导致人性害怕风险，在现实与自己的希望不同时，会通过强化希望来使自己坚持下去。这些在股市中都是庄家算计散户的惯用招，而且永不过时。骗子骗人时也是如此，利用人类进化过程中寻找最优解的惯性设套。所以有许多炒股高手说，如果你在后天没有克服人性中最共通的东西，就不要来炒股，譬如喜欢短期记忆的比较，忽视长期数据；短期风险出现时会忽略客观数据；希望与现实不符时用希望来催眠自己；天上掉馅饼时欣然接受等。­</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
  </entry>
  <entry>
    <title>分享我在第十届GOPS的PPT《百万并发下Nginx的优化之道》</title>
    <url>/2018/09/19/nginx/%E5%88%86%E4%BA%AB%E6%88%91%E5%9C%A8%E7%AC%AC%E5%8D%81%E5%B1%8Agops%E7%9A%84ppt%E3%80%8A%E7%99%BE%E4%B8%87%E5%B9%B6%E5%8F%91%E4%B8%8Bnginx%E7%9A%84%E4%BC%98%E5%8C%96%E4%B9%8B%E9%81%93%E3%80%8B/</url>
    <content><![CDATA[<p>非常荣幸参加已经举办了十届的GOPS。我在架构及高可用专场分享，并担任出品人及主持人。 <img src="/2018/09/unnamed-file-2-4.jpg"> </p>
<span id="more"></span>
<p>本次会议地点在上海光大会展中心，我在大会场超级五分钟里演讲的内容只是PPT的前5页。这次我想分享的是C10M问题在Nginx上的应用。优化从来都是一个持续过程，所以最需要的是方法论。我会从硬件、集群到单机软件的优化作一个系统的阐述，希望可以把我的心得有效的传达给大家。 PPT我分为四个部分，分别是方法论概述、一个请求在Nginx中是如何被处理的、应用层优化、系统层优化。其中第二部分我更希望用一种感性的方式，为后面的内容作好铺垫。 <img src="/2018/09/unnamed-file-5.jpg"> 以下只列出我在专场分享中的PPT正文： <img src="/2018/09/2-3-5.jpg"> <img src="/2018/09/3-1-6.jpg"> <img src="/2018/09/4-1-6.jpg"> <img src="/2018/09/5-1-2.jpg"> <img src="/2018/09/6-1-3.jpg"> <img src="/2018/09/7-1-2.jpg"> <img src="/2018/09/8-1-2.jpg"> <img src="/2018/09/9-1-4.jpg"> <img src="/2018/09/10-1-6.jpg"> <img src="/2018/09/11-1-7.jpg"> <img src="/2018/09/12-1-3.jpg"> <img src="/2018/09/13-1-8.jpg"> <img src="/2018/09/14-1-4.jpg"> <img src="/2018/09/15-1-7.jpg"> <img src="/2018/09/16-1-8.jpg"> <img src="/2018/09/17-1-3.jpg"> <img src="/2018/09/18-1-3.jpg"> <img src="/2018/09/19-1-6.jpg"> <img src="/2018/09/20-1-8.jpg"> <img src="/2018/09/21-1-7.jpg"> <img src="/2018/09/22-1-2.jpg"> <img src="/2018/09/23-1-3.jpg"> <img src="/2018/09/24-1-8.jpg"> <img src="/2018/09/25-1-5.jpg"> <img src="/2018/09/26-1-2.jpg"> <img src="/2018/09/27-1-2.jpg"> <img src="/2018/09/28-1-5.jpg"> <img src="/2018/09/29-1-7.jpg"> <img src="/2018/09/30-1-7.jpg"> <img src="/2018/09/31-1-3.jpg"> <img src="/2018/09/32-1-6.jpg"> <img src="/2018/09/33-1-8.jpg"> <img src="/2018/09/34-1-4.jpg"> <img src="/2018/09/35-1-5.jpg"> <img src="/2018/09/36-1-8.jpg"> <img src="/2018/09/37-1-4.jpg"></p>
]]></content>
      <categories>
        <category>技术人生</category>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>高可用</tag>
        <tag>C10M</tag>
        <tag>GOPS</tag>
        <tag>高效运维</tag>
      </tags>
  </entry>
  <entry>
    <title>如何高效的主持会议</title>
    <url>/2018/10/21/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E7%9A%84%E4%B8%BB%E6%8C%81%E4%BC%9A%E8%AE%AE/</url>
    <content><![CDATA[<p>达利欧《原则》谈到“如果由你主持会议，应把握好对话”，深有感触，主持好会议不容易，这需要各种综合能力：时间管理、冲突管理、同理心、对企业文化的理解、集体心理学、强大的逻辑分析能力等。这里我以达利欧的建议为主线，谈谈我的个人理解。</p>
<span id="more"></span>
<h2 id="1、明确主持人及会议服务对象"><a href="#1、明确主持人及会议服务对象" class="headerlink" title="1、明确主持人及会议服务对象"></a>1、明确主持人及会议服务对象</h2><p>会议一定要以实现负责人的某个目标为目的！比如，我有一个方案，但我不确定它是否足够完备、合理，那么我的目的就是找持有不同意见的权威人士坐下来，以开放式辩论的方法达成目标；或者我希望把我的方案明确的表述给实现者，那么会议就应当以讲清楚方案、达成共识为主。 <strong>如果会议没有主持人，或者主持人没有明确的目标，那么这个会议一定是效率低下的。</strong></p>
<h2 id="2、表达要清晰准确，不要造成语言上的困惑"><a href="#2、表达要清晰准确，不要造成语言上的困惑" class="headerlink" title="2、表达要清晰准确，不要造成语言上的困惑"></a>2、表达要清晰准确，不要造成语言上的困惑</h2><p>不同于编程语言是上下文无关的，我们的自然语言是有上下文相关性的。这个相关性不只是紧挨着的句子，还可能会跨度很长，还会包含大量的常识。所以，会议中的口头表达，要求与会者必须具备相应的上下文理解能力。请确保表达务必是清晰的。 在会议邀请（或者事后的会议纪要）的电子邮件中，把问题（及答案）清晰的记录下来是有必要的。</p>
<h2 id="3、根据目标及优先级确定沟通方式"><a href="#3、根据目标及优先级确定沟通方式" class="headerlink" title="3、根据目标及优先级确定沟通方式"></a>3、根据目标及优先级确定沟通方式</h2><p>如果你需要开放式辩论，请务必挑选合适的参会者。因为辩论极其耗时，而且随着参与者人数的增多，耗时会成几何级数上升！所以一定要挑对人，这些参会者对你目标的完成最有帮助！挑选专业方向权威且与你观念不同的人是个好主意！在开放式辩论会议中，出现大家都不发言表达独立观点、或者个人拒不接受不同观点都是非常糟糕的。 <strong>如果A群体对目标实现的帮助非常大，B群体则可能有一些帮助，我不建议把A、B两群人放在一场开放式辩论会议中，而应该第一场先与A群体进行会议，第二场再与B群体。这会大大提高效率。</strong></p>
<h2 id="4、主持讨论时要果断、开明"><a href="#4、主持讨论时要果断、开明" class="headerlink" title="4、主持讨论时要果断、开明"></a>4、主持讨论时要果断、开明</h2><p>所谓果断，就是判断一场讨论可能会耗时很久，但达成的结论对会议的目标达成没多少帮助，那么就应该果断停止讨论！例如产品评审会上，因为市场调研数据不足，可能出现研发挑战方案的执行意义，此时主持人必须快速判定这次讨论对完成方案落地的帮助有多大。有时参会者因为经验缺乏，他提出的问题主持人在剖析他提出的逻辑时有助于帮助他深化理解，如果时间允许这是值得的。 人的系统一（或者叫快系统，或者叫情绪系统，或者叫潜意识）总是倾向拒绝不同的意见（这很能提升内心自洽），主持人以及参与讨论的人必须牢记：<strong>与负责任的权威不同意见交锋，对自己是最有收获的。</strong></p>
<h2 id="5、在不同层面的讨论对话中穿梭对照"><a href="#5、在不同层面的讨论对话中穿梭对照" class="headerlink" title="5、在不同层面的讨论对话中穿梭对照"></a>5、在不同层面的讨论对话中穿梭对照</h2><p>会议讨论中会有两类问题：一类是具体问题，另一类则是方法论、原则。前者是一个萝卜一个坑，后者则是会对今后一类相似问题持续产生影响。所以后者明显更重要，后者应该持续的在工作中加以改进。在讨论中一定不时在这两类问题中转换，我们必须飞快的意识到当下究竟是在讨论具体问题还是方法论原则，如果是后者优先级应当更高，结论也需要更慎重。</p>
<h2 id="6、谨防“跑题”"><a href="#6、谨防“跑题”" class="headerlink" title="6、谨防“跑题”"></a>6、谨防“跑题”</h2><p><strong>会议中出现长时间跑题一定是会议主持者的锅！</strong>就参会者来说，“跑题”是必不可免的，所以主持者有责任提醒、管理当前正在进行的讨论。有必要的话，可以通过投影仪或者白板把会议所有议题展示给所有参会者，包括已经达成共识和未达成共识的议题（已经达成共识的结论被参会者再刨出来讨论是极浪费时间的）。</p>
<h2 id="7、坚持对话的逻辑性"><a href="#7、坚持对话的逻辑性" class="headerlink" title="7、坚持对话的逻辑性"></a>7、坚持对话的逻辑性</h2><p>出现冲突的双方为了维护自身的内心自洽很容易启动情绪攻击，此时很难做到对事不对人。相对来说，如果我们始终保持自己表达的意见是有内在逻辑性的，则很容易避免情绪影响共识达成的情形。一般在会议中，有参会者表达“我觉得···”并且接下来把这一假设事实当成其他结论的论据，那么这一定是缺乏逻辑性的。比如，“我觉得有些用户会觉得我们的产品···，所以我们的产品不应该···”，这种讨论一定会引发冲突！ <strong>讨论务必要建立在事实的基础上！</strong></p>
<h2 id="8、防止“责任分散效应”"><a href="#8、防止“责任分散效应”" class="headerlink" title="8、防止“责任分散效应”"></a>8、防止“责任分散效应”</h2><p>有些共识在会议中达成了共识，可是会议主持人却没有把工作分解并分配到个人，他可能默认参会者既然一致达成了结论，那么就会各自知道承担怎样的责任。这是错误的，心理学中有“责任分散效应”，这在1964年美国的一起杀人案里首次发现。纽约深夜一位酒吧工作归来的女性，在公寓下被歹徒用刀刺死，案发过程持续三十分钟，有38位邻居发现却无一人报警。事后对美国引发了巨大的震动，大家都在讨论大城市的人性冷漠，而记者采访这38位邻居得到的回答是：每个人都以为别人会报警，所以见死不救并不会引发内心的罪恶感。心理学家后续做了大量类似的实验，发现当个体认为责任是群体的，最终是没有人负责的。 因此<strong>主持人有义务分派、明确参会者个体的责任。</strong></p>
<h2 id="9、运用两分钟法则避免表述被持续打断"><a href="#9、运用两分钟法则避免表述被持续打断" class="headerlink" title="9、运用两分钟法则避免表述被持续打断"></a>9、运用两分钟法则避免表述被持续打断</h2><p>有些讨论激烈的会议中，可能出现有人的表达频繁被别人打断的场景。此时，主持者有义务让每位意见表达者至少拥有2分钟的时间，可以完整的表述清楚自己的想法。</p>
<h2 id="10、注意气场强大的“快嘴王”"><a href="#10、注意气场强大的“快嘴王”" class="headerlink" title="10、注意气场强大的“快嘴王”"></a>10、注意气场强大的“快嘴王”</h2><p>有的参会者对自己的观点坚信不疑，且他们很难被人说服，说话语速快，而且可以把这些特点外放表现出，强力推动会议进程，不给其他人认真思考和质疑的机会。此时主持人必须回到自己的目的上来，会议的目标达成有没有被阻碍？快嘴王很容易对语速慢、担心出错出丑的参会者产生影响。主持人应确保参会者能够畅通的提出疑问。</p>
<h2 id="11、让每一个议题有始有终"><a href="#11、让每一个议题有始有终" class="headerlink" title="11、让每一个议题有始有终"></a>11、让每一个议题有始有终</h2><p>如果议题的讨论持续很久却没有达成任何结论，这是对大家时间的极大浪费。即使议题的最终结论未达成，也应该记录下中间结果。所以，对议题的总结是必不可少的，也应当以会议纪要的方式发送给全体参会者。</p>
<h2 id="12、活用各种沟通手段"><a href="#12、活用各种沟通手段" class="headerlink" title="12、活用各种沟通手段"></a>12、活用各种沟通手段</h2><p>沟通是耗时的，挨个一对一私下沟通是低效的。并不是除了一对一私下沟通外，只能通过在会议中沟通，就像第2点所说，会议时间几乎是与参与辩论者数量的平方成正比的。我们可以善用公司内的沟通工具，例如wiki、论坛、邮件、公告等，把握信息分享的有效性。   无论大小公司里，总会遇到低效的会议（大公司里会更多），参加这样的会议我总是感觉自己以及多数参会者在<strong>浪费生命</strong>，时间就是生命嘛！但是，人又不适合一心多用，我们的大脑带宽是很低的，如果同时处理多件事，比如又在听会议发言，又在写代码，还在回邮件，一定是每件事都做不好，而且大脑很疲劳！企业文化应当扼杀这样的会议。 做一个高效的会议主持者并不容易，既要达成目的，也要少浪费大家的生命，故而特意写了这篇文章，希望与大家共勉！</p>
]]></content>
      <categories>
        <category>技术人生</category>
      </categories>
      <tags>
        <tag>两分钟法则</tag>
        <tag>原则</tag>
        <tag>开会</tag>
        <tag>责任分散</tag>
        <tag>跑题</tag>
        <tag>达利欧</tag>
        <tag>逻辑性</tag>
        <tag>高效会议</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核调度算法（1）--快速找到最高优先级进程</title>
    <url>/2015/01/27/%E7%AE%97%E6%B3%95/linux%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%EF%BC%881%EF%BC%89-%E5%BF%AB%E9%80%9F%E6%89%BE%E5%88%B0%E6%9C%80%E9%AB%98%E4%BC%98%E5%85%88%E7%BA%A7%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>为什么要了解内核的调度策略呢？呵呵，因为它值得我们学习，不算是废话吧。内核调度程序很先进很强大，管理你的<a href="http://lib.csdn.net/base/linux" title="Linux知识库">Linux</a>上跑的大量的乱七八糟的进程，同时还保持着对用户操作的高灵敏响应，如果可能，为什么不把这种思想放到自己的应用程序里呢？或者，有没有可能更好的实现自己的应用，使得<a href="http://lib.csdn.net/base/operatingsystem" title="操作系统知识库">操作系统</a>能够以自己的意志来分配资源给自己的进程？ </p>
<span id="more"></span>
<p>带着这两个问题来看看KERNEL。首先回顾上我们开发应用程序，基本上就两种类型，</p>
<ul>
<li>1、IO消耗型：比如hadoop上的trunk服务，很明显它的消耗主要在IO上，包括网络IO磁盘IO等等。</li>
<li>2、CPU消耗型，比如mapreduce或者其他的需要对大量数据进行计算处理的组件，就象对高清视频压缩成适合手机观看分辨率的进程，他们的消耗主要在CPU上。</li>
</ul>
<p>当两类进程都在一台SERVER上运行时，操作系统会如何调度它们呢？现在的服务器都是SMP多核的，那么一个进程在多CPU时会来回切换吗？如果我有一个程序，既有IO消耗又有CPU消耗，怎么让多核更好的调度我的程序呢？ </p>
<p>又多了几个问题。来看看内核调度程序吧，我们先从它的优先队列谈起吧。调度程序代码就在内核源码的kernel/sched.c的schedule函数中。 首先看下面的优先级队列，每一个runqueue都有。runqueue是什么？下面会详细说下，现在大家可以理解为，内核为每一颗CPU分配了一个runqueue，用于维护这颗CPU可以运行的进程。runqueue里，有几个成员是prio_array类型，这个东东就是优先队列，先看看它的定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct prio_array &#123;  </span><br><span class="line">    unsigned int nr_active;    表示等待执行的进程总数  </span><br><span class="line">    unsigned long bitmap[BITMAP_SIZE];    一个unsigned long在内核中只有32位哈，大家要跟64位OS上的C程序中的long区分开，那个是64位的。那么这个bitmap是干什么的呢？它是用位的方式，表示某个优先级上有没有待处理的队列，是实现快速找到最高待处理优先进程的关键。如果我定义了四种优先级，我只需要四位就能表示某个优先级上有没有进程要运行，例如优先级是2和3上有进程，那么就应该是0110.......非常省空间，效率也快，不是吗？  </span><br><span class="line">    struct list_head queue[MAX_PRIO];     与上面的bitmap是对应的，它存储所有等待运行的进程。  </span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure>

<p>看看BITMAP_SIZE是怎么算出来的：#define BITMAP_SIZE ((((MAX_PRIO+1+7)/8)+sizeof(long)-1)/sizeof(long)) 那么，LINUX默认配置（如果你用默认选项编译内核的话）MAX_PRIO是140，就是说一共内核对进程一共定义了140种优先级。等待某个CPU来处理的进程中，可能包含许多种优先级的进程，但，LINUX是个抢占式调度算法的操作系统，就是说，需要调度时一定是找到最高优先级的进程执行。上面的BITMAP_SIZE值根据MAX_PRIO算出来为5，那么bitmap实际是32*5=160位，这样就包含了MAX_PRIO的140位。优先级队列是怎么使用的？看2649行代码：idx = sched_find_first_bit(array-&gt;bitmap);这个方法就用来快速的找到优先级最高的队列。看看它的实现可以方便我们理解这个优先级位的设计：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static inline int sched_find_first_bit(unsigned long *b)  </span><br><span class="line">&#123;  </span><br><span class="line">    if (unlikely(b[0]))  </span><br><span class="line">        return __ffs(b[0]);  </span><br><span class="line">    if (unlikely(b[1]))  </span><br><span class="line">        return __ffs(b[1]) + 32;  </span><br><span class="line">    if (unlikely(b[2]))  </span><br><span class="line">        return __ffs(b[2]) + 64;  </span><br><span class="line">    if (b[3])  </span><br><span class="line">        return __ffs(b[3]) + 96;  </span><br><span class="line">    return __ffs(b[4]) + 128;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>那么__ffs是干什么的？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static inline int __ffs(int x)  </span><br><span class="line">&#123;  </span><br><span class="line">    int r &#x3D; 0;  </span><br><span class="line">  </span><br><span class="line">    if (!x)  </span><br><span class="line">        return 0;  </span><br><span class="line">    if (!(x &amp; 0xffff)) &#123;  </span><br><span class="line">        x &gt;&gt;&#x3D; 16;  </span><br><span class="line">        r +&#x3D; 16;  </span><br><span class="line">    &#125;  </span><br><span class="line">    if (!(x &amp; 0xff)) &#123;  </span><br><span class="line">        x &gt;&gt;&#x3D; 8;  </span><br><span class="line">        r +&#x3D; 8;  </span><br><span class="line">    &#125;  </span><br><span class="line">    if (!(x &amp; 0xf)) &#123;  </span><br><span class="line">        x &gt;&gt;&#x3D; 4;  </span><br><span class="line">        r +&#x3D; 4;  </span><br><span class="line">    &#125;  </span><br><span class="line">    if (!(x &amp; 3)) &#123;  </span><br><span class="line">        x &gt;&gt;&#x3D; 2;  </span><br><span class="line">        r +&#x3D; 2;  </span><br><span class="line">    &#125;  </span><br><span class="line">    if (!(x &amp; 1)) &#123;  </span><br><span class="line">        x &gt;&gt;&#x3D; 1;  </span><br><span class="line">        r +&#x3D; 1;  </span><br><span class="line">    &#125;  </span><br><span class="line">    return r;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>sched_find_first_bit返回值就是最高优先级所在队列的序号，与queue是对应使用的哈，queue = array-&gt;queue + idx;这样就取到了要处理的进程队列。这个设计在查找优先级时是非常快的，非常值得我们学习。 好，优先级队列搞明白了，现在来看看runqueue，每个runqueue包含三个优先级队列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct runqueue &#123;  </span><br><span class="line">    spinlock_t lock;   这是个自旋锁，nginx里解决惊群现象时也是用这个。与普通锁的区别就是，使用普通锁时，你去试图拿一把锁，结果发现已经被别人拿走了，你就在那睡觉，等别人锁用完了叫你起来。所以如果有一个人拿住锁了，一百个人都在门前睡觉等。当之前的人用完锁回来后，会叫醒所有100个等锁的人，然后这些人开始互相抢，抢到的人拿锁进去，其他的人继续等。自旋锁不同，当他去拿锁发现锁被别人拿走了，他在那不睡觉的等，稍打个盹就看看自己主动看看锁有没有还回来。大家比较出优劣了吗？  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * nr_running and cpu_load should be in the same cacheline because </span><br><span class="line">     * remote CPUs use both these fields when doing load calculation. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    unsigned long nr_running;  </span><br><span class="line">#ifdef CONFIG_SMP  </span><br><span class="line">    unsigned long cpu_load;  </span><br><span class="line">#endif  </span><br><span class="line">    unsigned long long nr_switches;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * This is part of a global counter where only the total sum </span><br><span class="line">     * over all CPUs matters. A task can increase this counter on </span><br><span class="line">     * one CPU and if it got migrated afterwards it may decrease </span><br><span class="line">     * it on another CPU. Always updated under the runqueue lock: </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    unsigned long nr_uninterruptible;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    unsigned long expired_timestamp;  </span><br><span class="line">    unsigned long long timestamp_last_tick;  </span><br><span class="line">    task_t *curr, *idle;  </span><br><span class="line">    struct mm_struct *prev_mm;  </span><br><span class="line">    prio_array_t *active, *expired, arrays[2];上面说了半天的优先级队列在这里，但是在runqueue里，为什么不只一个呢？这个在下面讲。  </span><br><span class="line">    int best_expired_prio;  </span><br><span class="line">    atomic_t nr_iowait;  </span><br><span class="line">    ... ...  </span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure>

<p>  LINUX是一个时间多路复用的系统，就是说，通过把CPU执行时间分成许多片，再分配给进程们使用，造成即使单CPU系统，也貌似允许多个任务在同时执行。那么，时间片大小假设为100ms，过短过长，过长了有些不灵敏，过短了，连切换进程时可能都要消耗几毫秒的时间。分给100个进程执行，在所有进程都用完自己的时间片后，需要重新给所有的进程重新分配时间片，怎么分配呢？for循环遍历所有的run状态进程，重设时间片？这个性能无法容忍！太慢了，跟当前系统进程数相关。那么2.6内核怎么做的呢？它用了上面提到的两个优先级队列active和expired，顾名思义，active是还有时间片的进程队列，而expired是时间片耗尽必须重新分配时间片的进程队列。 这么设计的好处就是不用再循环一遍所有进程重设时间片了，看看调度函数是怎么玩的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">array &#x3D; rq-&gt;active;  </span><br><span class="line">if (unlikely(!array-&gt;nr_active)) &#123;  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * Switch the active and expired arrays. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    schedstat_inc(rq, sched_switch);  </span><br><span class="line">    rq-&gt;active &#x3D; rq-&gt;expired;  </span><br><span class="line">    rq-&gt;expired &#x3D; array;  </span><br><span class="line">    array &#x3D; rq-&gt;active;  </span><br><span class="line">    rq-&gt;expired_timestamp &#x3D; 0;  </span><br><span class="line">    rq-&gt;best_expired_prio &#x3D; MAX_PRIO;  </span><br><span class="line">&#125; else  </span><br><span class="line">    schedstat_inc(rq, sched_noswitch);  </span><br></pre></td></tr></table></figure>

<p>  当所有运行进程的时间片都用完时，就把active和expired队列互换指针，没有遍历哦，而时间片耗尽的进程在出acitve队列入expired队列时，已经单独的重新分配好新时间片了。 再看一下schedule(void)调度函数，当某个进程休眠或者被抢占时，系统就开始调试schedule(void)决定接下来运行哪个进程。上面说过的东东都在这个函数里有体现哈。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">asmlinkage void __sched schedule(void)  </span><br><span class="line">&#123;  </span><br><span class="line">    long *switch_count;  </span><br><span class="line">    task_t *prev, *next;  </span><br><span class="line">    runqueue_t *rq;  </span><br><span class="line">    prio_array_t *array;  </span><br><span class="line">    struct list_head *queue;  </span><br><span class="line">    unsigned long long now;  </span><br><span class="line">    unsigned long run_time;  </span><br><span class="line">    int cpu, idx;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * Test if we are atomic.  Since do_exit() needs to call into </span><br><span class="line">     * schedule() atomically, we ignore that path for now. </span><br><span class="line">     * Otherwise, whine if we are scheduling when we should not be. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    if (likely(!(current-&gt;exit_state &amp; (EXIT_DEAD  EXIT_ZOMBIE)))) &#123;先看看当前运行进程的状态  </span><br><span class="line">        if (unlikely(in_atomic())) &#123;  </span><br><span class="line">            printk(KERN_ERR &quot;scheduling while atomic: &quot;  </span><br><span class="line">                &quot;%s&#x2F;0x%08x&#x2F;%d\n&quot;,  </span><br><span class="line">                current-&gt;comm, preempt_count(), current-&gt;pid);  </span><br><span class="line">            dump_stack();  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    profile_hit(SCHED_PROFILING, __builtin_return_address(0));  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">need_resched:  </span><br><span class="line">    preempt_disable();  </span><br><span class="line">    prev &#x3D; current;  </span><br><span class="line">    release_kernel_lock(prev);  </span><br><span class="line">need_resched_nonpreemptible:  </span><br><span class="line">    rq &#x3D; this_rq();      这行找到这个CPU对应的runqueue，再次强调，每个CPU有一个自己的runqueue  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * The idle thread is not allowed to schedule! </span><br><span class="line">     * Remove this check after it has been exercised a bit. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    if (unlikely(current &#x3D;&#x3D; rq-&gt;idle) &amp;&amp; current-&gt;state !&#x3D; TASK_RUNNING) &#123;  </span><br><span class="line">        printk(KERN_ERR &quot;bad: scheduling from the idle thread!\n&quot;);  </span><br><span class="line">        dump_stack();  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    schedstat_inc(rq, sched_cnt);  </span><br><span class="line">    now &#x3D; sched_clock();  </span><br><span class="line">    if (likely(now - prev-&gt;timestamp &lt; NS_MAX_SLEEP_AVG))  </span><br><span class="line">        run_time &#x3D; now - prev-&gt;timestamp;  </span><br><span class="line">    else  </span><br><span class="line">        run_time &#x3D; NS_MAX_SLEEP_AVG;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * Tasks with interactive credits get charged less run_time </span><br><span class="line">     * at high sleep_avg to delay them losing their interactive </span><br><span class="line">     * status </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    if (HIGH_CREDIT(prev))  </span><br><span class="line">        run_time &#x2F;&#x3D; (CURRENT_BONUS(prev) ? : 1);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    spin_lock_irq(&amp;rq-&gt;lock);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    if (unlikely(current-&gt;flags &amp; PF_DEAD))  </span><br><span class="line">        current-&gt;state &#x3D; EXIT_DEAD;  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * if entering off of a kernel preemption go straight </span><br><span class="line">     * to picking the next task. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    switch_count &#x3D; &amp;prev-&gt;nivcsw;  </span><br><span class="line">    if (prev-&gt;state &amp;&amp; !(preempt_count() &amp; PREEMPT_ACTIVE)) &#123;  </span><br><span class="line">        switch_count &#x3D; &amp;prev-&gt;nvcsw;  </span><br><span class="line">        if (unlikely((prev-&gt;state &amp; TASK_INTERRUPTIBLE) &amp;&amp;  </span><br><span class="line">                unlikely(signal_pending(prev))))  </span><br><span class="line">            prev-&gt;state &#x3D; TASK_RUNNING;  </span><br><span class="line">        else &#123;  </span><br><span class="line">            if (prev-&gt;state &#x3D;&#x3D; TASK_UNINTERRUPTIBLE)  </span><br><span class="line">                rq-&gt;nr_uninterruptible++;  </span><br><span class="line">            deactivate_task(prev, rq);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    cpu &#x3D; smp_processor_id();  </span><br><span class="line">    if (unlikely(!rq-&gt;nr_running)) &#123;  </span><br><span class="line">go_idle:  </span><br><span class="line">        idle_balance(cpu, rq);  </span><br><span class="line">        if (!rq-&gt;nr_running) &#123;  </span><br><span class="line">            next &#x3D; rq-&gt;idle;  </span><br><span class="line">            rq-&gt;expired_timestamp &#x3D; 0;  </span><br><span class="line">            wake_sleeping_dependent(cpu, rq);  </span><br><span class="line">            &#x2F;* </span><br><span class="line">             * wake_sleeping_dependent() might have released </span><br><span class="line">             * the runqueue, so break out if we got new </span><br><span class="line">             * tasks meanwhile: </span><br><span class="line">             *&#x2F;  </span><br><span class="line">            if (!rq-&gt;nr_running)  </span><br><span class="line">                goto switch_tasks;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125; else &#123;  </span><br><span class="line">        if (dependent_sleeper(cpu, rq)) &#123;  </span><br><span class="line">            next &#x3D; rq-&gt;idle;  </span><br><span class="line">            goto switch_tasks;  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#x2F;* </span><br><span class="line">         * dependent_sleeper() releases and reacquires the runqueue </span><br><span class="line">         * lock, hence go into the idle loop if the rq went </span><br><span class="line">         * empty meanwhile: </span><br><span class="line">         *&#x2F;  </span><br><span class="line">        if (unlikely(!rq-&gt;nr_running))  </span><br><span class="line">            goto go_idle;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    array &#x3D; rq-&gt;active;  </span><br><span class="line">    if (unlikely(!array-&gt;nr_active)) &#123;       上面说过的，需要重新计算时间片时，就用已经计算好的expired队列了  </span><br><span class="line">        &#x2F;* </span><br><span class="line">         * Switch the active and expired arrays. </span><br><span class="line">         *&#x2F;  </span><br><span class="line">        schedstat_inc(rq, sched_switch);  </span><br><span class="line">        rq-&gt;active &#x3D; rq-&gt;expired;  </span><br><span class="line">        rq-&gt;expired &#x3D; array;  </span><br><span class="line">        array &#x3D; rq-&gt;active;  </span><br><span class="line">        rq-&gt;expired_timestamp &#x3D; 0;  </span><br><span class="line">        rq-&gt;best_expired_prio &#x3D; MAX_PRIO;  </span><br><span class="line">    &#125; else  </span><br><span class="line">        schedstat_inc(rq, sched_noswitch);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    idx &#x3D; sched_find_first_bit(array-&gt;bitmap);         找到优先级最高的队列  </span><br><span class="line">    queue &#x3D; array-&gt;queue + idx;  </span><br><span class="line">    next &#x3D; list_entry(queue-&gt;next, task_t, run_list);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    if (!rt_task(next) &amp;&amp; next-&gt;activated &gt; 0) &#123;  </span><br><span class="line">        unsigned long long delta &#x3D; now - next-&gt;timestamp;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">        if (next-&gt;activated &#x3D;&#x3D; 1)  </span><br><span class="line">            delta &#x3D; delta * (ON_RUNQUEUE_WEIGHT * 128 &#x2F; 100) &#x2F; 128;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">        array &#x3D; next-&gt;array;  </span><br><span class="line">        dequeue_task(next, array);  </span><br><span class="line">        recalc_task_prio(next, next-&gt;timestamp + delta);  </span><br><span class="line">        enqueue_task(next, array);  </span><br><span class="line">    &#125;  </span><br><span class="line">    next-&gt;activated &#x3D; 0;  </span><br><span class="line">switch_tasks:  </span><br><span class="line">    if (next &#x3D;&#x3D; rq-&gt;idle)  </span><br><span class="line">        schedstat_inc(rq, sched_goidle);  </span><br><span class="line">    prefetch(next);  </span><br><span class="line">    clear_tsk_need_resched(prev);  </span><br><span class="line">    rcu_qsctr_inc(task_cpu(prev));  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    prev-&gt;sleep_avg -&#x3D; run_time;  </span><br><span class="line">    if ((long)prev-&gt;sleep_avg &lt;&#x3D; 0) &#123;  </span><br><span class="line">        prev-&gt;sleep_avg &#x3D; 0;  </span><br><span class="line">        if (!(HIGH_CREDIT(prev)  LOW_CREDIT(prev)))  </span><br><span class="line">            prev-&gt;interactive_credit--;  </span><br><span class="line">    &#125;  </span><br><span class="line">    prev-&gt;timestamp &#x3D; prev-&gt;last_ran &#x3D; now;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    sched_info_switch(prev, next);  </span><br><span class="line">    if (likely(prev !&#x3D; next)) &#123;              表面现在正在执行的进程，不是选出来的优先级最高的进程  </span><br><span class="line">        next-&gt;timestamp &#x3D; now;  </span><br><span class="line">        rq-&gt;nr_switches++;  </span><br><span class="line">        rq-&gt;curr &#x3D; next;  </span><br><span class="line">        ++*switch_count;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">        prepare_arch_switch(rq, next);  </span><br><span class="line">        prev &#x3D; context_switch(rq, prev, next);              所以需要完成进程上下文切换，把之前的进程信息CACHE住  </span><br><span class="line">        barrier();  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">        finish_task_switch(prev);  </span><br><span class="line">    &#125; else  </span><br><span class="line">        spin_unlock_irq(&amp;rq-&gt;lock);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    prev &#x3D; current;  </span><br><span class="line">    if (unlikely(reacquire_kernel_lock(prev) &lt; 0))  </span><br><span class="line">        goto need_resched_nonpreemptible;  </span><br><span class="line">    preempt_enable_no_resched();  </span><br><span class="line">    if (unlikely(test_thread_flag(TIF_NEED_RESCHED)))  </span><br><span class="line">        goto need_resched;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>当然，在我们程序中，也可以通过执行以下系统调用来改变自己进程的优先级。nice系统调用可以改变某个进程的基本优先级，setpriority可以改变一组进程的优先级。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>linux</tag>
        <tag>调度算法</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核调度算法（3）--多核系统的负载均衡</title>
    <url>/2015/01/27/%E7%AE%97%E6%B3%95/linux%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%EF%BC%883%EF%BC%89-%E5%A4%9A%E6%A0%B8%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<p>多核CPU现在很常见，那么问题来了，一个程序在运行时，只在一个CPU核上运行？还是交替在多个CPU核上运行呢？<a href="http://lib.csdn.net/base/linux" title="Linux知识库">Linux</a>内核是如何在多核间调度进程的呢？又是内核又是CPU核，两个核有点绕，下面称CPU处理器来代替CPU核。 </p>
<span id="more"></span>
<p>实际上，如果你没有对你的进程做过特殊处理的话，LINUX内核是有可能把它放到多个CPU处理器上运行的，这是内核的负载均衡。上文说过，每个处理器上有一个runqueue队列，表示这颗处理器上处于run状态的进程链表，在多处理器的内核中，就会有多个runqueue，而如果他们的大小很不均衡，就会触发内核的load_balance函数。这个函数会把某个CPU处理器上过多的进程移到runqueue元素相对少的CPU处理器上。 </p>
<p>举个例子来简单说明这个过程吧。当我们刚fork出一个子进程时，子进程也还在当前CPU处理器的runqueue里，它与父进程均分父进程的时间片。当然，时间片与多处理器间的负载均衡没有关系。假设我们的系统是双核的，父进程运行在cpu0上，那么这个fork出来的进程也是在cpu0的runqueue中。 </p>
<p>那么，什么时候会发生负载均衡呢？ </p>
<ol>
<li>当cpu1上的runqueue里一个可运行进程都没有的时候。这点很好理解，cpu1无事可作了，这时在cpu1上会调用load_balance，发现在cpu0上还有许多进程等待运行，那么它会从cpu0上的可运行进程里找到优先级最高的进程，拿到自己的runqueue里开始执行。 </li>
<li>第1种情形不适用于运行队列一直不为空的情况。例如，cpu0上一直有10个可运行进程，cpu1上一直有1个可运行进程，显然，cpu0上的进程们得到了不公平的对待，它们拿到cpu的时间要小得多，第1种情形下的load_balance也一直不会调用。所以，实际上，每经过一个时钟节拍，内核会调用scheduler_tick函数，而这个函数会做许多事，例如减少当前正在执行的进程的时间片，在函数结尾处则会调用rebalance_tick函数。rebalance_tick函数决定以什么样的频率执行负载均衡。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static void rebalance_tick(int this_cpu, runqueue_t *this_rq,  </span><br><span class="line">               enum idle_type idle)  </span><br><span class="line">&#123;  </span><br><span class="line">    unsigned long old_load, this_load;  </span><br><span class="line">    unsigned long j &#x3D; jiffies + CPU_OFFSET(this_cpu);  </span><br><span class="line">    struct sched_domain *sd;  </span><br><span class="line">  </span><br><span class="line">    &#x2F;* Update our load *&#x2F;  </span><br><span class="line">    old_load &#x3D; this_rq-&gt;cpu_load;  </span><br><span class="line">    this_load &#x3D; this_rq-&gt;nr_running * SCHED_LOAD_SCALE;  </span><br><span class="line">    &#x2F;* </span><br><span class="line">     * Round up the averaging division if load is increasing. This </span><br><span class="line">     * prevents us from getting stuck on 9 if the load is 10, for </span><br><span class="line">     * example. </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    if (this_load &gt; old_load)  </span><br><span class="line">        old_load++;  </span><br><span class="line">    this_rq-&gt;cpu_load &#x3D; (old_load + this_load) &#x2F; 2;  </span><br><span class="line">  </span><br><span class="line">    for_each_domain(this_cpu, sd) &#123;  </span><br><span class="line">        unsigned long interval;  </span><br><span class="line">  </span><br><span class="line">        if (!(sd-&gt;flags &amp; SD_LOAD_BALANCE))  </span><br><span class="line">            continue;  </span><br><span class="line">  </span><br><span class="line">        interval &#x3D; sd-&gt;balance_interval;  </span><br><span class="line">        if (idle !&#x3D; SCHED_IDLE)  </span><br><span class="line">            interval *&#x3D; sd-&gt;busy_factor;  </span><br><span class="line">  </span><br><span class="line">        &#x2F;* scale ms to jiffies *&#x2F;  </span><br><span class="line">        interval &#x3D; msecs_to_jiffies(interval);  </span><br><span class="line">        if (unlikely(!interval))  </span><br><span class="line">            interval &#x3D; 1;  </span><br><span class="line">  </span><br><span class="line">        if (j - sd-&gt;last_balance &gt;&#x3D; interval) &#123;  </span><br><span class="line">            if (load_balance(this_cpu, this_rq, sd, idle)) &#123;  </span><br><span class="line">                &#x2F;* We&#39;ve pulled tasks over so no longer idle *&#x2F;  </span><br><span class="line">                idle &#x3D; NOT_IDLE;  </span><br><span class="line">            &#125;  </span><br><span class="line">            sd-&gt;last_balance +&#x3D; interval;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>  当idle标志位是SCHED_IDLE时，表示当前CPU处理器空闲，就会以很高的频繁来调用load_balance（1、2个时钟节拍），反之表示当前CPU并不空闲，会以很低的频繁调用load_balance（10-100ms）。具体的数值要看上面的interval了。 当然，多核CPU也有许多种，例如INTEL的超线程技术，而LINUX内核对一个INTEL超线程CPU会看成多个不同的CPU处理器。 </p>
<p>上面说过，如果你没有对你的进程做过特殊处理的话，LINUX内核是有可能把它放到多个CPU处理器上运行的，但是，有时我们如果希望我们的进程一直运行在某个CPU处理器上，可以做到吗？内核提供了这样的系统调用。系统调用sched_getaffinity会返回当前进程使用的cpu掩码，而sched_setaffinity则可以设定该进程只能在哪几颗cpu处理器上执行。当我们对某些进程有强烈的期待，或者想自己来考虑CPU间的负载均衡，可以这么试试哈。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核调度算法（2）--CPU时间片如何分配</title>
    <url>/2015/01/27/%E7%AE%97%E6%B3%95/linux%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%EF%BC%882%EF%BC%89-cpu%E6%97%B6%E9%97%B4%E7%89%87%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D/</url>
    <content><![CDATA[<p>内核在微观上，把CPU的运行时间分成许多分，然后安排给各个进程轮流运行，造成宏观上所有的进程仿佛同时在执行。双核CPU，实际上最多只能有两个进程在同时运行，大家在top、vmstat命令里看到的正在运行的进程，并不是真的在占有着CPU哈。<br>所以，一些设计良好的高性能进程，比如nginx，都是实际上有几颗CPU，就配几个工作进程，道理就在这。比如你的服务器有8颗CPU，那么nginx worker应当只有8个，当你多于8个时，内核可能会放超过多个nginx worker进程到1个runqueue里，会发生什么呢？就是在这颗CPU上，会比较均匀的把时间分配给这几个nginx worker，每个worker进程运行完一个时间片后，内核需要做进程切换，把正在运行的进程上下文保存下来。假设内核分配的时间片是100ms，做进程切换的时间是5ms，那么进程性能下降还是很明显的，跟你配置的worker有关，越多下降得越厉害。 </p>
<span id="more"></span>
<p>当然，这是跟nginx的设计有关的。nginx是事件驱动的全异步进程，本身设计上就几乎不存在阻塞和中断，nginx的设计者就希望每一个nginx worker可以独占CPU的几乎全部时间片，这点就是nginx worker数量配置的依据所在。 </p>
<p>当然，实际的运行进程里，大部分并不是nginx这种希望独占CPU全部时间片的进程，许多进程，比如vi，它在很多时间是在等待用户输入，这时vi在等待IO中断，是不占用时间片的，内核面对多样化的进程，就需要技巧性的分配CPU时间片了。 </p>
<p>内核分配时间片是有策略和倾向性的。换句话说，内核是偏心的，它喜欢的是IO消耗型进程，因为这类进程如果不能及时响应，用户就会很不爽，所以它总会下意识的多分配CPU运行时间给这类进程。而CPU消耗进程内核就不太关心了。这有道理吗？太有了，CPU消耗型慢一点用户感知不出来，电信号和生物信号运转速度差距巨大。虽然内核尽量多的分配时间片给IO消耗型进程，但IO消耗进程常常在睡觉，给它的时间片根本用不掉。很合理吧？ </p>
<p>那么内核具体是怎么实现这种偏心呢？通过动态调整进程的优先级，以及分配不同长短的CPU时间处来实现。先说内核如何决定时间片的长度。 对每一个进程，有一个整型static_prio表示用户设置的静态优先级，内核里它与nice值是对应的。看看进程描述结构里的static_prio成员。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct task_struct &#123;  </span><br><span class="line">    int prio, static_prio;  </span><br><span class="line">......&#125;  </span><br></pre></td></tr></table></figure>

<p>nice值是什么？其实就是优先级针对用户进程的另一种表示法，nice的取值范围是-20到+19，-20优先级最高，+19最低。上篇曾经说过，内核优先级共有140，而用户能够设置的NICE优先级如何与这140个优先级对应起来呢？看代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define MAX_USER_RT_PRIO    100  </span><br><span class="line">#define MAX_RT_PRIO     MAX_USER_RT_PRIO  </span><br><span class="line">#define MAX_PRIO        (MAX_RT_PRIO + 40)  </span><br></pre></td></tr></table></figure>

<p>可以看到，MAX_PRIO就是140，也就是内核定义的最大优先级了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define USER_PRIO(p)        ((p)-MAX_RT_PRIO)  </span><br><span class="line">#define MAX_USER_PRIO       (USER_PRIO(MAX_PRIO))  </span><br></pre></td></tr></table></figure>

<p>而MAX_USER_PRIO就是40，意指，普通进程指定的优先级别最多40，就像前面我们讲的那样-20到+19。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define NICE_TO_PRIO(nice)  (MAX_RT_PRIO + (nice) + 20)  </span><br></pre></td></tr></table></figure>

<p>nice值是-20表示最高，对应着static_prio是多少呢？NICE_TO_PRIO(0)就是120，NICE_TO_PRIO(-20)就是100。 当该进程刚被其父进程fork出来时，是平分其父进程的剩余时间片的。这个时间片执行完后，就会根据它的初始优先级来重新分配时间片，优先级为+19时最低，只分配最小时间片5ms，优先级为0时是100ms，优先级是-20时是最大时间片800ms。我们看看内核是如何计算时间片长度的，大家先看下task_timeslice时间片计算函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define SCALE_PRIO(x, prio) \  </span><br><span class="line">    max(x * (MAX_PRIO - prio) &#x2F; (MAX_USER_PRIO&#x2F;2), MIN_TIMESLICE)  </span><br><span class="line">  </span><br><span class="line">static unsigned int task_timeslice(task_t *p)  </span><br><span class="line">&#123;  </span><br><span class="line">    if (p-&gt;static_prio &lt; NICE_TO_PRIO(0))  </span><br><span class="line">        return SCALE_PRIO(DEF_TIMESLICE*4, p-&gt;static_prio);  </span><br><span class="line">    else  </span><br><span class="line">        return SCALE_PRIO(DEF_TIMESLICE, p-&gt;static_prio);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>这里有一堆宏，我们把宏依次列出看看它们的值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># define HZ     1000      </span><br><span class="line">#define DEF_TIMESLICE       (100 * HZ &#x2F; 1000)  </span><br></pre></td></tr></table></figure>

<p>所以，DEF_TIMESLICE是100。假设nice值是-20，那么static_prio就是100，那么SCALE_PRIO(100*4, 100)就等于800，意味着最高优先级-20情形下，可以分到时间片是800ms，如果nice值是+19，则只能分到最小时间片5ms，nice值是默认的0则能分到100ms。</p>
<p>貌似时间片只与nice值有关系。实际上，内核会对初始的nice值有一个-5到+5的动态调整。这个动态调整的依据是什么呢？很简单，如果CPU用得多的进程，就把nice值调高点，等价于优先级调低点。CPU用得少的进程，认为它是交互性为主的进程，则会把nice值调低点，也就是优先级调高点。这样的好处很明显，因为</p>
<ol>
<li>一个进程的初始优先值的设定未必是准确的，内核根据该进程的实时表现来调整它的执行情况。</li>
<li>进程的表现不是始终如一的，比如一开始只是监听80端口，此时进程大部分时间在sleep，时间片用得少，于是nice值动态降低来提高优先级。这时有client接入80端口后，进程开始大量使用CPU，这以后nice值会动态增加来降低优先级。 </li>
</ol>
<p>思想明白了，代码实现上，优先级的动态补偿到底依据什么呢？effective_prio返回动态补偿后的优先级，注释非常详细，大家先看下。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;* </span><br><span class="line"> * effective_prio - return the priority that is based on the static </span><br><span class="line"> * priority but is modified by bonuses&#x2F;penalties. </span><br><span class="line"> * </span><br><span class="line"> * We scale the actual sleep average [0 .... MAX_SLEEP_AVG] </span><br><span class="line"> * into the -5 ... 0 ... +5 bonus&#x2F;penalty range. </span><br><span class="line"> * </span><br><span class="line"> * We use 25% of the full 0...39 priority range so that: </span><br><span class="line"> * </span><br><span class="line"> * 1) nice +19 interactive tasks do not preempt nice 0 CPU hogs. </span><br><span class="line"> * 2) nice -20 CPU hogs do not get preempted by nice 0 tasks. </span><br><span class="line"> * </span><br><span class="line"> * Both properties are important to certain workloads. </span><br><span class="line"> *&#x2F;  </span><br><span class="line">static int effective_prio(task_t *p)  </span><br><span class="line">&#123;  </span><br><span class="line">    int bonus, prio;  </span><br><span class="line">  </span><br><span class="line">    if (rt_task(p))  </span><br><span class="line">        return p-&gt;prio;  </span><br><span class="line">  </span><br><span class="line">    bonus &#x3D; CURRENT_BONUS(p) - MAX_BONUS &#x2F; 2;  </span><br><span class="line">  </span><br><span class="line">    prio &#x3D; p-&gt;static_prio - bonus;  </span><br><span class="line">    if (prio &lt; MAX_RT_PRIO)  </span><br><span class="line">        prio &#x3D; MAX_RT_PRIO;  </span><br><span class="line">    if (prio &gt; MAX_PRIO-1)  </span><br><span class="line">        prio &#x3D; MAX_PRIO-1;  </span><br><span class="line">    return prio;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>  可以看到bonus会对初始优先级做补偿。怎么计算出这个BONUS的呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define CURRENT_BONUS(p) \  </span><br><span class="line">    (NS_TO_JIFFIES((p)-&gt;sleep_avg) * MAX_BONUS &#x2F; \  </span><br><span class="line">        MAX_SLEEP_AVG)  </span><br></pre></td></tr></table></figure>

<p>可以看到，进程描述符里还有个sleep_avg，动态补偿完全是根据它的值来运作的。sleep_avg就是关键了，它表示进程睡眠和运行的时间，当进程由休眠转到运行时，sleep_avg会加上这次休眠用的时间。在运行时，每运行一个时钟节拍sleep_avg就递减直到0为止。所以，sleep_avg越大，那么就会给到越大的动态优先级补偿，达到MAX_SLEEP_AVG时会有nice值-5的补偿。 </p>
<p>内核就是这么偏爱交互型进程，从上面的优先级和时间片分配上都能看出来。实际上，内核还有方法对交互型进程搞优待。上篇说过，runqueue里的active和expired队列，一般的进程时间片用完后进expired队列，而对IO消耗的交互型进程来说，则会直接进入active队列中，保证高灵敏的响应，可见什么叫万千宠爱于一身了。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>cpu</tag>
        <tag>kernel</tag>
        <tag>nice</tag>
      </tags>
  </entry>
  <entry>
    <title>paxos分布式一致性算法--讲述诸葛亮的反穿越</title>
    <url>/2015/03/27/%E7%AE%97%E6%B3%95/paxos%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95-%E8%AE%B2%E8%BF%B0%E8%AF%B8%E8%91%9B%E4%BA%AE%E7%9A%84%E5%8F%8D%E7%A9%BF%E8%B6%8A/</url>
    <content><![CDATA[<h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>一日，诸葛亮找到刘备，突然献上一曲《独角戏》，而后放声大哭。刘备正沉醉于新曲，暗叹孔明大才，竟作得如此不凡仙乐，看到孔明忽而大悲，慌问：“水，何事悲恸？” </p>
<span id="more"></span>
<p>诸葛亮止住抽泣：“亮自主公三顾茅庐出山以来，蒙主公厚爱，自比如鱼得水，敢不尽力？然每日击鼓升帐，皆亮一人在上唱独角戏，众将在下唯唯诺诺，只是照亮的安排做事。如此下去，亮日后定会被司马懿那厮累死呀。”<br>刘备眨着充满问号的大眼睛：“孔明可是说曹贼丞相府小小的主薄司马懿？他有何德何能。。。”<br>诸葛亮慌打断：“亮心有些乱，且不提司马懿那小子。”<br>诸葛亮正襟危坐：“主公，我们要法制不要人制呀！万一哪天亮西去。。。”<br>（刘备止含泪花握住孔明双手，孔明亦紧紧反握住刘备的大手） </p>
<p>半晌，诸葛亮续道：“岂不人亡政息？且主公百年后，阿斗与亮的关系又怎能比得如今亮与主公般相敬如宾？若亮在外争战，阿斗与亮政见不合要亮退兵，决策没有一致性，必将造成大错！如此，我大蜀何以恢复汉室江山呀？！”<br>刘备：“备深感如此。” 诸葛亮：“亮昨夜夜观天象。。。”<br>刘备大喜：“孔明可有良法？”<br>诸葛亮：“。。。亮昨夜夜观天象，竟然睡着，原来近日太耗心力。做一梦，数千年弹指间，亮醒来才觉泪流满面。梦中一帅哥自称陶辉，献上色目人大牛Leslie一法名paxos，或可解我等燃眉之急。”<br>刘备狂喜：“好！”继而搔了搔头：“先请孔明试言我大蜀帝国决策上有哪些问题？”<br>诸葛亮：“喏。” </p>
<h2 id="蜀国现在决策制度的缺陷"><a href="#蜀国现在决策制度的缺陷" class="headerlink" title="蜀国现在决策制度的缺陷"></a>蜀国现在决策制度的缺陷</h2><p>诸葛亮：“主公，当下蜀国所有决策皆来自亮，这有两个问题，<br>一、若亮身体有恙则政令必有耽误。<br>二、随着汉中的收复，我们的地盘越来越大，事务也越来越多，目前亮乃五百年不世出奇才，尚能支撑，可若是将来收复长安，亮一人之力必不堪重负。请问主公有何策解此二难？”<br>刘备沉吟着：“可让法正法孝直，黄权黄公衡为你副手，平日助你共同议政决策，能帮你减负呀。孔明你老习惯在初一十五深入民间依红偎翠，那时他们都可暂时顶替于你，如此也不怕政令耽误了。”<br>诸葛亮咳嗽了下：“此二人皆治世之才！然，若子龙请求黄公衡允许蜀棉私营，而同时主公又请求亮加强垄断这有钱途的行业–禁止蜀棉私营，文武百官令行两出，或听亮的搞国家垄断，或听黄公衡的搞民营经济，百姓何以自处？”<br>刘备沉思半晌，方答道：“我们把决策分为两部分，一种是新增政策，如我正准备加税。另一种是下级官员请求政令的解释，比如马超出征归来时问伤兵抚恤金是多少等等。这样，孔明可处理所有新增决策，法正与黄权只负责解释已有决策。下面官员在执行时，任意找你三人中清闲者，就某个事件询问有何政令可指导，需要增加新的法令时，则只能找孔明你，孔明你决定新法令后，再通知法正和黄权这哥俩，这样法令就同步且一致了。当孔明不在时，由法正顶上这个决策位置；法正不在时，由黄权顶上。如此可好？”<br>诸葛亮惊喜道：“善！这可是master-slave设计呀！” 刘备也睁大了双眼闪着问号。<br>诸葛亮咳嗽了下：“亮昨夜未睡好，失言了。”<br>诸葛亮又说道：“可这样还有问题，日后若我们收复许昌洛阳建业后，那时新法令会更多，只允许一人处理新法令新决策，必然还会忙不过来！而且，人为的指定亮的第二顺拉继承者是法正，黄权为第三顺位，这样也不妥，在地位不平等时，若以后决策组又增加许多新人，或者同一时间多人一起吃酒吃坏肚子，都会非常麻烦。”<br>刘备拍案而起：“孔明你主张大家都是同样地位，没有主次之分？这样无论哪个人出问题了，都不会对蜀国有什么影响？而且多人之间信息共享后，不会因人废事，也不会有人亡政息之事了？”<br>诸葛亮：“Bingo！ 全对！这是真正的分布式！” 刘备大声叫好：“分布式？好名字，和八阵图一样响亮呀！” 诸葛亮：“但这完全平等的分布式决策机制，仍然必须政令统一，不能有不一致的法令，例如黄权认为他昨天中午通过的法令是嚼口香糖者一律杖责十板，免得有人随地乱吐影响市容（好象他们还立法大便后必须冲马桶）。而法正却在昨天上午就接受番邦李光耀的提议，允许嚼外国进口环保口香糖，百姓到底听谁的呢？” 刘备：“我知道孔明你很讨厌威权国家，别老抱怨，新加坡又没碍你事。上面这就是一致性问题了。孔明别卖关子了，快说你的paxos解决方法吧。” </p>
<h1 id="paxos需要解决的分布式问题"><a href="#paxos需要解决的分布式问题" class="headerlink" title="paxos需要解决的分布式问题"></a>paxos需要解决的分布式问题</h1><p>诸葛亮激动道：“paxos可是真正的民主呀，两千年后我们汉人仍然做不到，这不是汉人的劣根性（乌坎村都能办好的），实是历史遗毒呀。闲话少叙，我们先来看看除了能保持一致性，paxos能解决哪些问题吧。<br>一、决策委员会里缺了哪个人都可以，蜀国照常做出决策。<br>二、大家的办公地又不在一起，平时通过信使小吏们传递消息，若信使在路上传消息时被马车撞死，仍然不会有政令不一致。<br>三、若信使被马车撞伤了，医治后迟了几个月才送到某人（例如法正），还不会出现政令不一致。<br>四、若信使被马车撞失忆了，以为刚送过消息的黄权还没送过，又跑去告诉黄权一次，同样不会有不一致出现。” </p>
<p>刘备：“孔明，我知道你马车机关多，开名车也不用总提嘛！若是信使被曹操的间谍收买了也没事吗？”<br>诸葛亮尴尬道：“这个不行，我们还是要相信人性本善嘛。呃，蜀国大部分都是好人。嗯，好吧，我们国安局不是吃干饭的，信使可以丢失、重复传递、延迟，但是我们保证不会被收买的。” 刘备：“好吧，能解决这四个问题也很不错，基本异常都考虑到了。快说说这个paxos解决之道吧。” </p>
<h1 id="paxos的约束条件"><a href="#paxos的约束条件" class="headerlink" title="paxos的约束条件"></a>paxos的约束条件</h1><p>诸葛亮：“刚刚不是说了民主吗？民主是个宝呀，它能解决一切问题。决策者之间不分高下，所以既然想要他们保持一致，我们就要用投票，少数服从多数！”<br>刘备：“怎么个投法？”<br>诸葛亮：“如果主公手下五虎上将是五个决策者。。。”<br>刘备：“那五个肌肉男？”<br>诸葛亮：“正是，这证明即使五个头脑简单的武夫也能做好。”（五虎将齐打喷嚏。） </p>
<p>诸葛亮：“谁提议新政令（提案者），谁就发起投票。我们保证，投票者必须是决策者中的大多数。”<br>刘备：“怎么定大多数呢？”<br>诸葛亮：“任意两次投票中，必须有重合的决策者，这就是大多数了。比如五虎将做决策者，每次政令通过中，必须有三个人或更多投票的人才能决定，这样两次投票中至少有一人都参加了，他就可以拍板！对提案者来说，如果大多数投票者都投赞成这个提议，法令就通过。”<br>刘备沉重地说道：“孔明，万一总是凑不成大多数，岂不是耽误我们的现代化进程？民主，对中国国情来说，太复杂了。” </p>
<p>诸葛亮又激动了：“主公，不复杂的，长远来看好处很明显，不要短视！如果能做到以个三个基本点，所有政令绝对不会出现不一致，而且不会出现无法进行下去的事。一、所有政令必须被提出后才能批准；二、一次提出政令的过程中，只能批准一条政令；三、书记官（负责永久记录政令的官员）只能学习已经批准的政令。只要做到这三点，肯定不会政令不一致！” </p>
<p>刘备：“可是孔明，你在说什么呀？我只想知道决策者该怎么做。” 诸葛亮自信满满：“别急主公，从数学上可以证明，只要满足上面三条，一定不会出现政令不一。当然，这三条太宽泛了，不能对决策者做出指导。我还有更加严格的约束。一、每个决策者必须接受他收到的第一个提议政令。”<br>刘备：“凭什么呀？”诸葛亮：“我们要假定提议者已经搞清楚了一切，肯定是好提案啦。这不是我们的重点，别打断我。” </p>
<p>诸葛亮：“二、一旦关于一件事，我们通过一条法令后，之后关于这件事通过的任何法令，都还得是这个法令。”<br>刘备呆了下：“这不废话吗？”<br>诸葛亮自信满满：“虽然是废话，但你想，保证了这第2条，是不是所有的政令都必须一致呀？”<br>刘备：“可是对决策者没指导意义呀。”<br>诸葛亮自信满满：“是的，所以，我们加强约束，三、如果一条法令批准后，之后每一个决策者如果关于这件事又通过法令，那这个法令还得是同一条。”<br>刘备傻了：“你说得是没错，可这有什么用呢？”<br>诸葛亮自信满满：“所以继续加强约束：四、如果一条法令被批准通过了，之后提议者关于这件事，又提新法令，必须还得是同一个法令。”<br>刘备怒了：“孔明我想揍你了，你说这些有个屁用啊！” </p>
<p>诸葛亮自信满满：“别急主公，现在我要祭出最强约束条件作为我的奥义了：五、每个提案都得有个独一无二的编号，如果编号N的提案通过了，那么大多数决策者们，要么从没接受者编号小于N的任何提议，要么最近一次批准通过的法令就是这个提案。” 刘备开始追打诸葛亮：“孔明你个坏人，你玩我呀！这屁话你对我说！” 诸葛亮边逃边喊：“wiki里就是这么解释的，哎，主公你不懂数学别打我嘛。Leslie的论文也是这么写的。。。” </p>
<h1 id="paxos执行流程"><a href="#paxos执行流程" class="headerlink" title="paxos执行流程"></a>paxos执行流程</h1><p>刘备：“真爽，孔明你手感不错。说点实在的吧，不懂的东西少扯。”<br>诸葛亮：“主公，你不懂数学嘛。好吧，我来说说paxos<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">算法</a>的流程，就三段式，六个步骤而已。角色包括，提案者，决策者，书记官（学习政令的）。 </p>
<p>一、提案者先从主公那里搞到个独一无二的编号，例如N。找到决策者们的多数派，就说五虎将吧，找到三个肌肉男先。假设，这个提案者来自成都，想提的是，外地蜀国将级官员不得无故进入魏国使者驻蜀驿馆。那么，提案者发给三个五虎将，提案中说，我现在有个编号N的提案，关于蜀国高级将领进出魏国使者驿馆的事，请回答我。” </p>
<p>二、五虎将们收到了关于使者驿馆事件的提案，编号是N。其中任一个决策者，比如赵云，他在收到N提案后，首先检查，之前关于魏国使者驿馆事件，有没有收到过提案啊？如果没收到，当然回复提案通过，同时赵云拿出自己的小本本记上，已经回复编号N的提案。如果收到过关于驿馆事件的编号M的提案，就检查编号M，如果M大于N，那么跟信使说，我拒绝这个提案。如果M小于N，回复通过，并且说，关于这事，上次我已经收到了编号M的提案了。 </p>
<p>三、提案者如果收到多数决策者的通过回复，就开始正式提议了。这时，先检查五虎将的回复，如果都简单的回复通过，那么就正式提议之前想提议的《蜀国将级官员不得无故进入魏国使者驻蜀国驿馆》提案。如果决策者们不是简单的回复通过，而是说：这次我赵云通过了，但是我曾经回复过编号M的提案。这样，提案者需要从这次决策者们的回复中，找出所有编号M中的最大值。假设就赵云复杂的回复了，其他四人都是简单的回复通过。那么，提案者这次不能正式提议自己原来想提的，而要提议编号M对应的提案。 </p>
<p>四、同第二步骤一样，五虎将们根据二步骤的准则，选择通过还是不通过。 </p>
<p>五、提案者如果发现多数决策者同意了，意味着法令通过，这时他要记录法令，同时告诉书记官们。 六、书记官们在羊皮纸上记录法令。“ </p>
<h1 id="paxos算法里的各角色该做的事"><a href="#paxos算法里的各角色该做的事" class="headerlink" title="paxos算法里的各角色该做的事"></a>paxos算法里的各角色该做的事</h1><p>刘备搔搔头：“孔明，你再说说提案者，决策者要做的事吧，书记官的很简单，就不用说了。”<br>诸葛亮：“主公，书记官的工作不简单啊，信使会传丢消息的，书记官也会生病的。我们既要在法令通过时主动通知书记官，又要允许书记官在对法令不清楚时过来主动询问。不过，既然主公想多了解提案者和决策者的工作，我就来详细说说。 一、提案者。首先他得从主公那搞来一个独一无二的编号。”<br>刘备：“我很忙的孔明，我是一把手哎。” </p>
<p>诸葛亮有些无奈：“就光给编号也不干呀！那让他们自己维护自己的编号吧，遇到编号相同时，按级别排序，例如按关羽、张飞、赵云、马超、黄忠排序。然后要找到五虎将的多数派，例如关张赵这三人，发自己要决定的事以及编号过去。这是第一步。在第三步时，又到了提案者要做工作了。如果关羽又不响应自己了，那么再发给黄忠问问看。直到有大多数人响应自己。对于响应的处理，有以下情况： </p>
<p>A、这些响应中，如果有人明确拒绝，比如赵云说，关于驿馆事件，我已经批了编号大于N的提案，那么这次提案最好就放弃吧，或者加大自己的编号，重复第一步再提！ </p>
<p>B、张飞说我可以通过，但是之前我批准过驿馆事件编号小于N的提案，内容是允许进入达到政治避难目的。那么，这次提案内容必须变更为张飞之前提交的方案。 </p>
<p>C、所有人都无条件通过。继续正式提交自己的方案。 到第五步，如果多数派批准了，那么方案正式成为法令。提案者要告诉书记官记录哦。” 刘备：“你这么说我就明白了嘛。多简单？先前搞七搞八的说了一大通。” </p>
<p>诸葛亮：“唉，先前的证明嘛。当然，微软还搞了个两段式提交，号称fast paxos，那个雅虎的zookeeper也是的，其实也就对第五步做了优化。主公，不要打我，你不用管我刚才说了什么。我们继续说决策者的工作。 第二步，决策者开始工作了。例如还是说赵云，他在收到N提案后，首先检查，之前关于魏国使者驿馆事件，有没有收到过提案啊？如果没收到，简单的回复提案通过，同时赵云拿出自己的小本本记上，已经回复编号N的提案。赵云同时承诺，以后收到编号小于N的关于驿馆事件的提案，保证不批！如果收到过编号M的提案，检查这上次编号M，如果M大于N，那么跟信使说，我拒绝这个提案。如果M小于N，回复通过，并且说，关于这事，上次我已经收到了编号M的提案了。 第四步决策者批准时也和上面一样。不过fast paxos等两段式的paxos改进算法，在这里决策者们已经可以记录法案了。” </p>
<p>刘备：“好孔明！我有些明白了，不过光说不练假把式，演习下吧。把五个肌肉男叫来，你我来提案，外加捣乱，你可以用你的跑车撞信使了，看看是否出现不一致。” 诸葛亮：“No problem。不过现在我口干舌燥，咱们下回再说吧。”（想从具体的演习，从时间和各种容错上看paxos的效用，敬请期待下篇<a href="/paxos%E7%AE%97%E6%B3%95%E5%A6%82%E4%BD%95%E5%AE%B9%E9%94%99%E7%9A%84-%E8%AE%B2%E8%BF%B0%E4%BA%94%E8%99%8E%E5%B0%86%E7%9A%84%E5%AE%9E%E8%B7%B5/">《paxos算法如何容错的–讲述五虎将的实践》</a> 两人携手扬长而去。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>paxos</tag>
      </tags>
  </entry>
  <entry>
    <title>paxos算法如何容错的--讲述五虎将的实践</title>
    <url>/2015/07/27/%E7%AE%97%E6%B3%95/paxos%E7%AE%97%E6%B3%95%E5%A6%82%E4%BD%95%E5%AE%B9%E9%94%99%E7%9A%84-%E8%AE%B2%E8%BF%B0%E4%BA%94%E8%99%8E%E5%B0%86%E7%9A%84%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>（本文包括章节：1、由来，2、<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">算法</a>简单回顾，3、演习道具，4、演习，5、算法提出者Leslie的八卦。hoho） </p>
<h1 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h1><p>刘备接受了诸葛亮的提议，决定将paxos算法的思想应用到蜀帝国的决策机制上。然而，玄德生性谨慎，决定先行试点，实践下可行性。孔明提议，由蜀国五大肌肉男：关羽、张飞、赵云、马超、黄忠，做为决策者，而廖化、周仓、魏延分别无序的提出关于同一件事的水火不容的三个提案，孔明坚信：即使脑残者使用了paxos算法，也不会出现冲突的政令不一情况。paxos算法理论以及刘备是怎么被孔明忽悠的部分，同学们可以参考上篇<a href="https://www.taohui.pub/paxos%e5%88%86%e5%b8%83%e5%bc%8f%e4%b8%80%e8%87%b4%e6%80%a7%e7%ae%97%e6%b3%95-%e8%ae%b2%e8%bf%b0%e8%af%b8%e8%91%9b%e4%ba%ae%e7%9a%84%e5%8f%8d%e7%a9%bf%e8%b6%8a/">《paxos分布式一致性算法–讲述诸葛亮的反穿越》</a> </p>
<span id="more"></span>
<p>闲话少叙，书接上文。 </p>
<h1 id="提案"><a href="#提案" class="headerlink" title="提案"></a>提案</h1><p>为了少打点字，刘备与诸葛亮俩玻璃不再以对话形式出现了。他们设置了五个官署（五虎将办公地，相当于Server），三个提案点（周仓等三人，发起提案时的办公地。相当于Client），当然都不在一起，信使们从提案点到官署传递信息的话，正常情况下需要半个小时，也就是30分钟。这次演习，哥俩不关注学习情况，所以paxos第三段就不在演习内容里了。诸葛亮为廖化、周他、魏延对于事件e准备了三个自相矛盾的提案，我们分别用p1、p2和p3代替吧。</p>
<p>先行说明提案： 事件e（也就是本次paxos实例）：蜀国今后的发展路线 </p>
<h2 id="提案p1"><a href="#提案p1" class="headerlink" title="提案p1"></a>提案p1</h2><p>学习红色锤子镰刀，走激进主义，一切发展按照计划进行，小民们凭票消费，银子多了也没用，集中力量办大事，崇尚国家垄断主义。 </p>
<h2 id="提案p2"><a href="#提案p2" class="headerlink" title="提案p2"></a>提案p2</h2><p>学习自由联盟，走自由主义，宁失去效率也不失去公正，发展民营经济为先，民主、法制、新闻自由，通过这种公正来激发社会的整体创造力。 </p>
<h2 id="提案p3"><a href="#提案p3" class="headerlink" title="提案p3"></a>提案p3</h2><p>坚持孔孟之道，走保守主义，兼顾黄老之学，坚信中学为体、西学为用，国体不可大改，走有大汉国情的老路让别人说去吧。 </p>
<h1 id="算法简单回顾"><a href="#算法简单回顾" class="headerlink" title="算法简单回顾"></a>算法简单回顾</h1><p>我们再简单回顾下提案者和作为决策者的五虎将行动准则，共有六步，书记官（暂让五虎将兼职）负责记录下通过的提案p（通过了就叫法令了），这样，我们用1a,1b,2a,2b,3a,3c来表述全部的六步。（这六步就是三段式提交了，这在上篇《paxos分布式一致性算法–讲述诸葛亮的反穿越》里讲过，不再复述。） </p>
<h2 id="魏延、廖化、周仓："><a href="#魏延、廖化、周仓：" class="headerlink" title="魏延、廖化、周仓："></a>魏延、廖化、周仓：</h2><h3 id="1a"><a href="#1a" class="headerlink" title="1a"></a>1a</h3><p>作为提案者，首先向刘备要到个编号，搞清楚自己对事件e的态度。记录下当前时间，接下来向五虎将的多数派（3个或以上）发送事件+编号。 </p>
<h3 id="2a"><a href="#2a" class="headerlink" title="2a"></a>2a</h3><p>此时开始处理五虎将的回应，这就有多种情况了。收到明确拒绝就得放弃！检查沙漏，如果到达时间限制了，还没有足够的多数派回应，那么就试着给五虎将的其他人再发送提案看看。如果收到了足够的五虎将里多数派的回应，那么，确定在2a这步里，如果要提案，到底提哪个提议？是自己现在要提的提案？ </p>
<h3 id="3a"><a href="#3a" class="headerlink" title="3a"></a>3a</h3><p>提案者如果收到足够的五虎将多数派回应通过，则记录提案为通过的政策法令，同时通知所有书记官，也就是兼职的五虎将，把法令记录到羊皮纸上来。 </p>
<h2 id="五虎将"><a href="#五虎将" class="headerlink" title="五虎将"></a>五虎将</h2><h3 id="1b"><a href="#1b" class="headerlink" title="1b"></a>1b</h3><p>作为决策者，也需要沙漏，主要用于2b步骤后批准政策法令后，给自己设定个超时时间，若第三步信使没有过来，则超时后自动把提案变成政策法令记录到羊皮纸上。1b这个步骤是收到了信使的消息，来自于1a步骤里的提案者。收到事件e和编号N。五虎将这时将有可能出现三个动作：拒绝、通过以及第三个复杂点的动作，虽然通过但告诉魏延廖化，哥曾经批准过某提案了。（三种条件的达成请参考上篇文章《paxos分布式一致性算法–讲述诸葛亮的反穿越》） </p>
<h3 id="2b"><a href="#2b" class="headerlink" title="2b"></a>2b</h3><p>与1b步骤相同，唯一不一样的是，如果决定批准某个提案，必须先把该提案和编号记录到羊皮纸的背面。（羊皮纸的详细用途参见演习前提） </p>
<h3 id="3b"><a href="#3b" class="headerlink" title="3b"></a>3b</h3><p>记录法案到羊皮纸的正面上。（本步骤不在下面演习中出现） </p>
<h1 id="演习道具"><a href="#演习道具" class="headerlink" title="演习道具"></a>演习道具</h1><p>先解释下我们用到的道具吧。 </p>
<h2 id="羊皮纸（相当于硬盘）"><a href="#羊皮纸（相当于硬盘）" class="headerlink" title="羊皮纸（相当于硬盘）"></a>羊皮纸（相当于硬盘）</h2><p>其正面记录真正通过的法令，背面相当于永久有效的草纸，背面记录一个三元组（S，V，Sh），S表示上次批准的提案编号，V表示上次批准的提案，Sh表示处理过的最大提案编号。（羊皮纸丢掉后的效果在演习结束后说明） </p>
<h2 id="草纸"><a href="#草纸" class="headerlink" title="草纸"></a>草纸</h2><p>与羊皮纸背面相同，记录三元组。唯一不同的是，草纸容易丢失。 </p>
<h2 id="沙漏"><a href="#沙漏" class="headerlink" title="沙漏"></a>沙漏</h2><p>记录时间。我们简单的认为，任何两个地方一次通讯时间为30分钟。所以，如果我们从提案者那出发，信使到五虎将再回来，我们认为一个小时足矣（忽略五虎将或者提案者的处理时间）。 </p>
<h1 id="演习说明"><a href="#演习说明" class="headerlink" title="演习说明"></a>演习说明</h1><p>下面的演习中，只有消息的丢失，实际上对于消息的重发和延迟，也不会有任何问题。只是对五虎将的缺席，需要做说明。如果五虎将的羊皮纸丢失，是不能直接再次加入进五人决策团的，必须学习到最新的状态。没丢羊皮纸，则可以随时加入进来。 书记官记录法令中的不一致情况这里不加讨论。 <strong>为了方便在图表中表示，我们先给五虎将五个字母编号：关羽a，张飞b，赵云c，马超d，黄忠e。</strong><br><strong>三种颜色表示不同的提案者：黄色表示廖化，蓝色表示周仓，红色表示魏延。</strong><br><strong>下面这幅图，表示不同的时间点，五虎将和三个提案者当时的状态。</strong> <strong>-&gt;表示第一步预提案。包括1a和1b两步。</strong> <strong>--&gt;表示第二步提交提案，包括2a和2b。</strong> </p>
<p>五虎将记录的(s,v,sh)表示的三元组上面讲过了。法令项下面对应的是提案者魏、廖、周三人的状态。（wait）表示刚发出提案，1小时内等待返回呢。 e is drop表示发送给e黄忠的提案消息丢失了。 好了，可以往下看了。 </p>
<h1 id="演习"><a href="#演习" class="headerlink" title="演习"></a>演习</h1><p>先放图，解释在下面。 <img src="/2018/05/7590e07b2ae0df4112f71cb1ddf76472-1.jpg"><br>详细说明上图： </p>
<ol>
<li>8：30分上班了，红色周仓同学首先向关羽、赵云、黄忠三人发出了提案p1，编号为100，周仓开始等返回，预计9：30分时能收到三位的返回。我们假定，发给黄忠的信使出门就被孔明的跑车撞了。孔明闯祸后老实了，以下，不再出现信使失误事件了。 </li>
<li>8：40分，崇尚民主的廖化同学向关羽、张飞、黄忠三人发出了编号为101的提案p2，预计9：40分收到返回的信使。 </li>
<li>8：50分，喜欢孔孟的魏延同学向赵云、马超、黄忠三人发出了编号为110（魏延就是搞到大编号了啊）的提案p3，预计9：50收到返回的信使。 </li>
<li>9：00整，周仓的提案p1到了关羽、赵云手里（黄忠没收到），两人无条件接受，记录(100,p1,100)，承诺编号低于100的提案我可不会再处理了，然后两个信使开始返回。 </li>
<li>9：10分，廖化编号为101的提案p2到了关羽、张飞、黄忠之手，张飞、黄忠哥俩从没收过事件e的提案，毫无疑问记为(101,p2,101)，让信使回复接受。关羽则不然，红脸兄在10分钟前收到了周仓的编号为100的p1提案。所以，按规则办，关羽改自己的记录为（100,p1,101），让信使给廖化回复：你的编号101比较大，我同意你继续，不过我之前同意过一个编号为100的提案p1，请注意哦。 </li>
<li>9：20分，魏延的p3提案到了赵云、马超、黄忠三人之手，马超第一次收到提案，记为(110,p3,110)，回复批准。赵云和黄忠则不同，赵云收到过周仓的p1提案，这时要比提案编号了，魏延的110大于周仓的100，于是赵云记为(100,p1,110)，告诉信使：我通过了，我承诺编号小于110的我不会处理，同时，我曾经批准过编号为100的提案p1。同理，黄忠记为(101,p2,110)，也告诉信使：我曾经批准过编号为101的提案p2。 </li>
<li>9：30分，周仓同学检测返回的信使了，关羽和赵云都返回批准，但是黄忠没有返回。因为必须N/2+1，也就是大多数人批准才行，所以，周仓向张飞发出提案p1。 </li>
<li>9：40分，廖化收到了来自关羽、张飞、黄忠的回复，三人皆表示同意，但关羽表示：关某曾收到过编号100的p1提案。所以按照规则，廖化此时不能坚持自己原来的提案p2，而要改成关羽返回的提案p1，然后发起提交皆段，同样是让信使带给关羽、张飞、黄忠三人，我们用-&gt;&gt;(a,b,e)表示。 </li>
<li>9：50分，魏延收到了赵云、马超、黄忠三人在9:20分的答复，三人都同意了，但回答各不相同。马超没有多话，赵云说我曾收到过编号为100的p1提案，黄忠说我曾经收到过编号为101的p2提案。于是，魏延根据规则，不再提自己原来的p3提案，改为101编号对应的提案p2。接着，魏延开始向这三人发出提交请求，编号为110的提案p2。 </li>
<li>10：00整，张飞收到了9:30分周仓补发的编号为100的提案p1，这之前，张飞在9:10分时曾经批准过来自廖化的提案p2，编号是101。所以，张飞在9:10时就已经承诺了，以后决不再处理编号小于101的提案。于是，张飞大吼一声：我拒绝。当然信使将会在10:30才能把消息带给周仓。 </li>
<li>10：10分，关羽、张飞、黄忠收到了来自廖化于9：40分发出的(101,p1)提案，关羽和张飞都发现自己可以批准，记录到羊皮纸的背面，同时告诉信使：告诉廖化P1提案我批准了，我承诺编号小于101的提案不予理会。黄忠则不然，老将黄忠在9:20分时收到过魏延编号为110的提案，那时他批准了，意味着，所有小于110的提案他都会拒绝掉。这次廖化的提案才101，当然被拒绝掉了。三人的回复将于10:40会到达廖化处。 </li>
<li>10：20分，魏延编号为110的P2提案到达赵云、马超、黄忠，三人没有疑问，毕竟110编号最大，都表示批准，并记录(110,p2,110)到各自的羊皮纸背面，回复信使通过。 </li>
<li>10：30分，周仓收到了他在9：30分发给张飞的回复，张飞在10:00拒绝了，所以周仓这个提案就此作废。 </li>
<li>10：40分，廖化收到了10：10来自关羽、张飞、黄忠的回复，关张二人批准，然而老黄忠明确表示拒绝，于是这次编号101的提案作废。 </li>
<li>10：50分，魏延收到了赵云、马超、黄忠的回复，三人都表示批准，于是编号为110的提案p2最终作为法令记录下来（之后的3b学习过程略过），从此以后，蜀国的路线被确立为走民主路线，许多年后，蜀国统一了银河系。完。 </li>
</ol>
<p>以上任何步骤，大家可以任意制造难度，例如让同一个信使重复投递消息，或者延迟一天后消息到达某虎将处。或者让某个虎将正常如厕，而后正常归来。大家会发现，一致性是可以达到的，无论怎样，对于同一个事件e，互相冲突的三个法案：p1,p1,p3，一定只有一个可以达成。 </p>
<p>对于任一虎将兄的挂掉，我们要分情况。如果是去大便，那么他的羊皮纸是不能丢的。大便完了，可以正常回到自己的官署办公。但是如果把羊皮纸丢了，那就不能立刻加入，必须向所有其他人学习，把失落的过程都学到，才能正常加入。这点至关重要，就是说，只要硬盘不坏，随时SERVER重启都能加入。硬盘一坏，对不起，学习完了才能继续办公。 </p>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>Leslie的八卦： paxos算法是解决分布式服务数据一致性的终极算法，google的基础服务chubby（GFS的基础服务）的开发者说， “there is only one consensus（一致性） protocol, and that’s Paxos”。Microsoft有fast paxos论文，yahoo的zookeeper也用了paxos算法。可见，paxos是解决完全的分布式服务（无单点）间数据一致性的最好方法。但是paxos比较复杂，特别是网上的中文资料里少有能说得清楚的（主要是太多paxos变种算法了，掺合到一起搅得人头大），例如中文wiki上的paxos解释，光看这个是不可能搞懂paxos的。 </p>
<p>paxos算法由Leslie Lamport在1990年提出，毫无疑问，paxos想解决的就是分布式环境下（server会挂掉，通讯协议不可靠，消息可能延迟、丢失、重发）如何保持数据一致性的问题。Leslie Lamport同学在1982年提出的“拜占庭将军”问题上尝到了甜头，这也是个分布式环境下的一致性问题，Leslie通过类比的方式，伪造了“拜占庭将军”历史，通过这种简单的类比成功的简化了复杂的分布式环境，效果非常好。于是在1990年Leslie同样用类比的方式提出了paxos算法，该问题跟“拜占庭将军”问题的区别是，“拜占庭将军”允许有叛徒，也就是允许伪造消息（默许被黑客攻击），而paxos则不允许消息被伪造。 </p>
<p>Leslie很有幽默感的把论文写成一个考古发现，至始至终都在虚构他的“考古发现”。他说在考古中发现了失落的文明：希腊的paxos小岛。这里的议员通过邮递员传递消息，议会中一个议员提出法案，多数议员批准后法案获得通过。当然无论议员还是邮递员，都是兼职的，他们不可靠，随时可能走人，呵，典型的分布式环境，server可以挂，消息可以丢。Leslie根据考古文献反推出了paxos议会如何搞定法案一致性的问题。 发表论文时，Leslie一直用这种语气在写论文，于是《ACM Transactions on Computer Systems》编辑们认为太荒诞了，不能从头到尾虚构故事吧？毕竟是严谨的科学杂志，于是打回。Leslie同学身为牛人，坚持自己的看法，同时认为编辑们没有幽默感，拒绝修改。时间流逝，一晃九年过去，九年后有团队根据该论文开发出一个paxos实现，终于，编辑们低头了，允许发布Leslie的论文，但还是加了段编者著，在其中表示Leslie其实是个热爱计算机技术的考古学家！也算稍事解嘲。 写这两篇文章，我也试了下借喻的手段，用我们熟悉的三国人物，看看能否讲清楚paxos。其实paxos的算法本身算不得很复杂，但如果想讲清楚在各种异常情形下paxos算法的表现，给大家带来的明确的直观感受：paxos确实能解决一致性问题，这就不容易了。所以篇幅所限，只写了丢失一个消息的情况。不过大家如果从头看到这，应该可以简单的任意推导出其他异常吧？ 最后，上面说的只是算法机制，如果需要了解现有的各种产品实现，最方便的还是看zookeeper源码，毕竟是开源的，例如去：<a href="http://zookeeper.apache.org/doc/r3.3.2/zookeeperOver.html">http://zookeeper.apache.org/doc/r3.3.2/zookeeperOver.html</a>，可以看下概述。淘宝开发团队有许多关于zookeeper实现的文章，到网上搜下就能看到。 对google的chubby实现，因为不是开源的，只有篇论文可以看：<a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/zh-CN/us/archive/chubby-osdi06.pdf">http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/zh-CN/us/archive/chubby-osdi06.pdf</a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>paxos</tag>
      </tags>
  </entry>
  <entry>
    <title>《数学之美》与算法</title>
    <url>/2019/02/23/%E7%AE%97%E6%B3%95/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>《数学之美》是一本非常好的算法进阶书，它与吴军老师从事的工作领域密切相关，所以工程性很强。半年时间断断续续读完此书，这里做个笔记，也希望能帮助还未读过本书的同学快速了解主要内容。这本书里主要讲述了两个应用场景：</p>
<ol>
<li> 搜索引擎；</li>
<li> 机器翻译及输入法；</li>
</ol>
<p>这两个场景都与信息论紧密相关，我们便从信息熵谈起。</p>
<span id="more"></span>
<h1 id="1、计算出一段信息的价值"><a href="#1、计算出一段信息的价值" class="headerlink" title="1、计算出一段信息的价值"></a>1、计算出一段信息的价值</h1><p>信息熵便是一段信息的价值，计算出它有许多用处。例如：</p>
<ul>
<li>  为什么HTTP响应中，对json或者html格式要做压缩，而jpg、gif不做压缩？gzip压缩算法再改进还有多少余地吗？</li>
<li>  为什么五笔字形早些年很多人在学，现在基本被拼音输入法取代？拼音输入法输入速度越来越快，最快能几个键录入一个汉字？</li>
<li>  用户搜索“原子能的应用”时，“原子能”、“的”、“应用”这三个词谁的信息价值更大？大多少？</li>
</ul>
<p>信息的价值就是这段信息的信息量，如何计算出信息量呢？假如我从未来穿越回来，有人问我世界杯32支球队哪支是冠军，如果他很聪明的话，<strong>最多问5次</strong>就可以获得答案。他可以把32支球队编号，以二分法来问我：1-16号队中有冠军吗？根据我的回答，再问：1-8或者17-24队中有冠军吗？这样，最多[latex]log_{2}32[/latex]次即5次即可获得结果，那么32支球队中冠军是哪支队伍的信息量就是5。 </p>
<p>如果这个人是一个球迷，他知道巴西队夺冠的概率高，中国队夺冠的概率低，根据他历年的观察经验算出了这32支球队的夺冠概率，那么这条信息的信息量对他来说便<strong>小于5</strong>。因为他可以这么问：是某8个热门球队夺冠还是其他24支比较弱的队伍夺冠？这样便可以通过更少的次数从我这拿到结果。 所以，设信息量为H，每支球队的夺冠概率是P(n)，那么信息量[latex]H=-(P_{1}*logP_{1}+P_{2}*logP_{2}+… +P_{32}xlogP_{32})[/latex]。根据香农的定义，信息量*<em>[latex]H(x)=-\sum_{x=1}^{n}P(x)\</em>log_{2}P(x)[/latex]**。 </p>
<p>因此，“太阳每过24小时都会从东边升起”，这条信息对成人来说信息量很小，而对4岁的儿童信息量就很大，这是因为他们的已知信息不同，这也是为什么百度搜索信息总是没有谷歌准确的原因，即使他们使用了同样的PageRank算法，但当谷歌从搜索关键字里拿到更多信息量时（例如历史用户点击率、用户搜索的准确领域等），就能提供更准确的结果。 现在我们来回答第1个问题（第2、3问题留待搜索引擎与输入法章节再回答）。根据信息熵的定义，HTTP响应中每个字符的概率P(n)是不同的，怎么得到概率呢？首先我们要拿到统计样本，或者叫语料库，若该语料库足够大且覆盖所有场景，那么根据大数定理，只要统计量足够大那么相对频率便等于概率。设语料库共有字符N个，而待统计的字符x共出现了M次，那么x的概率P(x)便等于M/N。 例如对汉字而言，<strong>常用汉字大约7000个</strong>（参见<a href="https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E4%BA%A4%E6%8D%A2%E7%94%A8%E6%B1%89%E5%AD%97%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86/8074272?fromtitle=%E3%80%8A%E4%BF%A1%E6%81%AF%E4%BA%A4%E6%8D%A2%E7%94%A8%E6%B1%89%E5%AD%97%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86%E3%80%8B&fromid=2869556">GB2312</a>，共收录6763个汉字），若所有字等概率出现，那么每个字的概率是[latex]log_{2}7000=12.8[/latex]比特，而实际上前10%的汉字占到95%以上的出现概率，所以若不考虑上下文相关性那么每个汉字的独立概率大约是8-9比特，考虑上下文相关性后，每个汉字大约5比特。所以，一本50万字的图书信息量大约是[latex]5*500000=2500000[/latex]比特，若采用GBK编码（2字节1汉字）时需要[latex]500000\times2=1MB[/latex]空间，而好的压缩算法仅需要[latex]2500000\div8=320KB[/latex]空间。 所以，对于一段HTML或者JSON文本，它的信息熵远小于UTF-8直接按字符编码后的空间大小，而gzip压缩后的空间大小与信息熵的差值，就是压缩算法的改进余地。而JPG或者GIF图片事实上已经做过压缩，其信息熵与文件大小相差不大，所以没必要再做gzip压缩。</p>
<h1 id="2、拼音输入法与维特比算法"><a href="#2、拼音输入法与维特比算法" class="headerlink" title="2、拼音输入法与维特比算法"></a>2、拼音输入法与维特比算法</h1><p>笔者从94年开始学习五笔字形输入法（那个时代的小霸王学习机大家还有印象吗？），照着稿子打（拆字）可以达到每分钟500个字，由此极度鄙视拼音输入法。那时候的拼音输入法还分为全拼和双拼，全拼就是我们熟知的拼音，双拼又是什么鬼？由于觉得敲N个键出M个字，每个键的贡献度M/N太小了，于是把含多个键的声母或者韵母重新编码，以减少输入键数创造出来的编码方式。早期的拼音输入法也没有模糊音的概念，于是全中国非北京的同学都苦逼了，要么分不清平舌音和翘舌音，要么分不清前鼻音和后鼻音，要么分不清nlt。就像五笔输入法一样，双拼是需要额外学习成本的。 </p>
<p>输入一个汉字究竟最少需要敲几个键呢？ 若常用汉字7000个，而我们只用26个字母（不考虑数字键和方向键）输入，那么2个键[latex]26^{2}=676[/latex]是不够的，至少需要3个键[latex]26^{3}=17576[/latex]才能完成。 再细化点，根据香农的信息熵公式，不考虑相关性每个汉字的熵是10比特，只用26个字母输入的话每个键的熵是[latex]log_{2}26=4.7[/latex]次，所以每个汉字至少需要10/4.7=2.1次击键。 如果引入词组，汉字的平均熵下降到8比特，则每个汉字需要8/4.7=1.7次击键，再引入上下文把平均熵降到6比特，则平均每个汉字需要6/4.7=1.3次击键。当然，这是理论上的极限值，目前的全拼使用了常用词组、上下文后，每汉字击键次数约3次，这已经小于五笔字形等靠拆字为生的字形输入法了。 </p>
<p>当然，五笔字形等输入法最大的缺点是需要很高的学习成本（记忆成本，还记得“王旁青头兼五一”吗？），而且拆字会中断思维，一心二用的效率是低下的。拼音输入法能直线进步的一个重要原因是靠上下文猜出我们想输入的词组（包括模糊音、容错、只输入部分就猜出全部），这依赖马上要介绍的维特比算法。 由于我们输入的拼音没有声调，平均一个无声调拼音对应约13个汉字，如果我们要输入10个拼音，对应汉字的组合有多少呢？[latex]13^{10}约等于10^{16}[/latex]！我们现在的CPU每秒钟不过3GHz，如果用穷举法，一天都猜不出这10个字的组合里，哪个是用户最想输入的汉字组合。 </p>
<p>当然，所谓用户最想输入的汉字组合，就是概率最大的汉字组合，设10个汉字为w1到w10，则该组合的概率为P(w1,w2,w3,…,w10)。怎么算这个联合概率呢？需要用到<a href="https://baike.baidu.com/item/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87">条件概率</a>公式*<em>P(A,B)=P(AB)\</em>P(B)*<em>，其中P(AB)表示B已经发生时再发生A的概率，对应已经输入w1汉字后w2的概率。 所以，P(w1,w2,w3,…,w10)=P(w1)\</em>P(w2w1)*P(w3w1,w2)*…*P(w10w1,w2,…,w9)。怎样计算出这些概率呢？根据上一节我们介绍过的大数定理，只要语料库足够大，根据w1出现的次数就可以计算出P(w1)，也可以按词组计算出P(w2w1)，以此类推。但后面的计算量实在太大了，于是我们用到了<a href="https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/4017874">马尔可夫模型</a>。一元马尔可夫模型假定，P(w4w1,w2,w3)约等于P(w4w3)，即仅与前一个字相关，而二元模型下P(w4w1,w2,w3)约等于P(w4w2,w3)，当然计算量也更大。 当得到任10个汉字组合短语概率后，我们现在希望找出最大概率作为第1选择给到用户，此时，维特比算法登场了。 </p>
<p>每个拼音若对应13个汉字，那么求10个汉字组合，相当于从13*10的有向图中找出10个汉字相连后的最短路径（概率最大）。简化为下图中，共有4*4*4=64种路径，要找出最短的红色路径，便可以使用维特比算法： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/"><img src="/2019/02/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84.jpg"></a> 维特比算法其实就是一种<a href="https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92">动态规划算法</a>（动态规划算法是地图导航、3/4/5G通讯、基于有限状态机的通讯地址分析等场景下的基础算法，不了解的同学建议先读下《算法导论》第15章），它也用到了计算机编程中常用的递归思想。打个比方，如果你是马云，你怎么管理好数万人的阿里巴巴公司呢？你只需要找到最合适的几个高管，如果他们能把阿里云、大文娱、支付宝、天猫等公司管理到最好，则阿里巴巴集团自然也就是最好的了。动态规划便基于这个思想，当然，它的前提是：1、这是个求最优解的问题；2、每个问题的最优解可以分解为子问题的最优解。 维特比算法下，求B层到C层的最短路径时，并不用重新计算S到A或者A到B的路径，而只需要从B层所有节点到C层所有节点的路径上找出最短路径即可： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%842/"><img src="/2019/02/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%842.jpg"></a> 所以，10个汉字中找出最短路径的计算量是13*13*10，这远远小于穷举法中的[latex]13^{10}[/latex]！</p>
<h1 id="3、维特比与频分多址"><a href="#3、维特比与频分多址" class="headerlink" title="3、维特比与频分多址"></a>3、维特比与频分多址</h1><p>维特比算法是高通公司创始人维特比发明的算法，该算法对无线通讯中的3G4G5G网络有很大贡献。 上世纪九十年代的“大哥大”无线电话用的是1G网络，类似对讲机、卫星电话他们用的都是频分多址FDMA技术，该技术按波长把固定频率分给一组通话。它最大的问题是很难容纳大量的并发通话数。 到2G时代，欧洲主导的GSM技术使用的是TDMA时分多址，就像我们的操作系统，虽然所有进程共享同一个CPU，但把CPU的时间分成多片，进程们轮流占用时间片，进而产生多进程同时运行的效果。TDMA也是一样，在同一段频率下，许多通话同时分时共享频段。相比FDMA，它能容纳更多的并发通话，但问题是，时分多址会有一些频率浪费在分隔点左右，效率不高。 到3G时代的CDMA使用码分多址技术，每对通话使用不同的译码，虽然接收到完整的频率，但靠着不同的code译出想要的数据，如下图所示： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/fdma-tdma-cdma/"><img src="/2019/02/FDMA-TDMA-CDMA.png"></a> </p>
<p>什么叫译码呢？就像吉普赛纸牌，若我们接收到以下数据： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%90%89%E6%99%AE%E8%B5%9B%E7%BA%B8%E7%89%8C1/"><img src="/2019/02/%E5%90%89%E6%99%AE%E8%B5%9B%E7%BA%B8%E7%89%8C1.jpg"></a> 第1组通话的CODE是在卡片上方挖出6个孔，第2组通话的CODE是在卡片上挖出另外14个孔，把卡片分别盖在上面的接收数据上，便分别得到了2组通话待接收的数据，如下图所示： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%90%89%E6%99%AE%E8%B5%9B%E7%BA%B8%E7%89%8C2/"><img src="/2019/02/%E5%90%89%E6%99%AE%E8%B5%9B%E7%BA%B8%E7%89%8C2.jpg"></a> 基于FDMA频分多址后，我们的通话便可以尽情的使用尽可能多的频段。4G LTE、5G网速越来越快的原因，便在于基于FDMA后，加入更多的超高频扩展我们的频段后便通过更宽的通道带来更大的速率。 <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E9%80%9A%E8%AE%AF%E9%A2%91%E7%8E%87%E7%94%A8%E9%80%94%E5%88%92%E5%88%86/"><img src="/2019/02/%E9%80%9A%E8%AE%AF%E9%A2%91%E7%8E%87%E7%94%A8%E9%80%94%E5%88%92%E5%88%86.jpg"></a></p>
<h1 id="4、网络爬虫与布隆过滤器"><a href="#4、网络爬虫与布隆过滤器" class="headerlink" title="4、网络爬虫与布隆过滤器"></a>4、网络爬虫与布隆过滤器</h1><p>搜索引擎主要由三个组成部分：</p>
<ol>
<li> 由爬虫将网络中的网页爬下并建立倒排索引；</li>
<li> 类似SQL查询，把用户查询关键字解析为布尔代数，按规则从索引中取出数据（所谓的“搜商”便体现在这里）；</li>
<li> 根据PageRank算法、站点权威性、点击率等信息将网页结果排序。</li>
</ol>
<p>由于全网的页面之间互相引用，形成了一张图。网络爬虫希望在有效的时间段内快速下载页面，便面临2个问题：</p>
<ul>
<li>  <strong>问题1：应该以深度优先（先把一个网站的页面全部下载完）还是广度优先（先下载各大站点的首页，再依次下载它们的二级页面，等等）算法下载页面呢？</strong></li>
</ul>
<p>网页有生命周期，重要程度也不相同，往往首页最重要，二级页面次之。采用广度优先去下载全网页面，能照顾到页面的权重。 然而，纯按广度优先会使得TCP连接的效率很差，对同一个站点反复握手建立连接、拥塞窗口缓慢增加等，都降低了网络效率，使用深度优先可以基于长连接提升爬虫效率。所以，爬虫需要兼顾深度优先和广度优先算法。</p>
<ul>
<li>  <strong>问题2：页面之间互相引用，所以发现一个URL后，怎么判定该URL曾经下载过，页面已经存在了呢？</strong></li>
</ul>
<p>对非网络爬虫场景，使用哈希表都是没问题的，通过长度有限的信息指纹基于O(1)时间复杂度快速判定字符串URL是否被下载过。 但网络爬虫面对的URL集合太大，这表现在：1、URL数量太大；2、URL字符串长度达几十、几百字节。这造成需要几十几百台服务器才能以哈希表放下全量URL。而<a href="https://baike.baidu.com/item/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/5384697?fr=aladdin">布隆过滤器</a>可以使用更少的服务器解决这一场景。 布隆过滤器将一个元素通过多个哈希函数映射出多个值，按位保存在数组中。例如下图中，有h1、h2、h3三个哈希函数，对元素a而言h1(a)=3，h2(a)=9，h3(a)=14，于是将数组B中第3、9、14位置1。集合S里有a、b、c三个元素，分别在B中9个位置设为1，其余位置为0。 <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"><img src="/2019/02/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8.jpg"></a> </p>
<p>判定新元素d和e是否在S中很简单，若h1、h2、h3计算出的值对应在B数组中的位有任何一个不为1，那么一定不在集合S中，例如元素e，虽然h2(e)h3(e)都是1，但h1(e)是0，那么e一定不在S中。 但布隆过滤器就像任何哈希表一样，存在碰撞可能，也就是误算率。例如对元素d而言，三个哈希函数的值对应的位都为1，但d并不在S中。它的误算率到底是多少呢？设n是集合S中元素的个数，而m是B数组中位的个数，而k是哈希函数的个数，那么其<a href="http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html">误算率如下表</a>所示：</p>
<table>
<thead>
<tr>
<th><em>m</em>/<em>n</em></th>
<th><em>k</em></th>
<th>_k_=1</th>
<th>_k_=2</th>
<th>_k_=3</th>
<th>_k_=4</th>
<th>_k_=5</th>
<th>_k_=6</th>
<th>_k_=7</th>
<th>_k_=8</th>
</tr>
</thead>
<tbody><tr>
<td>2</td>
<td>1.39</td>
<td>0.393</td>
<td>0.400</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>2.08</td>
<td>0.283</td>
<td>0.237</td>
<td>0.253</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>2.77</td>
<td>0.221</td>
<td>0.155</td>
<td>0.147</td>
<td>0.160</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>3.46</td>
<td>0.181</td>
<td>0.109</td>
<td>0.092</td>
<td>0.092</td>
<td>0.101</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h1 id="5、网页分类与TF-IDF算法"><a href="#5、网页分类与TF-IDF算法" class="headerlink" title="5、网页分类与TF-IDF算法"></a>5、网页分类与TF-IDF算法</h1><p>怎样判定两个网页的内容是否相似呢？我们可以先取出网页的特征。我们把网页的词汇取出，为了防止相同的词汇偏向长网页，我们使用<a href="https://zh.wikipedia.org/wiki/Tf-idf">TF算法（term frequency）</a>，设网页1由w1,w2,w3,…等词语（已经去重）组成，若一个词反复出现则表示与主题更相关，其中w1出现了tf1次，w2出现了tf2次，依此类推。这样，我们得到了初级版本的特征，例如[0,0,…,tf1,0,…,tf2,…tf3,…]，其中词库是有序的，若某词未在网页中出现，则tf词频为0，相应位置也为0。 </p>
<p>TF算法没有解决词本身的主题区分度问题。例如，原子能的应用里，这三个词“原子能”、“的”、“应用”里，显然“原子能”的区分度最高，而“的”这种区分度非常低。IDF（inverse document frequency）算法可以计算出词语的区分度，若语料库中“原子能”出现M次，而所有词语总数为N，那么其IDF值就是M/N。这样，引入IDF逆词频算法后，我们的特征向量变成了[0,0,…,tf1*idf1,0,…,tf2*idf2,…tf3*idf3,…]，这便是TF-IDF算法。 网页根据TF-IDF算法得到向量后，我们可以利用余弦定理计算出向量的相似性。如果向量只有二维，那么在二维坐标系X,Y轴中我们可以根据[x1,y1]和[x2,y2]画出两个点，并从原点引出向量a和向量b。 <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BA%8C%E7%BB%B4%E5%90%91%E9%87%8F%E5%9B%BE/"><img src="/2019/02/%E4%BA%8C%E7%BB%B4%E5%90%91%E9%87%8F%E5%9B%BE.jpg"></a> 向量a、b的夹角就是其余弦值，我们再回顾下初中时学过的余弦定理： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BD%99%E5%BC%A6%E5%AE%9A%E7%90%86/"><img src="/2019/02/%E4%BD%99%E5%BC%A6%E5%AE%9A%E7%90%86.jpg"></a> </p>
<p>这样，扩展到高维后，向量间的余弦值越小，网页便越相似。 这里我们使用了余弦相似度，而人脸识别算法（可以参考我的另一篇文章<a href="/2017/10/29/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/">《深入浅出人脸识别》</a>）中每张人脸的特征向量是128维浮点型向量，使用的是欧氏距离也计算相似度。欧氏距离与余弦相似度是不同的，如下面的三维坐标图所示： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E4%BD%99%E5%BC%A6%E8%B7%9D%E7%A6%BB%E5%92%8C%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%AF%B9%E6%AF%94/"><img src="/2019/02/%E4%BD%99%E5%BC%A6%E8%B7%9D%E7%A6%BB%E5%92%8C%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%AF%B9%E6%AF%94.jpg"></a> 比如上面的欧氏距离dist(A,B)更强调距离，而下面的cos余弦更强调方向的相似。 当然，《数学之美》中还介绍了矩阵的奇异值分解、贝叶斯网络两种更快速的方法分类，这里不再介绍。</p>
<h1 id="6、PageRank算法与网页权威度"><a href="#6、PageRank算法与网页权威度" class="headerlink" title="6、PageRank算法与网页权威度"></a>6、PageRank算法与网页权威度</h1><p>当用户搜索关键字对应着成千上万个网页时，上个世纪的搜索引擎是没有办法把用户最需要的网页放在结果列表的最前面的，所以搜索引擎仅在学术领域小规模使用。当google的创始人拉里佩奇Larry Page发明了PageRank算法后，搜索引擎开始进入商用。 </p>
<p>PageRank算法认为，应当由网页们自己投票计算出谁是最重要的网页，这样便可以按重要度排序将搜索结果呈现给用户。那怎样民主投票出重要度呢？PageRank算法认为，重要的页面会被更多的网页引用，如下图所示：<a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/pagerank%E7%AE%97%E6%B3%95/"><img src="/2019/02/PageRank%E7%AE%97%E6%B3%95.png"></a> </p>
<p>其中页面是图中的结点，URL超链接则构成了边。指向页面的边越多，这个页面就越重要。 这里也有一个问题，一些娱乐性质的站点PageRank排名更高，但它更八卦更强调运营效果，把这个结果放在更优先的搜索结果是不合适的，因为学术性站点虽然PageRank结果低但其实更权威，所以PageRank只是结果排名中的一个比较重要的因素，如领域权威性、用户点击率等维度也需要加入到网页排名算法中。   </p>
<p>当然，《数学之美》书中远不止以上6点所介绍的算法，通过通俗易懂的方式点到为止的介绍诸多实用算法，这体现了吴军老师的深厚功力，这本书值得从事计算机领域工作的同学一读。最后列出我的读书笔记思维导图： <a href="/2019/02/23/%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E/"><img src="/2019/02/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E.jpg"></a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
        <tag>算法复杂度</tag>
        <tag>CDMA</tag>
        <tag>FDMA</tag>
        <tag>GB2312</tag>
        <tag>PageRank</tag>
        <tag>TDMA</tag>
        <tag>TF-IDF</tag>
        <tag>五笔字型</tag>
        <tag>余弦相似度</tag>
        <tag>信息熵</tag>
        <tag>动态规划</tag>
        <tag>吉普赛纸牌</tag>
        <tag>吴军</tag>
        <tag>布隆过滤器</tag>
        <tag>拼音输入法</tag>
        <tag>数学之美</tag>
        <tag>时分多址</tag>
        <tag>条件概率</tag>
        <tag>欧氏距离</tag>
        <tag>用户点击率</tag>
        <tag>码分多址</tag>
        <tag>维特比算法</tag>
        <tag>网络爬虫</tag>
        <tag>误算率</tag>
        <tag>频分多址</tag>
        <tag>马尔可夫模型</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式环境Raft一致性共识算法解读</title>
    <url>/2018/06/03/%E7%AE%97%E6%B3%95/%E8%A7%A3%E8%AF%BBraft%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>Raft是分布式环境下的一致性算法，它通过少数服从多数的选举来维持集群内数据的一致性。它与RBFT算法名称有点像，然而Raft算法里不能存在拜占庭节点，而RBFT则能容忍BFT节点的存在。Raft非常类似于paxos协议（参见我的这篇文章《<a href="/paxos%E7%AE%97%E6%B3%95%E5%A6%82%E4%BD%95%E5%AE%B9%E9%94%99%E7%9A%84-%E8%AE%B2%E8%BF%B0%E4%BA%94%E8%99%8E%E5%B0%86%E7%9A%84%E5%AE%9E%E8%B7%B5/">paxos算法如何容错的–讲述五虎将的实践</a>》），然而它比paxos协议好理解许多（因为paxos协议难以具体实现，所以zookeeper参考paxos实现了它自己的Zab算法）。同样，Raft有一个用GO语言实现的etcd服务，它的功能与Zookeeper相同，在容器操作系统CoreOS作为核心组件被使用。 本文先从算法整体上说明其特点，再细说其实现。为方便大家理解，本文还是以图为主，没有过多涉及算法的细节。Raft易理解易实现，是我们入门分布式一致性算法的捷径！</p>
<span id="more"></span>

<h1 id="1-算法易被理解"><a href="#1-算法易被理解" class="headerlink" title="1.算法易被理解"></a>1.算法易被理解</h1><p>Raft协议的性能并不比paxos的各种实现更高，它的优点主要在于协议的可理解性好，且非常具备可操作性，很容易照着协议就可以实现出稳定、健壮的算法。论文作者在斯坦福和加州大学做过测试，对本科及研究生分别学习paxos和Raft协议课程后测验，在总分60分的测试里其得分如下图所示： <img src="/2018/06/raft%E4%B8%8Epaxos%E5%AD%A6%E7%94%9F%E5%BA%94%E7%94%A8%E6%88%90%E7%BB%A9-3.png"> 从上图可见，Raft协议的得分（平均25.7）明显高于paxos（平均20.8）。我相信学习过paxos算法的人都有心得：很辛苦的理解后，一段时间后就完全不记得细节了，至少我本人是如此。而Raft协议非常简单清爽，这个测试也很能反映问题。在测试后，作者还发起了一个调查问卷，询问学生这两个算法哪个更容易实现？哪个更容易理解？其答案如下图所示：<img src="/2018/06/raft%E4%B8%8Epaxos%E5%AD%A6%E7%94%9F%E8%B0%83%E6%9F%A5%E9%97%AE%E5%8D%B7-3.png"> 可见，这个带有主观性的调查问卷呈现压倒性优势：Raft是一个容易理解、容易实现的算法。</p>
<h1 id="2-算法实现etcd的性能测试数据"><a href="#2-算法实现etcd的性能测试数据" class="headerlink" title="2.算法实现etcd的性能测试数据"></a>2.算法实现etcd的性能测试数据</h1><p>Raft有很多语言的实现，包括C++、GO、Scala、Java等（详见<a href="https://raft.github.io/">https://raft.github.io/</a>），但最有名的实现就是etcd了，它作为CoreOS生态的重要组件而闻名。我们可以通过etcd的性能数据看一看Raft算法的实际表现。</p>
<p>测试集群由3台服务器构成，其配置如下：</p>
<ul>
<li>  Google Cloud Compute Engine</li>
<li>  3 machines of 8 vCPUs + 16GB Memory + 50GB SSD</li>
<li>  1 machine(client) of 16 vCPUs + 30GB Memory + 50GB SSD</li>
<li>  Ubuntu 17.04</li>
<li>  etcd 3.2.0, go 1.8.3</li>
</ul>
<p>下面分别测试写和读的性能。在读性能数据中，Linearizable一致性高于Serializable，故性能稍差。其原始页面在这里：<a href="https://coreos.com/etcd/docs/latest/op-guide/performance.html">https://coreos.com/etcd/docs/latest/op-guide/performance.html</a>。 事实上，在算法的正常运行中与paxos并无差异。而一旦leader宕机，从发现到重新选举出新leader、新leader开始工作的这段时间的长短，是影响性能的重要指标。下图中对5个节点构成的集群反复的让leader宕机，观察恢复的时间，其结果如下： <img src="/2018/06/raft%E9%80%89%E4%B8%BE%E5%87%BA%E6%96%B0%E9%A2%86%E5%AF%BC%E4%BA%BA%E8%80%97%E6%97%B6%E6%95%B0%E6%8D%AE-2.jpg"> 在上图中有以下几个关注点：</p>
<ul>
<li>  不同颜色及线条代表着follower的定时器。如在300ms内没有收到leader的心跳，则发起选举。其中150-300ms这样的数据表明，这5台follower的定时器分布在150ms到300ms之间，呈现随机化。而150-150ms表示没有随机化，所有节点的超时时间是一样的。</li>
<li>  横坐标代表着发现到替换掉宕机leader开始服务的时间。数值的单位为毫秒。</li>
<li>  纵坐标表示测试时间在全部测试数据中的比例。以上每条线都做了1000次试验（除150-150ms只试验了100次）。</li>
</ul>
<p>上图表明，增加随机化后，可以大幅减少选举的平均用时。下面的图表明，通过降低最短的超时时间，也可以减少宕机时间。Raft推荐的时间为150-300ms。</p>
<h1 id="3、Raft算法概述"><a href="#3、Raft算法概述" class="headerlink" title="3、Raft算法概述"></a>3、Raft算法概述</h1><p>复杂的问题可以通过分解为多个简单的子问题来解决，Raft正是如此（paxos很难分解）。Raft首先定义自己是一个key/value数据库。那么，请求就分为读和写。Raft将问题分解为以下几个要点：</p>
<ul>
<li>  集群里有一台为leader节点服务器，且读写请求都只能向该节点发送，以此保证一致性；</li>
<li>  当集群内没有leader节点时，leader节点被多数节点选出来。比如集群有3个节点，那么2个节点同意的话，就可以选出1个作为leader；</li>
<li>  除leader节点外，其他节点叫做follower追随者。leader节点向follower节点同步每条写请求；</li>
</ul>
<p>因此Raft将一致性问题转换为leader的选举上，以及leader与follower之间的数据同步。我们先来谈leader与 follower之间的数据同步问题。每一次写请求会修改数据，读请求则不会，所以把leader收到的写请求当作一次操作日志记录下来，且同时把操作日志同步给所有的follower节点，而有一个最终状态数据库记录某一个key的最终值，如下图所示（事实上这与fabric区块链里，多条交易日志构成的世界状态数据库非常相似，详情请参见《<a href="https://www.taohui.pub/%e5%8c%ba%e5%9d%97%e9%93%be%e5%bc%80%e6%ba%90%e5%ae%9e%e7%8e%b0hyperledger-fabric%e6%9e%b6%e6%9e%84%e8%af%a6%e8%a7%a3/">区块链开源实现hyperledger fabric架构详解</a>》）： <img src="/2018/05/unnamed-file-2-3.png"> 上图中其步骤含义如下：</p>
<ol>
<li> leader收到写请求y=9，此时状态数据库是y=1；</li>
<li> 将y=9这条日志追加到Log的末尾，同时将该条日志同步给其他follower；</li>
<li> 当多数follower成功收到这条y=9的日志后，leader将状态数据库从y=1更新为y=9；</li>
<li> 返回client表示y=9设置成功。</li>
</ol>
<h1 id="4、如何选举出leader"><a href="#4、如何选举出leader" class="headerlink" title="4、如何选举出leader"></a>4、如何选举出leader</h1><p>当一个集群刚启动时，所有的节点都是follower，follower只能被动的接收leader的消息并响应。此时经过一段时间若follower节点发现全集群没有leader，开始把自己作为leader的候选人向大家征询投票，此时该节点叫做Candidate候选人。若多数follower节点同意后，则升级为leader节点。而leader节点有义务定时心跳通知所有的 follower节点，使follower节点知道此时集群中的leader是谁。如下图所示： <img src="/2018/05/unnamed-file-3-1.jpg"> 上图的状态变迁里，follower在一个随机定时器（例如150ms到300ms之间）内没有收到leader的心跳，则开始发起选举，而候选人就是自己，所以自己转化为Candidate，且自己首先投自己一票。若在投票未完成时，发现新的leader出现，则取消投票，由candidate转换为follower。 每次选举是一个任期，这个任期叫做term。每次任期有一个任期号，它是全局的、递增的，当网络中断时虽然会暂时不一致，但网络畅通后会很快同步，如下图所示： <img src="/2018/05/term%E4%BB%BB%E6%9C%9F%E4%B8%8Eleader%E9%80%89%E4%B8%BE-2.png"> 如上图中，蓝色是选举期，绿色是产生leader后。如果不出现意外，这个leader会一直当下云，所以term周期会很长。出现宕机或者网络波动时，重新选举于是出现term2。在term3时也可能一直选举不出新的leader，此时很可能多个candidate发起了投票，票数被平摊后谁也没拿到大多数（由于每台follower的定时器时间是随机的，因此该情况发生概率很小，且发生后也能很快回归正常）。于是会进入term4。</p>
<h1 id="5、操作日志的同步"><a href="#5、操作日志的同步" class="headerlink" title="5、操作日志的同步"></a>5、操作日志的同步</h1><p>leader需要把写日志同步到大多数follower后才能更新状态数据库，并向client回复写成功。如果没有得到多数follower的成功应答，leader会重复发送这条日志更新请求。下图中有8条日志3个任期5个节点，每条日志里除记录了操作行为外还记录了当时的任期： <img src="/2018/05/entries-2.jpg"> 上图中，绿色是第一个任期，其中3条日志条目中第3条日志y=9没有被第4个节点接收到。黄色是第2个任期。绿色与黄色任期内，所有的日志皆被多数节点收到，因此都是写入状态数据库的，这些日志的状态都是commited已提交状态。蓝色是第3个任期，其第8条日志x=4没有被多数节点收到，因此该日志不是committed状态。 leader与 follower之间的日志也可能存在不一致的情况，follower或者少了一些日志，或者多了一些日志，如下图所示： <img src="/2018/06/raft%E6%97%A5%E5%BF%97%E4%B8%8D%E4%B8%80%E8%87%B4-2.png"> 上图中最上面一行是leader的日志，而follower的日志存在以下情况：</p>
<ul>
<li>  a、b表示follower相比leader少了几条日志；</li>
<li>  c、d表示follower相比leader多了几条日志；</li>
<li>  e、f表示同时少了一些日志，又多了一些日志。比如f情况就是这台follower在任期2时被选为leader，刚添加3条日志还没有提交呢就宕机了，重启后被选为leader，又迅速收到5个写请求加了5条日志，还没提交又宕机了，此时再启动作为follower存在时的状态就是上图f的状态。</li>
</ul>
<p>leader如果确定多数机器收到日志，自然可以提交。如果新leader刚被选出来，它会试图把多数机器上保存的日志（即使它自己没有这条日志）–也就是前任的日志也提交，但这未必保证一定成功，如下图所示： <img src="/2018/06/unnamed-file-3.png"> 在上图中，d和e就是提交前任日志努力下可能导致的两种状况：</p>
<ol>
<li> 在a中，S1是leader，前写入日志2并只同步日志到S1和S2，还未到其他节点时就宕机了；</li>
<li> 在b中，S5通过它自己、S3、S4的投票被选为leader，因此它并不知道日志2的存在。此时它收到client的新请求写入日志3，而刚写入日志3就宕机了；</li>
<li> 在c中，S1重新被选为leader，此时它发现日志2还未被复制到多数follower，开始复制日志2。此时S1收到新请求，并记录了日志4；</li>
<li> 在d中是第一种场景，此时老的日志2被复制到了S3上，然而此时的日志2虽然被S1、S2、S3多数节点持有，但却是通过2次任期完成的，且新任期里的日志4并未被复制到多数机器上，所以日志2并不能认定可以处于commited状态。若此时S1宕机，S5重新当选，则日志2会被覆盖丢弃，当然也包括未被复制到多数机器的日志4；</li>
<li> 在e中是接着c的第二种场景，若日志4也被复制到S1、S2、S3这多数机器上，则日志2与日志3同时处于commited状态，永远不会被覆盖。</li>
</ol>
<h1 id="6、集群规模的配置变化"><a href="#6、集群规模的配置变化" class="headerlink" title="6、集群规模的配置变化"></a>6、集群规模的配置变化</h1><p>通常我们把raft集群配置为3或者5个节点，特别是5个节点时可以容忍2个节点宕机。这给我们平滑升级时带来了好处：1台台升级时仍然可以容忍1台宕机。但若我们的集群原来是3个节点的组合，却改为5个节点，如果这个过程是不停止服务动态完成的，这可能出现问题，如下图所示： <img src="/2018/06/Raft%E7%9B%B4%E6%8E%A5%E4%BB%8E3%E5%8F%B0%E8%B0%88%E5%88%B05%E5%8F%B0%E4%B8%8D%E5%AE%89%E5%85%A8-1.png"> 在上图中，绿色的老配置只有1、2、3这三台server组成集群，而在蓝色的新配置里则在1、2、3、4、5这五台server组成的新集群。于是，存在红色箭头指标的点，在该点上，可能1、2这两台server根据老配置在它们2个中选出第1个leader，而3、4、5根据新配置在它们3个中选出了第2个leader。同一时刻出现了2个leader，这样数据就会不一致。 为了解决上述问题，Raft提出了一个共同一致状态，该状态处于老配置和新配置生效的中间阶段。首先，我们设C(old)为老配置，而新配置为C(new)，欲从C(old)状态置C(new)，必须经历C(old,new)状态。其中，更新到C(old,new)以及C(new)时，仍然以复制日志的方式进行，即：先进行日志复制，当确定多数节点收到该日志后，则该日志为commited已提交状态。如下图所示： <img src="/2018/06/Raft%E6%9B%B4%E6%96%B0%E9%85%8D%E7%BD%AE%E6%97%B6%E7%9A%84%E5%85%B1%E5%90%8C%E4%B8%80%E8%87%B4%E7%8A%B6%E6%80%81-1.png"> 从上图中可以看到：</p>
<ol>
<li> 在C(old,new)日志开始复制时，仍然仅使用C(old)这一种配置，所以不会出现双leader；</li>
<li> 而C(old,new)一旦进入commited提交状态，此时若leader宕机重新选举，则要求必须是具备C(old,new)的candidate才能被选为新leader；</li>
<li> 之后，leader开始复制日志C(new)，从这一刻起leader的新配置开始生效。</li>
</ol>
<h1 id="7、日志的优化"><a href="#7、日志的优化" class="headerlink" title="7、日志的优化"></a>7、日志的优化</h1><p>可以看到，Raft算法的核心就是leader选举以及日志复制。而日志的无限增长，必然带来性能问题，这是从工程角度必须解决的问题。日志表示的是过程，状态数据库表示的是结果；同样，我们可以定期把某一时间点之前的日志做成状态数据库，或者称为快照，仅保留该时间点后的日志，这样就可以大幅减少日志的数量。如下图所示： <img src="/2018/06/raft%E6%97%A5%E5%BF%97%E5%BF%AB%E7%85%A7-1.jpg"> 在上图中，原先的已经被提交的5条日志最终导致的状态是x=0&amp;&amp;y=9，故可以被快照替代，这便减少了日志量。</p>
<h1 id="8、小结"><a href="#8、小结" class="headerlink" title="8、小结"></a>8、小结</h1><p>Raft还有一个非常形象的算法演示动画，包含了一致性算法的由来、leader的选举、隔离网络下的leader选举、日志的复制等场景，请打开<a href="http://thesecretlivesofdata.com/raft/">RaftUnderstandable Distributed Consensus</a>链接观看。 学习Raft算法有助于我们理解分布式环境下的一致性解决方案，而且它确实比paxos好理解许多，可以作为我们的入门算法。</p>
]]></content>
      <categories>
        <category>区块链</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>etcd</tag>
        <tag>paxos</tag>
        <tag>CoreOS</tag>
        <tag>Raft</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title>深入浅出人脸识别技术</title>
    <url>/2017/10/29/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>在深度学习出现后，人脸识别技术才真正有了可用性。这是因为之前的机器学习技术中，难以从图片中取出合适的特征值。轮廓？颜色？眼睛？如此多的面孔，且随着年纪、光线、拍摄角度、气色、表情、化妆、佩饰挂件等等的不同，同一个人的面孔照片在照片象素层面上差别很大，凭借专家们的经验与试错难以取出准确率较高的特征值，自然也没法对这些特征值进一步分类。</p>
<p>深度学习的最大优势在于由训练算法自行调整参数权重，构造出一个准确率较高的f(x)函数，给定一张照片则可以获取到特征值，进而再归类。本文中笔者试图用通俗的语言探讨人脸识别技术，首先概述人脸识别技术，接着探讨深度学习有效的原因以及梯度下降为什么可以训练出合适的权重参数，最后描述基于CNN卷积神经网络的人脸识别。 </p>
<span id="more"></span>
<h1 id="人脸识别技术概述"><a href="#人脸识别技术概述" class="headerlink" title="人脸识别技术概述"></a>人脸识别技术概述</h1><p>人脸识别技术大致由<strong>人脸检测和人脸识别</strong>两个环节组成。 之所以要有人脸检测，不光是为了检测出照片上是否有人脸，更重要的是把照片中人脸无关的部分删掉，否则整张照片的像素都传给f(x)识别函数肯定就不可用了。人脸检测不一定会使用深度学习技术，因为这里的技术要求相对低一些，只需要知道有没有人脸以及人脸在照片中的大致位置即可。一般我们考虑使用opencv、dlib等开源库的人脸检测功能（基于专家经验的传统特征值方法计算量少从而速度更快），也可以使用基于深度学习实现的技术如mtcnn（在神经网络较深较宽时运算量大从而慢一些）。 </p>
<p>在人脸检测环节中，我们主要关注检测率、漏检率、误检率三个指标，其中： </p>
<ul>
<li>检测率：存在人脸并且被检测出的图像在所有存在人脸图像中的比例；</li>
<li>漏检率：存在人脸但是没有检测出的图像在所有存在人脸图像中的比例；</li>
<li>误检率：不存在人脸但是检测出存在人脸的图像在所有不存在人脸图像中的比例。</li>
</ul>
<p>当然，检测速度也很重要。本文不对人脸检测做进一步描述。 在人脸识别环节，其应用场景一般分为<strong>1:1和1:N</strong>。 </p>
<p>1：1就是判断两张照片是否为同一个人，通常应用在人证匹配上，例如身份证与实时抓拍照是否为同一个人，常见于各种营业厅以及后面介绍的1:N场景中的注册环节。</p>
<p>而1:N应用场景，则是首先执行注册环节，给定N个输入包括人脸照片以及其ID标识，再执行识别环节，给定人脸照片作为输入，输出则是注册环节中的某个ID标识或者不在注册照片中。</p>
<p>可见，从概率角度上来看，前者相对简单许多，且由于证件照通常与当下照片年代间隔时间不定，所以通常我们设定的相似度阈值都是比较低的，以此获得比较好的通过率，容忍稍高的误识别率。 而后者1：N，随着N的变大误识别率会升高，识别时间也会增长，所以相似度阈值通常都设定得较高，通过率会下降。</p>
<p>这里简单解释下上面的几个名词：</p>
<ul>
<li>误识别率就是照片其实是A的却识别为B的比率；</li>
<li>通过率就是照片确实是A的，但可能每5张A的照片才能识别出4张是A其通过率就为80%；</li>
<li>相似度阈值是因为对特征值进行分类是概率行为，除非输入的两张照片其实是同一个文件，否则任何两张照片之间都有一个相似度，设定好相似度阈值后唯有两张照片的相似度超过阈值，才认为是同一个人。</li>
</ul>
<p>所以，单纯的评价某个人脸识别算法的准确率没有意义，我们最需要弄清楚的是<strong>误识别率小于某个值时（例如0.1%）的通过率</strong>。不管1:1还是1:N，其底层技术是相同的，只是难度不同而已。 </p>
<p>取出人脸特征值是最难的，那么深度学习是如何取特征值的？ 假定我们给出的人脸照片是100*100像素大小，由于每个像素有RGB三个通道，每个像素通道由0-255范围的字节表示，则共有3个100*100的矩阵计3万个字节作为输入数据。深度学习实际上就是生成一个近似函数，把上面的输入值转化为可以用作特征分类的特征值。那么，特征值可以是一个数字吗？当然不行，一个数字（或者叫标量）是无法有效表示出特征的。通常我们用多个数值组成的向量表示特征值，向量的维度即其中的数值个数。特征向量的维度并非越大越好，google的facenet项目（参见<a href="https://arxiv.org/abs/1503.03832%E8%AE%BA%E6%96%87%EF%BC%89%E5%81%9A%E8%BF%87%E7%9A%84%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C%E6%98%BE%E7%A4%BA%EF%BC%8C">https://arxiv.org/abs/1503.03832论文）做过的测试结果显示，</a>** 128 ** 个数值组成的特征向量结果最好，如下图所示： <img src="/2017/10/unnamed-file-9.jpg"> </p>
<p>那么，现在问题就转化为怎么把3*100*100的矩阵转化为128维的向量，且这个向量能够准确的区分出不同的人脸？ </p>
<p>假定照片为x，特征值为y，也就是说存在一个函数f(x)=y可以完美的找出照片的人脸特征值。现在我们有一个f*(x)近似函数，其中它有参数w（或者叫权重w）可以设置，例如写成f*(x;w)，若有训练集x及其id标识y，设初始参数p1后，那么每次f*(x;w)得到的y`与实际标识y相比，若正确则通过，若错误则适当调整参数w，如果能够正确的调整好参数w，f*(x;w)就会与理想中的f(x)函数足够接近，我们就获得了概率上足够高准确率的f*(x;w)函数。这一过程叫做监督学习下的训练。</p>
<p>而计算f*(x;w)值的过程因为是正常的函数运算，我们称为<strong>前向运算</strong>，而训练过程中比较y`与实际标识id值y结果后，调整参数p的过程则是反过来的，称为<strong>反向传播</strong>。 </p>
<p>由于我们传递的x入参毕竟是一张照片，照片既有对焦、光线、角度等导致的不太容易衡量的质量问题，也有本身的像素数多少问题。如果x本身含有的数据太少，即图片非常不清晰，例如28*28像素的照片，那么谁也无法准确的分辨出是哪个人。可以想见，必然像素数越多识别也越准，但像素数越多导致的计算、传输、存储消耗也越大，我们需要有根据的找到合适的阈值。下图是facenet论文的结果，虽然只是一家之言，但google的严谨态度使得数据也很有参考价值。 <img src="/2017/10/facenet%E5%83%8F%E7%B4%A0%E6%95%B0%E4%B8%8E%E8%AF%86%E5%88%AB%E7%8E%87-1.jpg"> 从图中可见排除照片其他质量外象素数至少也要有100*100（纯人脸部分）才能保证比较高的识别率。 </p>
<h1 id="深度学习技术的原理"><a href="#深度学习技术的原理" class="headerlink" title="深度学习技术的原理"></a>深度学习技术的原理</h1><p>由清晰的人脸照转化出的象素值矩阵，应当设计出什么样的函数f(x)转化为特征值呢？这个问题的答案依赖于分类问题。即，先不谈特征值，首先如何把照片集合按人正确的分类？这里就要先谈谈机器学习。机器学习认为可以从有限的训练集样本中把算法很好的泛化。所以，我们先找到有限的训练集，设计好初始函数f(x;w)，并已经量化好了训练集中x-&gt;y。如果数据x是低维的、简单的，例如只有二维，那么分类很简单，如下图所示：<br><img src="/2017/10/unnamed-file-6.png"> </p>
<p>上图中的二维数据x只有方形和圆形两个类别y，很好分，我们需要学习的分类函数用最简单的f(x,y)=ax+by+c就能表示出分类直线。例如f(x,y)大于0时表示圆形，小于0时表示方形。 给定随机数作为a,c,b的初始值，我们通过训练数据不断的优化参数a,b,c，把不合适的L1、L3等分类函数逐渐训练成L2，这样的L2去面对泛化的测试数据就可能获得更好的效果。然而如果有多个类别，就需要多条分类直线才能分出，如下图所示：<br><img src="/2017/10/unnamed-file-1-1.jpg"> </p>
<p>这其实相当于多条分类函数执行与&amp;&amp;、或操作后的结果。这个时候还可能用f1&gt;0 &amp;&amp; f2&lt;0 &amp;&amp; f3&gt;0这样的分类函数，但如果更复杂的话，例如本身的特征不明显也没有汇聚在一起，这种找特征的方式就玩不转了，如下图所示，不同的颜色表示不同的分类，此时的训练数据完全是<strong>非线性可分</strong>的状态：<br><img src="/2017/10/unnamed-file-2-1.jpg"> </p>
<p>这个时候，我们可以通过多层函数嵌套的方法来解决，例如f(x)=f1(f2(x))，这样f2函数可以是数条直线，而f1函数可以通过不同的权重w以及激励函数完成与&amp;&amp;、或等等操作。这里只有两层函数，<strong>如果函数嵌套层数越多，它越能表达出复杂的分类方法</strong>，这对高维数据很有帮助。例如我们的照片毫无疑问就是这样的输入。所谓激励函数就是把函数f计算出的非常大的值域转化为[0,1]这样较小的值域，这允许多层函数不断的前向运算、分类。 </p>
<p>前向运算只是把输入交给f1(x,w1)函数，计算出的值再交给f2(y1,w2)函数，依次类推，很简单就可以得到最终的分类值。但是，因为初始的w权重其实没有多大意义，它得出的分类值f*(x)肯定是错的，在训练集上我们知道正确的值y，那么事实上我们其实是希望y-f*(x)的值最小，这样分类就越准。这其实变成了求最小值的问题。当然，y-f*(x)只是示意，事实上我们得到的f*(x)只是落到各个分类上的概率，把这个概率与真实的分类相比较得到最小值的过程，我们称为<strong>损失函数</strong>，其值为loss，我们的目标是把损失函数的值loss最小化。在人脸识别场景中，softmax是一个效果比较好的损失函数，我们简单看下它是如何使用的。 </p>
<p>比如我们有训练数据集照片对应着cat、dog、ship三个类别，某个输入照片经过函数f(x)=x*W+b，前向运算得到该照片属于这3个分类的得分值。此时，这个函数被称为<strong>得分函数</strong>，如下图所示，假设左边关于猫的input image是一个4维向量[56,231,24,2]，而W权重是一个4*3的矩阵，那么相乘后再加上向量[1.1,3.2,-1.2]可得到在cat、 dog、ship三个类别上的得分： <img src="/2017/10/unnamed-file-3-1.jpg"> </p>
<p>从上图示例可见，虽然输入照片是猫，但得分上属于狗的得分值437.9最高，但究竟比猫和船高多少呢？很难衡量！如果我们把得分值转化为0-100的百分比概率，这就方便度量了。这里我们可以使用sigmoid函数，如下图所示：<br><img src="/2017/10/sigmoid%E5%9B%BE-1.jpg"> </p>
<p>从上图公式及图形可知，sigmoid可以把任意实数转换为0-1之间的某个数作为概率。但sigmoid概率不具有<strong>归一性</strong>，也就是说我们需要保证输入照片在所有类别的概率之和为1，这样我们还需要对得分值按softmax方式做以下处理：<br><img src="/2017/10/softmax%E5%85%AC%E5%BC%8F-1.png"><br>这样给定x后可以得到x在各个类别下的概率。假定三个类别的得分值分别为3、1、-3，则按照上面的公式运算后可得概率分别为[0.88、0.12、0]，计算过程如下图所示： <img src="/2017/10/softmax%E8%8E%B7%E5%BE%97%E6%A6%82%E7%8E%87%E7%A4%BA%E6%84%8F%E5%9B%BE-1.jpg"> </p>
<p>然而实际上x对应的概率其实是第一类，比如[1,0,0]，现在拿到的概率（或者可称为似然）是[0.88、0.12、0]。那么它们之间究竟有多大的差距呢？这个差距就是损失值loss。如何获取到损失值呢？在softmax里我们用<strong>互熵损失</strong>函数计算量最小（方便求导），如下所示：<br><img src="/2017/10/unnamed-file-4-1.jpg"> </p>
<p>其中i就是正确的分类，例如上面的例子中其loss值就是-ln0.88。这样我们有了损失函数f(x)后，怎么调整x才能够使得函数的loss值最小呢？这涉及到微分导数。 </p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>梯度下降就是为了快速的调整权重w，使得损失函数f(x;w)的值最小。因为损失函数的值loss最小，就表示上面所说的在训练集上的得分结果与正确的分类值最接近！ </p>
<p><strong>导数</strong>求的是函数在某一点上的变化率。例如从A点开车到B点，通过距离和时间可以算出平均速度，但在其中C点的瞬时速度是多少呢？如果用x表示时间，f(x)表示车子从A点驶出的距离，那么在x0的瞬时速度可以转化为：从x0时再开一个很小的时间，例如1秒，那么这一秒的平均速度就是这一秒开出的距离除以1秒，即(f(1+x0)-f(x0))/1。如果我们用的不是1秒而是1微秒，那么这个1微秒内的平均速度必然更接近x0时的瞬时速度。于是，到该时间段t趋向于0时，我们就得到了x0时的瞬时速度。这个瞬时速度就是函数f在x0上的变化率，所有x上的变化率就构成了函数f(x)的导数，称为f`(x)。即： <img src="/2017/10/unnamed-file-1-1.png"> </p>
<p>从几何意义上看，<strong>变化率就变成了斜率</strong>，这更容易理解怎样求函数的最小值。例如下图中有函数y=f(x)用粗体黑线表示，其在P0点的变化率就是切线红线的斜率：<br><img src="/2017/10/unnamed-file-5-1.jpg"><br>可以形象的看出，当斜率的值为正数时，把x向左移动变小一些，f(x)的值就会小一些；当斜率的值为负数时，把x向右移动变大一些，f(x)的值也会小一些，如下图所示：<br><img src="/2017/10/unnamed-file-6-1.jpg"><br>这样，斜率为0时我们其实就得到了函数f在该点可以得到最小值。那么，把x向左或者向右移一点，到底移多少呢？如果移多了，可能移过了，如果移得很少，则可能要移很久才能找到最小点。还有一个问题，如果f(x)操作函数有多个局部最小点、全局最小点时，如果x移的非常小，则可能导致通过导数只能找到某个并不足够小的局部最小点。如下图所示：<br><img src="/2017/10/unnamed-file-2-1.png"><br>蓝色的为局部最小点，红色是全局最小点。所以x移动多少是个问题，x每次的移动步长过大或者过小都可能导致找不到全局最小点。这个步长除了跟导数斜率有关外，我们还需要有一个超参数来控制它的移动速度，这个超参数称为<strong>学习率</strong>，由于它很难优化，所以一般需要手动设置而不能自动调整。考虑到训练时间也是成本，我们通常在初始训练阶段把学习率设的大一些，越往后学习率设的越小。 </p>
<p>那么每次移动的步长与导数的值有关吗？这是自然的，导数的正负值决定了移动的方向，而导数的绝对值大小则决定了斜率是否陡峭。越陡峭则移动的步长应当越大。所以，步长由学习率和导数共同决定。就像下面这个函数， λ是学习率，而∂F(ωj) / ∂ωj是在ωj点的导数。 ωj = ωj - λ ∂F(ωj) / ∂ωj 根据导数判断损失函数f在x0点上应当如何移动，才能使得f最快到达最小值的方法，我们称为<strong>梯度下降</strong>。梯度也就是导数，沿着负梯度的方向，按照梯度值控制移动步长，就能快速到达最小值。当然，实际上我们未必能找到最小点，特别是本身存在多个最小点时，但如果这个值本身也足够小，我们也是可以接受的，如下图所示：<br><img src="/2017/10/unnamed-file-7-1.jpg"><br>以上我们是以一维数据来看梯度下降，但我们的照片是多维数据，此时如何求导数？又如何梯度下降呢？此时我们需要用到偏导数的概念。其实它与导数很相似，因为x是多维向量，那么我们假定计算Xi的导数时，x上的其他数值不变，这就是Xi的偏导数。此时应用梯度下降法就如下图所示，θ是二维的，我们分别求θ0和θ1的导数，就可以同时从θ0和θ1两个方向移动相应的步长，寻找最低点，如下图所示：<br><img src="/2017/10/unnamed-file-8-1.jpg"><br>前文说过，根据有限的训练集，去适应无限的测试集，当然训练集容量越大效果就越好。但是，训练集如果很大，那么每次都根据全部数据执行梯度下降计算量就太大了。此时，我们选择每次只取全部训练集中的一小部分（究竟多少，一般根据内存和计算量而定），执行梯度下降，不断的迭代，根据经验一样可以快速的把梯度降下来。这就是<strong>随机梯度下降</strong>。 </p>
<p>上面的梯度下降法只能对f函数的w权重进行调整，而上文中我们说过实际是多层函数套在一起，例如f1(f2(x;w2);w1)，那么怎么求对每一层函数输入的导数呢？这也是所谓的<strong>反向传播</strong>怎样继续反向传递下去呢？这就要提到链式法则。其实质为，本来y对x的求导，可以通过引入中间变量z来实现，如下图所示：<br><img src="/2017/10/unnamed-file-3-1.png"> 这样，y对x的导数等价于y对z的导数乘以z对x的偏导。当输入为多维时则有下面的公式： <img src="/2017/10/unnamed-file-4-1.png"><br>如此，我们可以得到每一层函数的导数，这样可以得到每层函数的w权重应当调整的步长，优化权重参数。 由于函数的导数很多，例如resnet等网络已经达到100多层函数，所以为区别传统的机器学习，我们称其为<strong>深度学习</strong>。 </p>
<p>深度学习只是受到神经科学的启发，所以称为神经网络，但实质上就是上面提到的多层函数前向运算得到分类值，训练时根据实际标签分类取损失函数最小化后，根据随机梯度下降法来优化各层函数的权重参数。人脸识别也是这么一个流程。以上我们初步过完多层函数的参数调整，但函数本身应当如何设计呢？ </p>
<h1 id="基于CNN卷积神经网络进行人脸识别"><a href="#基于CNN卷积神经网络进行人脸识别" class="headerlink" title="基于CNN卷积神经网络进行人脸识别"></a>基于CNN卷积神经网络进行人脸识别</h1><p>我们先从全连接网络谈起。google的<strong>tensorflow游乐场</strong>里可以直观的体验全连接神经网络的威力，这是游乐场的网址：<a href="http://playground.tensorflow.org/%EF%BC%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E9%87%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%81%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%EF%BC%8C%E4%B8%94%E8%BF%87%E7%A8%8B%E4%B8%8E%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%82%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A">http://playground.tensorflow.org/，浏览器里就可以做神经网络训练，且过程与结果可视化。如下图所示：</a> <img src="/2017/10/tensorflow%E6%B8%B8%E4%B9%90%E5%9C%BA%E7%A4%BA%E4%BE%8B-1.jpg"> </p>
<p>这个神经网络游乐场共有1000个训练点和1000个测试点，用于对4种不同图案划分出蓝色点与黄色点。DATA处可选择4种不同图案。 整个网络的输入层是FEATURES（待解决问题的特征），例如x1和x2表示垂直或者水平切分来划分蓝色与黄色点，这是最容易理解的2种划分点的方法。其余5种其实不太容易想到，这也是传统的专家系统才需要的，实际上，这个游乐场就是为了演示，1、好的神经网络只用最基本的x1,x2这样的输入层FEATURES就可以完美的实现；2、即使有很多种输入特征，我们其实并不清楚谁的权重最高，但好的神经网络会解决掉这个问题。 </p>
<p>隐层HIDDEN LAYERS可以随意设置层数，每个隐层可以设置神经元数。实际上神经网络并不是在计算力足够的情况下，层数越多越好或者每层神经元越多越好。好的神经网络架构模型是很难找到的。本文后面我们会重点讲几个CNN经典网络模型。然而，在这个例子中，多一些隐层和神经元可以更好的划分。 epoch是训练的轮数。红色框出的loss值是衡量训练结果的最重要指标，如果loss值一直是在下降，比如可以低到0.01这样，就说明这个网络训练的结果好。loss也可能下降一会又突然上升，这就是不好的网络，大家可以尝试下。learning rate初始都会设得高些，训练到后面都会调低些。Activation是激励函数，目前CNN都在使用Relu函数。 </p>
<p>了解了神经网络后，现在我们回到人脸识别中来。每一层神经元就是一个f函数，上面的四层网络就是f1(f2(f3(f4(x))))。然而，就像上文所说，照片的象素太多了，全连接网络中任意两层之间每俩个神经元都需要有一次计算。特别之前提到的，复杂的分类依赖于许多层函数共同运算才能达到目的。当前的许多网络都是多达100层以上，如果每层都有3*100*100个神经元，可想而知计算量有多大！于是<strong>CNN卷积神经网络</strong>应运而生，它可以在大幅降低运算量的同时保留全连接网络的威力。 CNN认为可以只对整张图片的一个矩形窗口做全连接运算（可称为<strong>卷积核</strong>），滑动这个窗口以相同的权重参数w遍历整张图片后，可以得到下一层的输入，如下图所示：<br><img src="/2017/10/cnn%E5%A4%9A%E5%8D%B7%E7%A7%AF%E6%A0%B81-1.jpg"><br>CNN中认为同一层中的权重参数可以共享，因为同一张图片的各个不同区域具有一定的相似性。这样原本的全连接计算量过大问题就解决了，如下图所示：<br><img src="/2017/10/cnn%E5%B1%80%E9%83%A8%E6%84%9F%E7%9F%A5%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E9%87%8F%E8%BF%87%E5%A4%A7-1.jpg"><br>结合着之前的函数前向运算与矩阵，我们以一个动态图片直观的看一下前向运算过程：<br><img src="/2017/10/unnamed-file-1.gif"><br>这里卷积核大小与移动的步长stride、输出深度决定了下一层网络的大小。同时，核大小与stride步长在导致上一层矩阵不够大时，需要用padding来补0（如上图灰色的0）。以上就叫做<strong>卷积运算</strong>，这样的一层神经元称为卷积层。上图中W0和W1表示深度为2。 CNN卷积网络通常在每一层卷积层后加一个激励层，激励层就是一个函数，它把卷积层输出的数值以非线性的方式转换为另一个值，在保持大小关系的同时约束住值范围，使得整个网络能够训练下去。在人脸识别中，通常都使用Relu函数作为激励层，relu函数就是max(0,x)，如下所示：<br><img src="/2017/10/relu%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0-1.png"> </p>
<p>可见 relu的计算量其实非常小！ CNN中还有一个池化层，当某一层输出的数据量过大时，通过池化层可以对数据降维，在保持住特征的情况下减少数据量，例如下面的4*4矩阵通过取最大值降维到2*2矩阵： <img src="/2017/10/cnn%E6%B1%A0%E5%8C%961-1.jpg"> 上图中通过对每个颜色块筛选出最大数字进行池化，以减小计算数据量。 通常网络的最后一层为全连接层，这样一般的CNN网络结构如下所示： <img src="/2017/10/cnn%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96-1.jpg"> CONV就是卷积层，每个CONV后会携带RELU层。这只是一个示意图，实际的网络要复杂许多。目前开源的google facenet是采用resnet v1网络进行人脸识别的，关于resnet网络请参考论文<a href="https://arxiv.org/abs/1602.07261%EF%BC%8C%E5%85%B6%E5%AE%8C%E6%95%B4%E7%9A%84%E7%BD%91%E7%BB%9C%E8%BE%83%E4%B8%BA%E5%A4%8D%E6%9D%82%EF%BC%8C%E8%BF%99%E9%87%8C%E4%B8%8D%E5%86%8D%E5%88%97%E5%87%BA%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E5%9F%BA%E4%BA%8Etensorflow%E5%AE%9E%E7%8E%B0%E7%9A%84python%E4%BB%A3%E7%A0%81https://github.com/davidsandberg/facenet/blob/master/src/models/inception/_resnet/_v1.py%EF%BC%8C%E6%B3%A8%E6%84%8Fslim.conv2d%E5%90%AB%E6%9C%89relu%E6%BF%80%E5%8A%B1%E5%B1%82%E3%80%82">https://arxiv.org/abs/1602.07261，其完整的网络较为复杂，这里不再列出，也可以查看基于tensorflow实现的python代码https://github.com/davidsandberg/facenet/blob/master/src/models/inception\_resnet\_v1.py，注意slim.conv2d含有relu激励层。</a> 以上只是通用的CNN网络，由于人脸识别应用中不是直接分类，而是有一个注册阶段，需要把照片的特征值取出来。如果直接拿softmax分类前的数据作为特征值效果很不好，例如下图是直接将全连接层的输出转化为二维向量，在二维平面上通过颜色表示分类的可视化表示：<br><img src="/2017/10/centor-loss%E7%9A%84%E5%88%86%E7%B1%BB%E7%A4%BA%E4%BE%8B-1.png"><br>可见效果并不好，中间的样本距离太近了。通过<strong>centor loss</strong>方法处理后，可以把特征值间的距离扩大，如下图所示： <img src="/2017/10/centorloss%E5%9C%A8%E4%B8%8D%E5%90%8Cr%E4%B8%8B%E7%9A%84%E5%88%86%E7%B1%BB%E7%A4%BA%E6%84%8F-1.png"> </p>
<p>这样取出的特征值效果就会好很多。 实际训练resnetv1网络时，首先需要关注训练集照片的质量，且要把不同尺寸的人脸照片resize到resnet1网络首层接收的尺寸大小。另外除了上面提到的学习率和随机梯度下降中每一批batchsize图片的数量外，还需要正确的设置epochsize，因为每一轮epoch应当完整的遍历完训练集，而batchsize受限于硬件条件一般不变，但训练集可能一直在变大，这样应保持epochsize*batchsize接近全部训练集。训练过程中需要密切关注loss值是否在收敛，可适当调节学习率。 </p>
<p>最后说一句，目前人脸识别效果的评价唯一通行的标准是LFW(即Labeled Faces in the Wild，参见<a href="http://vis-www.cs.umass.edu/lfw/)%EF%BC%8C%E5%AE%83%E5%8C%85%E5%90%AB%E5%A4%A7%E7%BA%A66000%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BA%BA%E7%9A%8412000%E5%BC%A0%E7%85%A7%E7%89%87%EF%BC%8C%E8%AE%B8%E5%A4%9A%E7%AE%97%E6%B3%95%E9%83%BD%E4%BE%9D%E6%8D%AE%E5%AE%83%E6%9D%A5%E8%AF%84%E4%BB%B7%E5%87%86%E7%A1%AE%E7%8E%87%E3%80%82%E4%BD%86%E5%AE%83%E6%9C%89%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E4%B8%80%E6%98%AF%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8D%E5%A4%9F%E5%A4%A7%EF%BC%8C%E4%BA%8C%E6%98%AF%E6%95%B0%E6%8D%AE%E9%9B%86%E5%9C%BA%E6%99%AF%E5%BE%80%E5%BE%80%E4%B8%8E%E7%9C%9F%E5%AE%9E%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E5%B9%B6%E4%B8%8D%E5%8C%B9%E9%85%8D%E3%80%82%E6%89%80%E4%BB%A5%E5%A6%82%E6%9E%9C%E6%9F%90%E4%B8%AA%E7%AE%97%E6%B3%95%E7%A7%B0%E5%85%B6%E5%9C%A8LFW%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E8%BE%BE%E5%88%B0%E5%A4%9A%E4%B9%88%E7%9A%84%E9%AB%98%EF%BC%8C%E5%B9%B6%E4%B8%8D%E8%83%BD%E5%8F%8D%E5%BA%94%E5%85%B6%E7%9C%9F%E5%AE%9E%E5%8F%AF%E7%94%A8%E6%80%A7%E3%80%82">http://vis-www.cs.umass.edu/lfw/)，它包含大约6000个不同的人的12000张照片，许多算法都依据它来评价准确率。但它有两个问题，一是数据集不够大，二是数据集场景往往与真实应用场景并不匹配。所以如果某个算法称其在LFW上的准确率达到多么的高，并不能反应其真实可用性。</a> 笔者水平有限，如有错误欢迎大家指出。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>cnn卷积神经网络</tag>
        <tag>tensorflow</tag>
        <tag>人脸识别</tag>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title>详解rsync算法--如何减少同步文件时的网络传输量</title>
    <url>/2014/01/27/%E7%AE%97%E6%B3%95/%E8%AF%A6%E8%A7%A3rsync%E7%AE%97%E6%B3%95-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E5%90%8C%E6%AD%A5%E6%96%87%E4%BB%B6%E6%97%B6%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E9%87%8F/</url>
    <content><![CDATA[<p>先看下图中的场景，客户端A和B，以及服务器server都保存了同一个文件，最初，A、B和server上的文件内容都是相同的（记为File.1）。某一时刻，B修改了文件内容，上传到SERVER上（记为File.2）。客户端A这时试图向服务器SERVER更新文件到最新内容，也就是File.1更新为File.2。 <img src="/2017/01/0_1330418966gvnq-1-1.png"> </p>
<span id="more"></span>
<p>上面这个场景很常见，例如现在流行的网盘。假设我有一个文件a.txt在网盘上，上班时在公司的单位PC上更新了文件a.txt，下班后回到家里，家里PC硬盘上的a.txt就不是最新的内容，这时网盘就试图从服务器上去拿最新的a.txt了。 那么问题来了，如果在公司电脑上我只是更新了a.txt里很少的一部分内容，例如a.txt共有20M，我只更新了10个字节，难道家里的电脑上，网盘要从服务器上下载20M大小的文件？这明显很浪费带宽。 更有用的场景，假设我的手机<a href="http://lib.csdn.net/base/android" title="Android知识库">Android</a>上也用了这个网盘（手机上网费贵得多），只改了几十字节的内容，就要下载20M的文件，得不偿失。或者我把这个文件共享给其他朋友，也有同样的问题：修改少量的内容，却同步完整的文件！ rsync<a href="http://lib.csdn.net/base/datastructure" title="算法与数据结构知识库">算法</a>就是用来解决上述问题的。client A发送它所保存的旧文件File.1少量的rsync摘要，server拿到后对比本地的File.2内容，得到File.2相对于File.1的变化，然后通过仅发送这个变化来代替发送完整的File.2内容，这样大大减少了网络传输数据。client A收到这个变化后，更新本地的File.1到最新的File.2。就是这么简单。下面详述rsync算法的步骤。 </p>
<p>rsync首先需要客户端与服务器之间约定一个块大小，例如1K。然后把File.1等分成多个1K大小的字符串块，每块各计算出MD5摘要和Alder32校验和，如下图。 <img src="http://hi.csdn.net/attachment/201202/28/0_13304189720Wy0.gif"> </p>
<p>这里简单介绍下MD5和校验和。MD5是种哈希算法，用于把任意长度的字符串转化为固定为128位的定长字符串，这里可以保证，相同的字符串不可能计算出不同的MD5值。MD5的碰撞率是有的，就是说，两个不同的字符串有可能计算出相同的MD5值，但是这个机率非常小，这里我们忽略不计。例如，在rsync算法里，同一个文件按1K切分成多块，每块都有一个MD5值，如果两块字符串的MD5值相同，则我们认为这两块数据完全相同。 </p>
<p>校验和是把上述1K块数据映射为32位大小整型数字上，我们采用Alder32算法，这里同样可以保证，相同的字符串不可能计算出不同的Alder32值。Alder32有两个优点：</p>
<ol>
<li>计算非常快，比MD5快多了，成本小；</li>
<li>当我们有了从0-1024长度的校验和后，计算出1-1025或者2-1026等其他校验和非常方便，只要少量运算即可。<br>当然，它的缺点也很明显，就是碰撞率比MD5高多了，所以，我们要把每个rynsc块同时计算出Alder32校验和与MD5值。Alder32算法我会在本文最后解释。 </li>
</ol>
<p>客户端按1K大小划分File.1文件为许多块，并对每块计算出MD5、Alder32校验和。最后不满1K的数据不做计算。之后，客户端把这些MD5、Alder32校验和依序通过网络传输给服务器，最后不满1K的数据直接发给服务器。那么，服务器收到数据后怎么处理呢？看下图。 <img src="http://hi.csdn.net/attachment/201202/28/0_1330418977eQQm.gif"> </p>
<p>首先重申，计算Alder32校验和非常快！<br>所以，服务器先把最新文件File.2从0字节开始，按1K切分成许多块，每块计算出Alder32校验和，然后与客户端发来的File.1切分出来的Alder32校验和相比，如果alder32值都不一样，毫无疑问，文件内容是不相同的。接着，把File.2从1字节开始，按1K切分成许多块，每块计算出Alder32校验和，再与客户端的校验和比。如此循环下去，直到某个校验和相同了，那么把这段字符串再计算出MD5值，再与客户端过来的对应的MD5值相比（还记得吧？客户端对每个块既计算出Alder32又计算出MD5值），如果不同，则继续往后移1字节，继续比Alder32、MD5值。如果相同，则认为这1K数据，服务器与客户端保存的一致，忽略这块数据（例如1K字节），继续向下看。 </p>
<p>全部处理完后，按File.2的文件顺序，向客户端发送以下数据：对于不能够在客户端File.1数据块中找到相同块的字符串，直接列上发出；如果可以找到，则写上MD5和Alder32值，代替原来1024字节的数据块。同样，最后不足1K大小的部分直接列上发出。 纯理论读起来会有些吃力，我再把它简化了举个例子吧。假设客户端与服务器间约定的字符块大小不是1K，而是4个字节。客户端的文件内容是： <strong>taohuiissoman</strong> 而服务器的文件内容是： <strong>itaohuiamsoman</strong> 现在我们来看看，rsync算法是怎么运作的。 首先，客户端开始分块并计算出MD5和Alder32值。 <img src="http://hi.csdn.net/attachment/201202/28/0_13304189828LbQ.gif"><br>如上图，像taoh是一块，对taoh分别计算出MD5和alder32值。以此类推，最后一个n字母不足4位保留。于是，客户端把计算出的MD5和alder32按顺序发出，最后发出字符n。 </p>
<p>服务器收到后，先把自己保存的File.2的内容按4字节划分。 <img src="http://hi.csdn.net/attachment/201202/28/0_13304189879FFQ.gif"> 划分出itao、huia、msom、an，当然，这些串的Alder32值肯定无法从File.1里划分出的：taoh、uiis、soma、n找出相同的。于是向后移一个字节，从t开始继续按4字节划分。 <img src="http://hi.csdn.net/attachment/201202/29/0_1330475871lT5V.gif"> </p>
<p>从taoh上找到了alder32相同的块，接着再比较MD5值，也相同！于是记下来，跳过taoh这4个字符，看uiam，又找不到File.1上相同的块了。继续向后跳1个字节从i开始看。还是没有找到Alder32相同，继续向后移，以此类推。 <img src="http://hi.csdn.net/attachment/201202/29/0_133047587899Md.gif"> 到了soma，又找到相同的块了。 重复上面的步骤，直到File.2文件结束。 那么，最终客户端与服务器间传输的数据如下图所示。 <img src="http://hi.csdn.net/attachment/201202/28/0_13304190034nZb.gif"> 上面这个例子很简单，可由此推导出复杂的情况，包括File.2对File.1在任意位置上做了增、改、删，都能够完成。 如果这是个大文本文件，应用rsync算法就非常有意义，例如20M的文件，实际可能只传输1M的数据量！这样用户体验会好很多，特别是网速慢的场景。 同时增加的消耗，就是在PC上计算的MD5值和Alder32校验和，这只消耗少量的CPU和内存而已。 最后列下Alder32的算法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A &#x3D; 1 + D1 + D2 + ... + Dn (mod 65521)  </span><br><span class="line">B &#x3D; (1 + D1) + (1 + D1 + D2) + ... + (1 + D1 + D2 + ... + Dn) (mod 65521)  </span><br><span class="line">  &#x3D; n×D1 + (n−1)×D2 + (n−2)×D3 + ... + Dn + n (mod 65521)  </span><br><span class="line">  </span><br><span class="line">Adler-32(D) &#x3D; B × 65536 + A  </span><br></pre></td></tr></table></figure>

<p>D1到Dn就是待计算的字符串块，所有位上的ASC字符。它的C代码实现为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">const int MOD_ADLER &#x3D; 65521;  </span><br><span class="line">   </span><br><span class="line">unsigned long adler32(unsigned char *data, int len) &#x2F;* where data is the location of the data in physical memory and  </span><br><span class="line">                                                       len is the length of the data in bytes *&#x2F;  </span><br><span class="line">&#123;  </span><br><span class="line">    unsigned long a &#x3D; 1, b &#x3D; 0;  </span><br><span class="line">    int index;  </span><br><span class="line">   </span><br><span class="line">    &#x2F;* Process each byte of the data in order *&#x2F;  </span><br><span class="line">    for (index &#x3D; 0; index &lt; len; ++index)  </span><br><span class="line">    &#123;  </span><br><span class="line">        a &#x3D; (a + data[index]) % MOD_ADLER;  </span><br><span class="line">        b &#x3D; (b + a) % MOD_ADLER;  </span><br><span class="line">    &#125;  </span><br><span class="line">   </span><br><span class="line">    return (b &lt;&lt; 16)  a;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>alder32</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>一文解释清楚Google BBR拥塞控制算法原理</title>
    <url>/2019/08/07/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>BBR对TCP性能的提升是巨大的，它能更有效的使用当下网络环境，Youtube应用后在吞吐量上有平均4%提升（对于日本这样的网络环境有14%以上的提升）： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/youtube-bbs-vs-cubic-throughput-2/"><img src="/2019/07/Youtube-BBS-vs-CUBIC-Throughput-1.png"></a> 报文的往返时延RTT降低了33%，这样如视频这样的大文件传输更快，用户体验更好：</p>
<span id="more"></span>
<p> <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/youtube-bbs-vs-cubic-max-rtt-2/"><img src="/2019/07/Youtube-BBS-vs-CUBIC-Max-RTT-1.png"></a> 不像CUBIC这种基于丢包做拥塞控制，常导致瓶颈路由器大量报文丢失，所以重新缓存的平均间隔时间也有了11%提升： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/youtube-bbs-vs-cubic-rebuffers-2/"><img src="/2019/07/Youtube-BBS-vs-CUBIC-Rebuffers-1.png"></a> 在Linux4.19内核中已经将拥塞控制算法从CUBIC（该算法从2.6.19内核就引入Linux了）改为BBR，而即将面世的基于UDP的HTTP3也使用此算法。许多做应用开发的同学可能并不清楚什么是拥塞控制，BBR算法到底在做什么，我在《Web协议详解与抓包实战》这门课程中用了6节课在讲相关内容，这里我尝试下用一篇图片比文字还多的文章把这个事说清楚。 </p>
<p> TCP协议是面向字符流的协议，它允许应用层基于read/write方法来发送、读取任意长的字符流： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/tcp-socket-readwrite/"><img src="/2019/07/tcp-socket-readwrite.png"></a> 但TCP之下的IP层是基于块状的Packet报文来分片发送的，因此，TCP协议需要将应用交付给它的字符流拆分成多个Packet（在TCP传输层被称为Segment）发送，由于网速有变化且接收主机的处理性能有限，TCP还要决定何时发送这些Segment。TCP滑动窗口解决了Client、Server这两台主机的问题，但没有去管连接中大量路由器、交换机转发IP报文的问题，因此当瓶颈路由器的输入流大于其输出流时，便会发生拥塞： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E8%BE%83%E5%A4%A7%E7%AE%A1%E9%81%93%E5%90%91%E8%BE%83%E5%B0%8F%E7%AE%A1%E9%81%93%E4%BC%A0%E8%BE%93%E5%BC%95%E5%8F%91%E6%8B%A5%E5%A0%B5/"><img src="/2019/07/%E8%BE%83%E5%A4%A7%E7%AE%A1%E9%81%93%E5%90%91%E8%BE%83%E5%B0%8F%E7%AE%A1%E9%81%93%E4%BC%A0%E8%BE%93%E5%BC%95%E5%8F%91%E6%8B%A5%E5%A0%B5.png"></a> 这虽然是IP网络层的事，但如果TCP基于分层原则不去管，互联网上大量主机的TCP程序便会造成网络恶性拥堵。上图中瓶颈路由器已经造成了网速下降，但如果发送方不管不顾，那么瓶颈路由器的缓冲队列填满后便会发生大量丢包，且此时RTT（报文往返时间）由于存在长队列而极高。 <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/bbr%E9%98%9F%E5%88%97%E4%B8%A2%E5%8C%85-2/"><img src="/2019/07/BBR%E9%98%9F%E5%88%97%E4%B8%A2%E5%8C%85-1.png"></a> 如上图，最好的状态是没有队列，此时RTT最低，而State2中RTT升高，但没有丢包，到State 3队列满时开始发生丢包。 TCP的拥塞控制便用于解决这个问题。在BBR出现前，拥塞控制分为四个部分：慢启动、拥塞避免、快速重传、快速恢复： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/reno%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%A4%BA%E6%84%8F/"><img src="/2019/07/Reno%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%A4%BA%E6%84%8F.jpg"></a> 慢启动在BBR中仍然保留，它的意义是在不知道连接的瓶颈带宽时，以起始较低的发送速率，以每RTT两倍的速度快速增加发送速率，直到到达一个阈值，对应上图中0-4秒。到该阈值后，进入线性提高发送速率的阶段，该阶段叫做拥塞避免，直到发生丢包，对应上图中8-11秒。丢包后，发速速率大幅下降，针对丢包使用快速重传算法重送发送，同时也使用快速恢复算法把发送速率尽量平滑的升上来。 </p>
<p> 如果瓶颈路由器的缓存特别大，那么这种以丢包作为探测依据的拥塞算法将会导致严重问题：TCP链路上长时间RTT变大，但吞吐量维持不变。 事实上，我们的传输速度在3个阶段被不同的因素限制：</p>
<ol>
<li>应用程序限制阶段，此时RTT不变，随着应用程序开始发送大文件，速率直线上升；</li>
<li>BDP限制阶段，此时RTT开始不断上升，但吞吐量不变，因为此时瓶颈路由器已经达到上限，缓冲队列正在不断增加；</li>
<li>瓶颈路由器缓冲队列限制阶段，此时开始大量丢包。<br>如下所示： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6%E3%80%81rtt%E4%B8%8E%E9%A3%9E%E8%A1%8C%E6%8A%A5%E6%96%87%E7%9A%84%E5%85%B3%E7%B3%BB-2/"><img src="/2019/07/%E4%BC%A0%E8%BE%93%E9%80%9F%E5%BA%A6%E3%80%81RTT%E4%B8%8E%E9%A3%9E%E8%A1%8C%E6%8A%A5%E6%96%87%E7%9A%84%E5%85%B3%E7%B3%BB-1.png"></a> 如CUBIC这样基于丢包的拥塞控制算法在第2条灰色竖线发生作用，这已经太晚了，更好的作用点是BDP上限开始发挥作用时，也就是第1条灰色竖线。 什么叫做BDP呢？它叫做带宽时延积，例如一条链路的带宽是100Mbps，而RTT是40ms，那么</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BDP&#x3D;100Mbps*0.04s&#x3D;4Mb&#x3D;0.5MB</span><br></pre></td></tr></table></figure>

<p>即平均每秒飞行中的报文应当是0.5MB。因此Linux的接收窗口缓存常参考此设置： <a href="/2016/01/27/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B7-tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-bgp/"><img src="/2017/01/BGP-1.jpg"></a> 第1条灰色竖线，是瓶颈路由器的缓冲队列刚刚开始积压时的节点。随着内存的不断降价，路由器设备的缓冲队列也会越来越大，CUBIC算法会造成更大的RTT时延！ 而BBR通过检测RTprop和BtlBw来实现拥塞控制。什么是RTprop呢？这是链路的物理时延，因为RTT里含有报文在路由器队列里的排队时间、ACK的延迟确认时间等。什么叫延迟确认呢？TCP每个报文必须被确认，确认动作是通过接收端发送ACK报文实现的，但由于TCP和IP头部有40个字节，如果不携带数据只为发送ACK网络效率过低，所以会让独立的ACK报文等一等，看看有没有数据发的时候顺便带给对方，或者等等看多个ACK一起发。所以，可以用下列公式表示RTT与RTprop的差别： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/rtprop%E8%AE%A1%E7%AE%971/"><img src="/2019/07/RTprop%E8%AE%A1%E7%AE%971.png"></a> RTT我们可以测量得出，RTprop呢，我们只需要找到瓶颈路由器队列为空时多次RTT测量的最小值即可： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/rtprop%E8%AE%A1%E7%AE%972/"><img src="/2019/07/RTprop%E8%AE%A1%E7%AE%972.png"></a> 而BtlBw全称是bottleneck bandwith，即瓶颈带宽，我们可以通过测量已发送但未ACK确认的飞行中字节除以飞行时间deliveryRate来测量： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/btlbw%E8%AE%A1%E7%AE%97/"><img src="/2019/07/BtlBw%E8%AE%A1%E7%AE%97.png"></a> 早在1979年Leonard Kleinrock就提出了第1条竖线是最好的拥塞控制点，但被Jeffrey M. Jaffe证明不可能实现，因为没有办法判断RTT变化到底是不是因为链路变化了，从而不同的设备瓶颈导致的，还是瓶颈路由器上的其他TCP连接的流量发生了大的变化。但我们有了RTprop和BtlBw后，当RTprop升高时我们便得到了BtlBw，这便找到第1条灰色竖线最好的拥塞控制点，也有了后续发送速率的依据。 基于BBR算法，由于瓶颈路由器的队列为空，最直接的影响就是RTT大幅下降，可以看到下图中CUBIC红色线条的RTT比BBR要高很多： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/cubic%E4%B8%8Ebbr%E7%9A%84rtt%E5%AF%B9%E6%AF%94-2/"><img src="/2019/07/CUBIC%E4%B8%8EBBR%E7%9A%84RTT%E5%AF%B9%E6%AF%94-1.png"></a> 而因为没有丢包，BBR传输速率也会有大幅提升，下图中插入的图为CDF累积概率分布函数，从CDF中可以很清晰的看到CUBIC下大部分连接的吞吐量都更低： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/bbr%E5%B8%A6%E5%AE%BD%E6%8F%90%E5%8D%87-2/"><img src="/2019/07/BBR%E5%B8%A6%E5%AE%BD%E6%8F%90%E5%8D%87-1.png"></a> 如果链路发生了切换，新的瓶颈带宽升大或者变小怎么办呢？BBR会尝试周期性的探测新的瓶颈带宽，这个周期值为1.25、0.75、1、1、1、1，如下所示： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/bbr%E8%BF%90%E8%A1%8C%E7%BB%86%E8%8A%82-2/"><img src="/2019/07/BBR%E8%BF%90%E8%A1%8C%E7%BB%86%E8%8A%82-1.png"></a> 1.25会使得BBR尝试发送更多的飞行中报文，而如果产生了队列积压，0.75则会释放队列。下图中是先以10Mbps的链路传输TCP，在第20秒网络切换到了更快的40Mbps链路，由于1.25的存在BBR很快发现了更大的带宽，而第40秒又切换回了10Mbps链路，2秒内由于RTT的快速增加BBR调低了发送速率，可以看到由于有了pacing_gain周期变换BBR工作得很好。 <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E5%B8%A6%E5%AE%BD%E4%B8%8A%E5%8D%87%E5%90%8E%E5%8F%88%E4%B8%8B%E9%99%8D-2/"><img src="/2019/07/%E5%B8%A6%E5%AE%BD%E4%B8%8A%E5%8D%87%E5%90%8E%E5%8F%88%E4%B8%8B%E9%99%8D-1.png"></a> pacing_gain周期还有个优点，就是可以使多条初始速度不同的TCP链路快速的平均分享带宽，如下图所示，后启动的连接由于过高估计BDP产生队列积压，早先连接的BBR便会在数个周期内快速降低发送速率，最终由于不产生队列积压下RTT是一致的，故平衡时5条链路均分了带宽： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E5%A4%9A%E4%B8%AAbbr%E9%93%BE%E8%B7%AF%E5%BF%AB%E9%80%9F%E5%B9%B3%E5%88%86%E5%B8%A6%E5%AE%BD-2/"><img src="/2019/07/%E5%A4%9A%E4%B8%AABBR%E9%93%BE%E8%B7%AF%E5%BF%AB%E9%80%9F%E5%B9%B3%E5%88%86%E5%B8%A6%E5%AE%BD-1.png"></a> 我们再来看看慢启动阶段，下图网络是10Mbps、40ms，因此未确认的飞行字节数应为10Mbps*0.04s=0.05MB。红色线条是CUBIC算法下已发送字节数，而蓝色是ACK已确认字节数，绿色则是BBR算法下的已发送字节数。显然，最初CUBIC与BBR算法相同，在0.25秒时飞行字节数显然远超过了0.05MB字节数，大约在 0.1MB字节数也就是2倍BDP： <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E6%85%A2%E5%90%AF%E5%8A%A8%E4%B8%8B%E7%9A%84bbr%E6%8E%A2%E6%B5%8B-2/"><img src="/2019/07/%E6%85%A2%E5%90%AF%E5%8A%A8%E4%B8%8B%E7%9A%84BBR%E6%8E%A2%E6%B5%8B-1.png"></a> 大约在0.3秒时，CUBIC开始线性增加拥塞窗口，而到了0.5秒后BBR开始降低发送速率，即排空瓶颈路由器的拥塞队列，到0.75秒时飞行字节数调整到了BDP大小，这是最合适的发送速率。 当繁忙的网络出现大幅丢包时，BBR的表现也远好于CUBIC算法。下图中，丢包率从0.001%到50%时，可以看到绿色的BBR远好于红色的CUBIC。大约当丢包率到0.1%时，CUBIC由于不停的触发拥塞算法，所以吞吐量极速降到10Mbps只有原先的1/10，而BBR直到5%丢包率才出现明显的吞吐量下降。 <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E9%9A%8F%E6%9C%BA%E4%B8%A2%E5%8C%85%E4%B8%8B%E7%9A%84%E5%90%9E%E5%90%90%E9%87%8F-2/"><img src="/2019/07/%E9%9A%8F%E6%9C%BA%E4%B8%A2%E5%8C%85%E4%B8%8B%E7%9A%84%E5%90%9E%E5%90%90%E9%87%8F-1.png"></a> CUBIC造成瓶颈路由器的缓冲队列越来越满，RTT时延就会越来越大，而操作系统对三次握手的建立是有最大时间限制的，这导致建CUBIC下的网络极端拥塞时，新连接很难建立成功，如下图中RTT中位数达到 100秒时 Windows便很难建立成功新连接，而200秒时Linux/Android也无法建立成功。 <a href="/2019/08/07/%E4%B8%80%E6%96%87%E8%A7%A3%E9%87%8A%E6%B8%85%E6%A5%9Agoogle-bbr%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/%E6%96%B0%E8%BF%9E%E6%8E%A5%E5%BB%BA%E7%AB%8B%E5%9B%B0%E9%9A%BE-2/"><img src="/2019/07/%E6%96%B0%E8%BF%9E%E6%8E%A5%E5%BB%BA%E7%AB%8B%E5%9B%B0%E9%9A%BE-1.png"></a> BBR算法的伪代码如下，这里包括两个流程，收到ACK确认以及发送报文：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">function onAck(packet) </span><br><span class="line">  rtt = now - packet.sendtime </span><br><span class="line">  update_min_filter(RTpropFilter, rtt) </span><br><span class="line">  delivered += packet.size </span><br><span class="line">  delivered_time = now </span><br><span class="line">  deliveryRate = (delivered - packet.delivered) / (delivered_time - packet.delivered_time) </span><br><span class="line">  <span class="keyword">if</span> (deliveryRate &gt; BtlBwFilter.currentMax  ! packet.app_limited) </span><br><span class="line">     update_max_filter(BtlBwFilter, deliveryRate) </span><br><span class="line">  <span class="keyword">if</span> (app_limited_until &gt; <span class="number">0</span>) </span><br><span class="line">     app_limited_until = app_limited_until - packet.size</span><br></pre></td></tr></table></figure>

<p>这里的app_limited_until是在允许发送时观察是否有发送任务决定的。发送报文时伪码为：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">function send(packet) </span><br><span class="line">  bdp = BtlBwFilter.currentMax × RTpropFilter.currentMin </span><br><span class="line">  <span class="keyword">if</span> (inflight &gt;= cwnd_gain × bdp) </span><br><span class="line">     <span class="comment">// wait for ack or retransmission timeout </span></span><br><span class="line">     <span class="keyword">return</span> </span><br><span class="line">  <span class="keyword">if</span> (now &gt;= nextSendTime) </span><br><span class="line">     packet = nextPacketToSend() </span><br><span class="line">     <span class="keyword">if</span> (! packet) </span><br><span class="line">        app_limited_until = inflight </span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">     packet.app_limited = (app_limited_until &gt; <span class="number">0</span>) </span><br><span class="line">     packet.sendtime = now </span><br><span class="line">     packet.delivered = delivered </span><br><span class="line">     packet.delivered_time = delivered_time </span><br><span class="line">     ship(packet) </span><br><span class="line">     nextSendTime = now + packet.size / (pacing_gain × BtlBwFilter.currentMax) </span><br><span class="line">  timerCallbackAt(send, nextSendTime)</span><br></pre></td></tr></table></figure>

<p>pacing_gain便是决定链路速率调整的关键周期数组。 BBR算法对网络世界的拥塞控制有重大意义，尤其未来可以想见路由器的队列一定会越来越大。HTTP3放弃了TCP协议，这意味着它需要在应用层（各框架中间件）中基于BBR算法实现拥塞控制，所以，BBR算法其实离我们很近。理解BBR，我们便能更好的应对网络拥塞导致的性能问题，也会对未来的拥塞控制算法发展脉络更清晰。 我在《Web协议详解与抓包实战》第5部分课程中第15-20课对拥塞控制有更详细的介绍，详见下方课程二维码： <a href="/2019/05/06/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%87%BAweb%E5%8D%8F%E8%AE%AE%E8%BF%99%E9%97%A8%E8%AF%BE/poster-2/"><img src="/2019/05/poster.jpg"></a></p>
]]></content>
      <categories>
        <category>web</category>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>滑动窗口</tag>
        <tag>BBR</tag>
        <tag>BDP</tag>
        <tag>BtlBW</tag>
        <tag>CDF累积概率分布函数</tag>
        <tag>CUBIC</tag>
        <tag>pacing_gain</tag>
        <tag>RTprop</tag>
        <tag>RTT</tag>
        <tag>youtube</tag>
        <tag>丢包</tag>
        <tag>快速恢复</tag>
        <tag>快速重传</tag>
        <tag>慢启动</tag>
        <tag>拥塞控制</tag>
        <tag>拥塞避免</tag>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么要出web协议这门课</title>
    <url>/2019/05/06/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%87%BAweb%E5%8D%8F%E8%AE%AE%E8%BF%99%E9%97%A8%E8%AF%BE/</url>
    <content><![CDATA[<p>我们公司有定期的分享课，好几位开发部的同学–包括android原生、JS前端、python后端–要求我分享网络协议方面的知识，我做过两场培训，一个是讲TLS/SSL协议，一个是讲HTTP协议的设计原则，结果培训完大家反馈有收获，但是太难了，收获又不是很大。我总结大家学习效果不好的原因后得出： </p>
<ol>
<li>必须由浅入深，才能让团队中的新人快速成长； </li>
<li>必须系统化、体系化的讲解； </li>
<li>必须实时配合抓包讲解； </li>
<li>想要讲清楚，绝不是2、3个小时能做到的，至少要有10或者20个学时以上； <span id="more"></span>
而与极客时间团队合作了《Nginx核心知识100讲》后，我的编辑张浩老师也跟我说，订阅了课程的同学反映非常好，也希望我能再出一门课，好好讲一下在Nginx课程里简单介绍过的Web协议。因此便萌生了制作《Web协议详解与抓包实践》这门课的想法。 </li>
</ol>
<p>研发部一位前端同学跟我说：实在<strong>学不动</strong>了，框架又更新了！我对他说：你必须搞清楚框架为什么更新，框架想解决什么问题，它又是怎么解决这些问题的！互联网变化确实非常快，但是，它的设计原则却没什么变化。我们必须先去理解它的<strong>设计原则</strong>，再来看实现细节。这也是这门Web协议课的另一个制作思路。 </p>
<p>现在编程课已经从小学就开始了，而我上学那会，高中才有象征性的几节计算机课。在我看来，编程是拓展人脑计算能力的基础技能，所以，未来软件开发一定会成为全社会岗位的必备能力！这样的话，大家的学习负担就会非常重，怎么解决呢？我们需要理解，编程技术是为了解决实际问题的，而问题的本质并不经常变化，所以，<strong>我们要先学习那些不怎么变化的内容</strong>！像数据结构、算法、操作系统原理、Web协议等就是这些不怎么变化的知识点，值得我们首先花精力彻底搞懂它。这也是为什么我要出这门课的一个原因！ </p>
<p>我经常感慨，为什么中国唐宋时期如此辉煌，可是近代却饱受挫折，发展缓慢？从吴军老师那里，我了解到，这是因为中国迟迟没有诞生大学！大学的必要性在于，可以让学生系统化的学习知识，只有体系化的知识，才能在我们的大脑中建立起结构化的树状认识，便于我们记忆、输出、使用！所以，我认为碎片化学习是一种新的学习方式，它能充分利用我们的时间，但碎片化必须搭配系统化学习才能有效的达到我们的学习目的！所以，这门课的另一个制作思路，便是<strong>体系化</strong>、一步一步的向下进行，而不要有跳跃式的讲解。 </p>
<p>我现在所在的智链达还是一个典型的创业期公司，这与我之前所在的成熟期互联网公司都很不同，团队底子薄尤其需要快速成长，必须优先学习那些<strong>见效快</strong>、<strong>门槛低</strong>、可以利用<strong>碎片化</strong>时间学习的知识。所以，制作这门课程时，我特别放低了门槛，宁肯多讲些基础知识，再进入到协议的深层应用，也是出于此目的！ </p>
<p>最后，附上这门课程的目录，我希望能帮Web协议的常用知识点都覆盖到： <a href="/2019/05/06/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%87%BAweb%E5%8D%8F%E8%AE%AE%E8%BF%99%E9%97%A8%E8%AF%BE/catalog/"><img src="/2019/05/catalog.jpg"></a> 最后，订阅课程的二维码在这里： <a href="/2019/05/06/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%87%BAweb%E5%8D%8F%E8%AE%AE%E8%BF%99%E9%97%A8%E8%AF%BE/poster-2/"><img src="/2019/05/poster.jpg"></a></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>ssl</tag>
        <tag>tls</tag>
        <tag>极客时间</tag>
        <tag>session</tag>
        <tag>http</tag>
        <tag>rest</tag>
        <tag>cookie</tag>
        <tag>http/2.0</tag>
        <tag>ip</tag>
        <tag>ipv6</tag>
        <tag>web</tag>
        <tag>wireshark</tag>
        <tag>同源策略</tag>
        <tag>架构</tag>
        <tag>物联网</tag>
        <tag>编程</tag>
        <tag>网络协议</tag>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP性能极限优化</title>
    <url>/2020/01/08/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>（<a href="https://developpaper.com/tvp-wants-to-enjoy-four-new-dimensions-to-optimize-http-performance/">英文版链接</a>） 无论你在做前端、后端还是运维，HTTP都是不得不打交道的网络协议。它是最常用的应用层协议，对它的优化，既能通过降低时延带来更好的体验性，也能通过降低资源消耗带来更高的并发性。 可是，学习HTTP不久的同学，很难全面说出HTTP的所有优化点。这既有可能是你没好好准备过大厂的面试😊，也有可能你没有加入一个快速发展的项目，当产品的用户量不断翻番时，需求会倒逼着你优化HTTP协议。 这篇文章是根据我在2019年GOPS全球运维大会上海站的演讲PPT，重新提炼文字后的总结。我希望能<strong>从四个全新的维度，带你覆盖绝大部分的HTTP优化技巧</strong>。这样，即使还不需要极致方法去解决当前的性能瓶颈，也会知道优化方向在哪，当需求来临时，能够到Google上定向查阅资料。   第一个维度，是从编码效率上，更快速地把消息转换成更短的字符流。这是最直接的性能优化点。</p>
<span id="more"></span>
<h2 id="一、编码效率优化"><a href="#一、编码效率优化" class="headerlink" title="一、编码效率优化"></a><strong>一、编码效率优化</strong></h2><p>如果你对HTTP/1.1协议做过抓包分析，就会发现它是用“<strong>whitespace-delimited</strong>”方式编码的。用空格、回车来编码，是因为HTTP在诞生之初<strong>追求可读性</strong>，这样更有利于它的推广。 然而在当下，这种低效的编码方式已经严重影响性能了，所以2009年Google推出了基于二进制的SPDY协议，大幅提升了编码效率。2015年，稍做改进后它被确定为HTTP/2协议，现在50%以上的站点都在使用它。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%874-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%874.jpg"></a> 这是编码优化的大方向，包括即将推出的HTTP/3。 然而这些新技术到底是怎样提升性能的呢？那还得拆开了看，先从数据的压缩谈起。你抓包看到的是数据，它并不等于信息。数据其实是信息和冗余数据之和，而压缩技术，就是尽量地去除冗余数据。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%875-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%875.jpg"></a> </p>
<p>压缩分为无损压缩和有损压缩。针对图片、音视频，我们每天都在与有损压缩打交道。比如，当浏览器只需要缩略图时，就没有必要浪费带宽传输高清图片。而高清视频做过有损压缩后，在肉眼无法分清时，已经被压缩了上千倍。这是因为，声音、视频都可以做增量压缩。还记得曾经的VCD吗？当光盘有划痕时，整张盘都无法播放，就是因为那时的视频做了增量压缩，而且关键帧太少，导致关键帧损坏时，后面的增量帧全部无法播放了。 再来看无损压缩，你肯定用过gzip，它让http body实现了无损压缩。肉眼阅读压缩后的报文全是乱码，但接收端解压后，可以看到发送端的原文。然而，gzip的效率其实并不高，以Google推出的brotli做对比，你就知道它的缺陷了： <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%877-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%877.jpg"></a> </p>
<p>评价压缩算法时，我们重点看两个指标：压缩率和压缩速度。上图中可以看到，无论用gzip 9个压缩级别中的哪一个，它的压缩率都低于brotli（相比gzip，压缩级别它还可以配置为10），压缩速度也更慢。所以，如果可以，应该尽快更新你的gzip压缩算法了。 说完对body的压缩，再来看HTTP header的压缩。<strong>对于HTTP/1.x来说，header就是性能杀手</strong>。特别是当下cookie泛滥的时代，每次请求都要携带几个KB的头部，很浪费带宽、CPU、内存！HTTP2通过HPACK技术大幅度降低了header编码后的体积，这也是HTTP3的演进方向。 HPACK到底是怎样实现header压缩的呢？ <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%878-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%878.jpg"></a> </p>
<p>HPACK通过Huffman算法、静态表、动态表对三种header都做了压缩。比如上图中，method GET存在于静态表，用1个字节表示的整数2表达即可；user-agent Mozilla这行头部非常长，当它第2次出现时，用2个字节的整数62表示即可；即使它第1次出现时，也可以用Huffman算法压缩Mozilla这段很长的浏览器标识符，可以获得最多5/8的压缩率。 静态表中只存放最常见的header，有的只有name，有的同时包括name和value。静态表的大小很有限，目前只有61个元素。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%879-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%879.jpg"></a> </p>
<p>动态表应用了增量编码的思想，即，第1次出现时加入动态表，第2次出现的时候，传输它在动态表中的序号即可。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8710-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8710.jpg"></a> Huffman编码在winrar等压缩软件中广为使用，但HPACK中的Huffman有所不同，它使用的是静态huffman编码。即，它统计了互联网上几年内的HTTP头部，按照每个字符出现的概率，重建huffman树，这样，根据规则，出现次数最多的a、c、e或者1、2、3这些字符就只用5个bit位表示，而很少出现的字符则用几十个bit位表示。 说完header，再来看http body的编码。这里只举3个例子：1、只有几十字节的小图标，没有必要用独立的HTTP请求传输，根据RFC2397的规则，可以把它直接嵌入到HTML或者CSS文件中，而浏览器在解析时会识别出它们，就像下图中的头像： </p>
<p><a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8711-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8711.jpg"></a> 2、JS源码文件中，可能有许多小文件，这些文件中也有许多空行、注释，通过WebPack工具，先在服务器端打包为一个文件，并去除冗余的字符，编码效果也很好。 3、在表单中，可以一次传输多个元素，比如既有复选框，也可以有文件。这就减少了HTTP请求的个数。 可见，http协议从header到 body，都有许多编码手段，可以让传输的报文更短小，既节省了带宽，也降低了时延。   编码效率优化完后，再来看“信道”，这虽然是通讯领域的词汇，但用来概括HTTP的优化点非常合适，这里就借用下了。</p>
<h2 id="二、信道利用率优化"><a href="#二、信道利用率优化" class="headerlink" title="二、信道利用率优化"></a><strong>二、信道利用率优化</strong></h2><p>信道利用率包括3个优化点，第一个优化点是多路复用！高速的低层信道上，可以跑许多低速的高层信道。比如，主机上只有一块网卡，却能同时让浏览器、微信、钉钉收发消息；一个进程可以同时服务几万个TCP连接；一个TCP连接上可以同时传递多个HTTP2 STREAM消息。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8713-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8713.jpg"></a> 其次，为了让信道有更高的利用率，还得及时恢复错误。所以，TCP工作的很大一部分，都是在及时的发现丢包、乱序报文，并快速的处理它们。 最后，就像经济学里说的，资源总是稀缺的。有限的带宽下，如何公平的对待不同的连接、用户和对象呢？比如下载页面时，如果把CSS和图片以同等优先级下载就有问题，图片晚点显示没关系，但CSS没获取到页面就无法显示。另外，传输消息时，报文头报并不承载目标信息，但它又是必不可少的，如何降低这些控制信息的占比呢？ 我们先从多路复用谈起。广义上来说，多线程、协程都属于多路复用，但这里我主要指http2的stream。因为http协议被设计为client先发request，server才能回复response，这样收发消息，是没办法跑满带宽的。最有效率的方式是，发送端源源不断地发请求、接收端源源不断地发响应，这对于长肥网络尤为有效： <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8714-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8714.jpg"></a> HTTP2的stream就是这样复用连接的。我们知道，chrome对一个站点最多同时建立6个连接，而有了HTTP2后，只需要一个连接就能高效的传输页面上的数百个对象。我特意让我的个人站点<a href="http://www.taohui.pub同时支持http1和http2,下图是连接视角上http2和http1的区别./">www.taohui.pub同时支持HTTP1和HTTP2，下图是连接视角上HTTP2和HTTP1的区别。</a> <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8715-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8715.jpg"></a> 熟悉chrome Network网络面板的同学，肯定很熟悉waterfall，它可以帮助你分析HTTP请求到底慢在哪里，是请求发出的慢，还是响应接收的慢，又或者是解析得太慢了。下图还是我的站点在waterfall视角下的对比。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8716-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8716.jpg"></a> 从这两张图可以看出，HTTP2全面优于HTTP1。 再来看网络错误的恢复。在应用层，lingering_time通过延迟关闭连接来避免浏览器因RST错误收不到http response，而timeout则是用定时器及时发现错误并释放资源。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8717-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8717.jpg"></a> 在传输层，通过timestamp=1可以让TCP更精准的测量出定时器的超时时间RTO。当然，timestamp还有一个用途，就是防止长肥网络中的序列号回绕。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8718-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8718.jpg"></a> 什么是序列号回绕呢？我们知道，TCP每个报文都有序列号，它不是指报文的次序，而是已经发送的字节数。由于它是32位整数，所以最多可以处理232也就是4.2GB的飞行中报文。像上图中，当1G-2G这些报文在网络中飞行时间过长时，就会与5G-6G报文重叠，引发错误。 网络错误还有很多种，比如报文的次序也是无法保证的。打开tcp_sack可以减少乱序时的重发报文量，降低带宽消耗。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8719-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8719.jpg"></a> 用Chrome浏览器直接下载大文件时，网络不好时，一出错就得全部重传，体验很差。改用迅雷下载就快了很多。这是因为迅雷把大文件拆成很多小块，可以多线程下载，而且每个小块出错后，重新下载这一个块即可，效率很高。这个断点续传、多线程下载技术，就是HTTP的Range协议。如果你的服务是缓存，也可以使用Range协议，比如Nginx的Slice模块就做了这件事。 实际上对于网络错误恢复，最精妙的算法是拥塞控制，它可以全面提升网络性能。有同学会问，TCP不是有流量控制，为什么还会发生网络拥塞呢？这是因为，TCP链路中的各个路由器，处理能力并不互相匹配。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8720-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8720.jpg"></a> 就像上图，R1的峰值网络是700M/s，R2的峰值网络是600M/s，它们都需要通过R3才能到达R4。然而，R3的最大带宽只有1000M/s！当R1、R2中的TCP全速使用各自带宽时，就会引发R3丢包。拥塞控制就是解决丢包问题的。 自1982年TCP诞生起，就在使用传统的拥塞控制算法，它是发现丢包后再刹车减速，效果很不好。为什么呢？你可以观察下图，路由器中会有缓冲队列，当队列为空时，ping的时延最短；当队列将满时，ping的时延很大，但还未发生丢包；当队列已满时，丢包才会发生。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8721-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8721.jpg"></a> 所以，当队列出现积压时，丢包没有发生。虽然此时峰值带宽不会减少，但网络时延变大了，这是要避免的。而测量驱动的拥塞控制算法，就在队列刚出现积压这个点上开始刹车减速。在当今内存越来越便宜，队列越来越大的年代，新算法尤为有效。 当Linux内核更新到4.9版本时，原先的CUBIC拥塞控制算法就被替换为Google的BBR算法了。从下图中可以看到，当丢包率达到0.01%时，CUBIC就没法用了，而BBR并没有问题，直到丢包率达到5%时BBR的带宽才剧烈下降。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8722-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8722.jpg"></a> </p>
<p>再来看资源的平衡分配。为了公平的对待连接、用户，服务器会做限速。比如下图中的Leacky Bucket算法，它能够平滑突增的流量，更公平的分配带宽。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8723-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8723.jpg"></a> 再比如HTTP2中的优先级功能。 一个页面上有几百个对象，这些对象的重要性不同，有些之间还互相依赖。比如，有些JS文件会包含jQuery.js，如果同等对待的话，即使先下载完前者，也无法使用。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8724-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8724.jpg"></a> HTTP2允许浏览器下载对象时，根据解析规则，在stream中设置每一个对象的weight优先级（255最大，0最小）。而各代理、资源服务器都会根据优先级，分配内存和带宽，提升网络效率。 最后看下TCP的报文效率，它也会影响之上的HTTP性能。比如开启Nagle算法后，网络中的小报文数量大幅减少，考虑到40字节的报文头部，信息占比更高。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8726-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8726.jpg"></a> Cork算法与Nagle算法相似，但会更激进的控制小报文。Cork与Nagle是从发送端控制小报文，quickack则从接收端控制纯ack小报文的数量，提高信息占比。   说完相对微观一些的信道，我们再来从宏观上看第三个优化点：传输路径的优化。</p>
<h2 id="三、传输路径优化"><a href="#三、传输路径优化" class="headerlink" title="三、传输路径优化"></a><strong>三、传输路径优化</strong></h2><p>传输路径的第一个优化点是缓存，浏览器、CDN、负载均衡等组件中，缓存无处不在。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8728-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8728.jpg"></a> 缓存的基本用法你大概很熟悉了，这里我只讲过期缓存的用法。把过期缓存直接丢掉是很浪费的😊，因为“过期”是客户端的定时器决定的，并不代表资源真正失效。所以，可以把它的标识符带给源服务器，服务器会判断缓存是否仍然有效，如果有效，直接返回304和空body就可以了，非常节省带宽。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8729-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8729.jpg"></a> 对于负载均衡而言，过期缓存还能够保护源服务器，限制回源请求。当源服务器挂掉后，还能以过期缓存给用户带来降级后的服务体验，这比返回503要好得多。 传输路径的第二个优化点是慢启动。系统自带的TCP协议栈，为了避免瓶颈路由器丢包，会缓缓加大传输速度。它的起始速度就叫做初始拥塞窗口。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8732-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8732.jpg"></a> 早期的初始拥塞窗口是1个MSS（通常是576字节），后来改到3个MSS（Linux 2.5.32），在Google的建议下又改到10个MSS（Linux 3.0）。 之所以要不断提升起始窗口，是因为随着互联网的发展，网页越来越丰富，体积也越来越大。起始窗口太小，就需要更长的时间下载第一个网页，体验很差。 当然，修改起始窗口很简单，下图中是Linux下调整窗口的方法。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8733-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8733.jpg"></a> 修改起始窗口是常见的性能优化手段，比如CDN厂商都改过起始窗口，下图是主流CDN厂商2014和2017年的起始窗口大小。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8734-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8734.jpg"></a> 可见，有些窗口14年调得太大了，17年又缩回去了。所以，起始窗口并不是越大越好，它会增加瓶颈路由器的压力。 再来看传输路径上，如何从拉模式升级到推模式。比如index.html文件中包含<LINK href=”some.css”>，在HTTP/1中，必须先下载完index.html，才能去下载some.css，这是两个RTT的时间。但在HTTP/2中，服务器可以通过2个stream，同时并行传送index.html和some.css，节约了一半的时间。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8736-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8736.jpg"></a> 其实当出现丢包时，HTTP2的stream并行发送会严重退化，因为TCP的队头阻塞问题没有解决。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8737-3/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8737.jpg"></a> 上图中的SPDY与HTTP2是等价的。在红绿色这3个stream并发传输时，TCP层仍然会串行化，假设红色的stream在最先发送的，如果红色报文丢失，那么即使接收端已经收到了完整的蓝、绿stream，TCP也不会把它交给HTTP2，因为TCP自身必须保证报文有序。这样并发就没有保证了，这就是队头阻塞问题。 解决队头阻塞的办法就是绕开TCP，使用UDP协议实现HTTP，比如Google的GQUIC协议就是这么做的，B站在几年前就使用它提供服务了。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8738/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8738.jpg"></a> UDP协议自身是不能保证可靠传输的，所以GQUIC需要重新在UDP之上实现TCP曾经做过的事。这是HTTP的发展方向，所以目前HTTP3就基于GQUIC在制定标准。   最后，再从网络信息安全的角度，谈谈如何做优化。它实际上与编码、信道、传输路径都有关联，但其实又是独立的环节，所以放在最后讨论。</p>
<h2 id="四、信息安全优化"><a href="#四、信息安全优化" class="headerlink" title="四、信息安全优化"></a><strong>四、信息安全优化</strong></h2><p>互联网世界的信息安全，始于1995年的SSL3.0。到现在，许多大型网站都更新到2018年推出的TLS1.3了。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8740/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8740.jpg"></a> TLS1.2有什么问题呢？最大问题就是，它支持古老的密钥协商协议，这些协议现在已经不安全了。比如2015年出现的FREAK中间人攻击，就可以用Amazon上的虚拟机，分分钟攻陷支持老算法的服务器。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8741/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8741.jpg"></a> TLS1.3针对这一情况，取消了在当前的计算力下，数学上已经不再安全的非对称密钥协商算法。在Openssl的最新实现中，仅支持5种安全套件： <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8742/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8742.jpg"></a> TLS1.3的另一个优势是握手速度。在TLS1.2中，由于需要2个RTT才能协商完密钥，才诞生了session cache和session ticket这两个工具，它们都把协商密钥的握手降低为1个RTT。但是，这两种方式都无法应对重放攻击。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8743/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8743.jpg"></a> 而TLS1.2中的安全套件协商、ECDHE公钥交换这两步，在TLS1.3中被合并成一步，这大大提升了握手速度。 <a href="/2020/01/08/http%E6%80%A7%E8%83%BD%E6%9E%81%E9%99%90%E4%BC%98%E5%8C%96/%E5%B9%BB%E7%81%AF%E7%89%8744/"><img src="/2020/01/%E5%B9%BB%E7%81%AF%E7%89%8744.jpg"></a> 如果你还在使用TLS1.2，尽快升级到1.3吧，除了安全性，还有性能上的收益。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>HTTP的性能优化手段众多，从这四个维度出发，可以建立起树状的知识体系，囊括绝大部分的HTTP优化点。 编码效率优化包括http header和body ，它可以使传输的数据更短小紧凑，从而获得更低的时延和更高的并发。同时，好的编码算法也可以减少编解码时的CPU消耗。 信道利用率的优化，可以从多路复用、错误发现及恢复、资源分配这3个角度出发，让快速的底层信道，有效的承载慢速的应用层信道。 传输路径的优化，包括各级缓存、慢启动、消息传送模式等，它能够让消息更及时的发给浏览器，提升用户体验。 当下互联网中的信息安全，主要还是建立在TLS协议之上的。TLS1.3从安全性、性能上都有很大的提升，我们应当及时的升级。 希望这些知识能够帮助你全面、高效地优化HTTP协议！ </p>
]]></content>
      <categories>
        <category>web</category>
        <category>高并发</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>QUIC</tag>
        <tag>tls</tag>
        <tag>CDN</tag>
        <tag>http</tag>
        <tag>BBR</tag>
        <tag>CUBIC</tag>
        <tag>拥塞控制</tag>
        <tag>brotli</tag>
        <tag>cache</tag>
        <tag>Cork</tag>
        <tag>freak</tag>
        <tag>google</tag>
        <tag>gzip</tag>
        <tag>hpack</tag>
        <tag>huffman</tag>
        <tag>MSS</tag>
        <tag>Nagle</tag>
        <tag>openssl</tag>
        <tag>RTO</tag>
        <tag>spdy</tag>
        <tag>timestamp</tag>
        <tag>多路复用</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>如何快速掌握HTTP协议？</title>
    <url>/2019/05/12/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1http%E5%8D%8F%E8%AE%AE%EF%BC%9F%EF%BC%88%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%EF%BC%89/</url>
    <content><![CDATA[<p>HTTP 协议极其庞杂，它影响着浏览器、爬虫、代理服务器、防火墙、CDN、Web 容器、微服务等诸多方面，自身的规范却并不统一，所要面对的各类软件的新旧版本也同时存在于网络上。在这种情况下，如果对 HTTP 没有一个深入的理解，就很容易被各种各样的网络问题难倒。 那么，如何才能快速掌握HTTP协议呢？ 在我看来，需要从以下四个方面入手：</p>
<ol>
<li> 工欲善其事，必先利其器，首先我们先要掌握好抓包及相关的工具，这样在分析各种网络协议时也就更加得心应手。</li>
<li> 先从架构入手，搞清楚 HTTP 协议到底想解决什么问题，面临哪些非功能性的约束，又是怎样一步步发展变迁至今的。</li>
<li> 熟悉协议格式，对隧道或者正向代理下的 URI 格式、对多表述包体和不定长包体的传输格式要了解，对 DNS 的 QUESTION/ANSWER 也要了解。</li>
<li> 掌握应用场景，跨域访问与同源策略到底在纠结什么？代理服务器上的共享缓存如何精细化控制？<span id="more"></span>
先给大家分享我整理的 HTTP 学习知识图谱，你可以收藏起来，时不时地拿出来对照： <a href="http://taohui.pub/2019/05/12/%e5%a6%82%e4%bd%95%e5%bf%ab%e9%80%9f%e6%8e%8c%e6%8f%a1http%e5%8d%8f%e8%ae%ae%ef%bc%9f%ef%bc%88%e6%80%9d%e7%bb%b4%e5%af%bc%e5%9b%be%ef%bc%89/%e6%8e%8c%e6%8f%a1http/"><img src="/2019/05/%E6%8E%8C%E6%8F%A1HTTP.jpg"></a> 下面，我们来一一详述这四个方面。</li>
</ol>
<h1 id="1、用好工具"><a href="#1、用好工具" class="headerlink" title="1、用好工具"></a>1、用好工具</h1><p>学好HTTP协议，至少要用到下面4个工具：</p>
<h3 id="1-1-Chrome-Network抓包面板"><a href="#1-1-Chrome-Network抓包面板" class="headerlink" title="1.1 Chrome Network抓包面板"></a>1.1 Chrome Network抓包面板</h3><p>这个工具有4个优点：</p>
<ul>
<li>  快速分析HTTP请求</li>
<li>  便捷卸载TLS/SSL内容</li>
<li>  可协助分析页面加载性能</li>
<li>  方便分析websocket内容</li>
</ul>
<p>该工具包含5个面板，在过滤器的Filter输入栏中还支持复杂的属性过滤，在请求列表中可以看到请求的上下游，亦能看到每个请求的时间分布。 <a href="http://taohui.pub/2019/05/12/%e5%a6%82%e4%bd%95%e5%bf%ab%e9%80%9f%e6%8e%8c%e6%8f%a1http%e5%8d%8f%e8%ae%ae%ef%bc%9f%ef%bc%88%e6%80%9d%e7%bb%b4%e5%af%bc%e5%9b%be%ef%bc%89/chrome%e6%8a%93%e5%8c%85%e9%9d%a2%e6%9d%bf/"><img src="/2019/05/chrome%E6%8A%93%E5%8C%85%E9%9D%A2%E6%9D%BF.jpg"></a></p>
<h3 id="1-2-telnet"><a href="#1-2-telnet" class="headerlink" title="1.2 telnet"></a>1.2 telnet</h3><p>这个小工具主要用于构造原始的应用层协议，帮助我们理解HTTP实际在网络中传输的格式是什么样的。</p>
<h3 id="1-3-curl"><a href="#1-3-curl" class="headerlink" title="1.3 curl"></a>1.3 curl</h3><p>telnet有2个问题： 1、太过繁琐，每次要输入完整的请求。实际我们可能只是想改一下方法或者某个HEADER头部。 2、不支持HTTPS，不支持包体压缩，导致无法向某些站点发起请求。 而curl完美解决了这些问题。它也用于构造定制化的HTTP请求，并可以分析HTTP响应头部或者包体。</p>
<h3 id="1-4-Wireshark"><a href="#1-4-Wireshark" class="headerlink" title="1.4 Wireshark"></a>1.4 Wireshark</h3><p>这是学习完整Web协议栈的必备工具，我们可以在服务器端用tcpdump抓包后，在可视化的Wireshark上便捷分析。 Wireshark功能极为强大：</p>
<ul>
<li>  既支持BPF捕获过滤器，也支持分析时的显示过滤器；</li>
<li>  通过流跟踪或者会话图标，我们可以轻松的以session会话为单位进行分析;</li>
<li>  通过可配置的着色规则，但以不同的色彩帮助我们轻松找出有问题的报文；</li>
<li>  通过报文的标注及导出，以及文件的合并、时间的平移，可以轻松将多台机器上的抓到的报文放在一起分析对比；</li>
<li>  既可以通过Packet Detail中看到每层报文解析出的可读值，也能在Packet Byte中看到二进制流。</li>
<li>  支持报文统计，对大量HTTP报文的分析非常方便！</li>
</ul>
<p> </p>
<h1 id="2、理解架构"><a href="#2、理解架构" class="headerlink" title="2、理解架构"></a>2、理解架构</h1><p>要理解HTTP的架构，需要从以下4个方面入手：</p>
<h3 id="2-1-HTTP协议想解决什么问题？"><a href="#2-1-HTTP协议想解决什么问题？" class="headerlink" title="2.1 HTTP协议想解决什么问题？"></a>2.1 HTTP协议想解决什么问题？</h3><p>HTTP协议设计之初用于解决人与机器间的通讯，所谓“B/S架构”中的浏览器是我们必须考虑进的因素。 因此，HTTP协议需要传输超媒体数据（包括图片、视频等大粒度数据）。 当然，现在许多物联网中的设备也在使用HTTP协议，所以，它也在解决机器与机器间的通讯。 当然，网络爬虫也是HTTP协议要面对的问题，robots.txt这样的规范也应运而生。</p>
<h3 id="2-2-HTTP协议面对哪些非功能性约束？"><a href="#2-2-HTTP协议面对哪些非功能性约束？" class="headerlink" title="2.2 HTTP协议面对哪些非功能性约束？"></a>2.2 HTTP协议面对哪些非功能性约束？</h3><p>主要包括以下5个方面：</p>
<ul>
<li>  高可扩展性，因为它需要面对全世界用户群体以及数十年以上的寿命</li>
<li>  低门槛，既有使用门槛也包括开发门槛，JavaApplet的式微与Javascript的如日中天就是极好的例证</li>
<li>  分布式环境下的大粒度数据传输</li>
<li>  internet下无法控制的负载以及种类版本繁多的组件</li>
<li>  向前兼容，HTTP/1.1中的许多特性都需要照顾到还有仅支持HTTP/1.0的代理服务器在互联网上运行</li>
</ul>
<h3 id="2-3-遵循的架构设计方案是怎样的？"><a href="#2-3-遵循的架构设计方案是怎样的？" class="headerlink" title="2.3 遵循的架构设计方案是怎样的？"></a>2.3 遵循的架构设计方案是怎样的？</h3><p>HTTP/1.1是完全遵循REST架构设计，而REST架构主要包含以下4个子架构：</p>
<ul>
<li>  LCS：空间上分层的客户端服务器，因此我们才有了隧道、代理、网关、CDN、负载均衡等产品；</li>
<li>  CSS：无状态的客户端服务器，因此我们才有了Request/Response请求模式，才要求cookie头部或者URL不能超过4K等。</li>
<li>  COD：按需代码，即将代码从服务器移至客户端再运行，今天的前端生态都是基于此架构下而生的Javascript衍伸的。</li>
<li>  $：缓存，HTTP组件中无处没有缓存，共享缓存、私有缓存，没指明缓存时限还要预估一个缓存过期值。</li>
</ul>
<h3 id="2-4-HTTP协议特性有哪些？"><a href="#2-4-HTTP协议特性有哪些？" class="headerlink" title="2.4 HTTP协议特性有哪些？"></a>2.4 HTTP协议特性有哪些？</h3><p>首先，我们需要理解它在OSI概念模型的哪一层，它又是处在TCP/IP体系的什么位置。 其次，我们可以从上述架构中推导出它的定义：一种无状态的、应用层的、以请求/应答方式运行的协议，它使用可扩展的语义和自描述消息格式，与基于网络的超文本信息系统灵活的互动！</p>
<h1 id="3、熟悉协议格式"><a href="#3、熟悉协议格式" class="headerlink" title="3、熟悉协议格式"></a>3、熟悉协议格式</h1><p>学习HTTP协议格式时，应从以下3个方面入手：</p>
<h3 id="3-1-扩充巴科斯-瑙尔范式：ABNF元语言"><a href="#3-1-扩充巴科斯-瑙尔范式：ABNF元语言" class="headerlink" title="3.1 扩充巴科斯-瑙尔范式：ABNF元语言"></a>3.1 扩充巴科斯-瑙尔范式：ABNF元语言</h3><p>元语言可用于描述协议格式，而ABNF就严谨定义了HTTP的格式。 ABNF并不复杂，只需要我们花10分钟即可学会，它包括操作符和核心规则2大部分，这里不再列出。</p>
<h3 id="3-2-HTTP协议格式"><a href="#3-2-HTTP协议格式" class="headerlink" title="3.2 HTTP协议格式"></a>3.2 HTTP协议格式</h3><p>掌握HTTP协议格式需要理清一个树状知识图，参见本文末尾我整理的HTTP知识图谱。</p>
<h3 id="3-3-DNS协议格式"><a href="#3-3-DNS协议格式" class="headerlink" title="3.3 DNS协议格式"></a>3.3 DNS协议格式</h3><p>我们需要掌握3个方面的知识：</p>
<ul>
<li>  DNS报文是基于UDP的，它的通用格式是固定的，需要理解各字段含义</li>
<li>  Questions部分需要重点看QNAME域名是如何编码的，以及QTYPE的含义</li>
<li>  Answers部分字段更多，特别是对NAME及RDATA部分的偏移表示法要有所了解</li>
</ul>
<h1 id="4、掌握应用场景"><a href="#4、掌握应用场景" class="headerlink" title="4、掌握应用场景"></a>4、掌握应用场景</h1><p>HTTP的应用场景极其广泛，下面我列出常见的9个场景，在协议格式中提到的各方法、响应码、头部、包体编码方式都与具体场景相关。</p>
<h3 id="4-1-内容如何协商"><a href="#4-1-内容如何协商" class="headerlink" title="4.1 内容如何协商"></a>4.1 内容如何协商</h3><p>响应式协商由于RFC规范不明少有使用，而主动式协商关于语言、编码、媒体类型等是我们日常打交道的常见方式。</p>
<h3 id="4-2-FORM表单如何提交"><a href="#4-2-FORM表单如何提交" class="headerlink" title="4.2 FORM表单如何提交"></a>4.2 FORM表单如何提交</h3><p>表单提交虽然有3种编码方式，但最常用的还是boundary分隔的多表述共存于单一包体的方式，waf防火墙必须考虑如何应用这种包体内的SQL注入攻击。</p>
<h3 id="4-3-Range请求的使用"><a href="#4-3-Range请求的使用" class="headerlink" title="4.3 Range请求的使用"></a>4.3 Range请求的使用</h3><p>传输大文件所用到的断点续传和多线程下载，都需要使用Range规范，为防止多请求下载过程中服务器端更新的情况，还引入条件请求If-Range。</p>
<h3 id="4-4-Cookie与Session的设计"><a href="#4-4-Cookie与Session的设计" class="headerlink" title="4.4 Cookie与Session的设计"></a>4.4 Cookie与Session的设计</h3><p>Set-Cookie中有许多属性，既有限制有效期的expires-av、max-age-av，也有限制使用范围的domain-av、path-av，还有限制协议的secure-av或是限制使用对象的httponly-av。 这种种限制都在针对浏览器使用cookie是否安全，而同时为了便利性浏览器也支持第三方cookie，这更是为厂商搜集用户信息提供了方便。</p>
<h3 id="4-5-浏览器同源策略与跨域请求"><a href="#4-5-浏览器同源策略与跨域请求" class="headerlink" title="4.5 浏览器同源策略与跨域请求"></a>4.5 浏览器同源策略与跨域请求</h3><p>同源策略是浏览器所做的限制，如果我们直接基于网络库处理响应是不受此限制的。所以，这个同源策略的有效性非常依赖浏览器的实现。当然，同源策略中不包含防范CSRF攻击，服务器通常基于token策略解决CSRF攻击。 安全与便利是必须权衡取舍的，为了增加便利性，必须允许AJAX的跨域请求，于是CORS便诞生了。</p>
<h3 id="4-6-条件请求"><a href="#4-6-条件请求" class="headerlink" title="4.6 条件请求"></a>4.6 条件请求</h3><p>条件请求不只可应对多线程下载时的资源中途变量，也可针对多人协作的wiki系统生效，同时也能用于缓存更新。实际在Restful API设计中它大有发挥余地。</p>
<h3 id="4-7-共享缓存与私有缓存"><a href="#4-7-共享缓存与私有缓存" class="headerlink" title="4.7 共享缓存与私有缓存"></a>4.7 共享缓存与私有缓存</h3><p>当下的互联网上缓存无处不在，即使服务器上没有配置某些资源可以缓存，浏览器也在想尽办法预估出一段时间缓存资源。因为，缓存能够极大的提升用户体验、降低网络负载！能够控制缓存的HTTP头部非常多，它不只控制缓存的有效期，也在控制缓存依据的关键字。</p>
<h3 id="4-8-重定向的应用"><a href="#4-8-重定向的应用" class="headerlink" title="4.8 重定向的应用"></a>4.8 重定向的应用</h3><p>关于重定向我们需要从2个维度4个象限去理解：可更改方法 不可更改方法、可缓存不可缓存 这便引出了301、302、303、307、308这5种不同的响应状态码。</p>
<h3 id="4-9-网络爬虫"><a href="#4-9-网络爬虫" class="headerlink" title="4.9 网络爬虫"></a>4.9 网络爬虫</h3><p>爬虫无处不在，远不只久远的搜索引擎爬虫，当下在出行（例如12306火车票或者亚航）、电商、社交（新浪微博）等都广受爬虫骚扰，爬虫不只爬取信息，还模拟人类制造行为，例如许多抢票机、僵尸粉都如此。而另一方面，为了欢迎google/baidu的爬虫，又诞生了各种SEO策略及教程，还有许多利用PageRank漏洞提升关键词排名的商家在以此盈利。所以，理解爬虫的工作方式也是非常重要的。   当然，HTTP应用场景远不止这些，但彻底掌握这些场景将使我们完全理解HTTP协议中常见的方法、头部、响应码等等。</p>
<p>HTTP 协议是 Web 协议里非常重的一块，作为程序员，无论你是前后端工程师，还是运维测试，如果<strong>想面试更高的职位，或者要站在更高的角度去理解技术业务架构，并能在问题出现时快速、高效地解决问题，Web 协议一定是你绕不过去的一道坎。</strong>熟练掌握各种常用 Web 协议，可以帮你在工作中轻松应对各种网络难题。</p>
<p>基于此，我和极客时间合作推出了<strong>《Web 协议详解与抓包实战》</strong>视频课，<strong>完全从实战出发，在关键场景中结合抓包工具进行实战分析，为你深入浅出地讲解常见 Web 协议涉及到的核心知识，并彻底掌握这些协议。</strong></p>
<p><a href="http://taohui.pub/2019/05/06/%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e5%87%baweb%e5%8d%8f%e8%ae%ae%e8%bf%99%e9%97%a8%e8%af%be/poster-2/"><img src="/2019/05/poster.jpg"></a> 我的博客即将同步至腾讯云+社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite%5C_code=1zm6zm7eety8g">https://cloud.tencent.com/developer/support-plan?invite\_code=1zm6zm7eety8g</a></p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>OSI</tag>
        <tag>极客时间</tag>
        <tag>session</tag>
        <tag>http</tag>
        <tag>rest</tag>
        <tag>cookie</tag>
        <tag>web</tag>
        <tag>wireshark</tag>
        <tag>同源策略</tag>
        <tag>跨域</tag>
        <tag>缓存</tag>
        <tag>ABNF</tag>
        <tag>ajax</tag>
        <tag>BPF</tag>
        <tag>chrome</tag>
        <tag>CORS</tag>
        <tag>curl</tag>
        <tag>dns</tag>
        <tag>TCP/IP</tag>
        <tag>telnet</tag>
        <tag>抓包</tag>
        <tag>重定向</tag>
      </tags>
  </entry>
  <entry>
    <title>深入剖析HTTP3协议</title>
    <url>/2021/02/04/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90HTTP3%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>自2017年起HTTP3协议已发布了34个Draft，推出在即，Chrome、Nginx等软件都在跟进实现最新的草案。本文将介绍HTTP3协议规范、应用场景及实现原理。</p>
<p>2015年HTTP2协议正式推出后，已经有接近一半的互联网站点在使用它：<br> <img src="/images/http/http2%E7%AB%99%E7%82%B9%E4%BD%BF%E7%94%A8%E7%8E%87_20200824.png"><br>（图片来自<a href="https://w3techs.com/technologies/details/ce-http2%EF%BC%89">https://w3techs.com/technologies/details/ce-http2）</a><br>HTTP2协议虽然大幅提升了HTTP/1.1的性能，然而，基于TCP实现的HTTP2遗留下3个问题：<br> <span id="more"></span></p>
<ul>
<li>有序字节流引出的 <strong>队头阻塞</strong><a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">（Head-of-line blocking）</a>，使得HTTP2的多路复用能力大打折扣；</li>
<li><strong>TCP与TLS叠加了握手时延</strong>，建链时长还有1倍的下降空间；</li>
<li>基于TCP四元组确定一个连接，这种诞生于有线网络的设计，并不适合移动状态下的无线网络，这意味着<strong>IP地址的频繁变动会导致TCP连接、TLS会话反复握手</strong>，成本高昂。</li>
</ul>
<p>HTTP3协议解决了这些问题：</p>
<ul>
<li>HTTP3基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，解决了队头阻塞问题（包括基于QPACK解决了动态表的队头阻塞）；</li>
<li>HTTP3重新定义了TLS协议加密QUIC头部的方式，既提高了网络攻击成本，又降低了建立连接的速度（仅需1个RTT就可以同时完成建链与密钥协商）；</li>
<li>HTTP3 将Packet、QUIC Frame、HTTP3 Frame分离，实现了连接迁移功能，降低了5G环境下高速移动设备的连接维护成本。</li>
</ul>
<p>本文将会从HTTP3协议的概念讲起，从连接迁移的实现上学习HTTP3的报文格式，再围绕着队头阻塞问题来分析多路复用与QPACK动态表的实现。虽然正式的RFC规范还未推出，但最近的草案Change只有微小的变化，所以现在学习HTTP3正当其时，这将是下一代互联网最重要的基础设施。本文也是我在2020年8月3号<a href="https://www.nginx.org.cn/">Nginx中文社区</a>与QCON共同组织的<a href="https://www.bilibili.com/video/BV1hk4y1m7KE">QCON公开课</a>中部分内容的文字总结。</p>
<h1 id="HTTP3协议到底是什么？"><a href="#HTTP3协议到底是什么？" class="headerlink" title="HTTP3协议到底是什么？"></a>HTTP3协议到底是什么？</h1><p>就像HTTP2协议一样，HTTP3并没有改变HTTP1的语义。那什么是HTTP语义呢？在我看来，它包括以下3个点：</p>
<ul>
<li>请求只能由客户端发起，而服务器针对每个请求返回一个响应；</li>
<li>请求与响应都由Header、Body（可选）组成，其中请求必须含有URL和方法，而响应必须含有响应码；</li>
<li>Header中各Name对应的含义保持不变。</li>
</ul>
<p>HTTP3在保持HTTP1语义不变的情况下，更改了编码格式，这由2个原因所致：</p>
<p>首先，是为了减少编码长度。下图中HTTP1协议的编码使用了ASCII码，用空格、冒号以及\r\n作为分隔符，编码效率很低：<br><img src="/images/http/http1%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F.png"></p>
<p>HTTP2与HTTP3采用二进制、静态表、动态表与Huffman算法对HTTP Header编码，不只提供了高压缩率，还加快了发送端编码、接收端解码的速度。</p>
<p>其次，由于HTTP1协议不支持多路复用，这样高并发只能通过多开一些TCP连接实现。然而，通过TCP实现高并发有3个弊端：</p>
<ul>
<li>实现成本高。TCP是由操作系统内核实现的，如果通过多线程实现并发，并发线程数不能太多，否则线程间切换成本会以指数级上升；如果通过异步、非阻塞socket实现并发，开发效率又太低；</li>
<li>每个TCP连接与TLS会话都叠加了2-3个RTT的建链成本；</li>
<li>TCP连接有一个防止出现拥塞的慢启动流程，它会对每个TCP连接都产生减速效果。</li>
</ul>
<p>因此，HTTP2与HTTP3都在应用层实现了多路复用功能：<br> <img src="/images/http/http2_connection%E7%A4%BA%E6%84%8F.png"><br>（图片来自：<a href="https://blog.cloudflare.com/http3-the-past-present-and-future/%EF%BC%89">https://blog.cloudflare.com/http3-the-past-present-and-future/）</a></p>
<p>HTTP2协议基于TCP有序字节流实现，因此<strong>应用层的多路复用并不能做到无序地并发，在丢包场景下会出现队头阻塞问题。</strong>如下面的动态图片所示，服务器返回的绿色响应由5个TCP报文组成，而黄色响应由4个TCP报文组成，当第2个黄色报文丢失后，即使客户端接收到完整的5个绿色报文，但TCP层不会允许应用进程的read函数读取到最后5个报文，并发成了一纸空谈：<br><img src="/images/http/%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E%E7%9A%84%E5%8F%91%E7%94%9F.gif"></p>
<p>当网络繁忙时，丢包概率会很高，多路复用受到了很大限制。因此， <strong>HTTP3采用UDP作为传输层协议，重新实现了无序连接，并在此基础上通过有序的QUIC Stream提供了多路复用</strong> ，如下图所示：<br><img src="/images/http/http_123_osi_layer.png"><br>（图片来自：<a href="https://blog.cloudflare.com/http3-the-past-present-and-future/%EF%BC%89">https://blog.cloudflare.com/http3-the-past-present-and-future/）</a></p>
<p>最早这一实验性协议由Google推出，并命名为gQUIC，因此，IETF草案中仍然保留了QUIC概念，用来描述HTTP3协议的传输层和表示层。HTTP3协议规范由以下5个部分组成：</p>
<ol>
<li>QUIC层由<a href="https://tools.ietf.org/html/draft-ietf-quic-transport-29%E6%8F%8F%E8%BF%B0%EF%BC%8C%E5%AE%83%E5%AE%9A%E4%B9%89%E4%BA%86%E8%BF%9E%E6%8E%A5%E3%80%81%E6%8A%A5%E6%96%87%E7%9A%84%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E3%80%81%E6%9C%89%E5%BA%8F%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%9B">https://tools.ietf.org/html/draft-ietf-quic-transport-29描述，它定义了连接、报文的可靠传输、有序字节流的实现；</a></li>
<li>TLS协议会将QUIC层的部分报文头部暴露在明文中，方便代理服务器进行路由。<a href="https://tools.ietf.org/html/draft-ietf-quic-tls-29%E8%A7%84%E8%8C%83%E5%AE%9A%E4%B9%89%E4%BA%86QUIC%E4%B8%8ETLS%E7%9A%84%E7%BB%93%E5%90%88%E6%96%B9%E5%BC%8F%EF%BC%9B">https://tools.ietf.org/html/draft-ietf-quic-tls-29规范定义了QUIC与TLS的结合方式；</a></li>
<li>丢包检测、RTO重传定时器预估等功能由<a href="https://tools.ietf.org/html/draft-ietf-quic-recovery-29%E5%AE%9A%E4%B9%89%EF%BC%8C%E7%9B%AE%E5%89%8D%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%BD%BF%E7%94%A8%E4%BA%86%E7%B1%BB%E4%BC%BCTCP">https://tools.ietf.org/html/draft-ietf-quic-recovery-29定义，目前拥塞控制使用了类似TCP</a> New RENO的算法，未来有可能更换为基于带宽检测的算法（例如BBR）；</li>
<li>基于以上3个规范，<a href="https://tools.ietf.org/html/draft-ietf-quic-http-29%E5%AE%9A%E4%B9%89%E4%BA%86HTTP%E8%AF%AD%E4%B9%89%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%8C%E5%8C%85%E6%8B%AC%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81%E3%80%81%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E7%9A%84%E4%BC%A0%E8%BE%93%E7%AD%89%EF%BC%9B">https://tools.ietf.org/html/draft-ietf-quic-http-29定义了HTTP语义的实现，包括服务器推送、请求响应的传输等；</a></li>
<li>在HTTP2中，由HPACK规范定义HTTP头部的压缩算法。由于HPACK动态表的更新具有时序性，无法满足HTTP3的要求。在HTTP3中，QPACK定义HTTP头部的编码：<a href="https://tools.ietf.org/html/draft-ietf-quic-qpack-16%E3%80%82%E6%B3%A8%E6%84%8F%EF%BC%8C%E4%BB%A5%E4%B8%8A%E8%A7%84%E8%8C%83%E7%9A%84%E6%9C%80%E6%96%B0%E8%8D%89%E6%A1%88%E9%83%BD%E5%88%B0%E4%BA%8629%EF%BC%8C%E8%80%8CQPACK%E7%9B%B8%E5%AF%B9%E7%AE%80%E5%8D%95%EF%BC%8C%E5%AE%83%E7%9B%AE%E5%89%8D%E6%9B%B4%E6%96%B0%E5%88%B016%E3%80%82">https://tools.ietf.org/html/draft-ietf-quic-qpack-16。注意，以上规范的最新草案都到了29，而QPACK相对简单，它目前更新到16。</a></li>
</ol>
<p>自1991年诞生的HTTP/0.9协议已不再使用， <strong>但1996推出的HTTP/1.0、1999年推出的HTTP/1.1、2015年推出的HTTP2协议仍然共存于互联网中（HTTP/1.0在企业内网中还在广为使用，例如Nginx与上游的默认协议还是1.0版本），即将面世的HTTP3协议的加入，将会进一步增加协议适配的复杂度</strong> 。接下来，我们将深入HTTP3协议的细节。</p>
<h1 id="连接迁移功能是怎样实现的？"><a href="#连接迁移功能是怎样实现的？" class="headerlink" title="连接迁移功能是怎样实现的？"></a>连接迁移功能是怎样实现的？</h1><p>对于当下的HTTP1和HTTP2协议，传输请求前需要先完成耗时1个RTT的TCP三次握手、耗时1个RTT的TLS握手（TLS1.3），由于它们分属内核实现的传输层、openssl库实现的表示层，所以难以合并在一起，如下图所示：<br> <img src="/images/http/http+tls1_2%E6%8F%A1%E6%89%8B.png"><br>（图片来自：<a href="https://blog.cloudflare.com/http3-the-past-present-and-future/%EF%BC%89">https://blog.cloudflare.com/http3-the-past-present-and-future/）</a></p>
<p>在IoT时代，移动设备接入的网络会频繁变动，从而导致设备IP地址改变。<strong>对于通过四元组（源IP、源端口、目的IP、目的端口）定位连接的TCP协议来说，这意味着连接需要断开重连，所以上述2个RTT的建链时延、TCP慢启动都需要重新来过。</strong>而HTTP3的QUIC层实现了连接迁移功能，允许移动设备更换IP地址后，只要仍保有上下文信息（比如连接ID、TLS密钥等），就可以复用原连接。</p>
<p>在UDP报文头部与HTTP消息之间，共有3层头部，定义连接且实现了Connection Migration主要是在Packet Header中完成的，如下图所示：<br><img src="/images/http/http3_frame_layer.png"></p>
<p>这3层Header实现的功能各不相同：</p>
<ul>
<li>Packet Header实现了可靠的连接。当UDP报文丢失后，通过Packet Header中的Packet Number实现报文重传。连接也是通过其中的Connection ID字段定义的；</li>
<li>QUIC Frame Header在无序的Packet报文中，基于QUIC Stream概念实现了有序的字节流，这允许HTTP消息可以像在TCP连接上一样传输；</li>
<li>HTTP3 Frame Header定义了HTTP Header、Body的格式，以及服务器推送、QPACK编解码流等功能。</li>
</ul>
<p>为了进一步提升网络传输效率，Packet Header又可以细分为两种：</p>
<ul>
<li>Long Packet Header用于首次建立连接；</li>
<li>Short Packet Header用于日常传输数据。</li>
</ul>
<p>其中，Long Packet Header的格式如下图所示：<br><img src="/images/http/http3_long_packet_header.png"></p>
<p>建立连接时，连接是由服务器通过Source Connection ID字段分配的，这样，后续传输时，双方只需要固定住Destination Connection ID，就可以在客户端IP地址、端口变化后，绕过UDP四元组（与TCP四元组相同），实现连接迁移功能。下图是Short Packet Header头部的格式，这里就不再需要传输Source Connection ID字段了：<br><img src="/images/http/http3_short_packet_header.png"></p>
<p>上图中的Packet Number是每个报文独一无二的序号，基于它可以实现丢失报文的精准重发。如果你通过抓包观察Packet Header，会发现Packet Number被TLS层加密保护了，这是为了防范各类网络攻击的一种设计。下图给出了Packet Header中被加密保护的字段：<br><img src="/images/http/http3_tls_packet_header.png"></p>
<p>其中，显示为E（Encrypt）的字段表示被TLS加密过。当然，Packet Header只是描述了最基本的连接信息，其上的Stream层、HTTP消息也是被加密保护的：<br><img src="/images/http/quic_tls_header.png"></p>
<p>现在我们已经对HTTP3协议的格式有了基本的了解，接下来我们通过队头阻塞问题，看看Packet之上的QUIC Frame、HTTP3 Frame帧格式。</p>
<h1 id="Stream多路复用时的队头阻塞是怎样解决的？"><a href="#Stream多路复用时的队头阻塞是怎样解决的？" class="headerlink" title="Stream多路复用时的队头阻塞是怎样解决的？"></a>Stream多路复用时的队头阻塞是怎样解决的？</h1><p>其实，解决队头阻塞的方案，就是允许微观上有序发出的Packet报文，在接收端无序到达后也可以应用于并发请求中。比如上文的动态图中，如果丢失的黄色报文对其后发出的绿色报文不造成影响，队头阻塞问题自然就得到了解决：<br><img src="/images/http/%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E%E7%9A%84%E8%A7%A3%E5%86%B3.gif"></p>
<p>在Packet Header之上的QUIC Frame Header，定义了有序字节流Stream，而且Stream之间可以实现真正的并发。HTTP3的Stream，借鉴了HTTP2中的部分概念，所以在讨论QUIC Frame Header格式之前，我们先来看看HTTP2中的Stream长成什么样子：<br><img src="/images/http/http2_stream_frame_conn.png"><br>（图片参见：<a href="https://developers.google.com/web/fundamentals/performance/http2%EF%BC%89">https://developers.google.com/web/fundamentals/performance/http2）</a></p>
<p>每个Stream就像HTTP1中的TCP连接，它保证了承载的HEADERS frame（存放HTTP Header）、DATA frame（存放HTTP Body）是有序到达的，多个Stream之间可以并行传输。在HTTP3中，上图中的HTTP2 frame会被拆解为两层，我们先来看底层的QUIC Frame。</p>
<p>一个Packet报文中可以存放多个QUIC Frame，当然所有Frame的长度之和不能大于PMTUD（Path Maximum Transmission Unit Discovery，这是大于1200字节的值），你可以把它与IP路由中的MTU概念对照理解：<br><img src="/images/http/http3_quic_frame.png"></p>
<p>每一个Frame都有明确的类型：<br><img src="/images/http/http3_quic_frame_format.png"></p>
<p>前4个字节的Frame Type字段描述的类型不同，接下来的编码也不相同，下表是各类Frame的16进制Type值：</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Name</th>
<th>Value</th>
<th>Name</th>
</tr>
</thead>
<tbody><tr>
<td>0x00</td>
<td>PADDING</td>
<td>0x02 – 0x03</td>
<td>ACK</td>
</tr>
<tr>
<td>0x01</td>
<td>PING</td>
<td>0x08 – 0x0f</td>
<td>STREAM</td>
</tr>
<tr>
<td>0x04</td>
<td>RESET_STREAM</td>
<td>0x12-0x13</td>
<td>MAX_STREAMS</td>
</tr>
<tr>
<td>0x05</td>
<td>STOP_SENDING</td>
<td>0x16-0x17</td>
<td>STREAM_BLOCKED</td>
</tr>
<tr>
<td>0x06</td>
<td>CRYPTO</td>
<td>0x1c-0x1d</td>
<td>CONNECTION_CLOSE</td>
</tr>
<tr>
<td>0x07</td>
<td>NEW_TOKEN</td>
<td>0x11</td>
<td>MAX_STREAM_DATA</td>
</tr>
<tr>
<td>0x10</td>
<td>MAX_DATA</td>
<td>0x14</td>
<td>DATA_BLOCKED</td>
</tr>
<tr>
<td>0x15</td>
<td>STREAM_DATA_BLOCKED</td>
<td>0x1a</td>
<td>PATH_CHALLENGE</td>
</tr>
<tr>
<td>0x18</td>
<td>NEW_CONNECTION_ID</td>
<td>0x1b</td>
<td>PATH_RESPONSE</td>
</tr>
<tr>
<td>0x19</td>
<td>RETRY_CONNECTION_ID</td>
<td>0x1e</td>
<td>HANDSHAKE_DONE</td>
</tr>
</tbody></table>
<p>在上表中，我们只要分析0x08-0x0f这8种STREAM类型的Frame，就能弄明白Stream流的实现原理，自然也就清楚队头阻塞是怎样解决的了。Stream Frame用于传递HTTP消息，它的格式如下所示：<br><img src="/images/http/http3_quic_stream_frame.png"></p>
<p>可见，Stream Frame头部的3个字段，完成了多路复用、有序字节流以及报文段层面的二进制分隔功能，包括：</p>
<ul>
<li>Stream ID标识了一个有序字节流。当HTTP Body非常大，需要跨越多个Packet时，只要在每个Stream Frame中含有同样的Stream ID，就可以传输任意长度的消息。多个并发传输的HTTP消息，通过不同的Stream ID加以区别；</li>
<li>消息序列化后的“有序”特性，是通过Offset字段完成的，它类似于TCP协议中的Sequence序号，用于实现Stream内多个Frame间的累计确认功能；</li>
<li>Length指明了Frame数据的长度。</li>
</ul>
<p>你可能会奇怪，为什么会有8种Stream Frame呢？这是因为0x08-0x0f 这8种类型其实是由3个二进制位组成，它们实现了以下3 标志位的组合：</p>
<ul>
<li>第1位表示是否含有Offset，当它为0时，表示这是Stream中的起始Frame，这也是上图中Offset是可选字段的原因；</li>
<li>第2位表示是否含有Length字段；</li>
<li>第3位Fin，表示这是Stream中最后1个Frame，与HTTP2协议Frame帧中的FIN标志位相同。</li>
</ul>
<p>Stream数据中并不会直接存放HTTP消息，因为HTTP3还需要实现服务器推送、权重优先级设定、流量控制等功能，所以Stream Data中首先存放了HTTP3 Frame：<br><img src="/images/http/http3_frame.png"></p>
<p>其中，Length指明了HTTP消息的长度，而Type字段（请注意，低2位有特殊用途，在QPACK章节中会详细介绍）包含了以下类型：</p>
<ul>
<li>0x00：DATA帧，用于传输HTTP Body包体；</li>
<li>0x01：HEADERS帧，通过QPACK 编码，传输HTTP Header头部；</li>
<li>0x03：CANCEL_PUSH控制帧，用于取消1次服务器推送消息，通常客户端在收到PUSH_PROMISE帧后，通过它告知服务器不需要这次推送；</li>
<li>0x04：SETTINGS控制帧，设置各类通讯参数；</li>
<li>0x05：PUSH_PROMISE帧，用于服务器推送HTTP Body前，先将HTTP Header头部发给客户端，流程与HTTP2相似；</li>
<li>0x07：GOAWAY控制帧，用于关闭连接（注意，不是关闭Stream）；</li>
<li>0x0d：MAX_PUSH_ID，客户端用来限制服务器推送消息数量的控制帧。</li>
</ul>
<p>总结一下，QUIC Stream Frame定义了有序字节流，且多个Stream间的传输没有时序性要求，这样，HTTP消息基于QUIC Stream就实现了真正的多路复用，队头阻塞问题自然就被解决掉了。</p>
<h1 id="QPACK编码是如何解决队头阻塞问题的？"><a href="#QPACK编码是如何解决队头阻塞问题的？" class="headerlink" title="QPACK编码是如何解决队头阻塞问题的？"></a>QPACK编码是如何解决队头阻塞问题的？</h1><p>最后，我们再看下HTTP Header头部的编码方式，它需要面对另一种队头阻塞问题。</p>
<p>与HTTP2中的HPACK编码方式相似，HTTP3中的QPACK也采用了静态表、动态表及Huffman编码：<br><img src="/images/http/hpack%E7%A4%BA%E6%84%8F.png"><br>（图片参见：<a href="https://www.oreilly.com/content/http2-a-new-excerpt/%EF%BC%89">https://www.oreilly.com/content/http2-a-new-excerpt/）</a></p>
<p>先来看静态表的变化。在上图中，GET方法映射为数字2，这是通过客户端、服务器协议实现层的硬编码完成的。在HTTP2中，共有61个静态表项：<br><img src="/images/http/hpack%E9%9D%99%E6%80%81%E8%A1%A8.png"></p>
<p>而在QPACK中，则上升为98个静态表项，比如Nginx上的ngx_htt_v3_static_table数组所示：<br><img src="/images/http/qpack%E9%9D%99%E6%80%81%E8%A1%A8nginx.png"></p>
<p>你也可以从这里找到完整的HTTP3静态表。对于Huffman以及整数的编码，QPACK与HPACK并无多大不同，但动态表编解码方式差距很大。</p>
<p>所谓动态表，就是将未包含在静态表中的Header项，在其首次出现时加入动态表，这样后续传输时仅用1个数字表示，大大提升了编码效率。因此，动态表是天然具备时序性的，如果首次出现的请求出现了丢包，后续请求解码HPACK头部时，一定会被阻塞！</p>
<p>QPACK是如何解决队头阻塞问题的呢？事实上，QPACK将动态表的编码、解码独立在单向Stream中传输，仅当单向Stream中的动态表编码成功后，接收端才能解码双向Stream上HTTP消息里的动态表索引。</p>
<p>我们又引入了单向Stream和双向Stream概念，不要头疼，它其实很简单。单向指只有一端可以发送消息，双向则指两端都可以发送消息。还记得上一小节的QUIC Stream Frame头部吗？其中的Stream ID别有玄机，除了标识Stream外，它的低2位还可以表达以下组合：<br><img src="/images/http/quic_stream_id.png"></p>
<p>因此，当Stream ID是0、4、8、12时，这就是客户端发起的双向Stream（HTTP3不支持服务器发起双向Stream），它用于传输HTTP请求与响应。单向Stream有很多用途，所以它在数据前又多出一个Stream Type字段：<br><img src="/images/http/quic_stream_type.png"></p>
<p>Stream Type有以下取值：</p>
<ul>
<li>0x00：控制Stream，传递各类Stream控制消息；</li>
<li>0x01：服务器推送消息；</li>
<li>0x02：用于编码QPACK动态表，比如面对不属于静态表的HTTP请求头部，客户端可以通过这个Stream发送动态表编码；</li>
<li>0x03：用于通知编码端QPACK动态表的更新结果。</li>
</ul>
<p>由于HTTP3的STREAM之间是乱序传输的，因此，若先发送的编码Stream后到达，双向Stream中的QPACK头部就无法解码，此时传输HTTP消息的双向Stream就会进入Block阻塞状态（两端可以通过控制帧定义阻塞Stream的处理方式）。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>最后对本文内容做个小结。</p>
<p>基于四元组定义连接并不适用于下一代IoT网络，HTTP3创造出Connection ID概念实现了连接迁移，通过融合传输层、表示层，既缩短了握手时长，也加密了传输层中的绝大部分字段，提升了网络安全性。</p>
<p>HTTP3在Packet层保障了连接的可靠性，在QUIC Frame层实现了有序字节流，在HTTP3 Frame层实现了HTTP语义，这彻底解开了队头阻塞问题，真正实现了应用层的多路复用。</p>
<p>QPACK使用独立的单向Stream分别传输动态表编码、解码信息，这样乱序、并发传输HTTP消息的Stream既不会出现队头阻塞，也能基于时序性大幅压缩HTTP Header的体积。</p>
<p>在下一篇文章中，我将介绍如何基于Nginx搭建HTTP3 Web服务。</p>
]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>HTTP3</tag>
        <tag>HOL</tag>
        <tag>队头阻塞</tag>
        <tag>TLS</tag>
        <tag>udp</tag>
        <tag>http2</tag>
        <tag>OSI</tag>
        <tag>连接迁移</tag>
        <tag>QUIC</tag>
        <tag>HPACK</tag>
        <tag>QPACK</tag>
        <tag>静态表</tag>
      </tags>
  </entry>
  <entry>
    <title>百万并发连接挑战：wrk的高并发测试深度解析</title>
    <url>/2024/06/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%99%BE%E4%B8%87%E5%B9%B6%E5%8F%91%E8%BF%9E%E6%8E%A5%E6%8C%91%E6%88%98%EF%BC%9Awrk%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>当下性能测试已成为确保软件质量的关键环节。其中，wrk作为一款轻量级、高性能的HTTP基准测试工具，以其简洁的命令行界面和出色的性能著称。wrk通过-c参数能够模拟高并发的网络请求，帮助我们评估服务器在极端负载下的表现。如果你打算做C10K数万并发连接这个量级的测试，wrk是合适的（相比ab/jmeter等工具），然而，如果你想尝试进行数百万级别的高并发测试时，官方wrk就无能为力了。</p>
<p>首先，wrk不支持自定义源IP地址，这在需要模拟来自不同客户端的请求时尤为不便，做并发测试时TCP连接数也上不去（此时你在curl命令中验证会看到类似Cannot assign request address的错误）。其次，wrk在每个连接上预分配的内存相对较大，这在单机上尝试建立大量连接时，会导致内存资源迅速耗尽，wrk进程会因为OOM被内核杀掉（如果wrk进程突然消失，你通常可以在/var/log/messages中看到形如Out of memory的日志）。这些限制对于需要评估高性能服务的开发者来说，无疑是一个不小的障碍。</p>
<p>在接下来的内容中，我将探讨如何通过修改wrk源码解决上述问题，以期帮助读者更好地利用wrk进行极限并发测试。</p>
<span id="more"></span>
<h1 id="wrk与高并发测试挑战"><a href="#wrk与高并发测试挑战" class="headerlink" title="wrk与高并发测试挑战"></a>wrk与高并发测试挑战</h1><p>在软件工程实践中，性能测试是确保应用性能达标的核心环节。比如容量测试会评估系统的最大处理能力；压力测试会评估系统在高负载下的行为；瓶颈测试会识别高负载情况下可能影响性能的系统限制因素。本文主要关注容量测试中的并发连接/会话测试，即如何达到预定的并发连接数，并不会考虑同一时间的吞吐量、每秒新建连接数等指标。</p>
<p>wrk的核心优势在于其轻量级和高性能，它通过C语言+epoll这种异步事件驱动架构，能够在短时间内生成大量的HTTP请求，测试目标服务器的响应时间和吞吐量。wrk的设计哲学是简单至上，它提供了一个简洁的命令行界面，用户可以通过-c参数指定并发线程数、-d指定请求持续时间、-t指定使用线程数等，快速启动测试，并在SSL测试中自动忽略不合法证书（相当于curl命令加入了-k参数）。</p>
<p>做C10M并发测试时，有一个必然的限制条件：测试目标通常集中在一个业务上，这就意味着业务监听的VIP（虚拟IP地址）和端口是固定的。在TCP连接的五元组（包括源IP、源端口、目的IP、目的端口、协议类型，如下图所示）中，协议类型、目的IP和端口由于业务需求已经确定，这限制了我们只能在源IP和源端口上寻求建立多连接的可能性。UDP会话也面临同样的问题。<br><img src="/images/tcp/TCP%E4%B8%8EUDP%E4%BA%94%E5%85%83%E7%BB%84.jpg" alt="TCP与UDP五元组"></p>
<p>即使我们通过ip或者nmcli命令建立了许多可用IP，wrk测试时也只能使用访问目的IP时主机的默认IP地址作为源IP地址。由于源IP不可配置且数量只能为1，我们只能依赖于源端口的多样性来实现并发连接。然而，端口号是一个short类型的2字节变量，其取值范围有限，即使我们放宽操作系统的端口范围限制（在Linux中可通过sysctl调整net.ipv4.ip_local_port_range），端口的数量最多也只能达到6万多个，这远远不能满足百万级并发连接的需求。</p>
<p>为了解决这一问题，我们下面探索如何通过修改官方wrk源代码的方式，扩展wrk的功能，实现大规模并发测试。</p>
<h1 id="wrk源码分析：放开默认源地址的限制"><a href="#wrk源码分析：放开默认源地址的限制" class="headerlink" title="wrk源码分析：放开默认源地址的限制"></a>wrk源码分析：放开默认源地址的限制</h1><p>wrk并不是为测试C10M级别并发而编写的，但它的基因其实是支持的。我们首先要找到wrk限制源地址的代码，也就是wrk向服务器发起TCP连接的源代码段–<a href="https://github.com/wg/wrk/blob/master/src/wrk.c">src/wrk.c</a>文件中的connect_socket函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">connect_socket</span><span class="params">(thread *thread, connection *c)</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">addrinfo</span> *<span class="title">addr</span> =</span> thread-&gt;addr;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">aeEventLoop</span> *<span class="title">loop</span> =</span> thread-&gt;loop;</span><br><span class="line">    <span class="keyword">int</span> fd, flags;</span><br><span class="line"></span><br><span class="line">    fd = socket(addr-&gt;ai_family, addr-&gt;ai_socktype, addr-&gt;ai_protocol);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (connect(fd, addr-&gt;ai_addr, addr-&gt;ai_addrlen) == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (errno != EINPROGRESS) <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见，该函数使用thread结构体中的addrinfo结构来确定目标服务器的地址信息，而源IP地址则是由系统自动选择的。如果需要自定义源地址，以便模拟来自特定IP地址的请求，可以在调用connect函数之前，使用bind函数将文件描述符（fd）绑定到指定的源地址。通过这种方式，可以控制从哪个本地IP地址和端口发起连接，从而满足特定的测试需求。</p>
<p>当然，做并发测试时并不需要指定源端口，所以将sin_port指定为0就可以继续使用操作系统分配的端口。</p>
<p>另外，究竟需要指定哪些IP作为源地址，还需要在wrk启动前做好准备，在main函数中获取这些地址后，再到connect_socket函数中使用，即可实现源地址的指定。这样，我们就绕过了高并发测试中TCP五元组的限制！</p>
<h1 id="降低每连接消耗内存"><a href="#降低每连接消耗内存" class="headerlink" title="降低每连接消耗内存"></a>降低每连接消耗内存</h1><p>要想使得wrk实现单机C10M级并发连接，还有1个问题需要克服：如何避免Out of memory问题？这个问题等价于，如何让每个测试连接使用尽量少的内存。</p>
<p>在深入探讨如何减少TCP连接所消耗的内存之前，我们必须首先理解TCP与HTTP协议在内存消耗方面的特点。wrk，作为一款专业的HTTP基准测试工具，其高效性能的实现基础在于对TCP流式消息的处理方式。wrk通过socket和系统API将TCP的流式消息缓存在内存中，仅通过指针引用来维护HTTP消息，从而显著降低了用户态进程中的内存占用。</p>
<p>然而，尽管wrk在用户态进程中对内存的管理做到了高效，但TCP和IP协议栈是由操作系统内核实现的，这意味着内核同样需要为每个TCP连接分配内存资源。内核的内存分配主要用于维护连接状态、缓冲区管理以及其它必要的网络操作，这些内存资源对于保持TCP连接的稳定性和性能至关重要。<br><img src="/images/tcp/socket%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.png" alt="socket与TCP协议栈"></p>
<p>为了减少每个连接的内存消耗，我们需要从两个层面进行考虑：</p>
<ul>
<li><p>用户态进程中的内存优化：在wrk中，找到连接缓存、收发消息的代码，根据特定的测试场景减少其大小，或者采用更高效的数据结构来减少内存分配。</p>
</li>
<li><p>内核态的内存管理：对于操作系统内核中的TCP连接内存消耗，可以通过调整内核参数来优化内存使用，例如调整TCP缓冲区的大小、优化TCP的内存分配策略等。</p>
</li>
</ul>
<p>关于内核态内存的调整，可以参见我的《高性能网络编程》系列文章，共有七篇，第7篇重点说了下内存调整：<a href="https://www.taohui.pub/2016/01/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B7-tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/">《高性能网络编程7–tcp连接的内存使用》</a></p>
<p>接下来我们重点来看wrk是如何为TCP连接分配内存的。</p>
<h1 id="wrk源码分析：每个连接的内存分配"><a href="#wrk源码分析：每个连接的内存分配" class="headerlink" title="wrk源码分析：每个连接的内存分配"></a>wrk源码分析：每个连接的内存分配</h1><p>当我们通过-c指定并发连接数时，wrk.c文件中的parse_args函数会将参数保存到cfg-&gt;connections中：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">config</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> threads;</span><br><span class="line">    <span class="keyword">uint64_t</span> connections;</span><br><span class="line">    ...</span><br><span class="line">&#125; cfg;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">parse_args</span><span class="params">(struct config *cfg, <span class="keyword">char</span> **url, struct http_parser_url *parts, <span class="keyword">char</span> **headers, <span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">while</span> ((c = getopt_long(argc, argv, <span class="string">&quot;a:t:c:d:s:H:T:R:LUBrv?&quot;</span>, longopts, <span class="literal">NULL</span>)) != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">switch</span> (c) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;t&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (scan_metric(optarg, &amp;cfg-&gt;threads)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;c&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> (scan_metric(optarg, &amp;cfg-&gt;connections)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在main函数启动wrk测试前，会根据-t指定的线程数，为每个测试线程计算好待分配的连接数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">uint64_t</span> connections = cfg.connections / cfg.threads;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后在每个线程启动的thread_main函数中，预分配好每个连接能够使用的内存：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">thread_main</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">    thread *thread = arg;</span><br><span class="line">    aeEventLoop *loop = thread-&gt;loop;</span><br><span class="line"></span><br><span class="line">    thread-&gt;cs = zcalloc(thread-&gt;connections * <span class="keyword">sizeof</span>(connection));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来是<strong>重点部分</strong>：每个连接消耗的内存预分配为sizeof(connection)大小，这到底是多大呢？我们继续看<a href="https://github.com/wg/wrk/blob/master/src/wrk.h">wrk.h</a>文件中的connection结构体：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RECVBUF  8192</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">connection</span> &#123;</span></span><br><span class="line">    thread *thread;</span><br><span class="line">    http_parser parser;</span><br><span class="line">    <span class="class"><span class="keyword">enum</span> &#123;</span></span><br><span class="line">        FIELD, VALUE</span><br><span class="line">    &#125; state;</span><br><span class="line">    <span class="keyword">int</span> fd;</span><br><span class="line">    SSL *ssl;</span><br><span class="line">    <span class="keyword">double</span> throughput;</span><br><span class="line">    <span class="keyword">double</span> catch_up_throughput;</span><br><span class="line">    <span class="keyword">uint64_t</span> complete;</span><br><span class="line">    <span class="keyword">uint64_t</span> complete_at_last_batch_start;</span><br><span class="line">    <span class="keyword">uint64_t</span> catch_up_start_time;</span><br><span class="line">    <span class="keyword">uint64_t</span> complete_at_catch_up_start;</span><br><span class="line">    <span class="keyword">uint64_t</span> thread_start;</span><br><span class="line">    <span class="keyword">uint64_t</span> start;</span><br><span class="line">    <span class="keyword">char</span> *request;</span><br><span class="line">    <span class="keyword">size_t</span> length;</span><br><span class="line">    <span class="keyword">size_t</span> written;</span><br><span class="line">    <span class="keyword">uint64_t</span> pending;</span><br><span class="line">    buffer headers;</span><br><span class="line">    buffer body;</span><br><span class="line">    <span class="keyword">char</span> buf[RECVBUF];</span><br><span class="line">    <span class="keyword">uint64_t</span> actual_latency_start;</span><br><span class="line">    <span class="keyword">bool</span> has_pending;</span><br><span class="line">    <span class="keyword">bool</span> caught_up;</span><br><span class="line">    <span class="comment">// Internal tracking numbers (used purely for debugging):</span></span><br><span class="line">    <span class="keyword">uint64_t</span> latest_should_send_time;</span><br><span class="line">    <span class="keyword">uint64_t</span> latest_expected_start;</span><br><span class="line">    <span class="keyword">uint64_t</span> latest_connect;</span><br><span class="line">    <span class="keyword">uint64_t</span> latest_write;</span><br><span class="line">&#125; connection;</span><br></pre></td></tr></table></figure>

<p>可以看到，对于发起测试的HTTP请求内容，wrk全局只保存了一份，由所有连接共享使用（参见char *request成员），而每个连接接收到的消息则各自保存在8KB大小的内存中（wrk需要分析HTTP响应结果）！也就是说，除了buf数组，connection结构体几乎不消耗多少内存（http_parser只维持了一些必要的状态）。</p>
<p>通过减小buf数组的大小（修改RECVBUF宏的值），我们可以降低每个连接所需的内存量。这种方法简单易行，因为它直接减少了每个连接在用户态进程中分配的内存空间。这不仅有助于减少总体的内存消耗，而且可以使得更多的连接能够在有限的内存资源下被建立，从而提升了并发连接的数量。</p>
<p>当然，这种方法需要仔细考虑测试场景的需求。如果缓冲区设置得过小，可能无法满足某些情况下的数据接收需求，从而影响测试的准确性。因此，合理地调整缓冲区大小需要在内存消耗和测试需求之间找到一个平衡点。</p>
<p>当然，你还可以设计更灵活的内存管理策略来进一步优化内存使用。例如，可以实施动态内存分配策略、共享缓冲区、延迟分配等，这些技术可以在保持测试准确性的同时，进一步提高内存的使用效率。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>通过对官方wrk源码的适当修改，我们能够有效地降低每个TCP连接的内存消耗，从而避免内存溢出问题，同时通过指定多个源地址扩展了TCP连接的上限。这些改动配合Linux系统内核的TCP连接内存优化，使得单机wrk测试能够达到C10M，即百万并发级别的性能测试，这为评估高性能系统在极端负载下的并发度提供了一种有效的手段。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>C10M</tag>
        <tag>高并发</tag>
        <tag>wrk</tag>
        <tag>epoll</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程2----TCP消息的发送</title>
    <url>/2016/01/25/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%91%E9%80%81/</url>
    <content><![CDATA[<p>在<a href="http://blog.csdn.net/russell_tao/article/details/9111769">上一篇</a>中，我们已经建立好的TCP连接，对应着操作系统分配的1个套接字。操作TCP协议发送数据时，面对的是数据流。通常调用诸如send或者write方法来发送数据到另一台主机，那么，调用这样的方法时，在操作系统内核中发生了什么事情呢？我们带着以下3个问题来细细分析：发送方法成功返回时，能保证TCP另一端的主机接收到吗？能保证数据已经发送到网络上了吗？套接字为阻塞或者非阻塞时，发送方法做的事情有何不同？</p>
<p>要回答上面3个问题涉及了不少知识点，我们先在TCP层面上看看，发送方法调用时内核做了哪些事。我不想去罗列内核中的数据结构、方法等，毕竟大部分应用程序开发者不需要了解这些，仅以一幅示意图粗略表示，如下：</p>
<p> <img src="/2016/01/TCP%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B-1-2-1.jpg"></p>
<p>图1 一种典型场景下发送TCP消息的流程</p>
<span id="more"></span>
<p>再详述上图10个步骤前，先要澄清几个概念：MTU、MSS、tcp_write_queue发送队列、阻塞与非阻塞套接字、拥塞窗口、滑动窗口、Nagle算法。</p>
<p>当我们调用发送方法时，会把我们代码中构造好的消息流作为参数传递。这个消息流可大可小，例如几个字节，或者几兆字节。当消息流较大时，将有可能出现分片。我们先来讨论分片问题。</p>
<p>1、MSS与TCP的分片</p>
<p>由上一篇文中可知，TCP层是第4层传输层，第3层IP网络层、第2层数据链路层具备的约束条件同样对TCP层生效。下面来看看数据链路层中的一个概念：最大传输单元MTU。</p>
<p>无论何种类型的数据链路层，都会对网络分组的长度有一个限制。例如以太网限制为1500字节，802.3限制为1492字节。当内核的IP网络层试图发送报文时，若一个报文的长度大于MTU限制，就会被分成若干个小于MTU的报文，每个报文都会有独立的IP头部。</p>
<p>看看IP头部的格式：</p>
<p>图2 IP头部格式</p>
<p>可以看到，其指定IP包总长度的是一个16位（2字节）的字段，这意味一个IP包最大可以是65535字节。</p>
<p>若TCP层在以太网中试图发送一个大于1500字节的消息，调用IP网络层方法发送消息时，IP层会自动的获取所在局域网的MTU值，并按照所在网络的MTU大小来分片。IP层同时希望这个分片对于传输层来说是透明的，接收方的IP层会根据收到的多个IP包头部，将发送方IP层分片出的IP包重组为一个消息。</p>
<p>这种IP层的分片效率是很差的，因为必须所有分片都到达才能重组成一个包，其中任何一个分片丢失了，都必须重发所有分片。所以，TCP层会试图避免IP层执行数据报分片。</p>
<p>为了避免IP层的分片，TCP协议定义了一个新的概念：最大报文段长度MSS。它定义了一个TCP连接上，一个主机期望对端主机发送单个报文的最大长度。TCP3次握手建立连接时，连接双方都要互相告知自己期望接收到的MSS大小。例如（使用tcpdump抓包）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15:05:08.230782 IP 10.7.80.57.64569 &gt; houyi-vm02.dev.sd.aliyun.com.tproxy: S 3027092051:3027092051(0) win 8192 &lt;mss 1460,nop,wscale 8,nop,nop,sackOK&gt;</span><br><span class="line">15:05:08.234267 IP houyi-vm02.dev.sd.aliyun.com.tproxy &gt; 10.7.80.57.64569: S 26006838:26006838(0) ack 3027092052 win 5840 &lt;mss 1460,nop,nop,sackOK,nop,wscale 9&gt;</span><br><span class="line">15:05:08.233320 IP 10.7.80.57.64543 &gt; houyi-vm02.dev.sd.aliyun.com.tproxy: P 78972532:78972923(391) ack 12915963 win 255</span><br></pre></td></tr></table></figure>

<p>由于例子中两台主机都在以太网内，以太网的MTU为1500，减去IP和TCP头部的长度，MSS就是1460，三次握手中，SYN包都会携带期望的MSS大小。</p>
<p>当应用层调用TCP层提供的发送方法时，内核的TCP模块在tcp_sendmsg方法里，会按照对方告知的MSS来分片，把消息流分为多个网络分组（如图1中的3个网络分组），再调用IP层的方法发送数据。</p>
<p>这个MSS就不会改变了吗？</p>
<p>会的。上文说过，MSS就是为了避免IP层分片，在建立握手时告知对方期望接收的MSS值并不一定靠得住。因为这个值是预估的，TCP连接上的两台主机若处于不同的网络中，那么，连接上可能有许多中间网络，这些网络分别具有不同的数据链路层，这样，TCP连接上有许多个MTU。特别是，若中间途径的MTU小于两台主机所在的网络MTU时，选定的MSS仍然太大了，会导致中间路由器出现IP层的分片。</p>
<p>怎样避免中间网络可能出现的分片呢？</p>
<p>通过IP头部的DF标志位，这个标志位是告诉IP报文所途经的所有IP层代码：不要对这个报文分片。如果一个IP报文太大必须要分片，则直接返回一个ICMP错误，说明必须要分片了，且待分片路由器网络接受的MTU值。这样，连接上的发送方主机就可以重新确定MSS。</p>
<p>2、发送方法返回成功后，数据一定发送到了TCP的另一端吗？</p>
<p>答案当然是否定的。解释这个问题前，先来看看TCP是如何保证可靠传输的。</p>
<p>TCP把自己要发送的数据流里的每一个字节都看成一个序号，可靠性是要求连接对端在接收到数据后，要发送ACK确认，告诉它已经接收到了多少字节的数据。也就是说，怎样确保数据一定发送成功了呢？必须等待发送数据对应序号的ACK到达，才能确保数据一定发送成功。TCP层提供的send或者write这样的方法是不会做这件事的，看看图1，它究竟做了哪些事。</p>
<p>图1中分为10步。</p>
<p>（1）应用程序试图调用send方法来发送一段较长的数据。</p>
<p>（2）内核主要通过tcp_sendmsg方法来完成。</p>
<p>（3）（4）内核真正执行报文的发送，与send方法的调用并不是同步的。即，send方法返回成功了，也不一定把IP报文都发送到网络中了。因此，需要把用户需要发送的用户态内存中的数据，拷贝到内核态内存中，不依赖于用户态内存，也使得进程可以快速释放发送数据占用的用户态内存。但这个拷贝操作并不是简单的复制，而是把待发送数据，按照MSS来划分成多个尽量达到MSS大小的分片报文段，复制到内核中的sk_buff结构来存放，同时把这些分片组成队列，放到这个TCP连接对应的tcp_write_queue发送队列中。</p>
<p>（5）内核中为这个TCP连接分配的内核缓存是有限的（/proc/sys/net/core/wmem_default）。当没有多余的内核态缓存来复制用户态的待发送数据时，就需要调用一个方法sk_stream_wait_memory来等待滑动窗口移动，释放出一些缓存出来（收到ACK后，不需要再缓存原来已经发送出的报文，因为既然已经确认对方收到，就不需要定时重发，自然就释放缓存了）。例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">wait_for_memory:  </span><br><span class="line">            <span class="keyword">if</span> (copied)  </span><br><span class="line">                tcp_push(sk, tp, flags &amp; ~MSG_MORE, mss_now, TCP_NAGLE_PUSH);  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span> ((err = sk_stream_wait_memory(sk, &amp;timeo)) != <span class="number">0</span>)  </span><br><span class="line">                <span class="keyword">goto</span> do_error;  </span><br></pre></td></tr></table></figure>

<p>这里的sk_stream_wait_memory方法接受一个参数timeo，就是等待超时的时间。这个时间是tcp_sendmsg方法刚开始就拿到的，如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">timeo = sock_sndtimeo(sk, flags &amp; MSG_DONTWAIT);  </span><br></pre></td></tr></table></figure>

<p>看看其实现：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">long</span> <span class="title">sock_sndtimeo</span><span class="params">(<span class="keyword">const</span> struct sock *sk, <span class="keyword">int</span> noblock)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> noblock ? <span class="number">0</span> : sk-&gt;sk_sndtimeo;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>也就是说，当这个套接字是阻塞套接字时，timeo就是SO_SNDTIMEO选项指定的发送超时时间。如果这个套接字是非阻塞套接字， timeo变量就会是0。</p>
<p>实际上，sk_stream_wait_memory对于非阻塞套接字会直接返回，并将 errno错误码置为EAGAIN。</p>
<p>（6）在图1的例子中，我们假定使用了阻塞套接字，且等待了足够久的时间，收到了对方的ACK，滑动窗口释放出了缓存。</p>
<p>（7）将剩下的用户态数据都组成MSS报文拷贝到内核态的sk_buff中。</p>
<p>（8）最后，调用tcp_push等方法，它最终会调用IP层的方法来发送tcp_write_queue队列中的报文。</p>
<p>注意，IP层返回时，并不一定是把报文发送了出去。</p>
<p>（9）（10）发送方法返回。</p>
<p>从图1的10个步骤中可知，无论是使用阻塞还是非阻塞套接字，发送方法成功返回时（无论全部成功或者部分成功），既不代表TCP连接的另一端主机接收到了消息，也不代表本机把消息发送到了网络上，只是说明，内核将会试图保证把消息送达对方。</p>
<p>3、Nagle算法、滑动窗口、拥塞窗口对发送方法的影响</p>
<p>图1第8步tcp_push方法做了些什么呢？先来看看主要的流程：</p>
<p><img src="/2016/01/TCP%E6%B6%88%E6%81%AF%E7%9A%84%E7%AE%80%E6%98%93%E6%B5%81%E7%A8%8B-1.jpg"></p>
<p>图3 发送TCP消息的简易流程</p>
<p>下面简单看看这几个概念：</p>
<p>（1）滑动窗口</p>
<p>滑动窗口大家都比较熟悉，就不详细介绍了。TCP连接上的双方都会通知对方自己的接收窗口大小。而对方的接收窗口大小就是自己的发送窗口大小。tcp_push在发送数据时当然需要与发送窗口打交道。发送窗口是一个时刻变化的值，随着ACK的到达会变大，随着发出新的数据包会变小。当然，最大也只能到三次握手时对方通告的窗口大小。tcp_push在发送数据时，最终会使用tcp_snd_wnd_test方法来判断当前待发送的数据，其序号是否超出了发送滑动窗口的大小，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//检查这一次要发送的报文最大序号是否超出了发送滑动窗口大小  </span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">tcp_snd_wnd_test</span><span class="params">(struct tcp_sock *tp, struct sk_buff *skb, <span class="keyword">unsigned</span> <span class="keyword">int</span> cur_mss)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">        <span class="comment">//end_seq待发送的最大序号  </span></span><br><span class="line">    u32 end_seq = TCP_SKB_CB(skb)-&gt;end_seq;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (skb-&gt;len &gt; cur_mss)  </span><br><span class="line">        end_seq = TCP_SKB_CB(skb)-&gt;seq + cur_mss;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//snd_una是已经发送过的数据中，最小的没被确认的序号；而snd_wnd就是发送窗口的大小  </span></span><br><span class="line">    <span class="keyword">return</span> !after(end_seq, tp-&gt;snd_una + tp-&gt;snd_wnd);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>（2）慢启动和拥塞窗口</p>
<p>由于两台主机间的网络可能很复杂，通过广域网时，中间的路由器转发能力可能是瓶颈。也就是说，如果一方简单的按照另一方主机三次握手时通告的滑动窗口大小来发送数据的话，可能会使得网络上的转发路由器性能雪上加霜，最终丢失更多的分组。这时，各个操作系统内核都会对TCP的发送阶段加入慢启动和拥塞避免算法。慢启动算法说白了，就是对方通告的窗口大小只表示对方接收TCP分组的能力，不表示中间网络能够处理分组的能力。所以，发送方请悠着点发，确保网络非常通畅了后，再按照对方通告窗口来敞开了发。</p>
<p>拥塞窗口就是下面的cwnd，它用来帮助慢启动的实现。连接刚建立时，拥塞窗口的大小远小于发送窗口，它实际上是一个MSS。每收到一个ACK，拥塞窗口扩大一个MSS大小，当然，拥塞窗口最大只能到对方通告的接收窗口大小。当然，为了避免指数式增长，拥塞窗口大小的增长会更慢一些，是线性的平滑的增长过程。</p>
<p>所以，在tcp_push发送消息时，还会检查拥塞窗口，飞行中的报文数要小于拥塞窗口个数，而发送数据的长度也要小于拥塞窗口的长度。</p>
<p>如下所示，首先用unsigned int tcp_cwnd_test方法检查飞行的报文数是否小于拥塞窗口个数（多少个MSS的个数）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">tcp_cwnd_test</span><span class="params">(struct tcp_sock *tp, struct sk_buff *skb)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    u32 in_flight, cwnd;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* Don&#x27;t be strict about the congestion window for the final FIN.  */</span>  </span><br><span class="line">    <span class="keyword">if</span> (TCP_SKB_CB(skb)-&gt;flags &amp; TCPCB_FLAG_FIN)  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//飞行中的数据，也就是没有ACK的字节总数  </span></span><br><span class="line">    in_flight = tcp_packets_in_flight(tp);  </span><br><span class="line">    cwnd = tp-&gt;snd_cwnd;  </span><br><span class="line">        <span class="comment">//如果拥塞窗口允许，需要返回依据拥塞窗口的大小，还能发送多少字节的数据  </span></span><br><span class="line">    <span class="keyword">if</span> (in_flight &lt; cwnd)  </span><br><span class="line">        <span class="keyword">return</span> (cwnd - in_flight);  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>再通过tcp_window_allows方法获取拥塞窗口与滑动窗口的最小长度，检查待发送的数据是否超出：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">tcp_window_allows</span><span class="params">(struct tcp_sock *tp, struct sk_buff *skb, <span class="keyword">unsigned</span> <span class="keyword">int</span> mss_now, <span class="keyword">unsigned</span> <span class="keyword">int</span> cwnd)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    u32 window, cwnd_len;  </span><br><span class="line">  </span><br><span class="line">    window = (tp-&gt;snd_una + tp-&gt;snd_wnd - TCP_SKB_CB(skb)-&gt;seq);  </span><br><span class="line">    cwnd_len = mss_now * cwnd;  </span><br><span class="line">    <span class="keyword">return</span> min(window, cwnd_len);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>（3）是否符合NAGLE算法？</p>
<p>Nagle算法的初衷是这样的：应用进程调用发送方法时，可能每次只发送小块数据，造成这台机器发送了许多小的TCP报文。对于整个网络的执行效率来说，小的TCP报文会增加网络拥塞的可能，因此，如果有可能，应该将相临的TCP报文合并成一个较大的TCP报文（当然还是小于MSS的）发送。</p>
<p>Nagle算法要求一个TCP连接上最多只能有一个发送出去还没被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。</p>
<p>内核中是通过 tcp_nagle_test方法实现该算法的。我们简单的看下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">tcp_nagle_test</span><span class="params">(struct tcp_sock *tp, struct sk_buff *skb,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 <span class="keyword">unsigned</span> <span class="keyword">int</span> cur_mss, <span class="keyword">int</span> nonagle)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="comment">//nonagle标志位设置了，返回1表示允许这个分组发送出去  </span></span><br><span class="line">    <span class="keyword">if</span> (nonagle &amp; TCP_NAGLE_PUSH)  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//如果这个分组包含了四次握手关闭连接的FIN包，也可以发送出去  </span></span><br><span class="line">    <span class="keyword">if</span> (tp-&gt;urg_mode   </span><br><span class="line">        (TCP_SKB_CB(skb)-&gt;flags &amp; TCPCB_FLAG_FIN))  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//检查Nagle算法  </span></span><br><span class="line">    <span class="keyword">if</span> (!tcp_nagle_check(tp, skb, cur_mss, nonagle))  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>再来看看tcp_nagle_check方法，它与上一个方法不同，返回0表示可以发送，返回非0则不可以，正好相反。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">tcp_nagle_check</span><span class="params">(<span class="keyword">const</span> struct tcp_sock *tp,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">const</span> struct sk_buff *skb,   </span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">unsigned</span> mss_now, <span class="keyword">int</span> nonagle)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">        <span class="comment">//先检查是否为小分组，即报文长度是否小于MSS  </span></span><br><span class="line">    <span class="keyword">return</span> (skb-&gt;len &lt; mss_now &amp;&amp;  </span><br><span class="line">        ((nonagle&amp;TCP_NAGLE_CORK)   </span><br><span class="line">        <span class="comment">//如果开启了Nagle算法  </span></span><br><span class="line">         (!nonagle &amp;&amp;  </span><br><span class="line">        <span class="comment">//若已经有小分组发出（packets_out表示“飞行”中的分组）还没有确认  </span></span><br><span class="line">          tp-&gt;packets_out &amp;&amp;  </span><br><span class="line">          tcp_minshall_check(tp))));  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>最后看看tcp_minshall_check做了些什么：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">tcp_minshall_check</span><span class="params">(<span class="keyword">const</span> struct tcp_sock *tp)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">        <span class="comment">//最后一次发送的小分组还没有被确认  </span></span><br><span class="line">    <span class="keyword">return</span> after(tp-&gt;snd_sml,tp-&gt;snd_una) &amp;&amp;  </span><br><span class="line">                <span class="comment">//将要发送的序号是要大于等于上次发送分组对应的序号  </span></span><br><span class="line">        !after(tp-&gt;snd_sml, tp-&gt;snd_nxt);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>想象一种场景，当对请求的时延非常在意且网络环境非常好的时候（例如同一个机房内），Nagle算法可以关闭，这实在也没必要。使用TCP_NODELAY套接字选项就可以关闭Nagle算法。看看setsockopt是怎么与上述方法配合工作的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">do_tcp_setsockopt</span><span class="params">(struct sock *sk, <span class="keyword">int</span> level,  </span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> optname, <span class="keyword">char</span> __user *optval, <span class="keyword">int</span> optlen)</span>  </span></span><br><span class="line"><span class="function">        ...  </span></span><br><span class="line"><span class="function">    <span class="title">switch</span> <span class="params">(optname)</span> </span>&#123;  </span><br><span class="line">        ...  </span><br><span class="line">    <span class="keyword">case</span> TCP_NODELAY:  </span><br><span class="line">        <span class="keyword">if</span> (val) &#123;  </span><br><span class="line">                        <span class="comment">//如果设置了TCP_NODELAY，则更新nonagle标志  </span></span><br><span class="line">            tp-&gt;nonagle = TCP_NAGLE_OFFTCP_NAGLE_PUSH;  </span><br><span class="line">            tcp_push_pending_frames(sk, tp);  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            tp-&gt;nonagle &amp;= ~TCP_NAGLE_OFF;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="keyword">break</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>可以看到，nonagle标志位就是这么更改的。</p>
<p>当然，调用了IP层的方法返回后，也未必就保证此时数据一定发送到网络中去了。</p>
<p>下一篇我们探讨如何接收TCP消息，以及接收到ack后内核做了些什么。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程4--TCP连接的关闭</title>
    <url>/2016/01/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B4-tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%85%B3%E9%97%AD/</url>
    <content><![CDATA[<p>TCP连接的关闭有两个方法close和shutdown，这篇文章将尽量精简的说明它们分别做了些什么。</p>
<p>为方便阅读，我们可以带着以下5个问题来阅读本文：</p>
<p>1、当socket被多进程或者多线程共享时，关闭连接时有何区别？</p>
<p>2、关连接时，若连接上有来自对端的还未处理的消息，会怎么处理？</p>
<span id="more"></span>
<p>3、关连接时，若连接上有本进程待发送却未来得及发送出的消息，又会怎么处理？</p>
<p>4、so_linger这个功能的用处在哪？</p>
<p>5、对于监听socket执行关闭，和对处于ESTABLISH这种通讯的socket执行关闭，有何区别？</p>
<p>下面分三部分进行：首先说说多线程多进程关闭连接的区别；再用一幅流程图谈谈close；最后用一幅流程图说说shutdown。</p>
<p>先不提其原理和实现，从多进程、多线程下 close和shutdown方法调用时的区别说起。</p>
<p>看看close与shutdown这两个系统调用对应的内核函数：（参见unistd.h文件）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __NR_close                               3  </span></span><br><span class="line">__SYSCALL(__NR_close, sys_close)  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __NR_shutdown                           48  </span></span><br><span class="line">__SYSCALL(__NR_shutdown, sys_shutdown)  </span><br></pre></td></tr></table></figure>

<p>但sys_close和sys_shutdown这两个系统调用最终是由tcp_close和tcp_shutdown方法来实现的，调用过程如下图所示：</p>
<p><img src="http://img.blog.csdn.net/20131026122203109?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcnVzc2VsbF90YW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"></p>
<p><img src="file:///C:/Users/maomaoxiong/AppData/Local/youdao/ynote/images/02596B447A7C4511A85B857326F18861/close%26shutdown%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8.jpg"></p>
<p>sys_shutdown与多线程和多进程都没有任何关系，而sys_close则不然，上图中可以看到，层层封装调用中有一个方法叫fput，它有一个引用计数，记录这个socket被引用了多少次。在说明多线程或者多进程调用close的区别前，先在代码上简单看下close是怎么调用的，对内核代码没兴趣的同学可以仅看fput方法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> fastcall <span class="title">fput</span><span class="params">(struct file *file)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (atomic_dec_and_test(&amp;file-&gt;f_count))<span class="comment">//检查引用计数，直到为0才会真正去关闭socket  </span></span><br><span class="line">        __fput(file);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>当这个socket的引用计数f_count不为0时，是不会触发到真正关闭TCP连接的tcp_close方法的。</p>
<p>那么，这个引用计数的意义何在呢？为了说明它，先要说道下进程与线程的区别。</p>
<p>大家知道，所谓线程其实就是“轻量级”的进程。创建进程只能是一个进程（父进程）创建另一个进程（子进程），子进程会复制父进程的资源，这里的”复制“针对不同的资源其意义是不同的，例如对内存、文件、TCP连接等。创建进程是由clone系统调用实现的，而创建线程时同样也是clone实现的，只不过clone的参数不同，其行为也很不同。这个话题是很大的，这里我们仅讨论下TCP连接。</p>
<p>在clone系统调用中，会调用方法copy_files来拷贝文件描述符（包括socket）。创建线程时，传入的flag参数中包含标志位CLONE_FILES，此时，线程将会共享父进程中的文件描述符。而创建进程时没有这个标志位，这时，会把进程打开的所有文件描述符的引用计数加1，即把file数据结构的f_count成员加1，如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">copy_files</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">long</span> clone_flags, struct task_struct * tsk)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (clone_flags &amp; CLONE_FILES) &#123;  </span><br><span class="line">        <span class="keyword">goto</span> out;<span class="comment">//创建线程  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    newf = dup_fd(oldf, &amp;error);  </span><br><span class="line">out:  </span><br><span class="line">    <span class="keyword">return</span> error;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>再看看dup_fd方法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> struct files_struct *<span class="title">dup_fd</span><span class="params">(struct files_struct *oldf, <span class="keyword">int</span> *errorp)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">for</span> (i = open_files; i != <span class="number">0</span>; i--) &#123;  </span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span> =</span> *old_fds++;  </span><br><span class="line">        <span class="keyword">if</span> (f) &#123;  </span><br><span class="line">            get_file(f);<span class="comment">//创建进程  </span></span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>get_file宏就会加引用计数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define get_file(x) atomic_inc(&amp;(x)-&gt;f_count)  </span><br></pre></td></tr></table></figure>

<p>所以，子进程会将父进程中已经建立的socket加上引用计数。当进程中close一个socket时，只会减少引用计数，仅当引用计数为0时才会触发tcp_close。</p>
<p>到这里，对于第一个问题的close调用自然有了结论：单线程（进程）中使用close与多线程中是一致的，但这两者与多进程的行为并不一致，多进程中共享的同一个socket必须都调用了close才会真正的关闭连接。</p>
<p>而shutdown则不然，这里是没有引用计数什么事的，只要调用了就会去试图按需关闭连接。所以，调用shutdown与多线程、多进程无关。</p>
<p>下面我们首先深入探讨下close的行为，因为close比较shutdown来说要复杂许多。顺便回答其余四个问题。</p>
<p>TCP连接是一种双工的连接，何谓双工？即连接双方可以并行的发送或者接收消息，而无须顾及对方此时到底在发还是收消息。这样，关闭连接时，就存在3种情形：完全关闭连接；关闭发送消息的功能；关闭接收消息的功能。其中，后两者就叫做半关闭，由shutdown实现（所以 shutdown多出一个参数正是控制关闭发送或者关闭接收），前者由close实现。</p>
<p>TCP连接是一种可靠的连接，在这里可以这么理解：既要确认本机发出的包得到确认，又要确认收到的任何消息都已告知连接的对端。</p>
<p>以下主要从双工、可靠性这两点上理解连接的关闭。</p>
<p>TCP双工的这个特性使得连接的正常关闭需要四次握手，其含义为：主动端关闭了发送的功能；被动端认可；被动端也关闭了发送的功能；主动端认可。</p>
<p>但还存在程序异常的情形，此时，则通过异常的那端发送RST复位报文通知另一端关闭连接。</p>
<p>下图是close的主要流程：</p>
<p><img src="/2017/01/close%E4%B8%BB%E8%A6%81%E6%B5%81%E7%A8%8B-1-1.jpg"></p>
<p>这个图稍复杂，这是因为它覆盖了关闭监听句柄、关闭普通连接、关闭设置了SO_LINGER的连接这三种主要场景。</p>
<p>1）关闭监听句柄</p>
<p>先从最右边的分支说说关闭监听socket的那些事。用于listen的监听句柄也是使用close关闭，关闭这样的句柄含义当然很不同，它本身并不对应着某个TCP连接，但是，附着在它之上的却可能有半成品连接。什么意思呢？之前说过TCP是双工的，它的打开需要三次握手，三次握手也就是3个步骤，其含义为：客户端打开接收、发送的功能；服务器端认可并也打开接收、发送的功能；客户端认可。当第1、2步骤完成、第3步步骤未完成时，就会在服务器上有许多半连接，close这个操作主要是清理这些连接。</p>
<p>参照上图，close首先会移除keepalive定时器。keepalive功能常用于服务器上，防止僵死、异常退出的客户端占用服务器连接资源。移除此定时器后，若ESTABLISH状态的TCP连接在tcp_keepalive_time时间（如服务器上常配置为2小时）内没有通讯，服务器就会主动关闭连接。</p>
<p>接下来，关闭每一个半连接。如何关闭半连接？这时当然不能发FIN包，即正常的四次握手关闭连接，而是会发送RST复位标志去关闭请求。处理完所有半打开的连接close的任务就基本完成了。</p>
<p>2）关闭普通ESTABLISH状态的连接（未设置so_linger）</p>
<p>首先检查是否有接收到却未处理的消息。</p>
<p>如果close调用时存在收到远端的、没有处理的消息，这时根据close这一行为的意义，是要丢弃这些消息的。但丢弃消息后，意味着连接远端误以为发出的消息已经被本机收到处理了（因为ACK包确认过了），但实际上确是收到未处理，此时也不能使用正常的四次握手关闭，而是会向远端发送一个RST非正常复位关闭连接。这个做法的依据请参考draft-ietf-tcpimpl-prob-03.txt文档3.10节，Failure to RST on close with data pending。所以，这也要求我们程序员在关闭连接时，要确保已经接收、处理了连接上的消息。</p>
<p>如果此时没有未处理的消息，那么进入发送FIN来关闭连接的阶段。</p>
<p>这时，先看看是否有待发送的消息。前一篇已经说过，发消息时要计算滑动窗口、拥塞窗口、angle算法等，这些因素可能导致消息会延迟发送的。如果有待发送的消息，那么要尽力保证这些消息都发出去的。所以，会在最后一个报文中加入FIN标志，同时，关闭用于减少网络中小报文的angle算法，向连接对端发送消息。如果没有待发送的消息，则构造一个报文，仅含有FIN标志位，发送出去关闭连接。</p>
<p>3）使用了so_linger的连接</p>
<p>首先要澄清，为何要有so_linger这个功能？因为我们可能有强可靠性的需求，也就是说，必须确保发出的消息、FIN都被对方收到。例如，有些响应发出后调用close关闭连接，接下来就会关闭进程。如果close时发出的消息其实丢失在网络中了，那么，进程突然退出时连接上发出的RST就可能被对方收到，而且，之前丢失的消息不会有重发来保障可靠性了。</p>
<p>so_linger用来保证对方收到了close时发出的消息，即，至少需要对方通过发送ACK且到达本机。</p>
<p>怎么保证呢？等待！close会阻塞住进程，直到确认对方收到了消息再返回。然而，网络环境又得复杂的，如果对方总是不响应怎么办？所以还需要l_linger这个超时时间，控制close阻塞进程的最长时间。注意，务必慎用so_linger，它会在不经意间降低你程序中代码的执行速度（close的阻塞）。</p>
<p>所以，当这个进程设置了so_linger后，前半段依然没变化。检查是否有未读消息，若有则发RST关连接，不会触发等待。接下来检查是否有未发送的消息时与第2种情形一致，设好FIN后关闭angle算法发出。接下来，则会设置最大等待时间l_linger，然后开始将进程睡眠，直到确认对方收到后才会醒来，将控制权交还给用户进程。</p>
<p>这里需要注意，so_linger不是确保连接被四次握手关闭再使close返回，而只是保证我方发出的消息都已被对方收到。例如，若对方程序写的有问题，当它收到FIN进入CLOSE_WAIT状态，却一直不调用close发出FIN，此时，对方仍然会通过ACK确认，我方收到了ACK进入FIN_WAIT2状态，但没收到对方的FIN，我方的close调用却不会再阻塞，close直接返回，控制权交还用户进程。</p>
<p>从上图可知，so_linger还有个偏门的用法，若l_linger超时时间竟被设为0，则不会触发FIN包的发送，而是直接RST复位关闭连接。我个人认为，这种玩法确没多大用处。</p>
<p>最后做个总结。调用close时，可能导致发送RST复位关闭连接，例如有未读消息、打开so_linger但l_linger却为0、关闭监听句柄时半打开的连接。更多时会导致发FIN来四次握手关闭连接，但打开so_linger可能导致close阻塞住等待着对方的ACK表明收到了消息。</p>
<p>最后来看看较为简单的shutdown。</p>
<p><img src="/2017/01/shutdown%E4%B8%BB%E8%A6%81%E6%B5%81%E7%A8%8B-1-1-1.jpg"></p>
<p>解释下上图：</p>
<p>1）shutdown可携带一个参数，取值有3个，分别意味着：只关闭读、只关闭写、同时关闭读写。</p>
<p>对于监听句柄，如果参数为关闭写，显然没有任何意义。但关闭读从某方面来说是有意义的，例如不再接受新的连接。看看最右边蓝色分支，针对监听句柄，若参数为关闭写，则不做任何事；若为关闭读，则把端口上的半打开连接使用RST关闭，与close如出一辙。</p>
<p>2）若shutdown的是半打开的连接，则发出RST来关闭连接。</p>
<p>3）若shutdown的是正常连接，那么关闭读其实与对端是没有关系的。只要本机把接收掉的消息丢掉，其实就等价于关闭读了，并不一定非要对端关闭写的。实际上，shutdown正是这么干的。若参数中的标志位含有关闭读，只是标识下，当我们调用read等方法时这个标识就起作用了，会使进程读不到任何数据。</p>
<p>4）若参数中有标志位为关闭写，那么下面做的事与close是一致的：发出FIN包，告诉对方，本机不会再发消息了。</p>
<p>以上，就是close与shutdown的主要行为，同时也回答了本文最初的5个问题。下一篇，我们开始讨论多路复用中常见的epoll。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>so_linger</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程5--IO复用与并发编程</title>
    <url>/2016/01/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5-io%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<p>对于服务器的并发处理能力，我们需要的是：每一毫秒服务器都能及时处理这一毫秒内收到的数百个不同TCP连接上的报文，与此同时，可能服务器上还有数以十万计的最近几秒没有收发任何报文的相对不活跃连接。同时处理多个并行发生事件的连接，简称为并发；同时处理万计、十万计的连接，则是高并发。服务器的并发编程所追求的就是处理的并发连接数目无限大，同时维持着高效率使用CPU等资源，直至物理资源首先耗尽。</p>
<span id="more"></span>
<p>并发编程有很多种实现模型，最简单的就是与“线程”捆绑，1个线程处理1个连接的全部生命周期。优点：这个模型足够简单，它可以实现复杂的业务场景，同时，线程个数是可以远大于CPU个数的。然而，线程个数又不是可以无限增大的，为什么呢？因为线程什么时候执行是由操作系统内核调度算法决定的，调度算法并不会考虑某个线程可能只是为了一个连接服务的，它会做大一统的玩法：时间片到了就执行一下，哪怕这个线程一执行就会不得不继续睡眠。</p>
<p>这样反复的唤醒、睡眠线程在次数不多的情况下，是廉价的，但如果操作系统的线程总数很多时，它就是昂贵的（被放大了），因为这种技术性的调度损耗会影响到线程上执行的业务代码的时间。举个例子，这时大部分拥有不活跃连接的线程就像我们的国企，它们执行效率太低了，它总是唤醒就睡眠在做无用功，而它唤醒争到CPU资源的同时，就意味着处理活跃连接的民企线程减少获得了CPU的机会，CPU是核心竞争力，它的无效率进而影响了GDP总吞吐量。我们所追求的是并发处理数十万连接，当几千个线程出现时，系统的执行效率就已经无法满足高并发了。</p>
<p>对高并发编程，目前只有一种模型，也是本质上唯一有效的玩法。</p>
<p>从这个系列的前4篇文章可知，连接上的消息处理，可以分为两个阶段：等待消息准备好、消息处理。当使用默认的阻塞套接字时（例如上面提到的1个线程捆绑处理1个连接），往往是把这两个阶段合而为一，这样操作套接字的代码所在的线程就得睡眠来等待消息准备好，这导致了高并发下线程会频繁的睡眠、唤醒，从而影响了CPU的使用效率。</p>
<p>高并发编程方法当然就是把两个阶段分开处理。即，等待消息准备好的代码段，与处理消息的代码段是分离的。当然，这也要求套接字必须是非阻塞的，否则，处理消息的代码段很容易导致条件不满足时，所在线程又进入了睡眠等待阶段。那么问题来了，等待消息准备好这个阶段怎么实现？它毕竟还是等待，这意味着线程还是要睡眠的！解决办法就是，线程主动查询，或者让1个线程为所有连接而等待！</p>
<p>这就是IO多路复用了。多路复用就是处理等待消息准备好这件事的，但它可以同时处理多个连接！它也可能“等待”，所以它也会导致线程睡眠，然而这不要紧，因为它一对多、它可以监控所有连接。这样，当我们的线程被唤醒执行时，就一定是有一些连接准备好被我们的代码执行了，这是有效率的！没有那么多个线程都在争抢处理“等待消息准备好”阶段，整个世界终于清净了！</p>
<p>多路复用有很多种实现，在linux上，2.4内核前主要是select和poll，现在主流是epoll，它们的使用方法似乎很不同，但本质是一样的。</p>
<p>效率却也不同，这也是epoll完全替代了select的原因。</p>
<p>简单的谈下epoll为何会替代select。</p>
<p>前面提到过，高并发的核心解决方案是1个线程处理所有连接的“等待消息准备好”，这一点上epoll和select是无争议的。但select预估错误了一件事，就像我们开篇所说，当数十万并发连接存在时，可能每一毫秒只有数百个活跃的连接，同时其余数十万连接在这一毫秒是非活跃的。select的使用方法是这样的：</p>
<ul>
<li>  返回的活跃连接 ==select（全部待监控的连接）</li>
</ul>
<p>什么时候会调用select方法呢？在你认为需要找出有报文到达的活跃连接时，就应该调用。所以，调用select在高并发时是会被频繁调用的。这样，这个频繁调用的方法就很有必要看看它是否有效率，因为，它的轻微效率损失都会被“频繁”二字所放大。它有效率损失吗？显而易见，全部待监控连接是数以十万计的，返回的只是数百个活跃连接，这本身就是无效率的表现。被放大后就会发现，处理并发上万个连接时，select就完全力不从心了。</p>
<p>看几个图。当并发连接为一千以下，select的执行次数不算频繁，与epoll似乎并无多少差距：</p>
<p><img src="http://img.blog.csdn.net/20131204155307437?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcnVzc2VsbF90YW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"><a href="/2016/01/27/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5-io%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E4%BD%8E%E5%B9%B6%E5%8F%91epoll%E4%B8%8Eselect/"><img src="/2016/01/%E4%BD%8E%E5%B9%B6%E5%8F%91epoll%E4%B8%8Eselect.png"></a></p>
<p>然而，并发数一旦上去，select的缺点被“执行频繁”无限放大了，且并发数越多越明显：</p>
<p><img src="http://img.blog.csdn.net/20131204155323937?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcnVzc2VsbF90YW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"><a href="/2016/01/27/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5-io%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E9%AB%98%E5%B9%B6%E5%8F%91epoll%E4%B8%8Eselect/"><img src="/2016/01/%E9%AB%98%E5%B9%B6%E5%8F%91epoll%E4%B8%8Eselect.png"></a></p>
<p>再来说说epoll是如何解决的。它很聪明的用了3个方法来实现select方法要做的事：</p>
<ul>
<li>  新建的epoll描述符==epoll_create()</li>
<li>  epoll_ctrl(epoll描述符，添加或者删除所有待监控的连接)</li>
<li>  返回的活跃连接 ==epoll_wait（ epoll描述符 ）</li>
</ul>
<p>这么做的好处主要是：分清了频繁调用和不频繁调用的操作。例如，epoll_ctrl是不太频繁调用的，而epoll_wait是非常频繁调用的。这时，epoll_wait却几乎没有入参，这比select的效率高出一大截，而且，它也不会随着并发连接的增加使得入参越发多起来，导致内核执行效率下降。</p>
<p>epoll是怎么实现的呢？其实很简单，从这3个方法就可以看出，它比select聪明的避免了每次频繁调用“哪些连接已经处在消息准备好阶段”的 epoll_wait时，是不需要把所有待监控连接传入的。这意味着，它在内核态维护了一个数据结构保存着所有待监控的连接。这个数据结构就是一棵红黑树，它的结点的增加、减少是通过epoll_ctrl来完成的。用我在《深入理解Nginx》第8章中所画的图来看，它是非常简单的：</p>
<p><img src="http://img.blog.csdn.net/20131204155348718?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcnVzc2VsbF90YW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center"><a href="/2016/01/27/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5-io%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/epoll%E5%AE%9E%E7%8E%B0/"><img src="/2016/01/epoll%E5%AE%9E%E7%8E%B0.png"></a></p>
<p><img src="file:///C:/Users/hui.taoh/AppData/Local/youdao/ynote/images/0328F5789AA44AC5AA218CC0198EEF98/clipboard.png"></p>
<p>图中左下方的红黑树由所有待监控的连接构成。左上方的链表，同是目前所有活跃的连接。于是，epoll_wait执行时只是检查左上方的链表，并返回左上方链表中的连接给用户。这样，epoll_wait的执行效率能不高吗？</p>
<p>最后，再看看epoll提供的2种玩法ET和LT，即翻译过来的边缘触发和水平触发。其实这两个中文名字倒也有些贴切。这2种使用方式针对的仍然是效率问题，只不过变成了epoll_wait返回的连接如何能够更准确些。</p>
<p>例如，我们需要监控一个连接的写缓冲区是否空闲，满足“可写”时我们就可以从用户态将响应调用write发送给客户端 。但是，或者连接可写时，我们的“响应”内容还在磁盘上呢，此时若是磁盘读取还未完成呢？肯定不能使线程阻塞的，那么就不发送响应了。但是，下一次epoll_wait时可能又把这个连接返回给你了，你还得检查下是否要处理。可能，我们的程序有另一个模块专门处理磁盘IO，它会在磁盘IO完成时再发送响应。那么，每次epoll_wait都返回这个“可写”的、却无法立刻处理的连接，是否符合用户预期呢？</p>
<p>于是，ET和LT模式就应运而生了。LT是每次满足期待状态的连接，都得在epoll_wait中返回，所以它一视同仁，都在一条水平线上。ET则不然，它倾向更精确的返回连接。在上面的例子中，连接第一次变为可写后，若是程序未向连接上写入任何数据，那么下一次epoll_wait是不会返回这个连接的。ET叫做 边缘触发，就是指，只有连接从一个状态转到另一个状态时，才会触发epoll_wait返回它。可见，ET的编程要复杂不少，至少应用程序要小心的防止epoll_wait的返回的连接出现：可写时未写数据后却期待下一次“可写”、可读时未读尽数据却期待下一次“可读”。</p>
<p>当然，从一般应用场景上它们性能是不会有什么大的差距的，ET可能的优点是，epoll_wait的调用次数会减少一些，某些场景下连接在不必要唤醒时不会被唤醒（此唤醒指epoll_wait返回）。但如果像我上面举例所说的，有时它不单纯是一个网络问题，跟应用场景相关。当然，大部分开源框架都是基于ET写的，框架嘛，它追求的是纯技术问题，当然力求尽善尽美。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>epoll</tag>
        <tag>边缘触发</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程3----TCP消息的接收</title>
    <url>/2016/01/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/</url>
    <content><![CDATA[<p>这篇文章将试图说明应用程序如何接收网络上发送过来的TCP消息流，由于篇幅所限，暂时忽略ACK报文的回复和接收窗口的滑动。</p>
<p>为了快速掌握本文所要表达的思想，我们可以带着以下问题阅读：</p>
<p>1、应用程序调用read、recv等方法时，socket套接字可以设置为阻塞或者非阻塞，这两种方式是如何工作的？</p>
<span id="more"></span>
<p>2、若socket为默认的阻塞套接字，此时recv方法传入的len参数，是表示必须超时（SO_RCVTIMEO）或者接收到len长度的消息，recv方法才会返回吗？而且，socket上可以设置一个属性叫做SO_RCVLOWAT，它会与len产生什么样的交集，又是决定recv等接收方法什么时候返回？</p>
<p>3、应用程序开始收取TCP消息，与程序所在的机器网卡上接收到网络里发来的TCP消息，这是两个独立的流程。它们之间是如何互相影响的？例如，应用程序正在收取消息时，内核通过网卡又在这条TCP连接上收到消息时，究竟是如何处理的？若应用程序没有调用read或者recv时，内核收到TCP连接上的消息后又是怎样处理的？</p>
<p>4、recv这样的接收方法还可以传入各种flags，例如MSG_WAITALL、MSG_PEEK、MSG_TRUNK等等。它们是如何工作的？</p>
<p>5、1个socket套接字可能被多个进程在使用，出现并发访问时，内核是怎么处理这种状况的？</p>
<p>6、linux的sysctl系统参数中，有类似tcp_low_latency这样的开关，默认为0或者配置为1时是如何影响TCP消息处理流程的？</p>
<p>书接上文。本文将通过三幅图讲述三种典型的接收TCP消息场景，理清内核为实现TCP消息的接收所实现的4个队列容器。当然，了解内核的实现并不是目的，而是如何使用socket接口、如何配置操作系统内核参数，才能使TCP传输消息更高效，这才是最终目的。</p>
<p>很多同学不希望被内核代码扰乱了思维，如何阅读本文呢？</p>
<p>我会在图1的步骤都介绍完了才来从代码上说明tcp_v4_rcv等主要方法。像flags参数、非阻塞套接字会产生怎样的效果我是在代码介绍中说的。然后我会介绍图2、图3，介绍它们的步骤时我会穿插一些上文没有涉及的少量代码。不喜欢了解内核代码的同学请直接看完图1的步骤后，请跳到图2、图3中，我认为这3幅图覆盖了主要的TCP接收场景，能够帮助你理清其流程。</p>
<p>接收消息时调用的系统方法要比上一篇发送TCP消息复杂许多。接收TCP消息的过程可以一分为二：首先是PC上的网卡接收到网线传来的报文，通过软中断内核拿到并且解析其为TCP报文，然后TCP模块决定如何处理这个TCP报文。其次，用户进程调用read、recv等方法获取TCP消息，则是将内核已经从网卡上收到的消息流拷贝到用户进程里的内存中。</p>
<p>第一幅图描述的场景是，TCP连接上将要收到的消息序号是S1（TCP上的每个报文都有序号，详见《TCP/IP协议详解》），此时操作系统内核依次收到了序号S1-S2的报文、S3-S4、S2-S3的报文，注意后两个包乱序了。之后，用户进程分配了一段len大小的内存用于接收TCP消息，此时，len是大于S4-S1的。另外，用户进程始终没有对这个socket设置过SO_RCVLOWAT参数，因此，接收阀值SO_RCVLOWAT使用默认值1。另外，系统参数tcp_low_latency设置为0，即从操作系统的总体效率出发，使用prequeue队列提升吞吐量。当然，由于用户进程收消息时，并没有新包来临，所以此图中prequeue队列始终为空。先不细表。</p>
<p>图1如下：</p>
<p><a href="/2016/01/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3/"><img src="/2016/01/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3.jpg"></a></p>
<p>上图中有13个步骤，应用进程使用了阻塞套接字，调用recv等方法时flag标志位为0，用户进程读取套接字时没有发生进程睡眠。内核在处理接收到的TCP报文时使用了4个队列容器（当链表理解也可），分别为receive、out_of_order、prequeue、backlog队列，本文会说明它们存在的意义。下面详细说明这13个步骤。</p>
<p>1、当网卡接收到报文并判断为TCP协议后，将会调用到内核的tcp_v4_rcv方法。此时，这个TCP连接上需要接收的下一个报文序号恰好就是S1，而这一步里，网卡上收到了S1-S2的报文，所以，tcp_v4_rcv方法会把这个报文直接插入到receive队列中。</p>
<p>注意：receive队列是允许用户进程直接读取的，它是将已经接收到的TCP报文，去除了TCP头部、排好序放入的、用户进程可以直接按序读取的队列。由于socket不在进程上下文中（也就是没有进程在读socket），由于我们需要S1序号的报文，而恰好收到了S1-S2报文，因此，它进入了receive队列。</p>
<p>2、接着，我们收到了S3-S4报文。在第1步结束后，这时我们需要收到的是S2序号，但到来的报文却是S3打头的，怎么办呢？进入out_of_order队列！从这个队列名称就可以看出来，所有乱序的报文都会暂时放在这。</p>
<p>3、仍然没有进入来读取socket，但又过来了我们期望的S2-S3报文，它会像第1步一样，直接进入receive队列。不同的时，由于此时out_of_order队列不像第1步是空的，所以，引发了接来的第4步。</p>
<p>4、每次向receive队列插入报文时都会检查out_of_order队列。由于收到S2-S3报文后，期待的序号成为了S3，这样，out_of_order队列里的唯一报文S3-S4报文将会移出本队列而插入到receive队列中（这件事由tcp_ofo_queue方法完成）。</p>
<p>5、终于有用户进程开始读取socket了。做过应用端编程的同学都知道，先要在进程里分配一块内存，接着调用read或者recv等方法，把内存的首地址和内存长度传入，再把建立好连接的socket也传入。当然，对这个socket还可以配置其属性。这里，假定没有设置任何属性，都使用默认值，因此，此时socket是阻塞式，它的SO_RCVLOWAT是默认的1。当然，recv这样的方法还会接收一个flag参数，它可以设置为MSG_WAITALL、MSG_PEEK、MSG_TRUNK等等，这里我们假定为最常用的0。进程调用了recv方法。</p>
<p>6、无论是何种接口，C库和内核经过层层封装，接收TCP消息最终一定会走到tcp_recvmsg方法。下面介绍代码细节时，它会是重点。</p>
<p>7、在tcp_recvmsg方法里，会首先锁住socket。为什么呢？因此socket是可以被多进程同时使用的，同时，内核中断也会操作它，而下面的代码都是核心的、操作数据的、有状态的代码，不可以被重入的，锁住后，再有用户进程进来时拿不到锁就要休眠在这了。内核中断看到被锁住后也会做不同的处理，参见图2、图3。</p>
<p>8、此时，第1-4步已经为receive队列里准备好了3个报文。最上面的报文是S1-S2，将它拷贝到用户态内存中。由于第5步flag参数并没有携带MSG_PEEK这样的标志位，因此，再将S1-S2报文从receive队列的头部移除，从内核态释放掉。反之，MSG_PEEK标志位会导致receive队列不会删除报文。所以，MSG_PEEK主要用于多进程读取同一套接字的情形。</p>
<p>9、如第8步，拷贝S2-S3报文到用户态内存中。当然，执行拷贝前都会检查用户态内存的剩余空间是否足以放下当前这个报文，不足以时会直接返回已经拷贝的字节数。</p>
<p>10、同上。</p>
<p>11、receive队列为空了，此时会先来检查SO_RCVLOWAT这个阀值。如果已经拷贝的字节数到现在还小于它，那么可能导致进程会休眠，等待拷贝更多的数据。第5步已经说明过了，socket套接字使用的默认的SO_RCVLOWAT，也就是1，这表明，只要读取到报文了，就认为可以返回了。</p>
<p>做完这个检查了，再检查backlog队列。backlog队列是进程正在拷贝数据时，网卡收到的报文会进这个队列。此时若backlog队列有数据，就顺带处理下。图3会覆盖这种场景。</p>
<p>12、在本图对应的场景中，backlog队列是没有数据的，已经拷贝的字节数为S4-S1，它是大于1的，因此，释放第7步里加的锁，准备返回用户态了。</p>
<p>13、用户进程代码开始执行，此时recv等方法返回的就是S4-S1，即从内核拷贝的字节数。</p>
<p>图1描述的场景是最简单的1种场景，下面我们来看看上述步骤是怎样通过内核代码实现的（以下代码为2.6.18内核代码）。</p>
<p>我们知道，linux对中断的处理是分为上半部和下半部的，这是处于系统整体效率的考虑。我们将要介绍的都是在网络软中断的下半部里，例如这个tcp_v4_rcv方法。图1中的第1-4步都是在这个方法里完成的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_v4_rcv</span><span class="params">(struct sk_buff *skb)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">        ... ...  </span><br><span class="line">    <span class="comment">//是否有进程正在使用这个套接字，将会对处理流程产生影响  </span></span><br><span class="line">        <span class="comment">//或者从代码层面上，只要在tcp_recvmsg里，执行lock_sock后只能进入else，而release_sock后会进入if  </span></span><br><span class="line">    <span class="keyword">if</span> (!sock_owned_by_user(sk)) &#123;  </span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="comment">//当 tcp_prequeue 返回0时，表示这个函数没有处理该报文  </span></span><br><span class="line">            <span class="keyword">if</span> (!tcp_prequeue(sk, skb))<span class="comment">//如果报文放在prequeue队列，即表示延后处理，不占用软中断过长时间  </span></span><br><span class="line">                ret = tcp_v4_do_rcv(sk, skb);<span class="comment">//不使用prequeue或者没有用户进程读socket时（图3进入此分支），立刻开始处理这个报文  </span></span><br><span class="line">        &#125;  </span><br><span class="line">    &#125; <span class="keyword">else</span>  </span><br><span class="line">        sk_add_backlog(sk, skb);<span class="comment">//如果进程正在操作套接字，就把skb指向的TCP报文插入到backlog队列（图3涉及此分支）  </span></span><br><span class="line">        ... ...  </span><br><span class="line">｝  </span><br></pre></td></tr></table></figure>

<p>图1第1步里，我们从网络上收到了序号为S1-S2的包。此时，没有用户进程在读取套接字，因此，sock_owned_by_user(sk)会返回0。所以，tcp_prequeue方法将得到执行。简单看看它：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">tcp_prequeue</span><span class="params">(struct sock *sk, struct sk_buff *skb)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> =</span> tcp_sk(sk);  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//检查tcp_low_latency，默认其为0，表示使用prequeue队列。tp-&gt;ucopy.task不为0，表示有进程启动了拷贝TCP消息的流程  </span></span><br><span class="line">    <span class="keyword">if</span> (!sysctl_tcp_low_latency &amp;&amp; tp-&gt;ucopy.task) &#123;  </span><br><span class="line">        <span class="comment">//到这里，通常是用户进程读数据时没读到指定大小的数据，休眠了。直接将报文插入prequeue队列的末尾，延后处理  </span></span><br><span class="line">        __skb_queue_tail(&amp;tp-&gt;ucopy.prequeue, skb);  </span><br><span class="line">        tp-&gt;ucopy.memory += skb-&gt;truesize;  </span><br><span class="line">        <span class="comment">//当然，虽然通常是延后处理，但如果TCP的接收缓冲区不够用了，就会立刻处理prequeue队列里的所有报文  </span></span><br><span class="line">        <span class="keyword">if</span> (tp-&gt;ucopy.memory &gt; sk-&gt;sk_rcvbuf) &#123;  </span><br><span class="line">            <span class="keyword">while</span> ((skb1 = __skb_dequeue(&amp;tp-&gt;ucopy.prequeue)) != <span class="literal">NULL</span>) &#123;  </span><br><span class="line">                                <span class="comment">//sk_backlog_rcv就是下文将要介绍的tcp_v4_do_rcv方法  </span></span><br><span class="line">                sk-&gt;sk_backlog_rcv(sk, skb1);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (skb_queue_len(&amp;tp-&gt;ucopy.prequeue) == <span class="number">1</span>) &#123;  </span><br><span class="line">                        <span class="comment">//prequeue里有报文了，唤醒正在休眠等待数据的进程，让进程在它的上下文中处理这个prequeue队列的报文  </span></span><br><span class="line">            wake_up_interruptible(sk-&gt;sk_sleep);  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">//prequeue没有处理  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>由于tp-&gt;ucopy.task此时是NULL，所以我们收到的第1个报文在tcp_prequeue函数里直接返回了0，因此，将由 tcp_v4_do_rcv方法处理。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_v4_do_rcv</span><span class="params">(struct sock *sk, struct sk_buff *skb)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (sk-&gt;sk_state == TCP_ESTABLISHED) &#123; <span class="comment">/* Fast path */</span>  </span><br><span class="line">        <span class="comment">//当TCP连接已经建立好时，是由tcp_rcv_established方法处理接收报文的  </span></span><br><span class="line">        <span class="keyword">if</span> (tcp_rcv_established(sk, skb, skb-&gt;h.th, skb-&gt;len))  </span><br><span class="line">            <span class="keyword">goto</span> reset;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">        ... ...  </span><br><span class="line">｝  </span><br></pre></td></tr></table></figure>

<p>tcp_rcv_established方法在图1里，主要调用tcp_data_queue方法将报文放入队列中，继续看看它又干了些什么事：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">tcp_data_queue</span><span class="params">(struct sock *sk, struct sk_buff *skb)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> =</span> tcp_sk(sk);  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//如果这个报文是待接收的报文（看seq），它有两个出路：进入receive队列，正如图1；直接拷贝到用户内存中，如图3  </span></span><br><span class="line">    <span class="keyword">if</span> (TCP_SKB_CB(skb)-&gt;seq == tp-&gt;rcv_nxt) &#123;  </span><br><span class="line">                <span class="comment">//滑动窗口外的包暂不考虑，篇幅有限，下次再细谈  </span></span><br><span class="line">        <span class="keyword">if</span> (tcp_receive_window(tp) == <span class="number">0</span>)  </span><br><span class="line">            <span class="keyword">goto</span> out_of_window;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//如果有一个进程正在读取socket，且正准备要拷贝的序号就是当前报文的seq序号  </span></span><br><span class="line">        <span class="keyword">if</span> (tp-&gt;ucopy.task == current &amp;&amp;  </span><br><span class="line">            tp-&gt;copied_seq == tp-&gt;rcv_nxt &amp;&amp; tp-&gt;ucopy.len &amp;&amp;  </span><br><span class="line">            sock_owned_by_user(sk) &amp;&amp; !tp-&gt;urg_data) &#123;  </span><br><span class="line">            <span class="comment">//直接将报文内容拷贝到用户态内存中，参见图3  </span></span><br><span class="line">            <span class="keyword">if</span> (!skb_copy_datagram_iovec(skb, <span class="number">0</span>, tp-&gt;ucopy.iov, chunk)) &#123;  </span><br><span class="line">                tp-&gt;ucopy.len -= chunk;  </span><br><span class="line">                tp-&gt;copied_seq += chunk;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> (eaten &lt;= <span class="number">0</span>) &#123;  </span><br><span class="line">queue_and_out:  </span><br><span class="line">                        <span class="comment">//如果没有能够直接拷贝到用户内存中，那么，插入receive队列吧，正如图1中的第1、3步  </span></span><br><span class="line">            __skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);  </span><br><span class="line">        &#125;  </span><br><span class="line">                <span class="comment">//更新待接收的序号，例如图1第1步中，更新为S2  </span></span><br><span class="line">        tp-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;end_seq;  </span><br><span class="line">  </span><br><span class="line">                <span class="comment">//正如图1第4步，这时会检查out_of_order队列，若它不为空，需要处理它  </span></span><br><span class="line">        <span class="keyword">if</span> (!skb_queue_empty(&amp;tp-&gt;out_of_order_queue)) &#123;  </span><br><span class="line">                        <span class="comment">//tcp_ofo_queue方法会检查out_of_order队列中的所有报文  </span></span><br><span class="line">            tcp_ofo_queue(sk);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">        ... ...  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//这个包是无序的，又在接收滑动窗口内，那么就如图1第2步，把报文插入到out_of_order队列吧  </span></span><br><span class="line">    <span class="keyword">if</span> (!skb_peek(&amp;tp-&gt;out_of_order_queue)) &#123;  </span><br><span class="line">        __skb_queue_head(&amp;tp-&gt;out_of_order_queue,skb);  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">                    ... ...  </span><br><span class="line">            __skb_append(skb1, skb, &amp;tp-&gt;out_of_order_queue);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>图1第4步时，正是通过tcp_ofo_queue方法把之前乱序的S3-S4报文插入receive队列的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">tcp_ofo_queue</span><span class="params">(struct sock *sk)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> =</span> tcp_sk(sk);  </span><br><span class="line">    __u32 dsack_high = tp-&gt;rcv_nxt;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span> *<span class="title">skb</span>;</span>  </span><br><span class="line">        <span class="comment">//遍历out_of_order队列  </span></span><br><span class="line">    <span class="keyword">while</span> ((skb = skb_peek(&amp;tp-&gt;out_of_order_queue)) != <span class="literal">NULL</span>) &#123;  </span><br><span class="line">        ... ...  </span><br><span class="line">                <span class="comment">//若这个报文可以按seq插入有序的receive队列中，则将其移出out_of_order队列  </span></span><br><span class="line">        __skb_unlink(skb, &amp;tp-&gt;out_of_order_queue);  </span><br><span class="line">                <span class="comment">//插入receive队列  </span></span><br><span class="line">        __skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);  </span><br><span class="line">                <span class="comment">//更新socket上待接收的下一个有序seq  </span></span><br><span class="line">        tp-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;end_seq;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>下面再介绍图1第6步提到的tcp_recvmsg方法。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//参数里的len就是read、recv方法里的内存长度，flags正是方法的flags参数，nonblock则是阻塞、非阻塞标志位  </span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tcp_recvmsg</span><span class="params">(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,  </span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">size_t</span> len, <span class="keyword">int</span> nonblock, <span class="keyword">int</span> flags, <span class="keyword">int</span> *addr_len)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="comment">//锁住socket，防止多进程并发访问TCP连接，告知软中断目前socket在进程上下文中  </span></span><br><span class="line">    lock_sock(sk);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//初始化errno这个错误码  </span></span><br><span class="line">    err = -ENOTCONN;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//如果socket是阻塞套接字，则取出SO_RCVTIMEO作为读超时时间；若为非阻塞，则timeo为0。下面会看到timeo是如何生效的  </span></span><br><span class="line">    timeo = sock_rcvtimeo(sk, nonblock);  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//获取下一个要拷贝的字节序号  </span></span><br><span class="line">    <span class="comment">//注意：seq的定义为u32 *seq;，它是32位指针。为何？因为下面每向用户态内存拷贝后，会更新seq的值，这时就会直接更改套接字上的copied_seq  </span></span><br><span class="line">    seq = &amp;tp-&gt;copied_seq;  </span><br><span class="line">    <span class="comment">//当flags参数有MSG_PEEK标志位时，意味着这次拷贝的内容，当再次读取socket时（比如另一个进程）还能再次读到  </span></span><br><span class="line">    <span class="keyword">if</span> (flags &amp; MSG_PEEK) &#123;  </span><br><span class="line">        <span class="comment">//所以不会更新copied_seq，当然，下面会看到也不会删除报文，不会从receive队列中移除报文  </span></span><br><span class="line">        peek_seq = tp-&gt;copied_seq;  </span><br><span class="line">        seq = &amp;peek_seq;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//获取SO_RCVLOWAT最低接收阀值，当然，target实际上是用户态内存大小len和SO_RCVLOWAT的最小值  </span></span><br><span class="line">    <span class="comment">//注意：flags参数中若携带MSG_WAITALL标志位，则意味着必须等到读取到len长度的消息才能返回，此时target只能是len  </span></span><br><span class="line">    target = sock_rcvlowat(sk, flags &amp; MSG_WAITALL, len);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//以下开始读取消息  </span></span><br><span class="line">    <span class="keyword">do</span> &#123;  </span><br><span class="line">        <span class="comment">//从receive队列取出1个报文  </span></span><br><span class="line">        skb = skb_peek(&amp;sk-&gt;sk_receive_queue);  </span><br><span class="line">        <span class="keyword">do</span> &#123;  </span><br><span class="line">            <span class="comment">//没取到退出当前循环  </span></span><br><span class="line">            <span class="keyword">if</span> (!skb)  </span><br><span class="line">                <span class="keyword">break</span>;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">            <span class="comment">//offset是待拷贝序号在当前这个报文中的偏移量，在图1、2、3中它都是0，只有因为用户内存不足以接收完1个报文时才为非0  </span></span><br><span class="line">            offset = *seq - TCP_SKB_CB(skb)-&gt;seq;  </span><br><span class="line">            <span class="comment">//有些时候，三次握手的SYN包也会携带消息内容的，此时seq是多出1的（SYN占1个序号），所以offset减1  </span></span><br><span class="line">            <span class="keyword">if</span> (skb-&gt;h.th-&gt;syn)  </span><br><span class="line">                offset--;  </span><br><span class="line">            <span class="comment">//若偏移量还有这个报文之内，则认为它需要处理  </span></span><br><span class="line">            <span class="keyword">if</span> (offset &lt; skb-&gt;len)  </span><br><span class="line">                <span class="keyword">goto</span> found_ok_skb;  </span><br><span class="line">  </span><br><span class="line">            skb = skb-&gt;next;  </span><br><span class="line">        &#125; <span class="keyword">while</span> (skb != (struct sk_buff *)&amp;sk-&gt;sk_receive_queue);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//如果receive队列为空，则检查已经拷贝的字节数，是否达到了SO_RCVLOWAT或者长度len。满足了，且backlog队列也为空，则可以返回用户态了，正如图1的第11步  </span></span><br><span class="line">        <span class="keyword">if</span> (copied &gt;= target &amp;&amp; !sk-&gt;sk_backlog.tail)  </span><br><span class="line">            <span class="keyword">break</span>;  </span><br><span class="line">  </span><br><span class="line">                <span class="comment">//在tcp_recvmsg里，copied就是已经拷贝的字节数  </span></span><br><span class="line">        <span class="keyword">if</span> (copied) &#123;  </span><br><span class="line">            ... ...  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">                        <span class="comment">//一个字节都没拷贝到，但如果shutdown关闭了socket，一样直接返回。当然，本文不涉及关闭连接  </span></span><br><span class="line">            <span class="keyword">if</span> (sk-&gt;sk_shutdown &amp; RCV_SHUTDOWN)  </span><br><span class="line">                <span class="keyword">break</span>;  </span><br><span class="line">  </span><br><span class="line">            <span class="comment">//如果使用了非阻塞套接字，此时timeo为0  </span></span><br><span class="line">            <span class="keyword">if</span> (!timeo) &#123;  </span><br><span class="line">                                <span class="comment">//非阻塞套接字读取不到数据时也会返回，错误码正是EAGAIN  </span></span><br><span class="line">                copied = -EAGAIN;  </span><br><span class="line">                <span class="keyword">break</span>;  </span><br><span class="line">            &#125;  </span><br><span class="line">                        ... ...  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//tcp_low_latency默认是关闭的，图1、图2都是如此，图3则例外，即图3不会走进这个if  </span></span><br><span class="line">        <span class="keyword">if</span> (!sysctl_tcp_low_latency &amp;&amp; tp-&gt;ucopy.task == user_recv) &#123;  </span><br><span class="line">            <span class="comment">//prequeue队列就是为了提高系统整体效率的，即prequeue队列有可能不为空，这是因为进程休眠等待时可能有新报文到达prequeue队列  </span></span><br><span class="line">            <span class="keyword">if</span> (!skb_queue_empty(&amp;tp-&gt;ucopy.prequeue))  </span><br><span class="line">                <span class="keyword">goto</span> do_prequeue;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//如果已经拷贝了的字节数超过了最低阀值  </span></span><br><span class="line">        <span class="keyword">if</span> (copied &gt;= target) &#123;  </span><br><span class="line">            <span class="comment">//release_sock这个方法会遍历、处理backlog队列中的报文  </span></span><br><span class="line">            release_sock(sk);  </span><br><span class="line">            lock_sock(sk);  </span><br><span class="line">        &#125; <span class="keyword">else</span>  </span><br><span class="line">            sk_wait_data(sk, &amp;timeo);<span class="comment">//没有读取到足够长度的消息，因此会进程休眠，如果没有被唤醒，最长睡眠timeo时间  </span></span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> (user_recv) &#123;  </span><br><span class="line">            <span class="keyword">if</span> (tp-&gt;rcv_nxt == tp-&gt;copied_seq &amp;&amp;  </span><br><span class="line">                !skb_queue_empty(&amp;tp-&gt;ucopy.prequeue)) &#123;  </span><br><span class="line">do_prequeue:  </span><br><span class="line">                                <span class="comment">//接上面代码段，开始处理prequeue队列里的报文  </span></span><br><span class="line">                tcp_prequeue_process(sk);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//继续处理receive队列的下一个报文  </span></span><br><span class="line">        <span class="keyword">continue</span>;  </span><br><span class="line">  </span><br><span class="line">    found_ok_skb:  </span><br><span class="line">        <span class="comment">/* Ok so how much can we use? */</span>  </span><br><span class="line">        <span class="comment">//receive队列的这个报文从其可以使用的偏移量offset，到总长度len之间，可以拷贝的长度为used  </span></span><br><span class="line">        used = skb-&gt;len - offset;  </span><br><span class="line">        <span class="comment">//len是用户态空闲内存，len更小时，当然只能拷贝len长度消息，总不能导致内存溢出吧  </span></span><br><span class="line">        <span class="keyword">if</span> (len &lt; used)  </span><br><span class="line">            used = len;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//MSG_TRUNC标志位表示不要管len这个用户态内存有多大，只管拷贝数据吧  </span></span><br><span class="line">        <span class="keyword">if</span> (!(flags &amp; MSG_TRUNC)) &#123;  </span><br><span class="line">            &#123;  </span><br><span class="line">                <span class="comment">//向用户态拷贝数据  </span></span><br><span class="line">                err = skb_copy_datagram_iovec(skb, offset,  </span><br><span class="line">                        msg-&gt;msg_iov, used);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//因为是指针，所以同时更新copied_seq--下一个待接收的序号  </span></span><br><span class="line">        *seq += used;  </span><br><span class="line">        <span class="comment">//更新已经拷贝的长度  </span></span><br><span class="line">        copied += used;  </span><br><span class="line">        <span class="comment">//更新用户态内存的剩余空闲空间长度  </span></span><br><span class="line">        len -= used;  </span><br><span class="line">  </span><br><span class="line">                ... ...  </span><br><span class="line">    &#125; <span class="keyword">while</span> (len &gt; <span class="number">0</span>);  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//已经装载了接收器  </span></span><br><span class="line">    <span class="keyword">if</span> (user_recv) &#123;  </span><br><span class="line">        <span class="comment">//prequeue队列不为空则处理之  </span></span><br><span class="line">        <span class="keyword">if</span> (!skb_queue_empty(&amp;tp-&gt;ucopy.prequeue)) &#123;  </span><br><span class="line">            tcp_prequeue_process(sk);  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//准备返回用户态，socket上不再装载接收任务  </span></span><br><span class="line">        tp-&gt;ucopy.task = <span class="literal">NULL</span>;  </span><br><span class="line">        tp-&gt;ucopy.len = <span class="number">0</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//释放socket时，还会检查、处理backlog队列中的报文  </span></span><br><span class="line">    release_sock(sk);  </span><br><span class="line">    <span class="comment">//向用户返回已经拷贝的字节数  </span></span><br><span class="line">    <span class="keyword">return</span> copied;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>图2给出了第2种场景，这里涉及到prequeue队列。用户进程调用recv方法时，连接上没有任何接收并缓存到内核的报文，而socket是阻塞的，所以进程睡眠了。然后网卡中收到了TCP连接上的报文，此时prequeue队列开始产生作用。图2中tcp_low_latency为默认的0，套接字socket的SO_RCVLOWAT是默认的1，仍然是阻塞socket，如下图：</p>
<p><a href="/2016/01/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-2/"><img src="/2016/01/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-2.jpg"></a></p>
<p>简单描述上述11个步骤：</p>
<p>1、用户进程分配了一块len大小的内存，将其传入recv这样的函数，同时socket参数皆为默认，即阻塞的、SO_RCVLOWAT为1。调用接收方法，其中flags参数为0。</p>
<p>2、C库和内核最终调用到tcp_recvmsg方法来处理。</p>
<p>3、锁住socket。</p>
<p>4、由于此时receive、prequeue、backlog队列都是空的，即没有拷贝1个字节的消息到用户内存中，而我们的最低要求是拷贝至少SO_RCVLOWAT为1长度的消息。此时，开始进入阻塞式套接字的等待流程。最长等待时间为SO_RCVTIMEO指定的时间。</p>
<p>这个等待函数叫做sk_wait_data，有必要看下其实现：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sk_wait_data</span><span class="params">(struct sock *sk, <span class="keyword">long</span> *timeo)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">        <span class="comment">//注意，它的自动唤醒条件有两个，要么timeo时间到达，要么receive队列不为空  </span></span><br><span class="line">    rc = sk_wait_event(sk, timeo, !skb_queue_empty(&amp;sk-&gt;sk_receive_queue));  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>sk_wait_event也值得我们简单看下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> sk_wait_event(__sk, __timeo, __condition)       \  </span></span><br><span class="line">(&#123;  <span class="keyword">int</span> rc;                         \  </span><br><span class="line">    release_sock(__sk);                 \  </span><br><span class="line">    rc = __condition;                   \  </span><br><span class="line">    <span class="keyword">if</span> (!rc) &#123;                      \  </span><br><span class="line">        *(__timeo) = schedule_timeout(*(__timeo));  \  </span><br><span class="line">    &#125;                           \  </span><br><span class="line">    lock_sock(__sk);                    \  </span><br><span class="line">    rc = __condition;                   \  </span><br><span class="line">    rc;                         \  </span><br><span class="line">&#125;)  </span><br></pre></td></tr></table></figure>

<p>注意，它在睡眠前会调用release_sock，这个方法会释放socket锁，使得下面的第5步中，新到的报文不再只能进入backlog队列。</p>
<p>5、这个套接字上期望接收的序号也是S1，此时网卡恰好收到了S1-S2的报文，在tcp_v4_rcv方法中，通过调用tcp_prequeue方法把报文插入到prequeue队列中。</p>
<p>6、插入prequeue队列后，此时会接着调用wake_up_interruptible方法，唤醒在socket上睡眠的进程。参见tcp_prequque方法。</p>
<p>7、用户进程被唤醒后，重新调用lock_sock接管了这个socket，此后再进来的报文都只能进入backlog队列了。</p>
<p>8、进程醒来后，先去检查receive队列，当然仍然是空的；再去检查prequeue队列，发现有一个报文S1-S2，正好是socket连接待拷贝的起始序号S1，于是，从prequeue队列中取出这个报文并把内容复制到用户内存中，再释放内核中的这个报文。</p>
<p>9、目前已经拷贝了S2-S1个字节到用户态，检查这个长度是否超过了最低阀值（即len和SO_RCVLOWAT的最小值）。</p>
<p>10、由于SO_RCVLOWAT使用了默认的1，所以准备返回用户。此时会顺带再看看backlog队列中有没有数据，若有，则检查这个无序的队列中是否有可以直接拷贝给用户的报文。当然，此时是没有的。所以准备返回，释放socket锁。</p>
<p>11、返回用户已经拷贝的字节数。</p>
<p>图3给出了第3种场景。这个场景中，我们把系统参数tcp_low_latency设为1，socket上设置了SO_RCVLOWAT属性的值。服务器先是收到了S1-S2这个报文，但S2-S1的长度是小于SO_RCVLOWAT的，用户进程调用recv方法读套接字时，虽然读到了一些，但没有达到最小阀值，所以进程睡眠了，与此同时，在睡眠前收到的乱序的S3-S4包直接进入backlog队列。此时先到达了S2-S3包，由于没有使用prequeue队列，而它起始序号正是下一个待拷贝的值，所以直接拷贝到用户内存中，总共拷贝字节数已满足SO_RCVLOWAT的要求！最后在返回用户前把backlog队列中S3-S4报文也拷贝给用户了。如下图：</p>
<p><a href="/2016/01/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-3/"><img src="/2016/01/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-3.jpg"></a></p>
<p>简明描述上述15个步骤：</p>
<p>1、内核收到报文S1-S2，S1正是这个socket连接上待接收的序号，因此，直接将它插入有序的receive队列中。</p>
<p>2、用户进程所处的linux操作系统上，将sysctl中的tcp_low_latency设置为1。这意味着，这台服务器希望TCP进程能够更及时的接收到TCP消息。用户调用了recv方法接收socket上的消息，这个socket上设置了SO_RCVLOWAT属性为某个值n，这个n是大于S2-S1，也就是第1步收到的报文大小。这里，仍然是阻塞socket，用户依然是分配了足够大的len长度内存以接收TCP消息。</p>
<p>3、通过tcp_recvmsg方法来完成接收工作。先锁住socket，避免并发进程读取同一socket的同时，也在告诉内核网络软中断处理到这一socket时要有不同行为，如第6步。</p>
<p>4、准备处理内核各个接收队列中的报文。</p>
<p>5、receive队列中的有序报文可直接拷贝，在检查到S2-S1是小于len之后，将报文内容拷贝到用户态内存中。</p>
<p>6、在第5步进行的同时，socket是被锁住的，这时内核又收到了一个S3-S4报文，因此报文直接进入backlog队列。注意，这个报文不是有序的，因为此时连接上期待接收序号为S2。</p>
<p>7、在第5步，拷贝了S2-S1个字节到用户内存，它是小于SO_RCVLOWAT的，因此，由于socket是阻塞型套接字（超时时间在本文中忽略），进程将不得不转入睡眠。转入睡眠之前，还会干一件事，就是处理backlog队列里的报文，图2的第4步介绍过休眠方法sk_wait_data，它在睡眠前会执行release_sock方法，看看是如何实现的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> fastcall <span class="title">release_sock</span><span class="params">(struct sock *sk)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    mutex_release(&amp;sk-&gt;sk_lock.dep_map, <span class="number">1</span>, _RET_IP_);  </span><br><span class="line">  </span><br><span class="line">    spin_lock_bh(&amp;sk-&gt;sk_lock.slock);  </span><br><span class="line">        <span class="comment">//这里会遍历backlog队列中的每一个报文  </span></span><br><span class="line">    <span class="keyword">if</span> (sk-&gt;sk_backlog.tail)  </span><br><span class="line">        __release_sock(sk);  </span><br><span class="line">        <span class="comment">//这里是网络中断执行时，告诉内核，现在socket并不在进程上下文中  </span></span><br><span class="line">    sk-&gt;sk_lock.owner = <span class="literal">NULL</span>;  </span><br><span class="line">    <span class="keyword">if</span> (waitqueue_active(&amp;sk-&gt;sk_lock.wq))  </span><br><span class="line">        wake_up(&amp;sk-&gt;sk_lock.wq);  </span><br><span class="line">    spin_unlock_bh(&amp;sk-&gt;sk_lock.slock);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>再看看__release_sock方法是如何遍历backlog队列的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> __release_sock(struct sock *sk)  </span><br><span class="line">&#123;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span> *<span class="title">skb</span> =</span> sk-&gt;sk_backlog.head;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//遍历backlog队列  </span></span><br><span class="line">    <span class="keyword">do</span> &#123;  </span><br><span class="line">        sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = <span class="literal">NULL</span>;  </span><br><span class="line">        bh_unlock_sock(sk);  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">do</span> &#123;  </span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span> *<span class="title">next</span> =</span> skb-&gt;next;  </span><br><span class="line">  </span><br><span class="line">            skb-&gt;next = <span class="literal">NULL</span>;  </span><br><span class="line">                        <span class="comment">//处理报文，其实就是tcp_v4_do_rcv方法，上文介绍过，不再赘述  </span></span><br><span class="line">            sk-&gt;sk_backlog_rcv(sk, skb);  </span><br><span class="line">  </span><br><span class="line">            cond_resched_softirq();  </span><br><span class="line">  </span><br><span class="line">            skb = next;  </span><br><span class="line">        &#125; <span class="keyword">while</span> (skb != <span class="literal">NULL</span>);  </span><br><span class="line">  </span><br><span class="line">        bh_lock_sock(sk);  </span><br><span class="line">    &#125; <span class="keyword">while</span>((skb = sk-&gt;sk_backlog.head) != <span class="literal">NULL</span>);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>此时遍历到S3-S4报文，但因为它是失序的，所以从backlog队列中移入out_of_order队列中（参见上文说过的tcp_ofo_queue方法）。</p>
<p>8、进程休眠，直到超时或者receive队列不为空。</p>
<p>9、内核接收到了S2-S3报文。注意，这里由于打开了tcp_low_latency标志位，这个报文是不会进入prequeue队列以待进程上下文处理的。</p>
<p>10、此时，由于S2是连接上正要接收的序号，同时，有一个用户进程正在休眠等待接收数据中，且它要等待的数据起始序号正是S2，于是，这种种条件下，使得这一步同时也是网络软中断执行上下文中，把S2-S3报文直接拷贝进用户内存。</p>
<p>11、上文介绍tcp_data_queue方法时大家可以看到，每处理完1个有序报文（无论是拷贝到receive队列还是直接复制到用户内存）后都会检查out_of_order队列，看看是否有报文可以处理。那么，S3-S4报文恰好是待处理的，于是拷贝进用户内存。然后唤醒用户进程。</p>
<p>12、用户进程被唤醒了，当然唤醒后会先来拿到socket锁。以下执行又在进程上下文中了。</p>
<p>13、此时会检查已拷贝的字节数是否大于SO_RCVLOWAT，以及backlog队列是否为空。两者皆满足，准备返回。</p>
<p>14、释放socket锁，退出tcp_recvmsg方法。</p>
<p>15、返回用户已经复制的字节数S4-S1。</p>
<p>好了，这3个场景读完，想必大家对于TCP的接收流程是怎样的已经非常清楚了，本文起始的6个问题也在这一大篇中都涉及到了。下一篇我们来讨论TCP连接的关闭。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>linux</tag>
        <tag>SO_RCVLOWAT</tag>
        <tag>SO_RCVTIMEO</tag>
        <tag>tcp_low_latency</tag>
        <tag>阻塞</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程7--tcp连接的内存使用</title>
    <url>/2016/01/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B7-tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>当服务器的并发TCP连接数以十万计时，我们就会对一个TCP连接在操作系统内核上消耗的内存多少感兴趣。socket编程方法提供了SO_SNDBUF、SO_RCVBUF这样的接口来设置连接的读写缓存，linux上还提供了以下系统级的配置来整体设置服务器上的TCP内存使用，但这些配置看名字却有些互相冲突、概念模糊的感觉，如下（sysctl -a命令可以查看这些配置）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_rmem &#x3D; 8192 87380 16777216  </span><br><span class="line">net.ipv4.tcp_wmem &#x3D; 8192 65536 16777216  </span><br><span class="line">net.ipv4.tcp_mem &#x3D; 8388608 12582912 16777216  </span><br><span class="line">net.core.rmem_default &#x3D; 262144  </span><br><span class="line">net.core.wmem_default &#x3D; 262144  </span><br><span class="line">net.core.rmem_max &#x3D; 16777216  </span><br><span class="line">net.core.wmem_max &#x3D; 16777216  </span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>还有一些较少被提及的、也跟TCP内存相关的配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_moderate_rcvbuf &#x3D; 1  </span><br><span class="line">net.ipv4.tcp_adv_win_scale &#x3D; 2  </span><br></pre></td></tr></table></figure>

<p>（注：为方便下文讲述，介绍以上系统配置时前缀省略掉，配置值以空格分隔的多个数字以数组来称呼，例如tcp_rmem[2]表示上面第一行最后一列16777216。）</p>
<p>网上可以找到很多这些系统配置项的说明，然而往往还是让人费解，例如，tcp_rmem[2]和rmem_max似乎都跟接收缓存最大值有关，但它们却可以不一致，究竟有什么区别？或者tcp_wmem[1]和wmem_default似乎都表示发送缓存的默认值，冲突了怎么办？在用抓包软件抓到的syn握手包里，为什么TCP接收窗口大小似乎与这些配置完全没关系？</p>
<p>TCP连接在进程中使用的内存大小千变万化，通常程序较复杂时可能不是直接基于socket编程，这时平台级的组件可能就封装了TCP连接使用到的用户态内存。不同的平台、组件、中间件、网络库都大不相同。而内核态为TCP连接分配内存的算法则是基本不变的，这篇文章将试图说明TCP连接在内核态中会使用多少内存，操作系统使用怎样的策略来平衡宏观的吞吐量与微观的某个连接传输速度。这篇文章也将一如既往的面向应用程序开发者，而不是系统级的内核开发者，所以，不会详细的介绍为了一个TCP连接、一个TCP报文操作系统分配了多少字节的内存，内核级的数据结构也不是本文的关注点，这些也不是应用级程序员的关注点。这篇文章主要描述linux内核为了TCP连接上传输的数据是怎样管理读写缓存的。</p>
<p>一、缓存上限是什么？</p>
<p>（1）先从应用程序编程时可以设置的SO_SNDBUF、SO_RCVBUF说起。</p>
<p>无论何种语言，都对TCP连接提供基于setsockopt方法实现的SO_SNDBUF、SO_RCVBUF，怎么理解这两个属性的意义呢？</p>
<p>SO_SNDBUF、SO_RCVBUF都是个体化的设置，即，只会影响到设置过的连接，而不会对其他连接生效。SO_SNDBUF表示这个连接上的内核写缓存上限。实际上，进程设置的SO_SNDBUF也并不是真的上限，在内核中会把这个值翻一倍再作为写缓存上限使用，我们不需要纠结这种细节，只需要知道，当设置了SO_SNDBUF时，就相当于划定了所操作的TCP连接上的写缓存能够使用的最大内存。然而，这个值也不是可以由着进程随意设置的，它会受制于系统级的上下限，当它大于上面的系统配置wmem_max（net.core.wmem_max）时，将会被wmem_max替代（同样翻一倍）；而当它特别小时，例如在2.6.18内核中设计的写缓存最小值为2K字节，此时也会被直接替代为2K。</p>
<p>SO_RCVBUF表示连接上的读缓存上限，与SO_SNDBUF类似，它也受制于rmem_max配置项，实际在内核中也是2倍大小作为读缓存的使用上限。SO_RCVBUF设置时也有下限，同样在2.6.18内核中若这个值小于256字节就会被256所替代。</p>
<p>（2）那么，可以设置的SO_SNDBUF、SO_RCVBUF缓存使用上限与实际内存到底有怎样的关系呢？</p>
<p>TCP连接所用内存主要由读写缓存决定，而读写缓存的大小只与实际使用场景有关，在实际使用未达到上限时，SO_SNDBUF、SO_RCVBUF是不起任何作用的。对读缓存来说，接收到一个来自连接对端的TCP报文时，会导致读缓存增加，当然，如果加上报文大小后读缓存已经超过了读缓存上限，那么这个报文会被丢弃从而读缓存大小维持不变。什么时候读缓存使用的内存会减少呢？当进程调用read、recv这样的方法读取TCP流时，读缓存就会减少。因此，读缓存是一个动态变化的、实际用到多少才分配多少的缓冲内存，当这个连接非常空闲时，且用户进程已经把连接上接收到的数据都消费了，那么读缓存使用内存就是0。</p>
<p>写缓存也是同样道理。当用户进程调用send或者write这样的方法发送TCP流时，就会造成写缓存增大。当然，如果写缓存已经到达上限，那么写缓存维持不变，向用户进程返回失败。而每当接收到TCP连接对端发来的ACK确认了报文的成功发送时，写缓存就会减少，这是因为TCP的可靠性决定的，发出去报文后由于担心报文丢失而不会销毁它，可能会由重发定时器来重发报文。因此，写缓存也是动态变化的，空闲的正常连接上，写缓存所用内存通常也为0。</p>
<p>因此，只有当接收网络报文的速度大于应用程序读取报文的速度时，可能使读缓存达到了上限，这时这个缓存使用上限才会起作用。所起作用为：丢弃掉新收到的报文，防止这个TCP连接消耗太多的服务器资源。同样，当应用程序发送报文的速度大于接收对方确认ACK报文的速度时，写缓存可能达到上限，从而使send这样的方法失败，内核不为其分配内存。</p>
<p>二、缓存的大小与TCP的滑动窗口到底有什么关系？</p>
<p>（1）滑动窗口的大小与缓存大小肯定是有关的，但却不是一一对应的关系，更不会与缓存上限具有一一对应的关系。因此，网上很多资料介绍rmem_max等配置设置了滑动窗口的最大值，与我们tcpdump抓包时看到的win窗口值完全不一致，是讲得通的。下面我们来细探其分别在哪里。</p>
<p>读缓存的作用有2个：1、将无序的、落在接收滑动窗口内的TCP报文缓存起来；2、当有序的、可以供应用程序读取的报文出现时，由于应用程序的读取是延时的，所以会把待应用程序读取的报文也保存在读缓存中。所以，读缓存一分为二，一部分缓存无序报文，一部分缓存待延时读取的有序报文。这两部分缓存大小之和由于受制于同一个上限值，所以它们是会互相影响的，当应用程序读取速率过慢时，这块过大的应用缓存将会影响到套接字缓存，使接收滑动窗口缩小，从而通知连接的对端降低发送速度，避免无谓的网络传输。当应用程序长时间不读取数据，造成应用缓存将套接字缓存挤压到没空间，那么连接对端会收到接收窗口为0的通知，告诉对方：我现在消化不了更多的报文了。</p>
<p>反之，接收滑动窗口也是一直在变化的，我们用tcpdump抓三次握手的报文：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">14:49:52.421674 IP houyi-vm02.dev.sd.aliyun.com.6400 &gt; r14a02001.dg.tbsite.net.54073: S 2736789705:2736789705(0) ack 1609024383 win 5792 &lt;mss 1460,sackOK,timestamp 2925954240 2940689794,nop,wscale 9&gt;  </span><br></pre></td></tr></table></figure>

<p>可以看到初始的接收窗口是5792，当然也远小于最大接收缓存（稍后介绍的tcp_rmem[1]）。</p>
<p>这当然是有原因的，TCP协议需要考虑复杂的网络环境，所以使用了慢启动、拥塞窗口（参见<a href="http://blog.csdn.net/russell_tao/article/details/9370109">高性能网络编程2—-TCP消息的发送</a>），建立连接时的初始窗口并不会按照接收缓存的最大值来初始化。这是因为，过大的初始窗口从宏观角度，对整个网络可能造成过载引发恶性循环，也就是考虑到链路上各环节的诸多路由器、交换机可能扛不住压力不断的丢包（特别是广域网），而微观的TCP连接的双方却只按照自己的读缓存上限作为接收窗口，这样双方的发送窗口（对方的接收窗口）越大就对网络产生越坏的影响。慢启动就是使初始窗口尽量的小，随着接收到对方的有效报文，确认了网络的有效传输能力后，才开始增大接收窗口。</p>
<p>不同的linux内核有着不同的初始窗口，我们以广为使用的linux2.6.18内核为例，在以太网里，MSS大小为1460，此时初始窗口大小为4倍的MSS，简单列下代码（*rcv_wnd即初始接收窗口）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> init_cwnd = <span class="number">4</span>;  </span><br><span class="line"><span class="keyword">if</span> (mss &gt; <span class="number">1460</span>*<span class="number">3</span>)  </span><br><span class="line"> init_cwnd = <span class="number">2</span>;  </span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (mss &gt; <span class="number">1460</span>)  </span><br><span class="line"> init_cwnd = <span class="number">3</span>;  </span><br><span class="line"><span class="keyword">if</span> (*rcv_wnd &gt; init_cwnd*mss)  </span><br><span class="line"> *rcv_wnd = init_cwnd*mss;  </span><br></pre></td></tr></table></figure>

<p>大家可能要问，为何上面的抓包上显示窗口其实是5792，并不是1460*4为5840呢？这是因为1460想表达的意义是：将1500字节的MTU去除了20字节的IP头、20字节的TCP头以后，一个最大报文能够承载的有效数据长度。但有些网络中，会在TCP的可选头部里，使用12字节作为时间戳使用，这样，有效数据就是MSS再减去12，初始窗口就是（1460-12）*4=5792，这与窗口想表达的含义是一致的，即：我能够处理的有效数据长度。</p>
<p>在linux3以后的版本中，初始窗口调整到了10个MSS大小，这主要来自于GOOGLE的建议。原因是这样的，接收窗口虽然常以指数方式来快速增加窗口大小（拥塞阀值以下是指数增长的，阀值以上进入拥塞避免阶段则为线性增长，而且，拥塞阀值自身在收到128以上数据报文时也有机会快速增加），若是传输视频这样的大数据，那么随着窗口增加到（接近）最大读缓存后，就会“开足马力”传输数据，但若是通常都是几十KB的网页，那么过小的初始窗口还没有增加到合适的窗口时，连接就结束了。这样相比较大的初始窗口，就使得用户需要更多的时间（RTT）才能传输完数据，体验不好。</p>
<p>那么这时大家可能有疑问，当窗口从初始窗口一路扩张到最大接收窗口时，最大接收窗口就是最大读缓存吗？</p>
<p>不是，因为必须分一部分缓存用于应用程序的延时报文读取。到底会分多少出来呢？这是可配的系统选项，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_adv_win_scale &#x3D; 2  </span><br></pre></td></tr></table></figure>

<p>这里的tcp_adv_win_scale意味着，将要拿出1/(2^tcp_adv_win_scale)缓存出来做应用缓存。即，默认tcp_adv_win_scale配置为2时，就是拿出至少1/4的内存用于应用读缓存，那么，最大的接收滑动窗口的大小只能到达读缓存的3/4。</p>
<p>（2）最大读缓存到底应该设置到多少为合适呢？</p>
<p>当应用缓存所占的份额通过tcp_adv_win_scale配置确定后，读缓存的上限应当由最大的TCP接收窗口决定。初始窗口可能只有4个或者10个MSS，但在无丢包情形下随着报文的交互窗口就会增大，当窗口过大时，“过大”是什么意思呢？即，对于通讯的两台机器的内存而言不算大，但是对于整个网络负载来说过大了，就会对网络设备引发恶性循环，不断的因为繁忙的网络设备造成丢包。而窗口过小时，就无法充分的利用网络资源。所以，一般会以BDP来设置最大接收窗口（可计算出最大读缓存）。BDP叫做带宽时延积，也就是带宽与网络时延的乘积，例如若我们的带宽为2Gbps，时延为10ms，那么带宽时延积BDP则为2G/8*0.01=2.5MB，所以这样的网络中可以设最大接收窗口为2.5MB，这样最大读缓存可以设为4/3*2.5MB=3.3MB。</p>
<p>为什么呢？因为BDP就表示了网络承载能力，最大接收窗口就表示了网络承载能力内可以不经确认发出的报文。如下图所示：</p>
<p><img src="/2017/01/BGP-1.jpg"></p>
<p> 经常提及的所谓长肥网络，“长”就是是时延长，“肥”就是带宽大，这两者任何一个大时，BDP就大，都应导致最大窗口增大，进而导致读缓存上限增大。所以在长肥网络中的服务器，缓存上限都是比较大的。（当然，TCP原始的16位长度的数字表示窗口虽然有上限，但在RFC1323中定义的弹性滑动窗口使得滑动窗口可以扩展到足够大。）</p>
<p>发送窗口实际上就是TCP连接对方的接收窗口，所以大家可以按接收窗口来推断，这里不再啰嗦。</p>
<p>三、linux的TCP缓存上限自动调整策略</p>
<p>那么，设置好最大缓存限制后就高枕无忧了吗？对于一个TCP连接来说，可能已经充分利用网络资源，使用大窗口、大缓存来保持高速传输了。比如在长肥网络中，缓存上限可能会被设置为几十兆字节，但系统的总内存却是有限的，当每一个连接都全速飞奔使用到最大窗口时，1万个连接就会占用内存到几百G了，这就限制了高并发场景的使用，公平性也得不到保证。我们希望的场景是，在并发连接比较少时，把缓存限制放大一些，让每一个TCP连接开足马力工作；当并发连接很多时，此时系统内存资源不足，那么就把缓存限制缩小一些，使每一个TCP连接的缓存尽量的小一些，以容纳更多的连接。</p>
<p>linux为了实现这种场景，引入了自动调整内存分配的功能，由tcp_moderate_rcvbuf配置决定，如下：</p>
<p>net.ipv4.tcp_moderate_rcvbuf = 1</p>
<p>默认tcp_moderate_rcvbuf配置为1，表示打开了TCP内存自动调整功能。若配置为0，这个功能将不会生效（慎用）。</p>
<p>另外请注意：当我们在编程中对连接设置了SO_SNDBUF、SO_RCVBUF，将会使linux内核不再对这样的连接执行自动调整功能！</p>
<p>那么，这个功能到底是怎样起作用的呢？看以下配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_rmem &#x3D; 8192 87380 16777216  </span><br><span class="line">net.ipv4.tcp_wmem &#x3D; 8192 65536 16777216  </span><br><span class="line">net.ipv4.tcp_mem &#x3D; 8388608 12582912 16777216  </span><br></pre></td></tr></table></figure>

<p>tcp_rmem[3]数组表示任何一个TCP连接上的读缓存上限，其中tcp_rmem[0]表示最小上限，tcp_rmem[1]表示初始上限（注意，它会覆盖适用于所有协议的rmem_default配置），tcp_rmem[2]表示最大上限。</p>
<p>tcp_wmem[3]数组表示写缓存，与tcp_rmem[3]类似，不再赘述。</p>
<p>tcp_mem[3]数组就用来设定TCP内存的整体使用状况，所以它的值很大（它的单位也不是字节，而是页–4K或者8K等这样的单位！）。这3个值定义了TCP整体内存的无压力值、压力模式开启阀值、最大使用值。以这3个值为标记点则内存共有4种情况：</p>
<p>1、当TCP整体内存小于tcp_mem[0]时，表示系统内存总体无压力。若之前内存曾经超过了tcp_mem[1]使系统进入内存压力模式，那么此时也会把压力模式关闭。</p>
<p>这种情况下，只要TCP连接使用的缓存没有达到上限（注意，虽然初始上限是tcp_rmem[1]，但这个值是可变的，下文会详述），那么新内存的分配一定是成功的。</p>
<p>2、当TCP内存在tcp_mem[0]与tcp_mem[1]之间时，系统可能处于内存压力模式，例如总内存刚从tcp_mem[1]之上下来；也可能是在非压力模式下，例如总内存刚从tcp_mem[0]以下上来。</p>
<p>此时，无论是否在压力模式下，只要TCP连接所用缓存未超过tcp_rmem[0]或者tcp_wmem[0]，那么都一定都能成功分配新内存。否则，基本上就会面临分配失败的状况。（注意：还有一些例外场景允许分配内存成功，由于对于我们理解这几个配置项意义不大，故略过。）</p>
<p>3、当TCP内存在tcp_mem[1]与tcp_mem[2]之间时，系统一定处于系统压力模式下。其他行为与上同。</p>
<p>4、当TCP内存在tcp_mem[2]之上时，毫无疑问，系统一定在压力模式下，而且此时所有的新TCP缓存分配都会失败。</p>
<p>下图为需要新缓存时内核的简化逻辑：</p>
<p><img src="/2017/01/tcpmemory-1-1.jpg"></p>
<p><img src="file:///C:/Users/hui.taoh/AppData/Local/YNote/Data/iamtaohui%40126.com/b85c6327387d42eea2f188924cd51024/clipboard.png"></p>
<p>当系统在非压力模式下，上面我所说的每个连接的读写缓存上限，才有可能增加，当然最大也不会超过tcp_rmem[2]或者tcp_wmem[2]。相反，在压力模式下，读写缓存上限则有可能减少，虽然上限可能会小于tcp_rmem[0]或者tcp_wmem[0]。</p>
<p>所以，粗略的总结下，对这3个数组可以这么看：</p>
<p>1、只要系统TCP的总体内存超了 tcp_mem[2] ，新内存分配都会失败。</p>
<p>2、tcp_rmem[0]或者tcp_wmem[0]优先级也很高，只要条件1不超限，那么只要连接内存小于这两个值，就保证新内存分配一定成功。</p>
<p>3、只要总体内存不超过tcp_mem[0]，那么新内存在不超过连接缓存的上限时也能保证分配成功。</p>
<p>4、tcp_mem[1]与tcp_mem[0]构成了开启、关闭内存压力模式的开关。在压力模式下，连接缓存上限可能会减少。在非压力模式下，连接缓存上限可能会增加，最多增加到tcp_rmem[2]或者tcp_wmem[2]。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>BDP</tag>
        <tag>tcp_rmem</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程6--reactor反应堆与定时器管理</title>
    <url>/2016/01/27/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6-reactor%E5%8F%8D%E5%BA%94%E5%A0%86%E4%B8%8E%E5%AE%9A%E6%97%B6%E5%99%A8%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>反应堆开发模型被绝大多数高性能服务器所选择，上一篇所介绍的IO多路复用是它的实现基础。定时触发功能通常是服务器必备组件，反应堆模型往往还不得不将定时器的管理囊括在内。本篇将介绍反应堆模型的特点和用法。</p>
<p>首先我们要谈谈，网络编程界为什么需要反应堆？有了IO复用，有了epoll，我们已经可以使服务器并发几十万连接的同时，维持高TPS了，难道这还不够吗？</p>
<p>我的答案是，技术层面足够了，但在软件工程层面却是不够的。</p>
<span id="more"></span>
<p>程序使用IO复用的难点在哪里呢？1个请求虽然由多次IO处理完成，但相比传统的单线程完整处理请求生命期的方法，IO复用在人的大脑思维中并不自然，因为，程序员编程中，处理请求A的时候，假定A请求必须经过多个IO操作A1-An（两次IO间可能间隔很长时间），每经过一次IO操作，再调用IO复用时，IO复用的调用返回里，非常可能不再有A，而是返回了请求B。即请求A会经常被请求B打断，处理请求B时，又被C打断。这种思维下，编程容易出错。</p>
<p>形象的说，传统编程方法就好像是到了银行营业厅里，每个窗口前排了长队，业务员们在窗口后一个个的解决客户们的请求。一个业务员可以尽情思考着客户A依次提出的问题，例如：</p>
<p>“我要买2万XX理财产品。“</p>
<p>“看清楚了，5万起售。”</p>
<p>“等等，查下我活期余额。”</p>
<p>“余额5万。”</p>
<p>“那就买 5万吧。”</p>
<p>业务员开始录入信息。</p>
<p>”对了，XX理财产品年利率8%？”</p>
<p>“是预期8%，最低无利息保本。“</p>
<p>”早不说，拜拜，我去买余额宝。“</p>
<p>业务员无表情的删着已经录入的信息进行事务回滚。</p>
<p>”下一个！“</p>
<p>用了IO复用则是大师业务员开始挑战极限，在超大营业厅里给客户们人手一个牌子，黑压压的客户们都在大厅中，有问题时举牌申请提问，大师目光敏锐点名指定某人提问，该客户迅速得到大师的答复后，要经过一段时间思考，查查自己的银袋子，咨询下LD，才能再次进行下一个提问，直到得到完整的满意答复退出大厅。例如：大师刚指导A填写转帐单的某一项，B又来申请兑换泰铢，给了B兑换单后，C又来办理定转活，然后D与F在争抢有限的圆珠笔时出现了不和谐现象，被大师叫停业务，暂时等待。</p>
<p>这就是基于事件驱动的IO复用编程比起传统1线程1请求的方式来，有难度的设计点了，客户们都是上帝，既不能出错，还不能厚此薄彼。</p>
<p>当没有反应堆时，我们可能的设计方法是这样的：大师把每个客户的提问都记录下来，当客户A提问时，首先查阅A之前问过什么做过什么，这叫联系上下文，然后再根据上下文和当前提问查阅有关的银行规章制度，有针对性的回答A，并把回答也记录下来。当圆满回答了A的所有问题后，删除A的所有记录。</p>
<p>回到码农生涯，即，某一瞬间，服务器共有10万个并发连接，此时，一次IO复用接口的调用返回了100个活跃的连接等待处理。先根据这100个连接找出其对应的对象，这并不难，epoll的返回连接数据结构里就有这样的指针可以用。接着，循环的处理每一个连接，找出这个对象此刻的上下文状态，再使用read、write这样的网络IO获取此次的操作内容，结合上下文状态查询此时应当选择哪个业务方法处理，调用相应方法完成操作后，若请求结束，则删除对象及其上下文。</p>
<p>这样，我们就陷入了面向过程编程方法之中了，在面向应用、快速响应为王的移动互联网时代，这样做早晚得把自己玩死。我们的主程序需要关注各种不同类型的请求，在不同状态下，对于不同的请求命令选择不同的业务处理方法。这会导致随着请求类型的增加，请求状态的增加，请求命令的增加，主程序复杂度快速膨胀，导致维护越来越困难，苦逼的程序员再也不敢轻易接新需求、重构。</p>
<p>反应堆是解决上述软件工程问题的一种途径，它也许并不优雅，开发效率上也不是最高的，但其执行效率与面向过程的使用IO复用却几乎是等价的，所以，无论是nginx、memcached、redis等等这些高性能组件的代名词，都义无反顾的一头扎进了反应堆的怀抱中。</p>
<p>反应堆模式可以在软件工程层面，将事件驱动框架分离出具体业务，将不同类型请求之间用OO的思想分离。通常，反应堆不仅使用IO复用处理网络事件驱动，还会实现定时器来处理时间事件的驱动（请求的超时处理或者定时任务的处理），就像下面的示意图：</p>
<p><img src="/2017/01/unnamed-file-1.jpg"></p>
<p> <img src="file:///C:/Users/hui.taoh/AppData/Local/YNote/Data/iamtaohui%40126.com/f93696e98c4f4ebcae7f5f6c02413dfa/clipboard.png">这幅图有5点意思：</p>
<p>（1）处理应用时基于OO思想，不同的类型的请求处理间是分离的。例如，A类型请求是用户注册请求，B类型请求是查询用户头像，那么当我们把用户头像新增多种分辨率图片时，更改B类型请求的代码处理逻辑时，完全不涉及A类型请求代码的修改。</p>
<p>（2）应用处理请求的逻辑，与事件分发框架完全分离。什么意思呢？即写应用处理时，不用去管何时调用IO复用，不用去管什么调用epoll_wait，去处理它返回的多个socket连接。应用代码中，只关心如何读取、发送socket上的数据，如何处理业务逻辑。事件分发框架有一个抽象的事件接口，所有的应用必须实现抽象的事件接口，通过这种抽象才把应用与框架进行分离。</p>
<p>（3）反应堆上提供注册、移除事件方法，供应用代码使用，而分发事件方法，通常是循环的调用而已，是否提供给应用代码调用，还是由框架简单粗暴的直接循环使用，这是框架的自由。</p>
<p>（4）IO多路复用也是一个抽象，它可以是具体的select，也可以是epoll，它们只必须提供采集到某一瞬间所有待监控连接中活跃的连接。</p>
<p>（5）定时器也是由反应堆对象使用，它必须至少提供4个方法，包括添加、删除定时器事件，这该由应用代码调用。最近超时时间是需要的，这会被反应堆对象使用，用于确认select或者epoll_wait执行时的阻塞超时时间，防止IO的等待影响了定时事件的处理。遍历也是由反应堆框架使用，用于处理定时事件。</p>
<p>下面用极简流程来形象说明下反应堆是如何处理一个请求的，下图中桔色部分皆为反应堆的分发事件流程：</p>
<p><img src="/2017/01/unnamed-file-3-1.jpg"></p>
<p> 可以看到，分发IO、定时器事件都由反应堆框架来完成，应用代码只会关注于如何处理可读、可写事件。</p>
<p>当然，上图是极度简化的流程，实际上要处理的异常情况都没有列入。</p>
<p>这里可以看到，为什么定时器集合需要提供最近超时事件距离现在的时间？因为，调用epoll_wait或者select时，并不能够始终传入-1作为timeout参数。因为，我们的服务器主营业务往往是网络请求处理，如果网络请求很少时，那么CPU的所有时间都会被频繁却又不必要的epoll_wait调用所占用。在服务器闲时使进程的CPU利用率降低是很有意义的，它可以使服务器上其他进程得到更多的执行机会，也可以延长服务器的寿命，还可以省电。这样，就需要传入准确的timeout最大阻塞时间给epoll_wait了。</p>
<p>什么样的timeout时间才是准确的呢？这等价于，我们需要准确的分析，什么样的时段进程可以真正休息，进入sleep状态？</p>
<p>一个没有意义的答案是：不需要进程执行任务的时间段内是可以休息的。</p>
<p>这就要求我们仔细想想，进程做了哪几类任务，例如：</p>
<p>1、所有网络包的处理，例如TCP连接的建立、读写、关闭，基本上所有的正常请求都由网络包来驱动的。对这类任务而言，没有新的网络分组到达本机时，就是可以使进程休息的时段。</p>
<p>2、定时器的管理，它与网络、IO复用无关，虽然它们在业务上可能有相关性。定时器里的事件需要及时的触发执行，不能因为其他原因，例如阻塞在epoll_wait上时耽误了定时事件的处理。当一段时间内，可以预判没有定时事件达到触发条件时（这也是提供接口查询最近一个定时事件距当下的时间的意义所在），对定时任务的管理而言，进程就可以休息了。</p>
<p>3、其他类型的任务，例如磁盘IO执行完成，或者收到其他进程的signal信号，等等，这些任务明显不需要执行的时间段内，进程可以休息。</p>
<p>于是，使用反应堆模型的进程代码中，通常除了epoll_wait这样的IO复用外，其他调用都会基于无阻塞的方式使用。所以，epoll_wait的timeout超时时间，就是除网络外，其他任务所能允许的进程睡眠时间。而只考虑常见的定时器任务时，就像上图中那样，只需要定时器集合能够提供最近超时事件到现在的时间即可。</p>
<p>从这里也可以推导出，定时器集合通常会采用有序容器这样的数据结构，好处是：</p>
<p>1、容易取到最近超时事件的时间。</p>
<p>2、可以从最近超时事件开始，向后依次遍历已经超时的事件，直到第一个没有超时的事件为止即可停止遍历，不用全部遍历到。</p>
<p>因此，粗暴的采用无序的数据结构，例如普通的链表，通常是不足取的。但事无绝对，redis就是用了个毫无顺序的链表，原因何在？因为redis的客户端连接没有超时概念，所以对于并发的成千上万个连上，都不会因为超时被断开。redis的定时器唯一的用途在于定时的将内存数据刷到磁盘上，这样的定时事件通常只有个位数，其性能无关紧要。</p>
<p>如果定时事件非常多，综合插入、遍历、删除的使用频率，使用树的机会最多，例如小根堆（libevent）、二叉平衡树（nginx红黑树）。当然，场景特殊时，尽可以用有序数组、跳跃表等等实现。</p>
<p>综上所述，反应堆模型开发效率上比起直接使用IO复用要高，它通常是单线程的，设计目标是希望单线程使用一颗CPU的全部资源，但也有附带优点，即每个事件处理中很多时候可以不考虑共享资源的互斥访问。可是缺点也是明显的，现在的硬件发展，已经不再遵循摩尔定律，CPU的频率受制于材料的限制不再有大的提升，而改为是从核数的增加上提升能力，当程序需要使用多核资源时，反应堆模型就会悲剧，为何呢？</p>
<p>如果程序业务很简单，例如只是简单的访问一些提供了并发访问的服务，就可以直接开启多个反应堆，每个反应堆对应一颗CPU核心，这些反应堆上跑的请求互不相关，这是完全可以利用多核的。例如Nginx这样的http静态服务器。</p>
<p>如果程序比较复杂，例如一块内存数据的处理希望由多核共同完成，这样反应堆模型就很难做到了，需要昂贵的代价，引入许多复杂的机制。所以，大家就可以理解像redis、nodejs这样的服务，为什么只能是单线程，为什么memcached简单些的服务确可以是多线程。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>reactor</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能网络编程（一）----accept建立连接</title>
    <url>/2016/01/25/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89-accept%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5/</url>
    <content><![CDATA[<p>最近在部门内做了个高性能网络编程的培训，近日整理了下PPT，欲写成一系列文章从应用角度谈谈它。</p>
<p>编写服务器时，许多程序员习惯于使用高层次的组件、中间件（例如OO（面向对象）层层封装过的开源组件），相比于服务器的运行效率而言，他们更关注程序开发的效率，追求更快的完成项目功能点、希望应用代码完全不关心通讯细节。他们更喜欢在OO世界里，去实现某个接口、实现这个组件预定义的各种模式、设置组件参数来达到目的。学习复杂的通讯框架、底层细节，在习惯于使用OO语言的程序员眼里是绝对事倍功半的。以上做法无可厚非，但有一定的局限性，本文讲述的网络编程头前冠以“高性能”，它是指程序员设计编写的服务器需要处理很大的吞吐量，这与简单网络应用就有了质的不同。因为：</p>
<span id="more"></span>
<p>1、高吞吐量下，容易触发到一些设计上的边界条件；</p>
<p>2、偶然性的小概率事件，会在高吞吐量下变成必然性事件。</p>
<p>3、IO是慢速的，高吞吐量通常意味着高并发，如同一时刻存在数以万计、十万计、百万计的TCP活动连接。</p>
<p>所以，做高性能网络编程不能仅仅满足于学会开源组件、中间件是如何帮我实现期望功能的，对于企业级产品来说，需要了解更多的知识。</p>
<p>掌握高性能网络编程，涉及到对网络、操作系统协议栈、进程与线程、常见的网络组件等知识点，需要有丰富的项目开发经验，能够权衡服务器运行效率与项目开发效率。以下图来谈谈我个人对高性能网络编程的理解。</p>
<p><img src="/2016/01/unnamed-file-2.jpg"></p>
<p>上面这张图中，由上至下有以下特点：</p>
<ul>
<li>  •关注点，逐渐由特定业务向通用技术转移</li>
<li>  •使用场景上，由专业领域向通用领域转移</li>
<li>  •灵活性上要求越来越高</li>
<li>  •性能要求越来越高</li>
<li>  •对细节、原理的掌握，要求越来越高</li>
<li>  •对各种异常情况的处理，要求越来越高</li>
<li>  •稳定性越来越高，bug率越来越少</li>
</ul>
<p>在做应用层的网络编程时，若服务器吞吐量大，则应该适度了解以上各层的关注点。</p>
<p>如上图红色文字所示，我认为编写高性能服务器的关注点有3个：</p>
<p>1、如果基于通用组件编程，关注点多是在组件如何封装套接字编程细节。为了使应用程序不感知套接字层，这些组件往往是通过各种回调机制来向应用层代码提供网络服务，通常，出于为应用层提供更高的开发效率，组件都大量使用了线程（Nginx等是个例外），当然，使用了线程后往往可以降低代码复杂度。但多线程引入的并发解决机制还是需要重点关注的，特别是锁的使用。另外，使用多线程意味着把应用层的代码复杂度扔给了操作系统，大吞吐量时，需要关注多线程给操作系统内核带来的性能损耗。</p>
<p>基于通用组件编程，为了程序的高性能运行，需要清楚的了解组件的以下特性：怎么使用IO多路复用或者异步IO的？怎么实现并发性的？怎么组织线程模型的？怎么处理高吞吐量引发的异常情况的？</p>
<p>2、通用组件只是在封装套接字，操作系统是通过提供套接字来为进程提供网络通讯能力的。所以，不了解套接字编程，往往对组件的性能就没有原理上的认识。学习套接字层的编程是有必要的，或许很少会自己从头去写，但操作系统的API提供方式经久不变，一经学会，受用终身，同时在项目的架构设计时，选用何种网络组件就非常准确了。</p>
<p>学习套接字编程，关注点主要在：套接字的编程方法有哪些？阻塞套接字的各方法是如何阻塞住当前代码段的？非阻塞套接字上的方法如何不阻塞当前代码段的？IO多路复用机制是怎样与套接字结合的？异步IO是如何实现的？网络协议的各种异常情况、操作系统的各种异常情况是怎么通过套接字传递给应用性程序的？</p>
<p>3、网络的复杂性会影响到服务器的吞吐量，而且，高吞吐量场景下，多种临界条件会导致应用程序的不正常，特别是组件中有bug或考虑不周或没有配置正确时。了解网络分组可以定位出这些问题，可以正确的配置系统、组件，可以正确的理解系统的瓶颈。</p>
<p>这里的关注点主要在：TCP、UDP、IP协议的特点？linux等操作系统如何处理这些协议的？使用tcpdump等抓包工具分析各网络分组。</p>
<p>一般掌握以上3点，就可以挥洒自如的实现高性能网络服务器了。</p>
<p>下面具体谈谈如何做到高性能网络编程。</p>
<p>众所周知，IO是计算机上最慢的部分，先不看磁盘IO，针对网络编程，自然是针对网络IO。网络协议对网络IO影响很大，当下，TCP/IP协议是毫无疑问的主流协议，本文就主要以TCP协议为例来说明网络IO。</p>
<p>网络IO中应用服务器往往聚焦于以下几个由网络IO组成的功能中：A）与客户端建立起TCP连接。B）读取客户端的请求流。C）向客户端发送响应流。D）关闭TCP连接。E）向其他服务器发起TCP连接。</p>
<p>要掌握住这5个功能，不仅仅需要熟悉一些API的使用，更要理解底层网络如何与上层API之间互相发生影响。同时，还需要对不同的场景下，如何权衡开发效率、进程、线程与这些API的组合使用。下面依次来说说这些网络IO。</p>
<p>1、与客户端建立起TCP连接</p>
<p>谈这个功能前，先来看看网络、协议、应用服务器间的关系：</p>
<p><img src="/2016/01/unnamed-file-1-1.jpg"></p>
<p>上图中可知：</p>
<p>为简化不同场景下的编程，TCP/IP协议族划分了应用层、TCP传输层、IP网络层、链路层等，每一层只专注于少量功能。</p>
<p>例如，IP层只专注于每一个网络分组如何到达目的主机，而不管目的主机如何处理。</p>
<p>传输层最基本的功能是专注于端到端，也就是一台主机上的进程发出的包，如何到达目的主机上的某个进程。当然，TCP层为了可靠性，还额外需要解决3个大问题：丢包（网络分组在传输中存在的丢失）、重复（协议层异常引发的多个相同网络分组）、延迟（很久后网络分组才到达目的地）。</p>
<p>链路层则只关心以太网或其他二层网络内网络包的传输。</p>
<p>回到应用层，往往只需要调用类似于accept的API就可以建立TCP连接。建立连接的流程大家都了解–三次握手，它如何与accept交互呢？下面以一个不太精确却通俗易懂的图来说明之：</p>
<p><img src="/2017/01/accept%E9%98%9F%E5%88%97-1-1-1.jpg"><img src="/2017/01/clipboard-2.png"></p>
<p>研究过backlog含义的朋友都很容易理解上图。这两个队列是内核实现的，当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接，当图中1.1步骤客户端的SYN包到达了服务器后，内核会把这一信息放到SYN队列（即未完成握手队列）中，同时回一个SYN+ACK包给客户端。一段时间后，在较中2.1步骤中客户端再次发来了针对服务器SYN包的ACK网络分组时，内核会把连接从SYN队列中取出，再把这个连接放到ACCEPT队列（即已完成握手队列）中。而服务器在第3步调用accept时，其实就是直接从ACCEPT队列中取出已经建立成功的连接套接字而已。</p>
<p>现有我们可以来讨论应用层组件：为何有的应用服务器进程中，会单独使用1个线程，只调用accept方法来建立连接，例如tomcat；有的应用服务器进程中，却用1个线程做所有的事，包括accept获取新连接。</p>
<p>原因在于：首先，SYN队列和ACCEPT队列都不是无限长度的，它们的长度限制与调用listen监听某个地址端口时传递的backlog参数有关。既然队列长度是一个值，那么，队列会满吗？当然会，如果上图中第1步执行的速度大于第2步执行的速度，SYN队列就会不断增大直到队列满；如果第2步执行的速度远大于第3步执行的速度，ACCEPT队列同样会达到上限。第1、2步不是应用程序可控的，但第3步却是应用程序的行为，假设进程中调用accept获取新连接的代码段长期得不到执行，例如获取不到锁、IO阻塞等。</p>
<p>那么，这两个队列满了后，新的请求到达了又将发生什么？</p>
<p>若SYN队列满，则会直接丢弃请求，即新的SYN网络分组会被丢弃；如果ACCEPT队列满，则不会导致放弃连接，也不会把连接从SYN列队中移出，这会加剧SYN队列的增长。所以，对应用服务器来说，如果ACCEPT队列中有已经建立好的TCP连接，却没有及时的把它取出来，这样，一旦导致两个队列满了后，就会使客户端不能再建立新连接，引发严重问题。</p>
<p>所以，如TOMCAT等服务器会使用独立的线程，只做accept获取连接这一件事，以防止不能及时的去accept获取连接。</p>
<p>那么，为什么如Nginx等一些服务器，在一个线程内做accept的同时，还会做其他IO等操作呢？</p>
<p>这里就带出阻塞和非阻塞的概念。应用程序可以把listen时设置的套接字设为非阻塞模式（默认为阻塞模式），这两种模式会导致accept方法有不同的行为。对阻塞套接字，accept行为如下图：</p>
<p><img src="/2016/01/accept-2.jpg"><img src="/2017/01/clipboard-3.png"></p>
<p>这幅图中可以看到，阻塞套接字上使用accept，第一个阶段是等待ACCEPT队列不为空的阶段，它耗时不定，由客户端是否向自己发起了TCP请求而定，可能会耗时很长。</p>
<p>对非阻塞套接字，accept会有两种返回，如下图：</p>
<p><img src="/2016/01/accept-1-1.jpg"><img src="/2017/01/clipboard-4.png"></p>
<p>非阻塞套接字上的accept，不存在等待ACCEPT队列不为空的阶段，它要么返回成功并拿到建立好的连接，要么返回失败。</p>
<p>所以，企业级的服务器进程中，若某一线程既使用accept获取新连接，又继续在这个连接上读、写字符流，那么，这个连接对应的套接字通常要设为非阻塞。原因如上图，调用accept时不会长期占用所属线程的CPU时间片，使得线程能够及时的做其他工作。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>tcp</tag>
        <tag>协议栈</tag>
      </tags>
  </entry>
</search>
